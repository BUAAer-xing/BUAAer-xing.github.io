
[pdf](zotero://open-pdf/library/items/SINB87MA)

## 0-Abstract

稀疏矩阵乘法(SpGEMM)在许多科学和深度学习应用中得到了广泛的应用。SpGEMM 的高度不规则结构限制了其在传统计算平台上的性能和效率，从而激发了大量的专业硬件设计。**现有的 SpGEMM 加速器只支持特定类型的刚性执行数据流，如inner/output-product或基于行的方案**。每个数据流仅针对某些稀疏模式进行了优化，并且未能在不同领域中对不同的 SpGEMM 工作负载进行性能推广。

我们提出了 Spada，它结合了 SpGEMM 加速器的三种新技术，可以<font color='red'><b>有效地适应各种稀疏模式</b></font>。

- 首先，我们描述了一个**基于窗口的自适应数据流**，它可以灵活地适应不同的模式，以最好地匹配数据分布，实现不同的重用效益（<font color='red'><b>新的数据流模式</b></font>）。
- 然后，我们的**硬件体系结构**有效地支持该数据流模板，具有灵活、快速、低成本的可重构性和有效的负载平衡特性（<font color='red'><b>硬件结构</b></font>）。
- 最后，基于邻近矩阵区域的稀疏模式相似性的关键观测值，采用分析引导的方法对稀疏模式进行检测，并**确定优化后的数据流模式**（<font color='red'><b>选择最优的数据流模式</b></font>）。

我们的评估结果表明，Spada 能够**匹配或超过**三种最先进的 SpGEMM 加速器中的最佳加速器，并避免了在数据分布和数据流不匹配的情况下其他加速器的性能降低。该算法在大范围的稀疏矩阵和压缩神经网络模型上实现了平均1.44倍的加速比。

## 1-Introduction

稀疏矩阵乘法（SpGEMM）是许多重要科学计算领域中的关键组成部分，包括图分析、线性代数、经济建模、分子动力学以及机器学习等。与密集矩阵计算相比，**稀疏矩阵能够有效地消除所有无效的零元素（有时还包括接近于零的元素），从而节省大量存储空间和计算成本**，特别是在矩阵规模巨大且由于实际问题中的稀疏连接性和交互作用导致密度极低的情况下。而且，随着稀疏/压缩神经网络模型和大规模图分析的兴起，对SpGEMM的高性能和高效性的需求也越来越大。

然而，实际实现这种高性能和高效率的 SpGEMM 处理是困难的，<font color='red'><b>因为高度不规则的结构，导致低利用率的计算资源和内存带宽</b></font>。随着 **Dennard scaling 结束**，特定领域的加速成为加速具有挑战性的计算任务的越来越有吸引力的方法，SpGEMM 也见证了新的架构创新，以解决通用平台的低效率问题。

---

Dennard scaling ：指的是一种观察到的现象，在半导体领域，当晶体管的尺寸不断缩小时，其功能密度可以保持不变，因为晶体管的电压和电流也相应降低。具体来说，晶体管的性能随着尺寸的缩小而提升，而功耗不会显著增加。

在HPC中，**Dennard Scaling 的终结**意味着：
1. 增加计算性能的方式不再仅依赖于更高的时钟频率。
2. 计算系统必须通过多核并行化和架构优化等方式来提升整体性能。
3. 能耗效率成为设计和部署HPC系统时的关键考虑因素，因为大规模计算系统需要在功耗受限的条件下实现更高的计算能力。

---

在这项工作中，观察到，随着 SpGEMM 应用于越来越多的应用领域，**对硬件加速器有效支持高度多样化的稀疏模式的需求也在增加**。例如:
- 真实世界的图形数据集非常稀疏，通常只有0.0001% 的非零，但可能大到$10^{13}$。
- 相比之下，神经网络的权重矩阵要小得多，通常大小在$10^4$左右; 即使在压缩了零和接近零的值之后，它们仍然相对密集，只有10% 到90% 左右的中等稀疏度。
- 即使在一个领域或一个数据集内，不同的矩阵或矩阵的不同子区域在非零密度和分布中也不断地表现出各种稀疏模式。

**不幸的是，现有的 SpGEMM 加速器大多被设计成只有当数据处于特定的稀疏范围之内时才能有效地执行，只有在这些稀疏范围内才能最好地利用了它们的底层硬件架构。其核心原因是，这些加速器中的每一个都只使用固定的执行数据流，该数据流优化输入或输出数据重用，但牺牲了其他数据流。因此，如果工作负载不能很好地适应这种严格的设计假设，性能将受到影响。**

因此，本文提出Spada，这是硬件和软件创新的组合，可高效加速在各种稀疏模式下运行的SpGEMM应用程序。首先，我们全面研究了现有的SpGEMM数据流方案之间的权衡，包括内积、外积和基于行的。

---

![[SpGEMM中的数据流（三种计算方式）]]

---

然后我们提出了<font color='red'><b>基于窗口的自适应数据流</b></font>（WA）。WA支持一系列执行模式，它**可以灵活适应不同的数据稀疏模式，以实现在不同数据稀疏模式下每个单独数据流的输入和输出重用优势**。

其次，提出了 <font color='red'><b>Spada 硬件体系结构</b></font>，该体系结构支持 WA 作为数据流模板，当使用不同的 WA 配置时，可以灵活快速地重新配置为不同的执行模式。该体系结构使用专门设计的乘法处理元素，每个元素包含多个通道，可以动态划分为独立的合并组，以最小的硬件开销产生单独的输出部分和结果。支持灵活的 WA 方案的关键是**通过专门的<font color='red'><b>硬件组件</b></font>对这些车道组进行有效和快速的重新配置**，以进行分类和减少。我们还在每个车道组内使用动态负载平衡来减少空闲周期。此外，该体系结构使用专用的比较树和累加器进一步合并部分和结果，以及一个全局缓存与一个优化的 LRU 替换策略，以提高数据在 WA 数据流中的重用。

第三，提出了一种有效而简单的<font color='red'><b>窗口形状自适应算法</b></font>，并在硬件 Spada 调度器中实现，检测特定工作负载的稀疏模式，**动态确定最佳的 WA 模式**。关键的见解是稀疏模式在矩阵的局部区域内保持相似，并且复杂模式与非零值的行长度有很强的相关性。因此，我们设计了一种分析引导的方法，**使用前一行的性能结果来确定未来行的优化配置**，这是非常有效的，并且只有很小的硬件成本。

📒：提出了三部分idea：统一的数据流、为适应数据流设计的硬件结构、为数据流设计的最佳模式选择算法。

对Spada与三种最先进的SpGEMM加速器SIGMA（如第6节中优化）、SpArch 和GAMMA 进行评估，涵盖了各种稀疏矩阵和具有不同稀疏模式的压缩神经网络模型。实验结果观察到，Spada在拥有相同数量乘法器资源的情况下，能够成功实现与三个基准中的最佳性能相当甚至更好的表现，平均加速比为38.04×、1.44×和1.46×分别超过了SIGMA、SpArch和GAMMA。进一步考虑面积成本可将效率提高至分别为SpArch和GAMMA的3.32×和1.42×。当数据分布倾向于某种数据流方案时，Spada能够快速适应相应模式，并匹配专门为该数据流进行优化的基准性能，同时避免其他设计的显著退化。


## 2-Background and Motivations

稀疏矩阵通常被编码成特定的格式，最常用的两种格式是压缩稀疏行(CSR)和压缩稀疏列(CSC)。CSR 格式使用压缩编码对每行中的非零元素逐行存储矩阵。它保留三个数组，分别包含每行开头的偏移量(偏移量)、非零值(变量组)和它们的列索引(列)。CSC 与 CSR 类似，只是它按列对矩阵进行编码。CSR 适合于行-主遍历，而 CSC 更适合于列-主遍历。

### 2.1-多种稀疏格式

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410051730880.png" width="500"></img></div>

稀疏矩阵通常用于对来自各种领域的许多现实问题进行建模。**这些域的不同的固有字符特性导致了稀疏模式的急剧变化，包括矩阵大小和矩阵中非零的密度和分布**。为了研究它们的稀疏模式，我们使用来自SuiteSparse集合的真实稀疏矩阵，并从ResNet50生成压缩神经网络（NN）权矩阵。图1a显示，这些稀疏矩阵（例如）具有截然不同的大小和密度，跨度可达7个数量级。神经网络压缩技术通常生成相对较小的矩阵（$10^4$），具有中等稀疏度（10%至90%）。相比之下，现实世界的图结构，如社交网络，具有更大（$10^{13}$）和高度稀疏（1%到0.0001%）的矩阵。此外，如图1b所示，跨域甚至在一个域中，由于各种连通性和局部性行为，非零分布可能存在显著差异，这意味着完全不同的稀疏模式。

### 2.2-面向 SpGEMM 的硬件数据流

类似于大量关于密集矩阵/张量计算的数据流方案，SpGEMM 也有多种可能的数据流选择，这些选择在不同的稀疏模式下会显著影响性能和效率。之前提出的 SpGEMM 数据流方案主要分为三类：**内积法**（InP）、**外积法**（OutP）和**行基法**（ROW）。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410051622615.png" width="100%"></img></div>

实质上，<font color='red'><b>如果使用循环变换来分析，这三种数据流方案分别对应三种不同的循环顺序，其中化简维度 k 分别位于最内层、最外层和中间层</b></font>。


这些数据流方案在多个方面存在差异：
- 首先，它们对编码格式的要求不同：
	- InP 要求矩阵 A 使用压缩稀疏行（CSR）格式，矩阵 B 使用压缩稀疏列（CSC）格式；
	- OutP 则要求 A 使用 CSC，B 使用 CSR；
	- 而 ROW 要求两个操作数矩阵都使用 CSR，并且生成的输出矩阵也使用 CSR。这使得 ROW 更受青睐，因为它可以在输入和输出矩阵格式上保持一致，便于多个 SpGEMM 操作的连续执行。
- 其次，当片上缓存容量不足以轻松存储所有数据时，这三种数据流方案会表现出不同的数据重用行为。例如，假设矩阵 A 总是按行（维度 m）在 InP 和 ROW 中流式处理，或者在 OutP 中按列（维度 k）流式处理。
	- InP 中，C 可以实现完全重用，因为每个元素的部分和（psum）会立即被累积，但 B 的每一列需要为每一行 A 多次重新读取，导致重用性较差。
	- 相比之下，OutP 只需读取 B 的每一行一次，与相应的 A 列匹配。但如果 C 的部分和无法全部放入片上缓存中，则必须将其写入片外存储器并在稍后重新读取进行累积，这会带来大量的存储器传输开销。
	- 最后，ROW 每次只生成和存储少量的部分和，这些部分和对应于单个输出行，易于保留在片上缓存中，并实现类似于 InP 的 C 的良好重用。然而，B 的各行是**根据 A 每行的非零分布不规则地获取的**（B 的行索引 k 需要与 A 元素的列索引匹配），导致重用性较低。
- 第三，OutP 和 ROW 在输入矩阵之间的索引匹配上具有更高效的优势。
	- 在 InP 中，获取完整的 `A[𝑚, :]` 和 `B[:, 𝑛]` 数组后，只有具有匹配的 k 索引的非零元素才能为 `C[𝑚, 𝑛] `生成部分和（psum）。当矩阵非常稀疏时，这些有效的匹配远小于整个数组的大小，导致大量的数据获取是无用的。
	- 相反，OutP 获取的是已经匹配的 `A[:, 𝑘]` 和 `B[𝑘, :]`，ROW 获取的是已经匹配的 `A[𝑚, 𝑘]` 和 `B[𝑘, :]`，这些数据都已匹配并包含有效的输入对。
此外，这三种方案在生成部分和的粒度上也有所不同，这会影响到映射到硬件时的循环阻塞和并行化处理。

### 2.3-设计动机

由于不同的应用中使用的稀疏矩阵具有非常多样的模式，并且不同的数据流选择会表现出各种权衡，**没有一种单一的数据流在所有情况下都能胜过其他方案**。例如，在 OutP 中，稀疏模式会影响生成的部分和（psum）矩阵的大小，因此优化输出数据的重用至关重要。而在 ROW 中，稀疏模式（如非零元素的分布）也会影响 A 的相邻行之间列索引的重叠程度，在这种情况下，如果两个非零元素 `A[𝑚, 𝑘]` 和 `A[𝑚′ , 𝑘]` 具有相同的列索引，它们将重用相同的输入行` B[𝑘, :]`。

因此，硬件 SpGEMM 加速器要有效地支持不同领域的所有稀疏矩阵，就必须能够<font color='red'><b>利用工作负载稀疏模式，相应地调整执行数据流</b></font>。为了实现这一目标，我们确定了三个关键的设计挑战。
- 首先，我们需要设计一个<font color='red'><b>自适应的数据流</b></font>，当处理具有不同稀疏模式的输入矩阵时，它可以**很容易地调整到不同的模式**。它的不同模式应该涵盖投入和产出重用权衡的足够大空间。
- 其次，我们需要一个<font color='red'><b>有效和灵活的可重构架构</b></font>，以最小的**硬件开销支持这种自适应数据流和快速切换其模式**。
- 第三，我们还需要一个<font color='red'><b>有效和简单的运行时算法</b></font>来检测特定工作负载的稀疏模式，然后**动态地确定使用哪种模式**。


## 3-Window-Based Adaptive Dataflow

本文首先提出一种基于窗口的自适应数据流(WA) ，**可以调整到不同的模式来利用输入矩阵的局部稀疏模式**。WA 简化了硬件架构设计(第4节) ，同时仍然允许在不同模式之间进行灵活的适应(第5节)。

一个好的自适应数据流应该满足两个相互冲突的目标。
- 一方面，它应该是**灵活的**，以涵盖不同的重用特征，这样我们就有了丰富的适应空间。
- 另一方面，最好**让不同的模式共享相似的执行行为**，这样我们就可以保持硬件重构的简单和廉价。

这意味着试图直接组合InP、OutP和ROW的朴素设计不太可能很好地工作，因为它们具有完全不同的执行行为。例如，InP分别按行和列遍历A和B，而OutP的情况正好相反。

本文采取了不同的方法，它不是精确地模拟所有数据流方案的执行行为，而是只<font color='red'><b>旨在捕捉在不同的稀疏模式上数据重用的主要优势</b></font>。

首先，从“ROW”开始，因为在以前的研究中已经证明它的整体数据重用在许多情况下都比其他方法更好。它的主要缺点是**访问矩阵B的局部性不佳，其行索引由A的随机分布的非零元素的列索引确定**。然后，利用<font color='red'><b>循环阻塞技术</b></font>，来解决这个问题，这是提高密集线性代数中数据重用的有效方法。

从图2可以看出，OutP 在矩阵 B 上具有最佳的输入重用。关键区别在于如何遍历矩阵 A：在 ROW 中使用循环嵌套顺序 m-k-n 逐行遍历，而在 OutP 中使用 k-m-n 逐列遍历。因此，我们<font color='red'><b>使用 mo-ko-ki-mi-n 的循环嵌套顺序对外部两个维度进行分块</b></font>。通过调整块的大小，可以灵活适应分别优化输入和输出重用的模式。**实际上，如果将 mi 和 ki 设置为 1，就会简化为 ROW；如果将 mo 和 ko 设置为 1，就会简化为 OutP**。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410052244525.png" width="500"></img></div>

算法1形式化了这种窗口自适应（WA）数据流。实际上，内部两个维度 mi 和 ki 形成了 A 上的一个二维窗口。当映射到硬件时，会在并行处理单元上空间展开这个窗口。


#### WA 执行流程

**WA 每次提取一个小的二维窗口作为基本执行单元，并计算该窗口与相应的 B 行的乘积**。这与 ROW 不同，后者每次仅提取 A 的一个元素。**窗口直接基于压缩稀疏行（CSR 格式）定义**，而不是基于密集格式，因此不包含行内的零值或全零行。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410052309352.png" width="500"></img></div>

如图 3 所示，从 A 中提取一个 $2 \times 2$ 的窗口，包含四个非零元素，分别是 $a_{0,2}, a_{0,3}, a_{1,0}, a_{1,2}$。这些元素通过**四个标量-向量乘法并行处理**，与相应的 B 行 $b_2, b_3, b_0, b_2$ 相乘。

注意，$a_{0,2}$ 和 $a_{1,2}$ 重用了相同的 B 行 $b_2$。

窗口宽度维度（$k$）上的乘积合并为 C 行的一个部分和（psum），例如，$a_{0,2} \times b_2 + a_{0,3} \times b_3 = c_0^{(0)}$，并累加到 $c_0$。本质上，A 的每行 $\beta$ 个非零元素与其列索引匹配的 B 行相乘，然后合并为 C 行的一个部分和，这会生成 $\alpha$ 个部分和行。

与 ROW 类似，窗口本身首先沿着维度 $k$ 移动（不是滑动，而是**步长等于其宽度**）。我们将一个 pass 定义为窗口沿着 $k$ 方向移动当前 A 的行，然后下一个 pass 开始沿着 $m$ 维度向下移动。

为了适应数据稀疏模式，WA 允许在**开始新 pass**时**改变窗口形状**。一个 pass 包含多个窗口，每个窗口生成 $\alpha$ 个部分和行。这些部分和行需要合并为 C 的最终 $\alpha$ 个输出行，例如，所有 $c_0^{(t)}$ 合并为 $c_0$，而所有 $c_1^{(t)}$ 合并为 $c_1$，如图 3 底部所示。每个 $c_m$ 的合并过程是相互独立的，作为独立的归约树运行。

WA 以**内存友好**的方式获取所有三个矩阵，而不需要随机访问。在矩阵 A 上，WA 在窗口移动时同时获取 α 压缩行。所有的非零都被充分利用了。给定一个小的缓冲区空间，每行也可以预取相对较大的块，例如，8行的几百个字节。B 和 C 的访问模式与 ROW 中的相同，其中为 A 中的每个非零元素提取一个完整的压缩 B 行，并依次生成一个 psum 行。（矩阵A、B、C都是CSR存储格式？？？）

#### WA优势

首先，使用包含多个 A 元素的窗口，而不是像 ROW 中每次只使用一个元素，自然可以匹配底层硬件提供的并行性。在第 4 节中，我们将窗口大小 $\alpha \times \beta$ 设置为等于处理单元中乘法器的数量。

其次，更重要的是，通过调整 $\alpha \times \beta$ 的窗口形状，可以有效地实现不同模式，并获得各种数据重用的好处。具体来说，设置 $\alpha = 1$（沿 A 的 $k$ 方向遍历）可以实现高输出重用，因为较大的窗口宽度 $\beta$ 允许 C 的多个部分和行立即合并为一个，类似于 ROW 的行为。另一方面，设置 $\beta = 1$（使用 A 的一列）可能会实现更好的 B 的输入重用。这是因为较大的窗口高度 $\alpha$ 能够在同一列但不同行的多个 A 元素之间提供更多 B 行的重用机会（例如，$a_{0,2}$ 和 $a_{1,2}$ 重用了相同的 B 行 $b_2$）。此外，在这两个极端之间，WA 还启用了更多的模式，**通过不同的 $\alpha$ 和 $\beta$ 值，在输入和输出重用之间取得更平衡的权衡，展现出潜在的更好性能**。

最后，WA 继承了 ROW 的许多优势，例如**在所有矩阵中保持一致的 CSR 格式、适中的部分和生成粒度，以及避免了 InP 中无效的索引匹配**。实际上，通过将 ROW 作为许多模式之一，WA 至少能够匹配 ROW，并且在输入重用更为关键时，假设硬件支持自适应的开销较低，并有精确的策略选择模式，WA 甚至有可能超越 ROW。


## 4-Spada Hardware Architecture

在拥有自适应数据流 WA 之后，本文接下来<font color='red'><b>设计了 SpGEMM 加速器 Spada 的硬件架构</b></font>。与实现多个独立的数据流方案不同，Spada 将 WA 作为数据流模板，并允许在不同模式之间进行高效、灵活且快速的重配置，以最大限度地利用不同稀疏模式下的数据重用机会。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241005235549.png)

上图显示了 Spada 的架构概览。Spada 由多个乘法和加法处理单元（MPEs 和 APEs）、调度器以及位于片外内存之前的全局缓存组成。
- 每个 MPE 执行 WA 窗口中 A 元素和 B 行之间的多个**标量-向量乘法**，并在窗口内进行**第一级部分和（psum）归约**（称为乘法任务；见第 4.1 节）。
- APE 进一步完成**窗口间的归约**，以生成最终的输出行（称为合并任务；见第 4.2 节）。这一划分在图 3 底部进行了说明。
- 调度器跟踪两类 PE 的任务执行情况（第 4.3 节），并为每个新的 WA pass 自适应调整窗口形状（第 5 节）。
- 全局缓存使用改进的替换策略来存储和重用 B 和 C 的数据（第4.4节），而 A 则仅从内存中流式传输。

### 4.1-MPEs上的乘法任务

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410060052521.png" width="100%"></img></div>

Spada 加速器包含多个 MPE，每个 MPE 有若干个乘法器通道。每个 MPE 的通道数量与支持的 WA 窗口大小相匹配，在本文的设计中 $\alpha \times \beta = 8$。图 4 的底部部分展示了 MPE 的内部组件。每个通道都有一个乘法器、一个 B 行获取器（B fetcher）和一个 P 队列。每对通道使用一个排序数组（sort array）进行负载均衡。所有通道都连接到最终的 Bitonic 网络和一个灵活的归约树。

每个 MPE 被分配一个 **multiply task** 来执行，该任务对应于 WA 的一个窗口。该乘法任务的执行步骤如下：
1. 从 A 中加载一个 $\alpha \times \beta$ 的窗口，并将每个 $a_{m,k}$ 放入每个通道的乘法器中，同时放入其配对的通道用于负载均衡。
2. 每个通道的 B 获取器（B fetcher）使用其 $a_{m,k}$ 的列索引，从全局缓存中获取相应的 B 行 $b_k$，并依次将非零元素输入乘法器。
3. 通过**标量-向量乘法并行执行乘法操作**，每个通道处理 $a_{m,k}$ 和行 $b_k$。每对通道的排序数组动态平衡它们的进度，允许两个乘法器暂时处理落后通道的负载（稍后讨论）。**P 队列用于在合并前缓冲生成的乘积，从而进一步容忍通道之间进度不匹配的情况**。
4. 将乘积合并为 C 的 $\alpha$ 个部分和行。这样的合并在每 $\beta$ 个通道间独立进行，因此我们将每 $\beta$ 个通道称为一个 **group**，而一个 MPE 中有 $\alpha$ 个组。根据窗口形状，通道组可以动态重配置，以灵活支持不同的 WA 模式。这通过 Bitonic 网络和归约树实现。组大小 $\beta$ 可以是 1 到所有通道之间的任何 2 的幂。
5. 最后，部分和行被写回全局缓存，随后由 APE 进一步合并（参见第 4.2 节）。

---

**Bitonic 网络**是一种用于<font color='red'><b>并行排序算法</b></font>中的交换网络，通常用于高性能计算（HPC）系统中的并行排序问题。它是基于“bitonic序列”的概念设计的，bitonic序列是指一个序列先单调递增后单调递减，或者通过旋转使其成为先单调递增后单调递减。<font color='red'><b>Bitonic 网络的核心思想是在多处理器环境下对数据进行逐步比较和交换，从而最终实现全局排序</b></font>。它的并行性使其在高性能计算中非常高效，尤其是在处理大量数据时。

**Bitonic 网络的主要特点：**
1. **并行性**：Bitonic 网络通过多个处理器并行执行比较和交换操作，从而大大加速了排序过程。
2. **递归结构**：Bitonic 网络基于递归的排序过程，在每一层次上将序列分割为更小的子序列，最终得到完全排序的序列。
3. **分布式比较与交换**：在每一阶段，比较单元负责成对比较元素，并根据排序规则交换它们的位置，直到所有元素都排好序。
4. **拓扑结构**：<font color='red'><b>Bitonic 网络的拓扑是一种固定的比较网络，由若干比较器组成</b></font>。这使得**它可以适应硬件实现**，尤其是在FPGA、GPU等加速器上。
  
**Bitonic 网络排序的复杂度：**

在 n 个元素上进行 bitonic 排序的时间复杂度为 $O(log^2 n)$，这使得它在并行环境下具有良好的扩展性，尤其适用于那些需要高吞吐量和低延迟的大规模排序任务。

---

图 4 展示了 MPE 使用图 3 中窗口的执行示例。四个通道组成两个组，$a_{0,2}, a_{0,3}$ 分配给前两个通道，$a_{1,0}, a_{1,2}$ 分配给另外两个通道。相应的 B 行通过 B 获取器获取。这两个组分别合并为两个部分和行 $c_0^{(0)}$ 和 $c_1^{(0)}$。

**动态通道分组和组内合并**：我们注意到，每个通道都会生成一个排序的部分和行，按照列索引升序排列，并缓存在 P 队列中。同一组内来自不同通道的部分和行应被合并（并对具有相同列索引的元素进行归约）。支持 MPE 中灵活 WA 窗口形状的关键在于通道组的动态重配置。**分组不会影响标量-向量乘法，但主要改变了如何合并它们的乘积**（📒：因为进行了分块，在同一个块内的同一行的列元素才会进行合并）。我们使用专门的 P 队列、Bitonic 网络和灵活的归约树来实现这种重配置。

**P 队列**：每个通道中的 P 队列用于缓冲乘法器生成的部分和结果。它类似于一个普通的 FIFO 队列，但在输出端有以下增强功能：为了正确合并来自多个 P 队列的部分和行，必须确保任何队列的输出索引不会小于之前周期中任何队列的输出，或者等价地，<font color='red'><b>在每个周期中，所有队列（不仅仅是单个队列）中的最小索引被发送到后续阶段进行排序和合并</b></font>。例如，如果两个 P 队列的当前最小索引分别是 0 和 3，则第二个队列不能输出 3，除非它知道第一个队列中的下一个最小索引不小于 3。如果当前无法获取该索引，则第二个队列的输出必须暂停。

为确保这一要求，需要为每个 P 队列设置了一个阈值，如图 4 底部中间所示。**在每个周期中，只有队列头部的索引小于阈值的元素才能输出**。例如，在图中的当前阈值 (1, 2) 下，只有 (1, 0) 和 (1, 1) 可以输出，而 (1, 4) 无法输出。乘法器通常能够在每个周期中持续向队列中推送一个元素，但由于阈值的限制，某些周期中可能不会有输出。因此，我们设计了每个 P 队列能够在每个周期弹出最多两个元素，以弥补潜在的输出停滞。我们在第 7.4 节中通过实验证明，这种略微超量配置能够容忍大多数的停滞情况，并且在平均情况下实现匹配的吞吐量。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410062112541.png" width="500"></img></div>

每个组维护一个阈值，即同一个阈值适用于该组中的所有通道，表示该阈值小于未来所有 P 队列的输出索引。算法 2 说明了如何更新这个阈值。由于每个队列在每个周期最多可以弹出两个元素，我们**将阈值设置为每个队列的第三个索引或队列末尾元素索引中的最小值**。如果某个通道已经完成了其部分和行中的所有元素，它将不再限制组的阈值。此外，由于我们只弹出严格小于阈值的元素，因此队列在处理中途不会变空。


来自每个组所有 P 队列的输出，作为一组无序的元素，接下来被发送到 Bitonic 网络。**P 队列和 Bitonic 网络一起组成了一个两阶段的排序过程，P 队列保证不同周期之间的顺序，Bitonic 网络确保同一周期内的顺序**。由于每个 P 队列最多可以提供两个元素，因此 Bitonic 网络的输入宽度是通道数量的两倍。如图 4 底部右侧所示，**Bitonic 网络实现了硬件友好的 Bitonic 排序算法，具有对数级别的区块层次和每层的多个排序块。每个排序块对其输入进行排序，并输出有序结果**。为了适应灵活的通道分组，我们修改了原始的 Bitonic 网络，允许从任何级别获取输出。例如，如果我们想单独对两个通道的每个组进行排序，我们应该在第一个区块层次之后获取输出，并跳过其余层次。

来自 Bitonic 网络的输出已经排序，但具有相同列索引的元素尚未归约。我们最终使用了一个灵活的归约树，类似于 SIGMA 中的转发加法器网络。该归约树设计为可以任意分离其子树，以独立合并每个可变长度的子范围。在我们的案例中，这些子范围是根据列索引拆分的。如图 4 中部所示，归约树将两组排序的乘积 ${(0,0), (0,1), (0,2), (0,3)}$ 和 ${(1,0), (1,0), (1,1), (1,1)}$ 合并为 ${(0,0), (0,1), (0,2), (0,3)}$ 和 ${(1,0), (1,1)}$。子树的归约和在流水线中处理，最终生成有序的列索引结果 $c_m^{(t)}$，并写回全局缓存。


**动态负载均衡**：该设计中的一个潜在瓶颈是组内通道之间的负载不平衡。因为每个周期只能发送最小索引进行合并，如果某个通道有很多较小的索引大幅落后，其他通道就必须等待，最终导致 P 队列填满并阻塞乘法器。需要注意的是，每个通道的部分和行的列索引分布取决于其输入行 $b_k$，可能会有较大差异。

为解决此问题，Spada 的 MPE 支持**使用共享的排序数组在<font color='red'><b>每对相邻通道之间</b></font>进行动态负载均衡**。如果两个通道在同一组中，排序数组会比较每个通道的 B 获取器中接下来两个 $b_k$ 元素的列索引，并从中选择最小的两个发送到乘法器。例如，如图 4 底部左侧所示，B 获取器 2 包含 $(0,0), (0,1)$，而 B 获取器 3 包含 $(2,0), (2,1)$。具有最小列索引的两个元素，即 $ (0,0)$ 和 $ (2,0)$，将在该周期中被发送。记住，A 元素会加载到两个乘法器中，行索引用于选择使用哪个 $a_{m,k}$。

在 Spada 的 MPE 中，**排序数组仅在每两个通道之间进行重新负载均衡**，而不考虑组的大小。这是在性能和成本之间的一种权衡。每个排序数组需要 $O(n^2)$ 的资源，如果覆盖的通道数过多，数组的规模会变得过大。


**空行和不平衡行长度的影响**。A 中的任何空行都可以通过 CSR 偏移数组检测到，这些空行将被直接跳过，不会包含在 WA 窗口中，因此不会占用任何资源或引入负载不平衡。然而，如果某些压缩的 A 行在一个 pass 中比其他行短，则在 pass 的后期，窗口中的元素会减少，无法完全占用所有的乘法器通道。此外，当遇到 B 中的空行时，B 获取器不会获取任何元素，通道会立即完成其工作。在这两种情况下，**负载不平衡都可以通过排序数组缓解，该数组允许空闲的通道处理其邻近通道的工作负载**。


**重配置和任务流水线化**：MPE 通过上述灵活的通道分组机制支持不同的 WA 窗口形状 $\alpha \times \beta$。我们允许 MPE 只有在完成一个 pass 后，即完成当前 A/C 行的处理并<font color='red'><b>切换到下一行时，才重新配置为不同的窗口形状</b></font>。因此，重配置发生的频率比以前的工作要少得多。MPE 重新配置

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410062153814.png" width="500"></img></div>

例如，在图 5 中，当窗口形状从 $1 \times 4$ 更改为 $2 \times 2$ 时，组大小从 4 更新为 2（📒：这里的组大小应该指的是该窗口中，位于同一行的元素的个数，这就是组的大小。组的数目应该指的是，该窗口中的行数）。P 队列的阈值被更新以跟踪每组两个通道中的最小索引。Bitonic 网络被配置为仅在每组内进行排序，并在第二级输出。灵活的归约树也配置为仅在每组两个通道内合并。两个组的输出成为不同 C 行的两个部分和行。

在一个 pass 中的不同任务（相同的窗口形状）之间，MPE 的不同阶段有效地形成了一个流水线，因此下一个任务可以在上一个任务结束后立即开始（例如，乘法器加载 A 元素，B 获取器开始获取），而不会完全清空流水线。P 队列知道不同的任务，因此属于不同任务的乘积不会在同一周期弹出，以确保正确合并。

对于不同窗口形状的 pass 之间的连续任务，在 P 队列输出端需要额外的停顿，等待重新配置后续单元的输出端。特别是，在新 pass 中，不能让任何元素从 P 队列中弹出，直到上一 pass 的所有元素完全离开所有 P 队列为止；那些提前完成排空的通道需要停顿并等待。重配置本身也会增加一些流水线停顿周期，以改变配置位。不过，在这些停顿周期期间，B 获取器可以开始为下一任务的 B 行预取数据，并减少后续的缓存未命中。


### 4.2-APEs上的合并任务

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410060052521.png" width="100%"></img></div>
当每个 WA 窗口的部分和行在 MPE 内完全合并后，同一个 pass 中跨窗口的部分和行会在不同的周期分别写回全局缓存，之后需要进一步的合并。我们在 Spada 中使用专门的 APE（加法器处理单元）来执行这些合并任务。每个 APE 是一个轻量级单元，如图 4 左上所示，由一个基数为 $R$ 的比较器树和一个累加器组成。它将 $R$ 行部分和作为输入流入，在每个周期内输出其中列索引最小的元素。**累加器对输出中具有相同索引的元素进行归约**。如果部分和行的数量超过了 $R$，输出流则需要进一步的合并轮次，实质上形成一个合并任务的树结构。我们的实现使用 $R = 8$。

Spada 中的 MPE 和 APE 以宏流水线方式工作，由调度器协调（见第 4.3 节）。它们**通过共享的全局缓存传递部分和行**。为了平衡它们的吞吐量，我们通过提供足够数量的 APE 来匹配 MPE 的峰值吞吐量。MPE 是最昂贵的资源，因此我们希望保持它们的充分利用；而 APE 占用的面积和功耗较小，因此使用更多的 APE 只会带来轻微的开销。例如，在图 4 中，有两个 MPE，每个有四个通道，因此在最坏的情况下（组大小为 1 且每组没有发生任何归约时），它们每个周期最多生成八个部分和元素。因此，我们使用了八个 APE，每个周期每个 APE 消耗一个部分和元素。

### 4.3-调度器

Spada 的调度器包含多个组件，用于为 **MPE 和 APE 分配任务**、**跟踪任务执行状态和部分和行**，以及**收集性能信息并重新配置 WA 数据流模式**。

- <font color='red'><b>任务管理器</b></font>**负责生成新的乘法和合并任务并跟踪它们的执行状态**。
	- 对于每个 pass（即沿 $k$ 维度完全遍历窗口），Spada 使用固定的窗口形状（第 5 节确定）。任务管理器记录当前的 pass、当前的窗口形状以及窗口在此 pass 中的位置；通过移动窗口来生成新的乘法任务。此外，当部分和行足够多（例如，完全利用 APE 的基数 $R$）时，或者当一个 pass 中的所有乘法任务完成后，任务管理器会在部分和跟踪器（见下文）通知后生成新的合并任务。它还维护正在进行的任务状态，包括窗口形状、MPE/APE ID、输入矩阵行地址以及输入/输出部分和行地址。
- <font color='red'><b>部分和跟踪器</b></font>使用一个硬件表来管理所有中间的部分和行，如图 6 所示。
	- ![500](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241006223757.png)
	- 表中的每个条目对应于一个最终的输出行 $c_m$，并包含一个地址列表，用于记录应该合并到该行的部分和行 $c_m^{(t)}$。这个地址列表作为一个循环缓冲区进行管理，新的部分和行（来自乘法任务或合并任务）被推入，现有的部分和行被弹出以生成合并任务。当该 pass 中的所有乘法任务完成，并且条目中只剩下一个部分和行时，该部分和行成为最终结果。表的条目数量和每个条目的列表长度是设计参数，并且在我们的设计中是有界的。平均而言，表的条目数量应覆盖当前正在处理的所有 $c_m$ 行，这等于 MPE 的数量乘以每个 MPE 的行数（即窗口高度 $\alpha$）。地址列表需要足够长，以容纳特定输出行的所有中间部分和行。由于我们使用了足够的 APE，只要生成了 $R$ 个部分和行，就应该能很快找到一个空闲的 APE 来进行合并。对于这两个参数，我们还进一步应用了小幅度的超量配置。因此，一个包含 16 个条目、每个条目 10 个部分和行的表几乎可以避免所有停顿。
- 最后，<font color='red'><b>窗口适配器</b></font>收集运行时信息，并为每次通过确定优化的窗口形状。遵循第五部分的详细算法。

### 4.4-全局缓存和替换策略

Spada 为 B 中的输入行 $b_k$ 和 C 中的部分和行 $c_m^{(t)}$ 使用了<font color='red'><b>统一的全局缓存</b></font>。这两者都是以流式方式访问的。本文采用了 GAMMA 中的 FiberCache 设计。共享缓存相较于分开的缓存，当输入和输出重用在不同的数据流模式下有所权衡时，能够表现出更好的利用率。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241006224235.png" width="500"></img></div>
<center> <font face='华文宋体' size='4'> 图7: 全局缓存替换策略的比较。该图显示了矩阵 A 的 CSR 格式，其中数字是 A 非零的列索引，等于被乘以并缓存的 B 行的索引。全局缓存可以存储8个 B 行。当前处理行或窗口在红框中突出显示。 </font> </center>

为了更好地支持 WA，我们对缓存替换策略进行了小优化。在原始的 ROW 数据流中，简单的 LRU 策略可以有效地利用相邻行之间的稀疏模式局部性。如图 7 左上所示，之前 A 行使用的 $b_1$, $b_2$, $b_3$ 等行保留在缓存中，可以被当前行重用，而由较早的 A 行获取的那些行则被逐出。然而，对于同时处理多行 A 的 WA 模式，缓存可能不足以存储所有行。结果是，只有这些行的尾部部分可能保留在缓存中，而头部部分则被完全逐出。当当前窗口从后续行的开头开始时，只有少数 B 行可以被重用（如图 7 右上所示）。

为了提高重用，我们使用RidxLRU策略，它将全局缓存中的每个B行与使用它的最近的a行索引关联起来。在替换时，具有较小的A行索引的B行将被优先清除（图7底部）。RidxLRU在WA中有效地接近LRU在ROW中的效果，允许我们重用由前面的A行获取的更多B行。

## 5-Window Shape Adaption


如第 3 节所述，**WA 窗口的高度 $\alpha$ 决定了 B 行在多行 A 之间的输入重用，而窗口的宽度 $\beta$ 决定了输出重用中间部分和行的数量**（📒：高度越高，说明窗口中具有的行数越多，从而导致需要的传入的A的行越多，就越难得到重用。宽度越宽，说明窗口中A的列数越多，导致需要归约的数量就越多。）。在 Spada 中（见第 4 节），总的窗口大小 $\alpha \times \beta$ 固定为 MPE 中通道的数量。因此，用于确定优化窗口形状的运行时算法应适当调整 $\alpha$ 和 $\beta$ 之间的平衡，以最好地平衡输入和输出的重用。

然而，准确捕捉这些效应的分析模型几乎是不可能的。**B 行的重用高度依赖于 A 行之间的索引分布**。<font color='red'><b>如果相邻的 A 行有许多重叠的列索引，这些非零元素可以重用相同的 B 行</b></font>。但这些信息无法在不实际扫描 A 的每一行 CSR 的情况下提取，这会导致不可接受的开销。此外，即使我们能某种方式估计这种相似性，硬件上实际可实现的重用仍然取决于复杂的缓存行为以及 MPE 之间的干扰。

因此，我们的<font color='red'><b>窗口形状自适应算法设计为基于分析的方式</b></font>。其**核心思想是在局部矩阵区域内，可以通过对前几行的性能分析结果来确定后续行的优化窗口形状**。我们依赖于来自图 8 中实证研究的两个关键见解。
- 第一个见解，我们称之为**索引分布相似性**，指的是在连续行的局部区域内，相邻行之间重叠的列索引相对稳定。我们将这样的区域称为**带区**。在一个带区内，类似的索引重叠将导致类似的重用行为，因此相同的数据流优化选择适用。显然，带区作为我们的基于分析方法的粒度。带区的大小可以很大，例如，在 EternityII_Etilde 中可达数百行；也可以相对较小，例如，在 dbir2 中只有几十行。
- 另一个见解进一步解释了我们如何划分带区。显然，检查每一行的所有列索引是不切实际的。相反，我们观察到**索引分布和行长度之间存在很强的相关性**，即在具有相似索引分布的带区内，行长度也相对稳定。从图 8 中两条曲线的相似形状可以看出这一点：当一条曲线出现剧烈变化时，另一条曲线也会随之变化。注意，它们在不同带区内的相对比率不一定是恒定的；我们只需通过这些剧烈变化来检测带区的边界。我们推测这种行为是由于稀疏矩阵中广泛存在的规则局部模式（例如对角带、局部稠密区域）导致的。因此，我们只需通过查看行长度，即 CSR 偏移数组，就可以将矩阵划分为带区，这样速度更快。（📒：CSR的非零元行数越长，所具有的重叠列索引越多，这不是一定的嘛？？？）

为了确定要分析的内容，回顾一下，每个带区包含多行，因此需要执行多个 WA pass。执行一个 pass 的端到端性能是一个直观的候选指标。然而，由于乘法任务和合并任务之间的异步执行（参见第 4 节），总运行时间难以准确测量。相反，我们利用 Spada 的架构特点，即 APE 数量充足，可以匹配 MPE 的最大吞吐量，并且这两个阶段形成了宏流水线，因此整体性能主要由乘法任务决定。此外，索引分布主要影响 B 行的重用，而 B 行是乘法任务的输入。因此，我们**在 Spada 调度器的窗口适配器中跟踪乘法任务的平均运行时间**。

最后，对于如何进行分析，我们进一步优化了大带区和小带区的处理方式。
- 对于包含许多行的大带区，我们将其执行分为两个阶段：
	- 分析阶段，在此阶段我们在前几行上**尝试不同的窗口形状**；
	- 稳定阶段，在此阶段我们**将最佳窗口形状应用于剩余的行**。
- 对于小带区，分析阶段可能会主导执行时间，甚至由于行数太少而无法完成。因此，我们采用了更具自适应性的**成本递减法**。
	- 在尝试不同的窗口形状时，**一旦我们发现某个形状导致性能下降，就会立即停止分析，并使用迄今为止发现的最佳窗口形状**。
	- 这种方法适应得更快，但由于分析不足，可能不是最优的选择。

总结起来，在 Spada 中的窗口形状自适应算法如下：
1. **划分带区**：窗口适配器加载 A 的 CSR 偏移数组，并将行划分为带区。我们经验性地使用绝对阈值 $T_{\text{abs}} = 5$ 和相对阈值 $T_{\text{rel}} = 2$。如果 $\text{len}[i]$（即 $\text{offsets}[i] - \text{offsets}[i-1]$）和 $\text{len}[i-1]$ 之间的差异（或比率）大于 $T_{\text{abs}}$ 或 $T_{\text{rel}}$，则从第 $i$ 行开始一个新的带区。
2. **分类带区**：每个带区根据经验阈值 $T_{\text{band}} = 128$ 行来分类为大带区或小带区。
3. **处理大带区**：对于大带区，我们首先在分析阶段执行四个 pass，窗口形状分别为 $1 \times 8$，$2 \times 4$，$4 \times 2$，$8 \times 1$，并分别跟踪每个 pass 中乘法任务的数量及其运行时间总和。然后，在稳定阶段，使用具有最佳平均运行时间的窗口形状处理该带区的其余 pass。
4. **处理小带区**：对于小带区，我们从 $1 \times 8$ 窗口开始，然后是 $2 \times 4$，依次进行。当一个新的窗口形状导致性能下降时，我们停止尝试新的窗口形状，并使用目前为止找到的最佳形状。我们持续跟踪和更新最近执行的 pass 的性能，并始终使用最优的窗口形状。


## 6-Methodology

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241006234107.png" width="500"></img></div>
**配置**：我们使用表 1 中显示的默认配置评估 Spada。我们使用 2 个 MPE，每个 MPE 有 8 个通道，16 个 APE，以及 1.5 MB 的全局缓存。我们在 RTL 中实现了关键组件，即 MPE、APE 和调度器，并使用 Synopsys DC 在 TSMC 28 nm 技术上进行综合。Spada 芯片运行在 1 GHz，并连接到一个带宽为 128 GB/s 的高带宽存储器（HBM）模块。我们使用 CACTI 7.0 来模拟全局缓存，并使用 swizzle-switch 网络进行交叉连接。为了测量性能和内存流量，我们还在 Rust 中构建了一个 Spada 的周期精确模拟器。该模拟器仔细模拟了硬件组件之间的交互，并实现了第 5 节中的窗口形状自适应算法。该模拟器是开源的，可以在 [https://github.com/tsinghua-ideal/spada-sim](https://github.com/tsinghua-ideal/spada-sim) 获取。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410062348453.png" width="500"></img></div>

**工作负载**：我们使用了 27 个具有大幅度稀疏模式变化的稀疏矩阵，来自 SuiteSparse 集合和一些压缩神经网络（NN）模型，如表 3 所总结。我们从 SuiteSparse 中选择了 18 个矩阵，目标是让它们的密度覆盖图 1a 中的整个范围，即 $10^{-7}$ 到 $10^{-1}$（在表 3 中排序）。此外，它们的每行非零元素数从 4 到 5162 不等，进一步确保了多样性，并验证了灵活支持不同数据流方案的必要性。为了构建 SpGEMM 工作负载，我们遵循 GAMMA中的相同方法，将一个方阵与自身相乘，并将一个非方阵与其转置相乘。为了包含压缩神经网络模型，我们使用开源工具链训练并压缩了 ResNet50和 AlexNet。此外，还按照训练了一个剪枝后的 BERT-Base。我们从 ResNet50 的不同残差块中选择了具有代表性的卷积和全连接层，从 AlexNet 中选择了第二个全连接层，并从 BERT-Base 的第 0 层中选择了查询、键和前馈网络。

**基线**：我们使用了三种最先进的 SpGEMM 加速器，它们分别使用 InP、OutP 和 ROW，即 SIGMA、SpArch 和 GAMMA。为了进行公平比较，我们将所有设计设置为具有相同数量的乘法器，即 16 个。SpArch 和 Spada 本身就是这种规模，而我们将 GAMMA 缩小了一半，例如使用其原始 32 个处理单元的一半，并相应地将原本 3 MB 的 FiberCache 缩小了一半，现在与 Spada 的容量相同（1.5 MB）。对于 SIGMA，我们将 Flex-DPE 的宽度缩小为 16，SRAM 缓冲区缩小到 1.5 MB，并将频率提高到 1 GHz。由于其原始的位图格式在处理非常稀疏的工作负载时扩展性较差，我们将其修改为使用 CSR 格式，并采用 ExTensor 中实现的内容寻址内存来加速索引匹配。我们还在图 14 中评估了这些设计的放大版本。所有设计都使用与 Spada 相同的片外 HBM 模块。所有设计都使用 64 位双精度数据类型，这在科学计算中很常用，遵循 SpArch 和 GAMMA 相同的设置以确保公平比较。压缩神经网络的常见做法是在推理中使用较低精度。我们将这种灵活精度支持留作未来工作，类似于 GPU 支持这两类工作负载的方式以及其他学术提案。最后，我们还与 CPU 和 GPU 平台进行了比较。对于 CPU，我们在双 Xeon 6240 处理器的服务器上使用 Intel MKL 中的 mkl_sparse_spmm（每个处理器有 36 个超线程和 24.75 MB 的最后一级缓存）以及 8 个 DDR4-2933 通道。对于 GPU，我们在一块 NVIDIA RTX 3090 显卡上使用 cuSPARSE 中的 cusparseXcsrgemm2Nnz 和 cusparseDcsrgemm2 进行测量。

## 7-Evaluation

### 7.1-Area and Power

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070008367.png" width="500"></img></div>

表 2 显示了 Spada 在表 1 配置下的面积分布。与之前的工作类似，大部分 Spada 的芯片面积用于 1.5 MB 的大型全局缓存，因为 SpGEMM 主要受限于内存，需要大型缓存来缓解片外数据传输瓶颈。在逻辑组件中，MPE 占据了主导面积。每个 MPE 中，用于输入和输出数据的缓冲区（B 获取器和 P 队列）以及合并网络和归约树消耗了大部分空间。尽管 APE 的数量是 MPE 的 8 倍多，但它们的占用面积比 MPE 小 2.2 倍。这些较小的面积开销证明了为合并任务专门使用 APE 并让 MPE 专注于关键的乘法任务的合理性。调度器只为芯片增加了少量的额外面积。

与基线设计相比，如果将 GAMMA 和 SpArch 从 45 nm 缩放到 28 nm 与 Spada 相同，我们可以看到 GAMMA 和 Spada 的面积相似，分别为 6.13 mm² 和 6.32 mm²，而 SpArch 的面积约为 2 倍，达到 13.96 mm²。注意，这三种设计具有相同数量的乘法器，因此 Spada 和 GAMMA 的面积效率更高。我们没有与 SIGMA 进行具体的面积比较，因为其报告的面积是在 500 MHz 下测量的，并使用了更多资源，因此很难准确估算其缩小后的面积。

我们还报告了 Spada 的功耗，基于综合结果。MPE、APE 和调度器的总功耗为 1.66 W。整个 Spada 芯片的功耗约为 4.84 W，主要由全局缓存占主导。

### 7.2-性能

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070010617.png" width="100%"></img></div>

图 9 使用不同的工作负载对比了四种加速器：SIGMA、SpArch、GAMMA 和 Spada。我们可以看到，由于工作负载中稀疏模式的多样性，各加速器的性能差异很大，没有一种加速器能够在所有工作负载中始终实现最佳性能。这个结果验证了我们的假设，即不同的 SpGEMM 工作负载展示了不同的稀疏模式，它们更适合不同的执行数据流选择。

具体来说，对于图左侧来自 SuiteSparse 的稀疏工作负载，**InP 在大多数情况下性能较差**，主要受到低效的索引交集的影响，尽管我们进行了额外的优化。InP 在 lpi_forest6、cari 和 lp_fit2d 上表现相对较好，因为它们要么足够小，可以完全放入缓存，要么比其他工作负载明显更稠密。对于另外两个基线设计，SpArch（OutP）在 lpi_forest6、dbir2、cari 和 lp_fit2d 四个 SuiteSparse 工作负载上优于 GAMMA（ROW），在 cari 上的差距接近 20 倍。ROW 在 cari 上表现特别差，因为 A 和 B 中的长行大量占用缓存空间。而**在其他 SuiteSparse 工作负载上，ROW 表现更好**，在 email-Enron 上的加速达到了 6.2 倍。email-Enron 在 ROW 上最为高效，因为 A 行之间的列索引重叠有限，因此在 OutP 中的输入重用机会也有限。对于右侧较稠密的神经网络工作负载，虽然在许多工作负载上仍然效率不高，SIGMA 在 resnetb4_c3 上达到了 8.2 倍的加速，表现更为可比。SpArch 在两个压缩的全连接层 resnet50fc 和 alexnetfc2 上优于 GAMMA，而 GAMMA 在其余的卷积层和自注意力层上表现更好。

相比之下，由于 Spada 能够灵活地自适应其 WA 数据流模式，在输入和输出重用之间进行动态调整以匹配稀疏模式，它在几乎所有评估的工作负载上都能超越基线加速器（例如 kkt_power 和 bertl0_ffn），或者表现接近最佳。两个全连接层是例外，在这些工作负载上，WA 与最优的 OutP 之间仍存在差距。这是因为 A 行数较少（例如 16 行），不足以进行优化窗口形状的分析。Spada 甚至能够在某些工作负载上超越专为某一数据流优化的基线设计，因为这些工作负载中的稀疏模式即使在同一个矩阵内部也存在多样性，处理不同区域时偏好不同的方案。而 Spada 能够在这些情况下动态适应。总体而言，基于 WA 的 Spada 加速器显著提升了在不同稀疏模式下的 SpGEMM 性能，平均比 SIGMA、SpArch 和 GAMMA 快 38.04 倍、1.44 倍和 1.46 倍。在性能/面积比方面，Spada 比 SpArch 和 GAMMA 分别提升了 3.32 倍和 1.42 倍。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070014372.png" width="100%"></img></div>

图 10 将 Spada 与 CPU 和 GPU 基线进行了比较。尽管使用了高端 CPU，MKL 在几乎所有工作负载上表现最慢。相比之下，cuSPARSE 比 MKL 快，平均加速 2.84 倍。最终，Spada 平均实现了 12.52 GFLOPS，比 CPU 和 GPU 分别快 13.10 倍和 4.61 倍。值得注意的是，GPU 在某些工作负载上能够略微超过 Spada，例如 raefsky3，但这种性能提升是以更高的功耗和面积为代价的。

### 7.3-细节分析

我们接下来解释 Spada 的高性能提升原因。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070015461.png" width="100%"></img></div>

图 11 显示了四种加速器在不同工作负载上的片外内存流量，分别为 A、B、部分和（psum）以及 C 四种数据类型。不同的工作负载展示了不同的主要内存流量类型。由于 **SpArch 使用的 OutP 具有更好的输入重用**，而 **GAMMA 使用的 ROW 主要重用输出**（如图 2 所示），因此 GAMMA 在部分和与 C 流量占主导的工作负载上表现更好，例如 ca-CondMat 和 email-Enron；而 SpArch 在 B 流量占主导的工作负载上表现更佳，例如 cari 和 resnet50fc。在某些情况下，如 nemsemm1 和 resnetb4_c3，虽然 B 流量占主导，但 GAMMA 的 B 流量仍低于 SpArch。这是因为稀疏模式只在较小的局部区域提供了少量 B 的重用机会，而 OutP 获取了过多的 B 行，从而导致缓存占用过大。

基于 InP 的 SIGMA 具有良好的输出重用，但在非常稀疏的工作负载上，由于索引交集效率低下，其输入内存流量非常大。Spada 能够更好地平衡输入和输出的重用，因此在总内存流量方面，Spada 表现得与三种基线设计中的最佳方案相似。总体而言，Spada 平均比 SIGMA 节省了约 21.9 倍的内存流量，比 SpArch 节省了 1.69 倍，比 GAMMA 节省了 1.39 倍。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070017081.png" width="100%"></img></div>

图 12 进一步比较了四种加速器的乘法器利用率。总体而言，Spada 的乘法器利用率平均比 SIGMA 高 50.7 倍，比 SpArch 高 1.41 倍，比 GAMMA 高 1.42 倍。乘法器利用率的提升与图 11 中的流量减少密切相关，因为大多数工作负载都受内存限制。在某些情况下，如 poisson-3Da，虽然 Spada 和 GAMMA 的流量相似，Spada 的乘法器利用率稍高。这是因为由于局部稀疏模式的变化，如果数据能够很好地从缓存中重用，某些工作负载的部分实际上是计算受限的。

Spada 的乘法器利用率在排除内存和流水线停顿后仍然存在的一些损失，主要归因于乘法器通道之间的负载不平衡。这种损失平均仅为 12%，表明在排序数组的帮助下，Spada 具有合理的负载均衡行为。在所有工作负载中，ca-CondMat 的剩余利用率损失最大。其平均 A 行长度约为 9，略大于通道数量（8），因此每个 pass 包含两个窗口，分别包含 8 和 1 个非零元素，导致在第二个窗口期间硬件资源严重未被充分利用。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070020221.png" width="100%"></img></div>

为了说明第 5 节中窗口自适应算法的有效性，图 13 将 Spada 的性能与静态 WA 方案进行了比较，在这些静态方案中，我们将窗口高度固定为 1、2、4 和 8。不同的窗口高度代表了 B 和 C 重用之间的不同权衡点。由于稀疏模式的多样性，ca-CondMat、dbir2 和 resnetb4_c3 更倾向于较短的窗口，而 raefsky3、cari 和 lpi_forest6 更倾向于较高的窗口。在很多情况下，如 Hardesty2、email-Enron 和 resnet50fc，性能甚至表现出非单调变化。Spada 能够适应首选的窗口形状，并通过利用索引分布相似性，达到接近最佳静态方案甚至更好的性能。基于分析的策略还帮助 Spada 在非单调情况下快速收敛。

### 7.4-敏感性和可扩展性研究

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070020805.png" width="500"></img></div>

表 4 对 Spada 的几个关键配置参数进行了敏感性研究。首先，我们研究了 MPE 数量和每个 MPE 通道数之间的不同配置。增加 MPE 中的通道数扩大了 WA 的窗口大小，从而提高了灵活性，但也增加了流水线末端合并/归约的开销，并降低了通道利用率。我们默认的两个 8 通道 MPE 的设置达到了良好的平衡。其次，在 MPE 内部，我们探讨了 P 队列的详细设计，包括其长度和每周期弹出的最大元素数。较长的 P 队列可以容忍更多的索引分布不平衡并消除停顿，但代价是占用更多面积。长度为 8 的 P 队列是足够的。支持每周期弹出更多元素可以提高吞吐量，因为它能在停顿后快速清空队列，但也需要更大的 Bitonic 网络和归约树。我们发现每周期最多弹出 2 个元素的设计是合理的。第三，对于窗口自适应，我们通过实验证明，将 128 作为划分大带区和小带区的阈值是合适的。最后，我们评估了排序数组的效果，它带来了平均 9% 的加速效果。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/202410070021297.png" width="500"></img></div>

图 14 扩展了四种加速器并在不同规模下评估了它们的性能，从具有 16 个乘法器和 1.5 MB SRAM 的配置，到具有 128 个乘法器和 12 MB SRAM 的配置。随着可用硬件资源的增加，所有加速器的性能都具有可扩展性，而 Spada 在所有规模下都保持了最佳性能。SpArch 从 64 个乘法器扩展到 128 个时的加速比从 32 扩展到 64 个时更高，这是因为在最大配置下，主要的部分和数据开始能够适应片上缓存。虽然 SIGMA 在四种加速器中具有最高的扩展系数，但由于之前提到的低效性，其绝对性能仍然较低。

## 8-Other Related Work

SpGEMM 的性能优化在 CPU 和 GPU 上已经得到了广泛研究。例如，Intel MKL 是其 CPU 上最常用的 SpGEMM 库，而 cuSPARSE 则被广泛应用于 GPU 上。在 CPU 和 GPU 上的软件中应用 WA（窗口自适应）可能会享受到一些但并非全部使用专用硬件的优势。基于软件的分析和监控用于适应性调整可能会带来不可忽视的开销；线程初始化和负载均衡成本较高；而通用缓存缺乏对稀疏行的优化。

最近的研究使用领域专用硬件加速了机器学习、图分析和线性代数领域的 SpGEMM。然而，<font color='red'><b>与 Spada 不同的是，大多数这些加速器仅支持固定的数据流来匹配其特定目标应用</b></font>。例如，如第 2.2 节所分类的那样，**ExTensor 和 SIGMA 使用了 InP，OuterSPACE 和 SpArch 使用了 OutP，而 MatRaptor 和 GAMMA 使用了 ROW**。还有一系列加速器针对压缩深度学习模型中的特定 SpGEMM 进行优化。其中一些设计用于非结构化的 SpGEMM，它们对非零值分布不敏感，动态跳过不必要的计算。例如，SCNN 在模型权重或特征图值为零时跳过计算。另一方面，结构化稀疏加速器要求由协同设计的剪枝算法生成的规则稀疏模式。例如，Cambricon-S 依赖于专门设计的剪枝算法和编码格式，相较于其非结构化前身 Cambricon-X 实现了改进。

📒：都使用固定的数据流？？？？？？？？？？可以在一个计算方法中使用多种数据流吗？？？？？？？？？？？？？？

然而，很少有先前的设计考虑到工作负载内部和之间**不同稀疏度或稀疏分布的多样性**。相比之下，Spada 能够适应稀疏模式，并相应地重新配置硬件。STICKER 设计时考虑了稀疏分布，并将矩阵编码为不同的稀疏格式。它主要关注不同编码格式在元数据方面的优势，并且限制于深度学习模型，而没有考虑稀疏度更高的科学计算数据集。此外，它没有利用不同稀疏模式提供的数据重用权衡来提高性能。

## 9-Conclusions

我们提出了 Spada，这是一种软硬件协同设计，通过自适应重配置来加速 SpGEMM，基于不同科学计算和深度学习应用中的多样化稀疏模式。Spada 的关键创新包括一个基于窗口的自适应数据流模板、一个高效且可重配置的硬件架构，能够在不同数据分布下实现数据重用的优势，以及一个简单有效的动态窗口形状自适应算法，用于确定最佳配置。Spada 能够匹配甚至超越三种优化的基线设计，并平均实现 1.44 倍的加速效果。
