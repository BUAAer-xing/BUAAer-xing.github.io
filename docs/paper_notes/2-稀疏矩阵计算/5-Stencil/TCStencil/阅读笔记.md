
[pdf](zotero://open-pdf/library/items/9N4RGDYW)

## Abstract

张量核心单元（Tensor Core Unit，TCU）在现代高性能处理器中得到了越来越广泛的应用，专门用于提升通用矩阵乘法（GEMM）的性能。由于其高度优化的硬件设计，TCU能够显著加速广泛用于科学计算和深度学习应用中的基于GEMM的操作。然而，**目前很少有工作利用TCU来加速非GEMM操作**，例如在高性能计算领域同样重要的模板（stencil）计算。据我们所知，之前没有任何工作充分考虑模板计算的独特特性并高效地将其适配到TCU上。

在本文中，我们提出了一种名为<font color='red'><b>TCstencil</b></font>的新方法，**将TCU用于加速Stencil计算**。具体来说，我们将模板计算重新设计为一系列的归约和求和操作，以便充分利用TCU的计算能力。此外，我们还提出了相应的优化措施，以更好地利用GPU上的TCU和内存层次结构。我们在NVIDIA A100和V100 GPU上使用不同的模板和输入网格大小评估了我们的方法。实验结果表明，与当前最先进（the state-of-the-art）的stencil优化框架相比，我们的方法能够实现更优越的性能。


## Introduction

随着深度学习模型的普及，这些模型主要由通用矩阵乘法（GEMM）操作主导，现有和新兴的处理器普遍采用了加速GEMM的特殊单元，例如Google的张量处理单元（TPU）和NVIDIA GPU中的张量核心单元（TCU）。由于在加速矩阵乘法方面具有出色的计算吞吐量，TCU不仅能够为深度学习模型，还能为其他基于GEMM的应用（如科学模拟）提供显著的性能提升。许多世界领先的超级计算机，如Summit和Sierra，已经采用了带有TCU的加速器，以在高性能计算（HPC）领域提供强大的计算能力。

然而，与深度学习不同，在HPC领域，除了GEMM之外，计算模式非常多样。例如，一份著名的报告指出，在HPC中至少有13种不同的计算模式。**由于TCU最初是为加速GEMM而设计的，默认情况下它无法为其他非GEMM操作提供优势**。此外，**TCU通常被视为辅助处理单元，无法独立于主处理单元使用**。例如，NVIDIA GPU中的TCU位于流式多处理器（SM）中。一旦SM被占用，即使TCU处于空闲状态，其他内核也无法使用它，从而浪费了宝贵的计算资源。

虽然有一些先驱性的工作扩展了TCU在非GEMM操作（如归约和扫描原语）中的通用性，**但目前还没有任何工作充分利用TCU来加速更复杂的计算模式**，如stencil计算。stencil计算是一种源于有限差分法（FDM）的著名计算模式，FDM基于均匀网格（或网格）广泛应用于解决各种科学应用中的偏微分方程（PDE）。**为了更新网格中的某一点（中心点），stencil计算会计算该中心点及其邻域的加权和**。对于给定的维度，中心点与其最远邻点的距离被称为stencil的半径。由于其固有特性，stencil计算通常在现代处理器上面临低内存带宽和局部性差的问题，这使其在性能上表现不佳。

由于GPU处理器具有强大的并行性和高带宽，它们被认为是加速stencil计算的理想平台。大量工作已经致力于优化GPU上的stencil计算，包括手动优化和代码生成框架。Tiling（或分块）和流式处理是广泛采用的方法，用于提高stencil计算的并行性和数据局部性。此外，分析算法和自动调优技术也被用于确定最佳分块参数。还有研究致力于提高算术密度，以缓解stencil计算中的内存瓶颈，例如<font color='red'><b>内核融合</b></font>和<font color='red'><b>循环展开</b></font>。然而，现有的GPU上stencil计算优化工作尚未充分利用TCU的潜力来进一步提升性能。

本文提出了一种通用方法，称为TCStencil，通过重新设计其计算过程，高效利用TCU进行stencil计算。此外，我们还提出了针对TCU和GPU内存层次结构的并行优化。我们在NVIDIA A100和V100 GPU上使用不同的stencil和网格大小评估了我们的方法，结果表明该方法在性能上具有明显优势。通过将stencil计算适配到TCU，TCStencil扩展了TCU的通用性，使其能够加速更广泛的科学应用。具体来说，本文的主要贡献如下：
- 我们提出了TCStencil，用于<font color='red'><b>利用TCU进行stencil计算</b></font>。该方法克服了TCU的计算约束，从而能够有效地使用GEMM操作进行stencil计算。
- 我们提出了多项在NVIDIA GPU上实现该方法的<font color='red'><b>优化措施</b></font>。这些优化能够有效利用TCU和内存层次结构，显著提升stencil计算的性能。
- 我们将TCStencil与当前最先进的stencil优化框架（如Artemis、AN5D和Brick）<font color='red'><b>进行比较</b></font>，实验结果表明TCStencil能够实现更优的性能。

文章的其余部分组织如下：第二部分介绍了stencil计算和TCU的背景；第三部分描述了我们利用TCU进行stencil计算的方法；第四部分介绍了相应的实现细节和并行优化；第五部分展示了评估结果；第六部分讨论了本文的进一步工作；第七部分介绍了相关工作，第八部分总结了本文的研究成果。

## Background

### 2.1-基于 GPU 的二维Stencil计算

为了简化说明，本文仅考虑二维stencil。对于三维stencil，可以首先应用流式处理策略，然后对从三维网格中提取的二维切片再使用本文的方法。假设stencil的半径为$r$，输入网格为$A$，每个时间步的输出网格为$B$。算法1展示了一个5点（5pt）二维stencil的计算（也可以称为星型计算），其中$c_1$到$c_5$是累加系数。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014204346.png" width="100%"></img></div>

Tiling是加速GPU上stencil计算最有效的优化方法之一。具体来说，整个输入网格首先被划分为多个子网格。每个线程块在每个时间步内独立更新其分配的子网格。主机通过遍历时间步，并在每个时间步通过halo交换来同步子网格的计算。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014204625.png" width="800"></img></div>

上图展示了子网格的halo区域、边界区域和内部区域。特别是，为了更新子网格的边界点，需要相邻子网格的点。边界区域所需的点通过halo交换存储在halo区域中，内部区域的点可以通过子网格内部的点进行更新。

NVIDIA GPU中的张量核心最初是为加速矩阵乘法与累加（MMA）操作而设计的（如方程1所示），这一设计首次引入于Volta GPU。最近，NVIDIA发布了第三代A100 GPU的TCU架构。V100和A100 GPU分别在CUDA核心上实现了31.4 TFLOPS和78 TFLOPS的FP16融合乘法-加法（FMA）操作性能。然而，当使用FP16张量核心时，它们可以分别实现125 TFLOPS和312 TFLOPS的性能，比CUDA核心快大约4倍。

$$
D_{m×k} = A_{m×n} × B_{n×k} + C_{m×k} \tag{1}
$$

**张量核心可以通过CUDA Warp Matrix Multiply and Accumulate (WMMA) API 在warp级别进行编程**。在被张量核心使用之前，数据需要加载到一种特殊数据类型片段（fragment）中。WMMA API提供了专门的函数来加载输入矩阵（`load_matrix_sync`），执行MMA操作（`mma_sync`），并存储结果矩阵（`store_matrix_sync`）。特别是，矩阵的尺寸限制为几个设置（例如，FP16 GEMM必须是16×16×16、32×8×16或8×32×16中的一种）。而且，`load_matrix_sync`和`store_matrix_sync`的**地址需要是256位对齐**的。尽管张量核心可以大大加速GEMM操作，但对于非GEMM操作的优化却很困难。现有的一些工作已经通过构造特殊形式的GEMM来使用张量核心加速并行原语，如归约和扫描。例如，归约原语可以通过在张量核心上执行两次GEMM操作实现，比传统的CUDA核心方法快100倍。然而，使用张量核心加速stencil计算的潜力尚未被开发。

$$
D = [1]_{m \times m} \times
\begin{bmatrix}
x_{11} & \cdots & x_{1m} \\
\vdots & \ddots & \vdots \\
x_{m1} & \cdots & x_{mm}
\end{bmatrix}
+ [0]_{m \times m}
=
\begin{bmatrix}
\sum_{i=1}^{m} x_{i1} & \cdots & \sum_{i=1}^{m} x_{im} \\
\vdots & \ddots & \vdots \\
\sum_{i=1}^{m} x_{i1} & \cdots & \sum_{i=1}^{m} x_{im}
\end{bmatrix}

\tag{2}
$$
📒：计算矩阵中各个列的和，进行GEMM之后，结果矩阵中的每一列上的元素，表示原来矩阵中该列的所有元素的和。

$$
D' = 
\begin{bmatrix}
\sum_{i=1}^{m} x_{i1} & \cdots & \sum_{i=1}^{m} x_{im} \\
\vdots & \ddots & \vdots \\
\sum_{i=1}^{m} x_{i1} & \cdots & \sum_{i=1}^{m} x_{im}
\end{bmatrix}
\times [1]_{m \times m} + [0]_{m \times m}
=
\begin{bmatrix}
\sum_{i=1}^{m} \sum_{j=1}^{m} x_{ij} & \cdots & \sum_{i=1}^{m} \sum_{j=1}^{m} x_{ij} \\
\vdots & \ddots & \vdots \\
\sum_{i=1}^{m} \sum_{j=1}^{m} x_{ij} & \cdots & \sum_{i=1}^{m} \sum_{j=1}^{m} x_{ij}
\end{bmatrix}
\tag{3}
$$
📒：计算矩阵所有元素的和，进行GEMM之后，结果矩阵中的每个元素，表示原来矩阵中所有元素的求和结果值。


## Methodology

在本节描述了TCStencil的设计，以及用于提升其性能的优化技术。假设stencil的输入网格的大小为$N \times N$，并且具有恒定的边界条件。输入网格和输出网格分别表示为$M$和$O$。我们假设TCU支持的GEMM尺寸为$L \times L \times L$，并且$A’_{L \times L}$（$M$的子网格）是TCU的一个输入矩阵。请注意，$L > 2r + 1$，其中$r$是stencil的半径。此外，我们使用9点星形stencil和半径为$r = 2$的25点方形stencil来简要说明我们的方法。同样的思路可以应用于具有不同半径的各种stencil。

（📒：也就是$r<\frac{L-1}{2}$，在16的fragment中，半径最大为7）

### 3.1-星型Stencil在TCU上的适配

如图2所示，星形stencil的计算可以分为三个步骤：
- 1）计算垂直切片（📒：计算该切片的时候，是直接加到了部分结果矩阵的具体一个点上！）
- 2）计算水平切片（📒：计算该切片的时候，是直接加到了部分结果矩阵的具体一个点上！）
- 3）将垂直切片和水平切片的结果相加（📒：最后将两个部分结果矩阵进行相加，就得到了这个具体的点上的完整结果！）
具体而言，垂直切片和水平切片的计算可以看作是加权归约。以9点星形stencil为例，$v_1 \sim v_5$ 和 $h_1 \sim h_5$ 分别表示垂直切片和水平切片的系数。我们将中心点的系数存储在$v_3$中。需要注意的是，$h_3$为0，因为中心点的系数只需要乘积并累加一次。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014210325.png" width="800"></img></div>

#### 一种直接的方法

$$
\begin{align}
P_{\text{ver}} \times Q_1 = T_1, \text{ where } 
\quad P_{\text{ver}}[i][j] &=
\begin{cases}
B[j][r+1], & \text{if } i = 1 \land (j \leq 2r + 1), \\
0, & \text{otherwise}.
\end{cases}

\\ 

Q_1[i][j] &= 
\begin{cases}
A'[m - r + i - 1][n], & \text{if } j = 1 \land (i \leq 2r + 1), \\
0, & \text{otherwise}.
\end{cases}
\tag{4}
\end{align}
$$
$$
\begin{align} 
Q_2 \times P_{\text{hor}} = T_2, \text{ where } 
\quad P_{\text{hor}}[i][j] &=
\begin{cases}
B[r+1][i], & \text{if } j = 1 \land (i \leq 2r + 1) \land (i \neq r + 1), \\
0, & \text{otherwise}.
\end{cases}
\\
Q_2[i][j] &= 
\begin{cases}
A'[m][n - r + j - 1], & \text{if } i = 1 \land (j \leq 2r + 1), \\
0, & \text{otherwise}.
\end{cases}
\tag{5}
\end{align}
$$
$$
C[m][n] = T_1[1][1] + T_2[1][1]
\tag{6}
$$

一种直接的方法是利用TCU加速第1步和第2步中的加权归约。方程4至方程6展示了如何使用TCU更新输入网格中$(m,n)$点，其中**在TCU上执行的矩阵乘法操作将方程2-3中的“1”替换为相应的系数**。$A’$中的垂直切片和水平切片分别存储在矩阵$Q_1$和$Q_2$中，并且这两个切片上的矩阵乘法结果分别存储在矩阵$T_1$和$T_2$中。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014215116.png" width="800"></img></div>

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014220929.png" width="800"></img></div>

本文将包含加权归约系数的矩阵称为参数矩阵。具体而言，方程4中的参数矩阵$P_{\text{ver}}$和方程5中的参数矩阵$P_{\text{hor}}$分别用于计算垂直切片和水平切片的归约结果。然后，通过将两个切片的归约结果相加，可以获得网格中某一点的stencil结果。然而，这种直接的方法可能导致TCU利用率较低。这是**因为每次在TCU上启动两个GEMM内核<font color='red'><b>只更新输入网格中的一个点</b></font>，并且大多数内核中的输入值为零（即除了垂直和水平切片外，参数矩阵中的大多数值为零）**。

#### 本文的方法

为了克服上述缺点，我们将参数矩阵进行编排，使其在单个TCU的GEMM内核中包含多个垂直切片或水平切片。首先，我们构造参数矩阵$P_{\text{ver}}$和$P_{\text{hor}}$。如下图所示，$P_{\text{ver}}$在第$r + 1$行到第$L - r$行存储$v_1 \sim v_5$（垂直切片的系数），而$P_{\text{hor}}$在第$r + 1$列到第$L - r$列存储$h_1 \sim h_5$（水平切片的系数），其余参数矩阵的部分填充为零。我们用$A’[ * ][n] = A’[k][n], k \in [1,L]$和$A’[m][ * ] = A’[m][k], k \in [1,L]$分别表示子网格$A’$的第$n$列向量和第$n$行向量。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014221349.png" width="100%"></img></div>

我们以更新点$(m,n)$为例，说明如何通过两次GEMM操作获得该网格点的stencil结果。第一次GEMM操作后，垂直切片的归约结果（即$A’[ * ][n]$与系数$v_1 \sim v_5$的加权归约，注意$P_{\text{ver}}[m][k] = 0$当$k < n - r$或$k > n + r$时）存储在中间矩阵$T_1[m][n]$中。第二次GEMM操作后，水平切片的归约结果（即$A’[m][ * ]$与系数$h_1 \sim h_5$的加权归约，注意$P_{\text{hor}}[k][n] = 0$当$k < n - r$或$k > n + r$时）存储在中间矩阵$T_2[m][n]$中。然后，通过将中间矩阵中的相应元素相加，可以得到网格点$(m,n)$的最终stencil结果，例如，$B’[m][n] = T_1[m][n] + T_2[m][n]$。

值得注意的是，所有的网格点都可以使用基于垂直和水平切片的方法同时计算，这实际上是使用 TCU 上的 GEMM 操作作为加权归约和求和计算的。具体地说，$A^′$内部区域的stencil结果可以用本文的方法组织为两次 GEMM 操作。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014225118.png" width="100%"></img></div>

以第一次GEMM操作（$P_{\text{ver}} \times A’$）为例，上图展示了第一次GEMM操作产生的切片结果。当$P_{\text{vec}}$的第$i$行与矩阵$A’$相乘时，可以得出从$A’$的第$i$行开始的垂直切片的归约结果。当$i = r$（$P_{\text{vec}}$的第一行非零行）时，可以得出$A’$中具有最小行号和长度为$2r + 1$的垂直切片的归约结果，这些是$A’$内区域第一行的stencil结果。同样，当$i = L - r$（$P_{\text{vec}}$的最后一行非零行）时，可以得到$A’$中具有最大行号和长度为$2r + 1$的垂直切片的归约结果，这些是$A’$内区域最后一行的stencil结果。因此，可以得出$A’$内点的所有垂直切片和水平切片的归约结果，并分别存储在中间矩阵$T_1$和$T_2$中。最后，通过逐元素相加矩阵$T_1$和$T_2$，我们可以得到$A’$内所有点的stencil结果。

尽管基于垂直和水平切片的方法可以有效地执行stencil计算，但它只能应用于$A’[r:L-r, r:L-r]$内区域的点，而不是整个子网格$A’[1:L, 1:L]$的所有点。为了进一步提高TCU的利用率，我们在$P_{\text{ver}}$和$P_{\text{hor}}$的全零行或列中填入部分系数。然后我们可以使用这些部分系数来计算所需点的部分加权归约结果，从而更新$A’$边界点的stencil结果。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014225857.png" width="100%"></img></div>

如图5所示，我们在参数矩阵中填入更多的系数，这些系数是部分水平/垂直切片的系数。例如，$T_1[1][1]$是更新$Afi[1][1]$所需的归约结果，可以通过$v_3 \times A’[1][1] + v_4 \times A’[2][1] + v_5 \times A’[3][1]$与$A’$中的值计算得到。对于剩余点的归约（例如，$v_1 \times A’[-2][1] + v_2 \times A’[-1][1]$，注意$A’[-2][1]$和$A’[-1][1]$是子网格$A’$之外的点），**可以使用FMA（浮点乘加单元）操作来执行其他部分归约，并将归约结果加到GEMM操作输出的矩阵中**。

通过这种方式，我们可以更好地重用TCU中的输入数据，从而提高CUDA核心浮点单元（FPU）的利用率。特别地，我们的方法可以最大限度地利用TCU在$Afi$的stencil计算中的作用。对于那些未被我们的方法处理的stencil点，它们需要$A’$之外的点，而这些点如果只加载一个子网格，TCU是无法访问的。

### 3.2-盒型Stencil在TCU上的适配

类似地，box stencil的计算可以表示为一系列水平切片或垂直切片的加权归约。由于使用水平切片或垂直切片的方法是相同的，本文中我们将box stencil表示为一系列水平切片。以25点box stencil为例，如图6所示，$a_1 \sim a_5$，…，$e_1 \sim e_5$表示五个水平切片的系数。图7展示了25点box stencil的五个参数矩阵（$P_a$，$P_b$，$P_c$，$P_d$，$P_e$），我们为每个水平切片的归约构建一个参数矩阵。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014230505.png" width="800"></img></div>

与星形stencil不同，box stencil中每个水平切片的归约起始行是不同的。如上图所示，我们在TCU上执行第一次GEMM操作以获得$T_a = A’ \times P_a$，其中$T_a[1][1] = a_1 \times A’[3][1] + … + a_5 \times A’[3][5]$。接着，我们执行第二次GEMM操作以获得$T_b = A’ \times P_b$，其中$T_b[1][1] = b_1 \times A’[3][1] + … + b_5 \times A’[3][5]$。然而，将$T_a[1][1]$和$T_b[1][1]$相加会导致错误的结果。原因是$P_b$的第一列是$A’$中第二行归约所需的系数，而不是第一行（实际需要的是$b_1 \times A’[4][1] + … + b_5 \times A’[4][5]$）。因此，矩阵$A’$不能像星形stencil那样直接与参数矩阵相乘。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014230759.png" width="800"></img></div>

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014231414.png" width="100%"></img></div>

为了解决上述问题，我们仍然使用图中的参数矩阵，但改变每次GEMM操作的起始位置。如上图所示，在每次GEMM操作后，我们将$A’$沿输入网格向下移动一行。例如，为了更新点$M[5][3]$，第一次GEMM操作从输入网格的第一行开始，此时$T_a[3][3] = a_1 \times M[3][1] + … + a_5 \times M[3][5]$。第二次GEMM操作从第二行开始，此时$T_b[3][3] = b_1 \times M[4][1] + … + b_5 \times M[4][5]$。类似的计算适用于其余各行。最后一次GEMM操作从第七行开始，此时$T_e[3][3] = e_1 \times M[7][1] + … + e_5 \times M[7][5]$。然后，通过将中间矩阵中的相应元素相加，$M[3][5]$的stencil结果可以通过$T_a[3][3] + T_b[3][3] + … + T_e[3][3]$计算得到。该方法确保参数矩阵中的系数与输入网格的正确行相乘。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014231458.png" width="600"></img></div>

类似于星形stencil，对于box stencil，内区域中大小为$L + 2r \times L$的所有点可以通过在TCU上执行$2r + 1$次GEMM操作来计算，如图9所示，并且边界区域的点可以通过GEMM操作进行部分加权归约来更新（其他部分加权归约通过CUDA核心上的FMA计算）。通过使TCU执行stencil计算，TCStencil可以显著提高stencil计算的性能（详见第5节评估）。此外，TCStencil仅依赖于TCU的GEMM原语，不依赖于其他架构特性，因此可以很容易地应用于具有TCU的其他处理器。

### 3.3-性能优势

为了更好地展示我们方法在不同TCU使用场景下加速stencil计算的潜力和效果，我们列出了应用TCStencil的三段代码片段，如图所示。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014232206.png" width="500"></img></div>

在第一种情况中，TCU作为独立的GEMM加速器使用，TCStencil可以将stencil计算卸载到TCU上以提高性能。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014232230.png" width="500"></img></div>

在第二种情况中，FPU和TCU同时可用，但只能单独使用，TCStencil选择使用TCU代替FPU进行stencil计算，以获得更好的性能。以A100 GPU上的9点星形stencil在FP16精度下为例，一个FP16 FPU每周期可以更新$1 ÷ 9 = 0.11$个点。而TCStencil通过执行两次$16 \times 16 \times 16$的HMMA操作，至少更新$12 \times 12$个内区域点，每个HMMA操作在A100上消耗16个周期。因此，TCStencil每周期可以更新$12 \times 12 ÷ (16 \times 2) = 4.5$个点。综上所述，在A100和V100 GPU上，TCStencil使用TCU进行stencil计算可以实现比FPU更高的吞吐量。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014232255.png" width="500"></img></div>

在第三种情况中，FPU和TCU同时可用，并且可以同时使用。在这种情况下，TCStencil可以利用TCU加速stencil计算，从而缓解FPU的压力，使其加速其他计算。图展示了在烧结应用中更新浓度场的stencil内核，其中cond是输入网格，con_lapd是输出网格。在该应用中，stencil计算和偏导数计算可以分别使用TCU和FMA并行进行。


## Implementation

我们在NVIDIA A100和V100 GPU上使用张量核心实现了TCStencil。由于TCU仅支持FP16精度下的GEMM操作，我们在FP16精度下实现了TCStencil，以展示其在加速stencil计算中的有效性。虽然<font color='red'><b>传统的科学应用通常要求高精度（例如FP64）</b></font>，但采用较低精度来加速stencil计算的兴趣日益增加。然而，如何在低精度下满足特定的计算精度需求的研究不在本文的讨论范围内。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014234158.png" width="100%"></img></div>

具体而言，我们使用张量核心实现了半径为$r=1$和$r=2$的星形stencil和box stencil。上展示了$r=1$的stencil计算参数矩阵（与$r=2$的参数矩阵类似，因此省略）。张量核心执行$16 \times 16 \times 16$的矩阵乘法（$L=16$），并且只能通过load_matrix_sync和store_matrix_sync API读写$16 \times 16$的矩阵，这使得张量核心的全局内存访问成为性能瓶颈。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014234703.png" width="100%"></img></div>

如图12(a)所示，同一$A’$中的元素地址可能相差多达$N-L$。此外，两个相邻$A’$的地址距离也可能较大。为了解决这个问题，我们将数据重新组织为$16 \times 16$的子矩阵，并按行优先顺序顺序存储$A’$中的元素，如图12(b)所示。由于相邻访问的$A’$之间的地址距离较小，使用$16 \times 16$的子矩阵可以提高数据局部性并减少内存访问延迟。需要注意的是，子矩阵仅改变了stencil计算中的地址索引，在运行时不会引入额外的内存访问。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241014234558.png" width="500"></img></div>

算法2展示了使用TCStencil实现的stencil内核。我们使用每个线程块更新一组连续的$A’$。每个线程块更新的$A’$数量称为tileX。通过一个线程块更新多个$A’$可以共享存储在TCU片段中的相同参数矩阵，避免重新构建参数矩阵的开销。我们还应用了众所周知的GPU优化技术，例如内存合并、寄存器优化和避免bank冲突，以进一步提高实现的性能。在算法2中，线程块首先初始化参数矩阵（第2行）。然后，线程块从全局内存中将每个$A’$加载到共享内存$sin$中（第4行），并通过张量核心计算stencil结果（第5行）。接着，线程块将halo区域加载到$shalo$中（第6行），并计算halo区域的结果并将其加到$sout$中（第7行）。最后，线程块内的线程将stencil结果写回全局内存（第8行）。


## Evaluation

### 5.1-实验设置

我们的实验在两个平台上进行：一个配备了两块NVIDIA A100 GPU，另一个配备了两块NVIDIA V100 GPU。A100和V100的全局内存分别为40GB和32GB。由于架构改进，A100的峰值性能高于V100。平台上的CPU均为双插槽Intel E5-2680v4。我们使用CUDA11编译器并加上`-O3`选项来编译stencil代码。我们在GPU上使用FP16精度评估不同输入网格大小的stencil（$N = 160 \times i + 2r$，其中$i$的范围为1到45）。我们使用**NVIDIA Nsight Profiler**中的**Duration度量指标**来报告stencil计算的执行时间（不包括内核启动和CPU-GPU数据传输时间）。在所有实验中，我们将GPU固定在最高频率（A100为1410 MHz，V100为1380 MHz），以获得稳定的结果（通过nvidia-smi-lgc设置）。我们使用每秒更新点数来表示stencil计算的性能，计算公式为$\frac{(N - 2r)^2}{\text{execution\_time}}$。


### 5.2-性能提升

#### 使用张量核心加速

为了更好地理解张量核心带来的性能提升，我们对比了使用张量核心优化的TCStencil（记作TC）与不使用张量核心的TCStencil（记作TC-w/o-tc）的stencil代码。两种实现采用相同的线程配置和并行优化技术（例如，数据重组、共享内存、分块和内存合并）。我们为TC和TC-w/o-tc都设置了tileX=1。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241015102550.png" width="100%"></img></div>

星型stencil和盒型 stencil展示了在A100和V100 GPU上TCStencil和TC-w/o-tc的性能对比。一般来说，具有较小半径的stencil可以实现更高的吞吐量，因为内存压力较低。随着输入网格大小的增加，stencil计算的性能最初迅速提升，这是由于SM（流式多处理器）资源充足，能够支持并行化。当输入网格足够大时，SM资源达到饱和，stencil的性能趋于稳定。

在图中可以明显看出，当$N$足够大时，使用张量核心的TC表现出更好的性能。随着$N$的增加，TC的性能逐渐提升并趋于稳定。在A100 GPU上，TC的平均加速比和最高加速比分别为：5点星形stencil为1.14×/1.08×，9点box stencil为1.35×/1.17×，9点星形stencil为1.20×/1.14×，25点box stencil为1.47×/1.20×。在V100 GPU上，平均加速比和最高加速比分别为：1.14×/1.14×，1.62×/1.26×，1.18×/1.18×，1.69×/1.49×。对比TC和TC-w/o-tc的性能，显然使用张量核心可以显著提升stencil计算的性能。

为了定量了解TCStencil的性能潜力，我们以A100 GPU上$r=2$的星形stencil为例说明。在A100 GPU上，FP16精度的峰值性能是FP32精度的4倍，且FP16精度的指令延迟是FP32的一半。由于每个A100 GPU的SM（流式多处理器）上有64个FP32精度的单元，我们假设每个SM每周期可以执行128次FP16精度的FMA操作。正如第3.3节所述，FP16 FMA单元和张量核心单元每周期可以分别更新0.11个点和4.5个stencil点。因此，每个SM使用FMA可以更新$0.11 \times 128 = 14.08$个点，而使用张量核心可以更新$4.5 \times 4 = 18$个点（A100 GPU的每个SM有四个张量核心）。基于我们的分析，A100 GPU上9点星形stencil的TC相比TC-w/o-tc的理论加速比为1.28×。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241015102737.png" width="500"></img></div>

表1展示了TCStencil在网格大小为7200×7200时的FLOPS和带宽性能。由于现有的GPU分析工具不支持FP16计算的FLOPS和带宽测量，我们通过分析计算FLOPS和数据传输带宽。TCStencil在A100 GPU上实现的最高TFLOPS/内存带宽（TB/s）分别为41.71/7.82，在V100 GPU上为15.94/3.89。

#### 参数调优

我们注意到，TCStencil的性能对参数矩阵的大小（tileX）非常敏感。较大的tileX可以增加参数矩阵的重用，但会减少并行性。因此，我们通过搜索$tileX$设置从1到15的值，针对所有stencil和网格大小进行参数调优。最佳的tileX取决于stencil的形状、半径、网格大小和GPU架构。例如，与$tileX=1$相比，当$N=7,204$时，最佳tileX可以分别将A100 GPU上的5点星形/9点box/9点星形/25点box stencil的性能提高1.15×/1.14×/1.24×/1.38×。我们使用TC-best来表示在最佳tileX设置下TC的最佳性能。

### 5.3 与现存工作的比较

我们将TCStencil与三种最先进的GPU stencil优化框架进行了对比，包括Artemis、AN5D和Brick。需要注意的是，Artemis相比其前代框架（如STENCILGEN和PPCG）是一个高度优化的stencil框架。对于Artemis，我们利用其自动调优机制来确定参数设置，如块维度和循环展开因子，并选择性能最高的参数设置来代表Artemis的结果。对于AN5D，参数设置是通过其性能模型确定的。此外，我们专注于与AN5D在单时间步（不进行时间阻塞优化）的性能比较，因为实际应用中通常包含复杂的计算过程，无法对stencil计算进行时间优化。对于Brick，我们使用其开源库中的优化stencil实现。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241015113420.png" width="100%"></img></div>

具体而言，这些框架都不支持FP16精度的stencil计算。为了确保公平的对比，我们将Artemis、AN5D和Brick的优化stencil代码转换为FP16精度。此外，我们也对Artemis的FP16精度代码进行了调优。我们用#framework-fp32和#framework-fp16来表示FP32和FP16精度的stencil代码。我们使用TC-best来表示由TCStencil优化的stencil代码的性能。图15和图16展示了在A100和V100 GPU上各种stencil下的性能比较。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241015113605.png" width="100%"></img></div>

与TCStencil类似，其他stencil优化框架的性能在最初随着$N$的增加而提升，随后由于资源饱和而趋于平稳。我们还注意到，当输入网格较大时，AN5D的性能会随着$N$的变化而剧烈波动。图17展示了AN5D在大$N$（从3200到9600）下的性能表现。根据我们的调查，这是因为AN5D的性能模型与实际性能相比不够准确，特别是在$N$较大时。当$N$较大时，stencil计算会导致更复杂的缓存行为，而这些行为难以精确建模。因此，AN5D在大$N$的情况下很难获得最佳参数，导致性能波动。

Artemis性能较差的原因可以归结为其自动调优机制无效以及共享内存利用率低下。需要注意的是，Artemis在FP32和FP16精度生成的stencil代码使用了不同的参数设置，因此低精度代码的运行速度可能甚至比高精度代码还要慢。

在图15和图16中，当$N$较大时，TCStencil在FP32和FP16精度下的性能始终优于三种stencil优化框架。表2展示了TCStencil的平均加速比和最高加速比。显然，TCStencil在FP32精度下相比现有框架实现，获得了更高的性能加速。而在FP16精度下，TCStencil的性能加速可以归因于其有效利用张量核心，通过高吞吐量的GEMM操作加速stencil计算。当$N$较小时，TCStencil的加速比接近于Artemis和Brick，但当$N$较大时，TCStencil由于利用张量核心加速计算，表现出明显的性能优势。由于AN5D为复杂内存管理引入了额外的开销，它在小网格尺寸下的性能明显慢于其他实现。

对于FP32精度，TCStencil相比Artemis、AN5D和Brick的平均加速比分别为2.79×、3.77×和2.33×，最高加速比分别为4.71×、17.63×和3.50×。对于FP16精度，TCStencil相比其他框架的平均加速比分别为2.89×、3.18×和1.23×，最高加速比分别为5.45×、17.13×和1.55×。最高的性能加速比（FP32为17.63×，FP16为17.13×）在$N=164$时，相比AN5D实现。

  <div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241015113914.png" width="100%"></img></div>

由于当前GPU设计的限制，TCU和FPU无法在同一个SM上同时使用。然而，我们相信，在未来的GPU架构中，如果TCU和FPU能够独立利用，TCStencil将拥有更多的性能潜力。在这种情况下，TCU可以作为stencil加速器，而FPU则可以用于同时加速其他操作。TCStencil的设计能够轻松利用这样的架构特性，进一步提高科学应用的并行性和性能。

## Discussion

精度对FP16的影响——尽管传统的stencil应用通常使用更高的精度，如FP64和FP32，但越来越多的研究表明，FP16精度在stencil应用中也取得了成功。此外，使用FP16精度带来的精度损失可以通过迭代精化、混合精度技术和修正方案来补偿。因此，我们认为，我们提出的使用FP16精度在TCU上加速stencil计算的方法，可以与上述技术相结合，以应对不同的应用场景。

进一步性能优化——我们确定了几个进一步优化TCStencil的方向。首先，我们注意到，对于给定的stencil，参数矩阵在计算过程中是恒定的。因此，我们可以通过使用GPU上的持久线程等机制，在时间步之间共享参数矩阵，使得参数矩阵只需构建和加载一次。此外，由于本文提出的stencil优化方法与现有优化技术（如流处理和内核融合）是正交的，我们可以通过将TCStencil与这些优化方法集成来实现更好的性能。

适用性超越特定精度/半径——本文提出的方法不仅限于加速TCU上特定精度和半径的stencil计算。然而，由于当前NVIDIA A100和V100 Tensor Core的资源限制，我们选择了特定的精度（FP16）和半径（$r=1, 2$）来展示我们方法的有效性。随着TCU逐渐支持更强大的高精度计算（如NVIDIA Hopper中的60TFLOPS FP64 Tensor Core）和更大的GEMM形状（如TPU中的256×256×256），我们相信TCStencil在未来的TCU上将有更大的潜力，以在广泛的stencil应用中实现更好的性能和精度。

## Related Work

GPU上常见的stencil优化包括空间/时间分块、流处理、循环展开和硬件特定的优化，这些已经在许多先前的工作中得到了广泛的探索。例如，STENCILGEN通过空间/时间流处理优化stencil，而PPCG使用多面体方法采用了混合分块。Artemis提出了一种代码生成器，支持各种stencil优化技术，包括分块、流处理、重新定时等。此外，Artemis还采用自动调优机制来确定最佳参数设置。AN5D采用了时间分块并提出了优化方案，以减少共享内存和寄存器压力，其参数设置由性能模型决定。Brick采用了细粒度的数据分块，能够减少TLB、硬件预取和缓存压力，优化的分块大小基于经验研究选择。

然而，据我们所知，现有的工作中尚未有利用张量核心加速GPU上的stencil计算的研究。为了提高数据重用，许多工作致力于重新排序stencil计算。例如，Semi-stencil算法将stencil计算划分为多个部分更新，每次更新仅计算部分stencil结果，最终累积得出最终结果，这与我们的思路类似。还有一些研究致力于消除公共子表达式，以减少stencil计算中使用的寄存器数量。这类工作通常是针对高阶半径和高维输入网格中的寄存器溢出问题，属于与本研究正交的内容。

TCU是一个高吞吐量且高能效的单元，吸引了研究人员探索其在深度学习以外的更多通用应用场景。有一些工作尝试通过将stencil计算转换为TCU支持的算法来使用TCU进行加速。然而，这些工作在使用TCU时没有充分考虑stencil计算的特性，因此无法充分利用TCU的计算资源。例如，Chowdhury等人将每次stencil计算转换为权重矩阵（stencil系数）与数据矩阵（stencil网格）之间的卷积，但由于权重矩阵的大多数值为零，每次卷积只能更新一个点，导致优化性能低效。还有一些研究将stencil计算转换为稀疏（stencil系数）-密集（stencil网格）矩阵乘法（SpMM），并使用TCU加速SpMM。然而，这种方法不仅引入了索引开销和额外的内存消耗，而且由于未能适应TCU的特性（stencil计算产生的稀疏矩阵是对角稀疏，而SpMM为TCU设计的是基于块的稀疏），导致资源利用率较低。

因此，我们认为TCStencil是首个通过考虑TCU独特特性而有效适配stencil计算的工作。


## Conclusion

本文介绍了第一个利用 TCU 加速非 GEMM 计算模式的工作，重点介绍了模具计算。具体来说，我们提出了一种有效的方法 TCstenil 来适应模板计算在 TCU 上的应用，并进行了相应的优化，以更好地利用 TCU 和内存阶层处理器。我们在不同模板和输入网格尺寸上的实验表明，与 NVIDIA A100和 V100图形处理器上的最先进的模板优化框架相比，TCStenil 可以实现有希望的性能加速。






