
[pdf](zotero://open-pdf/library/items/ZAKQPC28)

# Abstract

张量核心单元（Tensor Core Unit, TCU）越来越多地集成到现代高性能处理器中，以提升矩阵乘法的性能。然而，由于其规格的限制，它在提高其他关键科学操作（如Stencil计算）方面的潜力尚未得到充分利用。

本文介绍了ConvStencil，这是一种新颖的Stencil计算系统，旨在<font color='red'><b>将Stencil计算高效地转化为在张量核心（Tensor Cores）上的矩阵乘法</b></font>。首先为ConvStencil开发了一个性能模型，以指导在TCU上的算法设计和优化。

基于该模型，本文提出了三项技术：
- (1) 使用stencil2row方法进行内存高效的布局转换；
- (2) 通过双重镶嵌（Dual Tessellation）和内核融合进行计算密集型的计算适配；
- (3) 使用查找表和Dirty Bits Padding进行性能提升的冲突消除。

（📒：重点关注**内核融合**的概念以及**冲突消除**的方法！）

ConvStencil的性能优于其他Stencil优化框架，与AMOS、cuDNN、Brick、DRStencil和TCStencil等解决方案相比，实现了显著的加速。通过<font color='red'><b>将Stencil计算转化为在张量核心上的执行</b></font>，ConvStencil有望提升各种科学和工程应用的性能。


## Introduction

随着深度学习模型的日益普及，其主要特征是矩阵乘法（MM）操作，现有的和新兴的处理器越来越多地集成了专门的单元来加速矩阵乘法。这些专门的单元被称为<font color='red'><b>张量核心单元（Tensor Core Units, TCUs）</b></font>，它们为基于矩阵乘法的深度学习模型提供了显著的性能加速，例如NVIDIA GPU中的张量核心。

虽然张量核心能够提供出色的性能，但需要注意的是，高性能计算（HPC）领域的**计算模式更加多样且复杂**，其中<font color='red'><b>大多数难以直接用矩阵乘法（MM）表达</b></font>。

Stencil计算是被Berkeley视为七种关键性能计算模式之一的代表。Stencil包含一个预定义的模式，该模式在时间维度上迭代更新𝑑维空间网格中的每个点。在时间𝑡时，某个点的值是它自身及其在前一个时间 $t−1$ 的邻居点的加权和。Stencil作为一种重要的计算核，广泛应用于科学和工程领域，例如流体动力学、地球建模和天气模拟。

目前，只有少量研究探索了张量核心在非矩阵乘法（MM）操作中的应用。最初的工作在张量核心上实现了简单的归约和扫描操作，这标志着首次尝试扩展可以通过张量核心执行的非MM操作范围。更近期的研究TCStencil试图将张量核心应用于更复杂的计算模式，如Stencil计算。然而，TCStencil在算法的通用性和张量核心的利用率方面存在问题。
- 一方面，TCStencil受限于FP16张量核心上的对称矩阵乘法（即形状相同的矩阵相乘），而大多数Stencil计算需要FP64精度，而FP64张量核心仅支持特定的不对称矩阵乘法。
- 另一方面，TCStencil遇到了**全局内存访问不合并以及共享内存中的bank冲突**，这限制了张量核心计算能力的充分发挥。据我们所知，目前没有其他工作能够有效地将Stencil计算适配到张量核心上。

本文提出了一种新颖的Stencil计算系统ConvStencil，旨在<font color='red'><b>将Stencil计算高效地转换为在张量核心上的矩阵乘法</b></font>。

ConvStencil的设计基于一个关键的观察，即**高性能计算中的Stencil计算与深度学习中的卷积在计算模式上存在相似性**。两者都使用Stencil核（或卷积核）形成滑动窗口，对输入矩阵内的窗口数据执行加权计算。为了**在张量核心上高效支持卷积**，GEMM（通用矩阵乘法）卷积计算中使用了<font color='red'><b>im2row（或im2col）方法</b></font>，该方法将输入数据和滤波器转换为矩阵，<font color='red'><b>使得卷积可以通过矩阵乘法来进行</b></font>。


基于这一观察，ConvStencil的关键见解得以启发：**既然Stencil计算和卷积的计算模式如此相似，为什么不通过im2row机制在Stencil计算和张量核心之间架起桥梁呢？** 然而，考虑到Stencil和卷积在算法细节上的重要差异，这仍然不是一个简单的任务，需要解决多个技术难题。
- 首先，将im2row应用于卷积操作可以将其转化为矩阵乘法（MM），但由于每次迭代中Stencil核和通道的数量都是1，这种转换会导致矩阵向量乘法，从而**可能引发显著的内存膨胀和低张量核心利用率**。
- 其次，FP64张量核心操作仅支持特定的不对称小型矩阵乘法，这为算法在此限制下的高效适配带来了挑战。此外，**算法的实现和设计可能会遇到性能瓶颈**，例如算法实现与硬件设计之间的冲突（如warp分支和存储器bank冲突），导致性能大幅下降。


ConvStencil包含三项关键技术，以应对上述挑战：
- <font color='red'><b>内存高效的布局转换</b></font>
	- 在布局转换中，本文引入了**stencil2row方法**，创建了一种内存使用更少的矩阵乘法内存布局，与im2row相比，内存占用减少了70.0%到96.4%。
- <font color='red'><b>计算密集的计算适配</b></font>
	- 在计算适配中，提出了**双重镶嵌（Dual Tessellation）**，通过矩阵镶嵌提高Tensor Core的利用率，将Tensor Core的利用率从12.5%提升至87.5%。
	- 同时，内核融合（Kernel Fusion）减少了矩阵的稀疏性，进一步提高了Tensor Core的计算密度。
- <font color='red'><b>性能提升的冲突消除</b></font>
	- 在冲突消除方面，设计了**查找表**以避免昂贵的操作，并减少冗余的地址计算。
	- 此外，**脏位填充（Dirty Bits Padding）** 利用填充区来写入无效数据，避免条件分支，从而实现无冲突的实现，进一步提升性能。

与同样使用Tensor Cores的TCStencil相比，ConvStencil平均减少了44.0%的非合并全局内存访问，并将每个请求的银行冲突减少了63.5%。通过一组多样化的Stencil内核，结果从三个方面展示了我们的设计和优化的有效性。首先，每个提出的技术都显著提升了性能。其次，在多项基准测试中，ConvStencil性能优于五种先进技术（cuDNN、AMOS、Brick、DRStencil和TCStencil）。第三，ConvStencil在三时间步融合下也优于DRStencil，表明我们的性能提升不仅源于内核融合优化，还来自于算法设计。

贡献如下所示:
- 提出了ConvStencil，这是一种新颖的Stencil计算系统，旨在将Stencil计算高效地转换为在张量核心上的矩阵乘法。
- 提出了Stencil2row布局转换方法，减少了im2row结果中的冗余，并保持了矩阵乘法操作的高效内存布局。
- 计算适配采用双重镶嵌（Dual Tessellation）以提高张量核心的利用率，并通过内核融合（Kernel Fusion）进一步提升张量核心的计算密度。
- 冲突消除采用查找表和Dirty Bits Padding，消除影响性能的冲突，进一步提升性能。


## Background and Challenge

### 2.1 Stencil 计算

Stencil计算是一种在科学和工程领域广泛采用的技术，它根据预定义的计算模式对多维输入进行迭代更新。该预定义模式被称为**形状**，主要有两种类型：星形（star）和盒形（box）。
- 星形Stencil计算的是中心点及其邻近点的加权和，这些邻近点仅在单个维度上与中心点分离。
- 盒形Stencil则计算一个方形或立方体的加权和，其中中心点位于几何形状的核心。
参与特定计算模式的点的范围由**半径**（也称为阶数）决定。例如，半径为1的盒形Stencil的计算模式是一个3×3的方形。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241011192250.png" width="100%"></img></div>

### 2.2 基于 GEMM 的张量核卷积

张量核心是由NVIDIA开发的一种专用硬件组件，旨在加速矩阵乘法运算。其独特的能力在于能够执行<font color='red'><b>混合精度的矩阵乘法与累加运算</b></font>（**MMA**，如公式1所示），这使得它的处理速度远超CUDA核心。
$$D_{m\times n}=A_{m\times k}\times B_{k\times n}+C_{m\times n}$$

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241011224408.png" width="100%"></img></div>

基于GEMM（通用矩阵乘法）的卷积将卷积操作转换为矩阵乘法（MM），成为在张量核心上计算卷积的一种高效方法。其过程如图1所示。在这个过程中，<font color='red'><b>多通道输入和卷积核都被重新形成为二维矩阵，然后卷积操作被表达为矩阵乘法</b></font>。输入矩阵通过将图像中的每个核大小的块展开成一行（im2row）来创建，而卷积核（或滤波器）矩阵则通过将滤波器权重展开成一列来创建。卷积操作通常包含多个卷积核，通常为2的幂次。通过卷积重塑的列形成了卷积核矩阵，随后对这两个矩阵执行矩阵乘法操作。


### 2.3 挑战

卷积和Stencil计算在很大程度上具有相似性。**它们都通过滑动核在输入网格上进行计算，并计算加权和**。尽管已有大量研究，但在如何高效利用张量核心执行Stencil计算方面，仍然缺乏有效且实用的方法。这引发了一个问题：为什么Stencil计算难以像卷积那样方便地映射到张量核心上？在这里，我们识别并讨论了导致这一问题的三个主要挑战。

#### 空间膨胀（Space explosion）

采用im2row转换将Stencil计算转换为矩阵乘法（MM）是一个直接的想法。然而，<font color='red'><b>im2row转换要求极高的内存需求，生成的矩阵内存占用通常是原始输入的几倍甚至几十倍，导致空间爆炸</b></font>。例如，对于一个10 × 10的输入和3 × 3的核，输入矩阵的大小会扩展为100 × 9，比原始输入大了9倍。对于普通的卷积运算来说，空间爆炸通常不是问题，因为卷积核矩阵的列足够多，使得矩阵乘法更加密集，达到了内存和计算开销的平衡。然而，**在Stencil计算中，im2row转换后变成了矩阵-向量乘法，由于张量核心中的矩阵-向量乘法稀疏性问题，空间爆炸变得更加严重**。此外，Stencil计算通常需要FP64精度，进一步加剧了内存需求。相比之下，GPU上的共享内存非常有限，例如在A100上，每个流式多处理器（SM）只有164KB的共享内存。

#### Tensor Core 的利用率低

卷积转换为Stencil计算，有下面这两个条件：
1.  输入数据和卷积核的通道数为1；
2.  Stencil计算中只有一个核。
在这种情况下，**Stencil计算被转换为矩阵-向量乘法**。然而，对于FP64精度的计算，NVIDIA A100上的张量核心仅支持8 × 8 × 4的矩阵乘法与累加运算（MMA），这意味着右侧被乘的矩阵的7/8列都被浪费，导致张量核心的利用率极低。

#### 算法和硬件的冲突

在完成针对张量核心的算法设计后，很明显在映射过程中算法实现与硬件设计之间存在两个主要冲突：
1.  **大量重复的内存访问偏移计算**，这与标准的Stencil计算发生冲突。这些冲突消耗了计算资源，导致性能下降。
2.  在布局转换过程中存在大量**条件分支**和**内存bank冲突**，导致严重的<font color='red'><b>线程束（warp）发散</b></font>和<font color='red'><b>串行内存访问</b></font>问题，进一步影响了性能表现。

## ConvStencil

ConvStencil代表了一种新颖的Stencil计算方法，通过类似卷积的方式利用张量核心（Tensor Cores）。我们首先介绍了理论性能模型，然后介绍了ConvStencil的基本组成部分，包括布局转换、计算适配和冲突消除。

在布局转换阶段，我们提出了Stencil2row方法，将输入重新排列为两个不同且较小的矩阵，为后续的张量核心计算做好准备。在计算适配阶段，双重镶嵌（Dual Tessellation）方法迭代地对从Stencil2row矩阵中选取的块应用张量核心的MMA操作，以生成Stencil计算结果。在冲突消除部分，我们预先计算指针偏移，以避免耗时的整数除法和取模操作。此外，我们提出了”dirty bits padding”，通过使用填充区域消除内存银行冲突并移除条件分支。


### 3.1 性能模型

这张图展示了ConvStencil性能模型的公式，包括计算时间（$\mathcal{T}_{compute}$）和内存访问时间（$\mathcal{T}_{memory}$），以及总体时间的计算方式（$\mathcal{T}$）。

#### 总时间$\mathcal{T}$

总时间是计算时间$\mathcal{T}_{compute}$和内存时间$\mathcal{T}_{memory}$中的最大值，即
  $$
\mathcal{T} = \max(\mathcal{T}{compute}, \mathcal{T}{memory})
$$
这意味着Stencil计算的性能瓶颈可能来自**计算时间**或**内存访问时间**中的任意一个。

#### 计算时间

计算时间$\mathcal{T}_{compute}$的公式：
$$
\mathcal{T}{compute} = \frac{1}{f N_{tcu}} \sum_{i=0}^{K_{tcu}} \left(k_{tcui} \times CPI_{tcui}\right)
$$
其中：
• $f$ 是GPU的频率，
• $N_{tcu}$ 是张量核心的数量，
• $K_{tcu}$ 是不同类型的 Tensor core 指令的数量，
• $k_{tcui}$ 是第 $i$ 类 Tensor core 指令的数量，
• $CPI_{tcui}$ 是第 $i$ 类 Tensor core 指令的每个周期内执行的指令数。


#### 内存访问时间

内存访问时间$\mathcal{T}_{memory}$的公式：

$$
\mathcal{T}{memory} = \max\left(\frac{data_{R}}{bw_{G}} + \frac{data_{W}}{bw_{G}}, \frac{data_{transW}}{bw_{S}} + \frac{data_{transR}}{bw_{S}}\right)

$$

其中：
• $data_R$ 和 $data_W$ 是从全局内存读取和写入的数据量，
• $bw_G$ 是全局内存带宽，
• $data_{transW}$ 和 $data_{transR}$ 是写入和读取共享内存的数据量，
• $bw_S$ 是共享内存带宽。
  
计算所需的时间是时钟频率的倒数与所需周期数的乘积。所需的周期数通过将程序中每种指令的数量与该指令所需的周期数相乘后相加得到。在NVIDIA A100 GPU上，张量核心中执行一次FP64 MMA指令需要16个周期。内存访问所需的时间是不同内存层次中的读写时间的最大和。


### 3.2 布局转换

#### Stencil2row

**Stencil2row**：当前的im2row转换存在内存爆炸问题。当原始输入被转换为im2row矩阵时，内存需求增加了好几倍。图通过一个7 × 7卷积核展示了这一现象。例如，当通过im2row将一个$m \times n$的输入转换时，会形成一个$(m-6)(n-6) \times 49$的im2row矩阵。随着卷积核大小的增加，im2row转换所需的内存也会增加。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241012222704.png" width="100%"></img></div>



📒：这样，每对颜色不同的一组，就可以构成一个大小为$(n+1)(n+1)$的矩阵，但不需要存储完整的矩阵数据，只需要存储该矩阵的头和尾即刻，因为矩阵内部的数据都可以由第一行矩阵数据和最后一行矩阵数据拼接而来。

Stencil2row方法是基于以下三个观察结果提出的：
1. 当原始输入被转换为im2row矩阵时，im2row矩阵中的大多数元素是冗余的，这种转换导致内存爆炸。例如，图2中$1^{st}$到$6^{th}$行的元素都与$0^{th}$和$7^{th}$行的元素重复。
2. 在im2row转换中，观察到冗余行中的数据序列已经存储在冗余行之中。
	- 例如，图中im2row矩阵的$3^{rd}$行可以分为两部分（棕色和浅蓝色）。第一部分（棕色）的数据序列可以在$0^{th}$行中找到，而第二部分（浅蓝色）的数据序列可以在$7^{th}$行中找到。这个观察结果表明，中间行（例如$1^{st}$到$6^{th}$行）的冗余数据结构可以由其他行（例如$0^{th}$和$7^{th}$行）替代，这意味着可以仅通过其他行构造出中间行的结果。
3. 共享内存位于芯片上，因此其延迟比全局内存低得多。表2显示了不同类型内存的访问延迟。全局内存的访问延迟比共享内存高出一个数量级以上。
	- <div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241012224720.png" width="500"></img></div>


基于这三个观察结果，本文提出了**stencil2row**方法。Stencil2row将原始输入转换为两个较小的矩阵。在图2中，这两个矩阵标记为**Stencil2row矩阵A和B**。Stencil2row矩阵A的第0行可以看作是im2row矩阵第0行的扩展。**Stencil2row矩阵A的第0行扩展到原始输入矩阵的最后一行**。换句话说，Stencil2row矩阵A的最后一个元素是原始输入矩阵最后一行的元素。接下来，**Stencil2row矩阵A的第1行可以看作是im2row矩阵第8行的扩展**。这种模式继续下去，从而构建了Stencil2row矩阵A。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241012222839.png" width="100%"></img></div>

Stencil2row矩阵A的映射函数表示为方程(5)中的向量函数：$Y = stencil2row_A(X)$

$$
Y =
\begin{bmatrix}
\left\lfloor \frac{y}{(n_{kernel} + 1)} \right\rfloor \\
n_{kernel}x + y \mod (n_{kernel} + 1)
\end{bmatrix}
$$
其中
$$
X =
\begin{bmatrix}
x \\
y
\end{bmatrix}, \ (y + 1) \mod  (n_{kernel} + 1) \neq 0
$$

$X$ 表示原始输入元素的索引，$Y$ 表示Stencil2row矩阵A中元素的索引，$n_{kernel}$ 是核的边长。


Stencil2row矩阵B的构建方式类似，如方程(6)所示：$Y = stencil2row_B(X)$
$$
Y =
\begin{bmatrix}
\left\lfloor \frac{(y - n_{kernel})}{(n_{kernel} + 1)} \right\rfloor \\
n_{kernel}x + (y - n_{kernel}) \mod (n_{kernel} + 1)
\end{bmatrix}
$$
其中
$$
X =
\begin{bmatrix}
x \\
y
\end{bmatrix}, \ ((y - n_{kernel} + 1) \mod (n_{kernel} + 1) \neq 0)
$$

在定义了如何构造Stencil2row矩阵后，我们根据不同的全局内存和共享内存的访问延迟，隐式地在共享内存中构建Stencil2row矩阵。在NVIDIA GPU的环境下，我们从全局内存中读取原始数据，然后在共享内存中动态构建Stencil2row矩阵的块，并利用张量核心从共享内存中读取数据进行矩阵计算。<font color='red'><b>在整个过程中，Stencil2row矩阵不会显式地完全构建出来</b></font>。

Stencil2row消除了im2row矩阵中的大多数冗余元素，缓解了内存压力。此外，Stencil2row不仅保留了im2row的优点，使得可以使用矩阵乘法，还更适合于张量核心专门进行Stencil计算。更重要的是，我们<font color='red'><b>在加载原始输入数据时动态地在共享内存中构建Stencil2row矩阵的块，这减少了全局内存的读写操作</b></font>。在Stencil2row转换之后，通过双重镶嵌（在3.3节介绍）由张量核心对矩阵进行计算。在详细描述了Stencil2row之后，我们从内存节省和数据传输节省的角度对Stencil2row的优势进行了定量分析。

#### Memory saving

对于 stencil2row 数据布局，将原始输入转换为两个矩阵。每个矩阵的行数和列数分别为：

$$m_{stencil2row}=\frac n{n_{kernel}+1}$$
$$n_{stencil2row}=n_{kernel}\times m$$
其中 m 和 n 表示输入的尺寸。

对于 im2row 数据布局，im2row 矩阵的行数和列数分别为：

$$

m_{im2row}=mn

$$
$$

m_{im2row}=(m - n_{kernel} + 1) \times (n - n_{kernel} + 1) 

$$
$$n_{im2row}=n_{kernel}^2$$

因此， stencil2row 和 im2row 占用的存储空间比例为：

$$\frac{stencil2row}{im2row}=\frac2{(n_{kernel}+1)n_{kernel}}$$


<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241012232610.png" width="500"></img></div>

上表显示了 im2row 和 stencil2row 与各种形状的输入内存相比的内存扩展的乘法因子，以及 stencil2row 与 im2row 相比减少的内存量。与 im2row 相比，stencil2row 在所有形状中减少了超过70% 的内存使用。


#### Data Transfer Saving

**节省数据转换开销**：虽然Stencil2row相比于im2row减少了70%以上的内存扩展，但传输这些数据仍然是一个相当大的开销。全局内存与共享内存/寄存器之间的数据传输代价较高。Stencil2row在两个方面节省了数据传输：
1. 首先，Stencil2row隐式地在共享内存中构建Stencil2row矩阵的块。ConvStencil只进行一次全局内存的读写操作，因此不会增加全局内存读写操作的开销。
2. 其次，与im2row相比，Stencil2row减少了内存空间的占用，从而减少了写入共享内存的数据量。由于很难完全消除共享内存中的写入bank冲突，因此通过Stencil2row减少写入共享内存的数据量，对性能提升更有帮助。


### 3.3 自适应计算

在完成布局转换后，接下来的问题是如何在Stencil2row矩阵上利用张量核心（Tensor Cores）高效地计算Stencil结果。为了解决这个问题，本文提出了双重镶嵌（dual tessellation）方法，以便高效利用张量核心进行Stencil计算。同时，还利用内核融合（kernel fusion）进一步提高张量核心的利用率。

#### Dual Tessellation

将现有的基于GEMM的卷积方法应用于Stencil计算可能会导致张量核心（Tensor Cores）利用率低下和内存爆炸问题。Stencil2row转换减少了内存需求，因此需要基于Stencil2row矩阵高效利用张量核心进行Stencil计算。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013112320.png" width="800"></img></div>

可以观察到，im2row矩阵中冗余行的顺序已经存储在非冗余行中。此外，<font color='red'><b>这些冗余具有明确的模式</b></font>。在图中，展示了冗余行可能由多个三角形组成。**棕色三角形中的每个元素都包含在第一个非冗余行中，而蓝色三角形中的每个元素则包含在第二个非冗余行中**。由于这个特点，能够基于Stencil2row矩阵在张量核心上构建一个高效的Stencil算法。

我们提出了双重镶嵌（dual tessellation），这是一种基于Stencil2row转换的全新Stencil计算算法。双重镶嵌通过迭代调用来逐步计算所有的Stencil。每次双重镶嵌**首先构建两个半结果矩阵，称为vitrolite A和vitrolite B。然后，将这两个vitrolite结果相加，得到最终的Stencil计算结果**，这一过程被称为“镶嵌”。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013111028.png" width="100%"></img></div>
<center> <font face='华文宋体' size='4'> Dual tessellation的简化过程 </font> </center>



在图中，**双重镶嵌**包含三个步骤。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013115055.png" width="100%"></img></div>

在**步骤1**中，从Stencil2row矩阵A中提取的一个**块（tile）需要与权重矩阵A相乘以构建vitrolite A**。我们分别介绍块和权重矩阵A。

双重镶嵌过程是迭代地从Stencil2row矩阵A中提取块。这个块由8行组成，因为矩阵中的行数在张量核心进行左乘时是8，块的列数是$n_{kernel}^2$ （因为一个kernel可以覆盖的元素个数为该值）。如图中Box-2D49P所示，块的大小是$8 \times 49$。**每次双重镶嵌都会从Stencil2row矩阵A中提取一个不同的块**。方程给出了每个块的基地址：

$$
\text{base address}_i = 8n_{stencil2row} \left\lfloor \frac{i}{m} \right\rfloor + (i \mod m)n_{kernel}
$$

其中$i \in {0, 1, 2, \cdots}$。直观上，这意味着每个块在双重镶嵌后会向右移动$n_{kernel}$个元素。第一组8行计算完成后，接下来的一组8行将继续处理，直到Stencil2row矩阵A的末尾。

权重矩阵A的大小为$n_{kernel}^2 \times n_{kernel}$。在图中，权重矩阵的大小为49 × 7，并且为了适应张量核心的MMA操作，填充为49 × 8。权重矩阵A由七个下三角矩阵拼接而成。权重矩阵A的第一列包含所有49个权重（$a_1 \sim a_{49}$），因此Stencil2row矩阵A中的块与第一列的乘积计算出8个完整的Stencil结果。

在图3中，这个乘积是vitrolite A（半结果矩阵A）的第一列，标注为最深的红色。权重矩阵A的第二到第七列包含部分权重，因此vitrolite A的第二到第七列构成部分Stencil计算结果。图中的红色渐变表示Stencil计算完成的比例。权重矩阵A的最后一列全为零，这也导致vitrolite A的最后一列也全为零，如图中白色所示。此时，已经构建了vitrolite A并完成了步骤1。

**步骤2**与步骤1相似，但它从Stencil2row矩阵B中提取块，并使用不同的权重矩阵B。权重矩阵B由上三角矩阵组成。这样设计的目的是为了使两个乘积矩阵能够直接相加。**Vitrolite B**是Stencil2row矩阵B中的块与权重矩阵B相乘的结果。在精心设计下，**Vitrolite B与Vitrolite A相反：它的第一列完全由零组成，而最后一列包含完整的Stencil计算结果，每个位置都直接与Vitrolite A相对应**。

在**步骤3**中，称为**镶嵌**（tessellation），通过将Vitrolite A和Vitrolite B相加，得到了Stencil计算的结果。第一次双重镶嵌的结果索引为$[3][3:66]$。最后，将结果写回到全局内存中。由于张量核心MMA操作可以融合矩阵乘法和累加，因此在实现中，我们并没有单独计算Vitrolite A和Vitrolite B并将它们相加。相反，在计算Vitrolite A之后，Vitrolite B的每次矩阵乘法结果直接累加到Vitrolite A上。这种方法为每次双重镶嵌减少了一次MMA操作。

在一次双重镶嵌中，MMA操作的次数为 $2 \times \left\lceil \frac{n_{kernel}^2}{4} \right\rceil$ 。对于Stencil计算，双重镶嵌显著提高了张量核心的利用率，并且与我们的Stencil2row转换方法兼容。


#### Kernel Fusion

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013121053.png" width="500"></img></div>

双重镶嵌适用于任何Stencil内核。然而，一些小内核难以有效利用张量核心。因此，我们**对某些Stencil内核进行了时间融合**，以提高张量核心中的计算密度。例如，在图4中，Box-2D9P的权重矩阵A只有3列，浪费了张量核心片段中的5列。**为了提高张量核心的利用率，我们进行了两次时间融合**，将Box-2D9P转换为Box-2D49P。经过内核融合后，张量核心片段只浪费1列，从而提高了张量核心的利用率。

📒：这两次时间融合是如何进行的？？？？
  

#### Quantitative Performance Analysis

**计算时间分析**：

为了更好地理解ConvStencil在与卷积相比之下的Stencil计算中的优势，我们对ConvStencil的性能进行了定量分析。我们基于第3.1节中讨论的理论性能模型，分析了ConvStencil与基于GEMM的卷积的性能。根据公式(2)，由于总时间是计算时间和内存访问时间中的最大值，我们分别分析了计算时间和内存访问时间。

每次双重镶嵌都会计算Stencil。因此，对于一个$m \times n$的输入，所需的双重镶嵌次数为：
$$

\frac{mn}{8n_{kernel} + 8}

$$
由于一次双重镶嵌中MMA操作的次数为 $2 \times \frac{n_{kernel}^2}{4}$，ConvStencil所需的MMA操作次数如公式13所示。
$$N_{MMA}=\frac{2mn}{8\times(n_{kernel}+1)}\left\lceil\frac{n_{kernel}^2}4\right\rceil $$
因此，ConvStencil的计算时间为：
$$\mathcal{T}_{\text{compute}_{ConvStencil}}=\frac{\frac{2mn}{8(n_{kernel}+1)}\left\lceil\frac{n_{kernel}^2}4\right\rceil\times CPI_{tcu} }{ f N _ {tcu}}$$
在A100 FP64上下文中，$f$ 为1410 MHz，$N_{tcu}$ 为432，$CPI_{tcu}$ 为16个周期。

然而，使用基于GEMM的卷积来计算Stencil的计算时间为：

$$\mathcal{T}_{\text{compute}_{GEMM-basedConv} }=\frac{\frac{n_{kernel}^2mn}{32}\times CPI_{tcu} }{ f N _ {tcu}}$$

由于Stencil的阶数总是大于1，即 $n_{kernel} \geq 3$，因此ConvStencil的计算时间比基于GEMM的卷积要少。

  
**内存访问时间分析**：我们假设基于GEMM的卷积实现是隐式的，不会引入加载或存储全局内存数据的额外开销。因此，基于公式(4)，$data_R$、$data_W$、$bw_G$ 和 $bw_S$ 都是常量。我们只需要分析 $data_{transW}$ 和 $data_{transR}$。如公式11所示，ConvStencil的 $data_{transW}$ 仅为基于GEMM卷积的 $\frac{2}{(n_{kernel}+1)n_{kernel}}$，而 $data_{transR}$ 为基于GEMM卷积的 $\frac{2}{n_{kernel}+1}$。因此，ConvStencil的内存访问时间比基于GEMM的卷积少。

综上所述，由于ConvStencil的计算时间和内存访问时间均少于基于GEMM的卷积，ConvStencil在Stencil计算方面优于基于GEMM的卷积。

### 3.4 冲突消除

在引入布局转换和计算适配后，ConvStencil中隐藏的三个冲突削弱了其性能：
1. 在布局转换中不可避免地**涉及大量的整数除法和取模运算**，这会导致计算中断与连续数据传输之间的冲突。
2. 在双重镶嵌过程中出现的**内存bank冲突**限制了共享内存的带宽。
3. 由于Stencil2row矩阵A或B比原始输入小，因此需要使用条件语句来判断数据是否需要处理。这些**条件分支引入了线程控制中的冲突**。
为了解决这三个冲突，引入了**查找表**和“**脏位填充**”（dirty bits padding）技术。

#### Lookup Table

在布局转换过程中，**需要计算地址指针偏移量以将数据从全局内存传输到共享内存**。这些计算包含大量的整数除法和取模操作，而这些操作在GPU上非常耗时。此外，这些偏移量的计算在不同的块之间是重复的。**为了减少布局转换过程中的计算开销，我们在主机端预先计算这些指针偏移量，并将它们作为查找表提供给CUDA内核使用**。

#### Dirty Bits Padding

<font color='red'><b>填充区域用于缓解内存bank冲突，并通过填充无效数据来消除条件分支语句</b></font>。在双重镶嵌过程中，当张量核心从共享内存加载Stencil2row矩阵的数据时，通常会发生内存bank冲突。**内存bank冲突发生在同一个warp中的多个线程同时访问同一个内存bank的不同地址时**。硬件会将这个请求拆分为多个独立的无冲突请求，从而降低共享内存的吞吐量。

我们**通过填充额外的空间来改变数据映射到共享内存的方式，从而消除共享内存中的bank冲突**。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013124814.png" width="500"></img></div>

图5举例说明了Stencil2row矩阵A（266列）中的填充如何消除加载bank冲突。在A100 GPU上，bank的大小为4字节，这意味着一个FP64元素占据2个bank。在CUDA WMMA API中，一个warp（32个线程）加载一个8 × 4的矩阵片段，因此每个线程读取一个FP64元素。然而，32个FP64元素占据64个bank，而一个warp可以同时从多达32个不同的bank中读取数据。因此，<font color='red'><b>一个8 × 4矩阵片段的读取由两个共享内存请求组成</b></font>。**前16个线程读取前部的4 × 4片段，后16个线程读取后部的4 × 4片段**。因此，检查银行bank的单位应为一个4 × 4的片段。

在图中，如果不使用填充，$A[0][0:3]$ 和 $A[3][4:7]$ 都落在bank0-3，导致第一个请求的bank冲突。第二个请求的情况类似。通过填充两个FP64元素，第一个和第二个4 × 4片段的请求被均匀分布到32个不同的bank，从而消除了加载bank冲突。

然而，通常情况下，填充区域在改变内存布局后是浪费的。我们发现可以将未使用的数据（脏位）填充到填充空间中，从而消除条件分支和相应的计算操作。如第3.2节所述，Stencil2row将原始输入转换为两个矩阵，每个矩阵的大小都小于原始矩阵。这意味着对于每个转换后的矩阵，一些输入元素无法映射到转换后的矩阵中，从而引入了条件分支和相应的比较操作。正如图5所示，通过使用脏位填充，未使用的数据通过查找表映射到填充区域，并不会被使用。经过这一优化后，不再需要条件分支语句来选择要使用的数据，从而提高了Stencil计算的性能。

## Generalization

在介绍了ConvStencil在二维中的实现后，ConvStencil可以轻松推广到其他维度。

### 4.1 一维（1D）

对于一维Stencil，Stencil2row矩阵的形状发生变化。Stencil2row矩阵的行数和列数分别为 $n / (n_{kernel} + 1)$ 和 $n_{kernel}$，其中 $n_{kernel}$ 表示核的长度，$n$ 表示输入的大小。经过布局转换后，ConvStencil的一维计算过程与二维ConvStencil相同。通过迭代地应用双重镶嵌来计算所有Stencil。

  

### 4.2 三维（3D）

**三维Stencil计算可以分解为具有不同权重的二维Stencil计算，这些权重通过ConvStencil计算，然后在不同的二维平面上相加**。在星形的三维Stencil中，每个二维平面的大小不同。我们使用CUDA核心来计算小平面，而对于大平面则使用张量核心。尽管商用GPU尚未提供显式实现张量核心和CUDA核心并行计算的warp调度接口，但同时利用张量核心和CUDA核心可以为GPU调度提供机会，从而并行利用这两种计算单元。


## Evaluation

### 5.1 实验设置

**实现**：我们使用CUDA C++和WMMA API实现了ConvStencil，并通过NVCC 12.2编译。

**平台**：我们的实验平台由AMD EPYC 7V13处理器和NVIDIA A100张量核心GPU组成。我们使用的A100 GPU通过PCIe Gen4连接到主板，传输带宽为64GB/s。A100 GPU拥有80GB的HBM2e内存，内存带宽为1935GB/s。A100 GPU具有108个SM（流式多处理器），每个SM包含4个张量核心。张量核心的FP64峰值性能为19.5 TFLOPS。平台还配备了8通道的216GB DDR4 DRAM内存。

**最先进的对比方法**：我们将ConvStencil与多种最先进的技术进行了对比，包括cuDNN、AMOS、Brick、DRStencil和TCStencil，均在FP64精度下进行。我们使用cuDNN卷积API，并设置 $channel = 1$ 来使用FWD_IMPLICIT_PRECOMP_GEMM算法进行Stencil计算，这与ConvStencil最为相关。AMOS支持深度卷积，其计算等同于Stencil操作。由于AMOS需要进行空间搜索以找到更好的映射，我们在进行了1000次搜索后的结果中进行对比。TCStencil仅支持FP16精度的Stencil计算。由于张量核心上FP16和FP64的矩阵形状不同，无法直接转换为FP64精度。在相同的内存带宽下，读取和写入FP16数据的速度是FP64的四倍。此外，在A100的张量核心上，FP16的计算速度是FP64的16倍。因此，如果将TCStencil修改为支持FP64，在最理想的情况下，其速度（以GStencils/s计）将降为原来的四分之一。因此，在我们的评估中，我们通过将TCStencil的速度除以4进行比较。

**基准测试**：我们应用了多种Stencil核来进行基准测试，包括Heat-1D、1D5P、Heat-2D、Box-2D9P、Star-2D13P、Box-2D49P、Heat-3D和Box-3D27P。具体细节见表4。这些Stencil核涵盖了一维、二维和三维的多种典型计算模式，用于评估ConvStencil的性能表现。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013152552.png" width="500"></img></div>

**度量标准**：大多数关于Stencil的研究使用GStencils/s（或GCells/s）来展示其结果，表示每秒更新的Stencil点的数量，其定义见公式16：
$$
GStencils/s = \frac{T \times \prod_{x=1}^{n} N_x}{t \times 10^9}
$$
其中，$T$ 表示迭代轮数，$N_x$ 表示第$x$维度的问题大小，$t$ 表示执行时间。


### 5.2 性能分析

在本小节中，我们探讨了ConvStencil从不同优化中获得的收益。我们展示了ConvStencil在三个基准测试上的性能分解，包括Heat-1D、Box-2D9P和Box-3D27P，因为这些基准测试代表了不同维度中的复杂形状。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013153022.png" width="500"></img></div>

从图中可以看出，Stencil2row转换相较于全局内存中的显式转换，分别在Heat-1D、Box-2D9P和Box-3D27P中提供了22%、170%和67%的加速。这种性能提升源于减少了数据传输。Stencil2row在全局内存中对原始数据进行了100%的读写操作，而没有引入任何额外的全局内存事务开销。

接下来，ConvStencil引入了张量核心（Tensor Cores）。由于张量核心强大的FP64浮点计算能力，性能分别提升了76%、68%和44%。

然后，我们使用填充（paddings）来减少GPU中共享内存的银行冲突。填充改变了数据在共享内存bank中的布局，消除了加载bank冲突。在ConvStencil中，读取操作的次数远超过写入操作的次数。尽管写入操作仍存在bank冲突，我们在Heat-1D、Box-2D9P和Box-3D27P中分别获得了1%、14%和10%的性能提升。Heat-1D中的填充性能提升相对不明显，主要是因为Heat-1D的Stencil2row矩阵列数和读取操作较少，因此填充的收益相对较小。

然而，普通的填充技术中的填充区域通常是空白且浪费的。最后，我们提出了脏位填充（dirty bits padding）技术，利用这些区域并消除了条件分支。在这一阶段，我们的性能指标分别提升了4%、19%和13%。


### 5.3 最先进技术对比

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013153152.png" width="100%"></img></div>

在图中，ConvStencil展现出了相对于所有最先进技术的显著性能优势。

**在卷积方面**，与cuDNN相比，ConvStencil的性能提升最少为2.89倍，最多达到42.62倍。这一结果归因于cuDNN未使用张量核心，并且未针对单通道的情况进行优化。虽然AMOS将Stencil计算映射到张量核心上，但其性能甚至比cuDNN还差，因为它执行了直接且未优化的Stencil到张量核心的映射，浪费了大部分张量核心的计算能力。

**在Stencil方面**，ConvStencil相比Brick实现了平均2.77倍的加速。相较于DRStencil，ConvStencil也实现了平均2.02倍的整体加速。在Heat-2D和Box-2D9P中，TCStencil的性能优于DRStencil，但仍然明显落后于ConvStencil。尽管TCStencil使用了张量核心，但其低效表现源于其算法并非最优，导致张量核心计算中大部分元素为零。此外，如表5所示，每个请求的非合并全局访问次数和银行冲突次数明显多于ConvStencil，导致了性能下降。

### 5.4 内核融合带来性能提升

虽然本文没有涉及时间块化（temporal blocking），但我们应用了内核融合技术来增加计算密度，适用于某些合适的形状。本节探讨了内核融合技术带来的性能提升。

<div style={{ textAlign: 'center' }}><img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20241013153657.png" width="100%"></img></div>

图8展示了ConvStencil和DRStencil在融合3个时间步（DRStencil-T3）情况下的性能对比。对于二维形状，输入规模步长为256，而对于三维形状，输入规模步长为32。正如图8所示，ConvStencil在绝大多数情况下优于DRStencil-T3。在Heat-2D和Box-2D9P的情况下，当输入大小超过$768^2$和$512^2$时，ConvStencil的性能超过DRStencil-T3。当性能趋于稳定时，ConvStencil相较于DRStencil-T3分别实现了1.42倍和2.13倍的加速。


在Heat-3D和Box-3D27P的情况下，当输入大小超过$288^3$和$128^3$时，ConvStencil的性能超过DRStencil-T3。性能稳定后，ConvStencil在Heat-3D和Box-3D27P中分别实现了1.63倍和5.22倍的加速。另一个现象是ConvStencil在三维内核中的性能波动。这是由于输入规模步长为32，而ConvStencil使用的空间平铺（spatial tiling）步长为64所导致的。本文未涉及DRStencil中与空间和时间块化相关的其他优化。

通过与DRStencil-T3的对比，我们得出结论：**性能提升并非主要来源于内核融合**。

## Related Work

在CPU上对Stencil计算的优化与加速一直是广泛研究的主题。向量化利用SIMD指令来提升Stencil计算的性能。数据重用技术优化了指令的执行顺序，减少加载或存储操作，从而降低寄存器压力。分块技术利用多重循环嵌套的数据局部性来加速Stencil计算，例如菱形分块、时间倾斜分块、矩形分块和镶嵌分块。在GPU上的Stencil优化同样被广泛研究。分块技术在GPU上同样具有强大效果，包括空间分块和时间分块。此外，GPU上的Stencil优化还包括循环展开、预取和流式处理。

Brick技术在Stencil计算的细粒度块内挖掘数据重用机会，实现了在CPU和GPU之间的性能可移植性。DRStencil通过融合-分区优化加速了Stencil计算，并将其实现为一个高效的代码生成框架。上述研究主要聚焦于CUDA核心，而少数研究探索了张量核心在Stencil中的应用。据我们所知，TCStencil是唯一将张量核心应用于Stencil计算的研究，然而它仅支持FP16精度，限制了其实用性。cuDNN是NVIDIA为深度学习开发的库，提供了高度优化的基础函数实现，例如卷积。AMOS将不同的软件操作映射到不同的硬件单元，包括张量核心，并支持计算上等同于Stencil操作的深度卷积。

## Conclusion

本文介绍了ConvStencil，将Stencil计算转换为在张量核心上的矩阵乘法。受基于GEMM的卷积启发，ConvStencil由布局转换、计算适配和冲突消除三部分组成。我们的评估显示，这些设计是有效的，ConvStencil的性能优于现有的最先进技术。我们相信并期待ConvStencil能够提升各种科学和工程应用的性能。

