<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="Abstract"><meta data-rh="true" property="og:description" content="Abstract"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.0287982b.css">
<script src="/assets/js/runtime~main.6e1bc470.js" defer="defer"></script>
<script src="/assets/js/main.c1d9f81a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper-notes-intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs-intro">个人博客</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper-notes-intro">笔记说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/LU/intro">LU</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/LU/intro">说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/LU/A Communication-Avoiding 3D LU Factorization Algorithm for Sparse Matrices/知识补充">A Communication-Avoiding 3D LU Factorization Algorithm for Sparse Matrices</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/LU/A communication-avoiding 3D sparse triangular solver/论文原件">A communication-avoiding 3D sparse triangular solver</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/LU/Making Sparse Gaussian Elimination Scalable by Static Pivoting/阅读笔记">Making Sparse Gaussian Elimination Scalable by Static Pivoting</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/论文原件">Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记">阅读笔记</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/Kernel/intro">Kernel</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">LU</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">阅读笔记</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>阅读笔记</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#abstract">​</a></h2>
<p><strong>背景:</strong> 现有的分布式稀疏矩阵直接求解器大多采用multifrontal/super-nodal 模式来聚合相同几乎相同形式的列，并利用dense BLAS 再进行计算。这种方法的缺点是：当输入的矩阵结构不理想时，这样的数据结构可能会带来更多的不均衡性，而且使用dense BLAS 可能会在fill-in上浪费很多浮点运算。</p>
<p><strong>本篇文章</strong>：提出新的直接求解器算法--PanguLU。</p>
<ul>
<li>与之前的方法不同的是，该工作依赖于更加简单的常规<strong>二维块状结构</strong>，并且<strong>以稀疏的形式存储块</strong>，从而避免额外的填充。</li>
<li>同时，根据二维块的稀疏模式，开发并选择了<strong>多种块级稀疏BLAS方法</strong>，从而可以在本地GPU上实现更高的效率。</li>
<li>为了提高PanguLU的可扩展性，<strong>调整了区块到进程的映射</strong>，从而使得整体的工作量更加均衡。</li>
<li>考虑到不同子任务之间的依赖性，提出一种<strong>同步免费通信策略</strong>，减少了总体延迟开销。</li>
</ul>
<p><strong>测试效果</strong>：在由 128 个英伟达 A100 GPU 和 128 个 AMD MI50 GPU 组成的两个分布式异构平台上进行的实验表明 ，与最新的 SuperLU_DIST 相比，PanguLU 的速度分别提高了 11.70 倍和 17.97 倍，与单个 GPU 相比，在 128 个 A100 和 MI50 GPU 上的速度分别提高了 47.51 倍和 74.84 倍。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#1-introduction">​</a></h2>
<p>线性方程<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax=b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>直接求解的步骤：先进行LU分解，随后再进行上三角或下三角求解器求解。</p>
<p>与稠密矩阵LU分解不同的是，稀疏矩阵的LU分解需要分为三个阶段来适应稀疏性：<strong>reordering</strong>、<strong>symbolic factorisation</strong>、<strong>numeric factorisation</strong>。</p>
<ul>
<li>reordering：减少填充非零点，保持数值稳定性。</li>
<li>symbolic factorisation：确定矩阵L和U的结构。</li>
<li>numeric factorisation：进行LU分解（<strong>数值因式分解阶段通常包含大量浮点运算</strong>，因此近年来许多直接求解器将<strong>数值因式分解阶段的并行性</strong>作为单线程处理器、多线程处理器、异构处理器  和分布式内存系统的主要优化方向）。</li>
</ul>
<p>在进行完LU分解之后，现在的大多是求解器（例如：SuperLU）使用<strong>multifrontal</strong>和<strong>super-nodal</strong>来<strong>聚合密集列</strong>，以使用密集 BLAS，从而为具有许多类似列结构的矩阵提供良好的可扩展性和性能。但是，在分布式内存系统中，它可能会<strong>对不规则矩阵造成性能问题</strong>。<font color="red">要么是聚集的相似列太少（导致扩展性不足），要么是使用了太多的零填充来聚集更多的相似列（导致计算效率降低）。</font></p>
<p>本篇文章提出一个比较新颖的直接求解器用于分布式异构系统的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax=b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>的求解--PanguLU。</p>
<p>PanguLU 使用规则的二维区块进行布局，并<strong>以块内稀疏子矩阵为基本单元</strong>，构建了一种新的分布式稀疏LU分解算法。由于存储的矩阵块是稀疏的，因此利用稀疏BLAS进行计算，进而避免不必要的填充，并优化稀疏属性，使得计算更加高效。</p>
<p>对于在具有异构处理器的大规模超级计算机上，使用直接求解器具有以下几个挑战：</p>
<ul>
<li>
<p>如何平衡各个分布式处理器之间的<strong>工作负载</strong></p>
<ul>
<li>设计一种静态块映射方案来<strong>平衡负载</strong></li>
<li>思路：计算每个任务的相应权重，权重高的任务会及时迁移到负载较轻的进程，从而平衡每个进程的工作量。</li>
</ul>
</li>
<li>
<p>如何基于稀疏矩阵结构设计适当的<strong>并行算法</strong>，从而利用异构加速器的优势</p>
<ul>
<li>引入专用的稀疏BLAS设计，<strong>使用不同的并行方法开发17个稀疏内核</strong></li>
<li>设计<strong>决策树</strong>方法，根据稀疏矩阵的结构选择更快的稀疏内核</li>
</ul>
</li>
<li>
<p>如何降低具有不规则稀疏结构依赖性的进程之间<strong>同步成本</strong></p>
<ul>
<li>设计无同步调度策略，该策略使用无同步阵列，<strong>允许分布式系统中的每个进程计算尽可能多的可执行稀疏内核</strong>，并确保稀疏LU因子分解的正确性。</li>
<li>减少同步开销来提高性能</li>
</ul>
</li>
<li>
<p>为了使 PanguLU 更具可扩展性，我们设计了一个块映射方案来调整每个进程的任务，来更好地平衡它们之间的负载；</p>
</li>
<li>
<p>我们为PanguLU开发并设计了专用的稀疏BLAS，包含了许多不同的并行方法，此外还设计了一个选择树的方法根据矩阵的稀疏结构特性选择更快的稀疏BLAS；</p>
</li>
<li>
<p>我们还关注在分布式系统上不同子任务之间的依赖关系，设计了一种无同步调度策略，在分布式系统中尽可能多地进行计算，从而减少整个计算过程的延迟成本；</p>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-background">2-Background<a class="hash-link" aria-label="Direct link to 2-Background" title="Direct link to 2-Background" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#2-background">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-dense-lu-and-its-block-algorithm">2.1 Dense LU and its Block Algorithm<a class="hash-link" aria-label="Direct link to 2.1 Dense LU and its Block Algorithm" title="Direct link to 2.1 Dense LU and its Block Algorithm" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#21-dense-lu-and-its-block-algorithm">​</a></h3>
<p>稠密矩阵的LU分解算法，就是高斯分解的算法表示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231119211523.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>为了提高性能，可以利用数据的空间位置提出了一种<strong>块LU 因式分解算法</strong>。该算法采用固定大小的分块法，每个分块的处理都独立于其他分块。对角线块从矩阵的左上角到右下角依次执行。相同颜色的区块可同时处理，以充分利用并行性。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231119212815.png" alt="image.png" class="img_ev3q"></p>
<p>[[A Communication-Avoiding 3D LU Factorization Algorithm for Sparse Matrices##^818cc3|SuperLU论文中的依赖关系]]</p>
<p>对角线区块从矩阵的左上角到右下角依次执行。相同颜色的图块可以同时处理，以充分利用并行性。例如，当块𝐴11 完成 LU 因式分解后，三角块𝑈11 和𝐿11 可以同时对𝐴21、𝐴31、𝐴12 和𝐴13 进行三角求解。然后，四个区块可以同时进行舒尔补码，更新 𝐴22、𝐴23、𝐴32 和 𝐴33。接下来以类似的方式计算对角线块，直到处理完最后一个对角线块，标志着块 LU 因式分解的完成。显然，块 LU 因式分解涉及大量具有复杂依赖关系的计算，对并行性能有很大影响。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-sparse-lu-and-its-multi-frontal--super-nodal-algorithms">2.2 Sparse LU and its Multi-frontal / Super-nodal Algorithms<a class="hash-link" aria-label="Direct link to 2.2 Sparse LU and its Multi-frontal / Super-nodal Algorithms" title="Direct link to 2.2 Sparse LU and its Multi-frontal / Super-nodal Algorithms" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#22-sparse-lu-and-its-multi-frontal--super-nodal-algorithms">​</a></h3>
<p>在求解大规模稀疏线性系统时，稀疏LU分解通常被认为优于密集LU分解。这种偏好是由于<strong>在进行稀疏矩阵的密集LU分解时，由于稀疏矩阵中存在大量的零元素计算，从而引起冗余计算，这样会使得计算效率变低</strong>。</p>
<p>稀疏LU分解可分为三个阶段:重新排序、符号分解和数值分解。下图显示了一个带有细节的稀疏LU分解示例。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231119234716.png" alt="image.png" class="img_ev3q"></p>
<ul>
<li>重新排序：某些行和列重新排序方法通常用于在符号因子填充阶段之前<strong>最小化非零填充</strong>。</li>
<li>符号分解：在图(c)所示的符号相位中，引入了额外的非零填充来<strong>确定三角形矩阵𝐿和𝑈的稀疏模式</strong>，并提前为数值相位分配空间。这个阶段涉及创建因子分解所需的数据结构，但不执行任何数值计算。它包括<strong>在不计算因子L和U的数值的情况下确定它们的结构</strong>。这一步骤有助于估计结果因子的内存需求和结构。</li>
<li>数值计算：在数值阶段，执行必要的浮点运算以确定𝐿和𝑈中的值。由于浮点运算的复杂性和广泛性，数字分解通常需要很长时间。此外，由于矩阵的稀疏性和分布不均匀，会导致数据访问模式的不均匀，从而增加了计算时间。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="multi-frontal-method">Multi-frontal method<a class="hash-link" aria-label="Direct link to Multi-frontal method" title="Direct link to Multi-frontal method" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#multi-frontal-method">​</a></h4>
<p>The multifrontal [36] method is proposed based on the rightlooking sparse LU factorisation. This method reorganises sparse matrices into a sequence of partial factorisation of smaller dense matrices. The elimination tree [25, 57, 72] is used to identify the rows and columns of the matrix involved in each factorisation step. It is usually constructed according to the following rule: Consider each diagonal element as a node, and a node 𝑘 is a child of a node 𝑗 in the elimination tree if the factorisation of the diagonal element 𝑗 follows the diagonal element 𝑘.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="super-nodal-method">Super-nodal method<a class="hash-link" aria-label="Direct link to Super-nodal method" title="Direct link to Super-nodal method" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#super-nodal-method">​</a></h4>
<p>Unlike the multifrontal method,the supernodal [24] method merges a number of similar row structure columns to form supernodes. As shown in Figure 1(d), the layout of the supernodal method includes crosses representing the additional zero fill-ins introduced during the supernode formation process. In addition, the supernodal method of identifying columns with similar row structures can be challenging due to the identification of the unevenness in matrix structures.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-motivation">3-Motivation<a class="hash-link" aria-label="Direct link to 3-Motivation" title="Direct link to 3-Motivation" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#3-motivation">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-uneven-block-sizes">3.1 Uneven Block Sizes<a class="hash-link" aria-label="Direct link to 3.1 Uneven Block Sizes" title="Direct link to 3.1 Uneven Block Sizes" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#31-uneven-block-sizes">​</a></h3>
<p>许多研究都提出了稀疏 LU 因式分解的优化算法，例如超节点法，它将具有相同非零模式的列集中在一起，作为密集块进行计算。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231120164601.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>显示了两种典型矩阵的supernode大小的显著差异，可以看出，由超级节点生成的矩阵块可能非常不规则，这会影响计算和存储效率，并且不规则的结构使得难以在内核级别优化性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-redundant-zero-fill-ins">3.2 Redundant Zero Fill-ins<a class="hash-link" aria-label="Direct link to 3.2 Redundant Zero Fill-ins" title="Direct link to 3.2 Redundant Zero Fill-ins" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#32-redundant-zero-fill-ins">​</a></h3>
<p>Multifrontal算法和Supernodal算法<strong>将矩阵划分为不均匀的密集块</strong>，使用第 3 级 BLAS 例程进行计算，这可能会导致两个问题。</p>
<ul>
<li>在形成密集块时可能会出现多余的零填充，从而增加额外的浮点运算。</li>
<li>在对密集块进行 GEMM 计算时，无法利用矩阵的局部稀疏性，从而可能导致性能下降。</li>
</ul>
<p>在图 4 中，参与 GEMM 运算的块矩阵密度显示出巨大差异。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231120165518.png" alt="image.png|center|800" class="img_ev3q"></p>
<p><strong>块矩阵密度</strong>是指：上面的算法将矩阵分为不均匀的密集块，说的是这个块中非零元素与所有元素的比值。
<strong>Density</strong>是指：块矩阵密度在一定范围内的数量和这个稀疏矩阵可以被分为密集块的总数量的比值。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="33-high-synchronization-costs">3.3 High Synchronization Costs<a class="hash-link" aria-label="Direct link to 3.3 High Synchronization Costs" title="Direct link to 3.3 High Synchronization Costs" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#33-high-synchronization-costs">​</a></h3>
<p>SuperLU_DIST 使用level-set method生成消除树，并将<strong>树节点作为最小调度单元</strong>。<strong>树节点由多个密集的 BLAS 操作组成</strong>，<strong>每个层级之间都有依赖关系，需要在完成时同步</strong>，因此会产生额外的同步开销。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231120165828.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>在图 5 中，我们展示了 SuperLU_DIST（在 64 个英伟达 A100 GPU 上，从 1 到 64 个进程）在不同应用的六个矩阵上的同步成本比。如图所示，<strong>同步成本随着进程数的增加而逐渐增加，在 64 个进程时，同步成本可占总计算时间的 60%</strong>。因此，对于一些同步时间比例较高的矩阵，我们可以<strong>考虑降低同步成本来探索优化空间</strong>。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-pangu-lu">4-PanGu LU<a class="hash-link" aria-label="Direct link to 4-PanGu LU" title="Direct link to 4-PanGu LU" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#4-pangu-lu">​</a></h2>
<p>PanGuLU--新的用于分布式异构系统的直接求解器，包括五个主要的步骤：</p>
<ol>
<li><strong>reordering</strong>
<ul>
<li>使用<font color="##c00000">MC64算法</font>来保持数值稳定性</li>
<li>使用<font color="##c0000000">METIS算法</font>来减少符号分解过程中的非零填充。</li>
</ul>
</li>
<li><strong>symbolic</strong> <strong>factorisation</strong>
<ul>
<li>相比非对称剪枝法，PanguLU 的符号因式分解法采用了<font color="##c0000000">对称剪枝法</font>，以降低计算复杂度并提高性能。</li>
</ul>
</li>
<li><strong>preprocessing</strong>
<ul>
<li>预处理将矩阵划分为子矩阵块，并将它们发送给每个进程。</li>
<li>块的大小根据矩阵阶数和符号因式分解后的矩阵密度计算得出，以平衡计算和通信。</li>
<li>每个进程构建自己的双层稀疏结构。</li>
</ul>
</li>
<li><strong>numeric</strong> <strong>factorisation</strong>
<ul>
<li>数值因式分解包含大量浮点运算，以确定𝐿 和𝑈 的数值。</li>
</ul>
</li>
<li><strong>triangular</strong> <strong>solve</strong>
<ul>
<li>使用三角解法求解 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi><mi>y</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ly = b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mi>x</mi><mo>=</mo><mi>y</mi></mrow><annotation encoding="application/x-tex">Ux = y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">Ux</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span> 的最终解 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> 为向量，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span> 为已知值。</li>
</ul>
</li>
</ol>
<p>为了使PanguLU能够更好地利用异构分布式系统的计算能力，提出了一种新的稀疏LU数值分解算法。它由三个主要的组件组成，以消除现有工作的缺点:</p>
<ul>
<li>(1)<strong>规则的二维稀疏块结构</strong>;<!-- -->
<ul>
<li>PanguLU将原始矩阵分割成几个大小相等的块，并使用(CSC)格式存储它们。</li>
<li>为了平衡进程之间的计算负载，开发了一种映射方法来重新分配计算负载</li>
</ul>
</li>
<li>(2)<strong>自适应稀疏BLAS内核</strong>;<!-- -->
<ul>
<li>在PanguLU的数值分解中，由于矩阵块是稀疏的，我们开发了四个专用的稀疏核:<strong>一般三角分解</strong>(GETRF)、<strong>稀疏下三角解</strong>(GESSM)、<strong>稀疏上三角解</strong>(TSTRF)和<strong>稀疏-稀疏矩阵乘法的Schur补</strong>(SSSSM)。对于具有不同结构和不同方法的稀疏块，稀疏BLAS的性能差异很大。因此，我们设计自适应稀疏BLAS，根据输入稀疏矩阵的结构选择合适的算法，加快计算速度。</li>
</ul>
</li>
<li>(3)<strong>无同步调度策略</strong>。<!-- -->
<ul>
<li>为了更好地减少分布式系统上的同步开销，PanguLU提出了一种<strong>无同步调度控制策略</strong>。该策略使用稀疏核作为最小调度单元。无同步阵列用于执行调度和维护正确性。</li>
<li>每个进程首先执行最高优先级的稀疏内核。</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-data-layout-and-mapping">4.2 Data Layout and Mapping<a class="hash-link" aria-label="Direct link to 4.2 Data Layout and Mapping" title="Direct link to 4.2 Data Layout and Mapping" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#42-data-layout-and-mapping">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="双层稀疏结构存储矩阵">双层稀疏结构存储矩阵<a class="hash-link" aria-label="Direct link to 双层稀疏结构存储矩阵" title="Direct link to 双层稀疏结构存储矩阵" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#双层稀疏结构存储矩阵">​</a></h4>
<p>PanguLU 使用规则的二维分块，分块大小相等，按照<strong>二维进程网格</strong>分配给每个进程。每个进程使用<font color="##c0000000">双层稀疏结构</font>来存储矩阵。</p>
<ul>
<li>在块层，我们使用<strong>基于块的 CSC 格式来压缩非零块</strong>。</li>
<li>在每个块内，<strong>子矩阵块也采用 CSC 格式存储</strong>。</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231120181354.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>子矩阵块由常规的二维分块法产生，连续编号的灰色块表示包含非零的子矩阵块。空块用空白表示。<strong>非空块分配给二维进程网格中的四个进程，每个进程用一种独特的颜色标识</strong>。<strong>每个进程只存储用于计算的重要子矩阵块，并利用子矩  阵块在原始矩阵中的位置信息来促进通信</strong>。这项工作使用三个辅助数组（blk_ColumnPointer、blk_RowIndex 和 blk_Value）来存储子矩阵块的位置。它们分别存储每列中非零子矩阵块的前缀和、矩阵分块后每个非零子矩阵块的行索引及其子矩阵块指针。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231120181607.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>第二层的稀疏结构如图所示。<strong>子矩阵块内的非零点用 CSC 格式进行压缩存储</strong>，我们可以看到第六个子矩阵块的存储结果。从上节可以看出，子矩阵块的计算使用了四个主要内核。GETRF 将输入矩阵 𝐴 因式分解为下三角矩阵 𝐿 和上三角矩阵 𝑈；GESSM 和 TSTRF 执行下三角或上三角求解；SSSSM 执行舒尔补码运算。</p>
<p>值得注意的是，这种<strong>双层稀疏结构没有显著的额外开销</strong>，因为我们只需要三个额外数组就能有效地表示和访问块级稀疏结构。</p>
<p>此外，PanguLU还在预处理过程中为每个进程拥有的子矩阵块分配所需的内存，并为计算所需的矩阵 L 和 U 分配空间，以便通过重复使用空间最大限度地减少内存消耗。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="实现负载均衡">实现负载均衡<a class="hash-link" aria-label="Direct link to 实现负载均衡" title="Direct link to 实现负载均衡" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#实现负载均衡">​</a></h4>
<ul>
<li>GETRF：一般三角分解，将输入矩阵 𝐴 因式分解为下三角矩阵 𝐿 和上三角矩阵 𝑈；</li>
<li>GESSM：稀疏下三角解，专门用于计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>U</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mi>L</mi><mrow><mi>i</mi><mi>i</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">U_{ij}=L_{ii}^{-1}A_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1403em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8542em"><span style="top:-2.4231em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ii</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span></li>
<li>TSTRF：稀疏上三角解,专门用于计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>j</mi><mi>i</mi></mrow></msub><msubsup><mi>U</mi><mrow><mi>i</mi><mi>i</mi></mrow><mrow><mo>−</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">L_{ji}=A_{ji}U_{ii}^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1403em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ji</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8542em"><span style="top:-2.4231em;margin-left:-0.109em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ii</span></span></span></span><span style="top:-3.1031em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2769em"><span></span></span></span></span></span></span></span></span></span></li>
<li>SSSSM：稀疏矩阵-稀疏矩阵乘法的Schur补更新，执行舒尔补码运算。</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205122148.png" alt="image.png|center|100" class="img_ev3q">
<center> <font face="华文宋体" size="5">   采用SuperLU中进程的分布方式 </font> </center></p>
<font color="red">相应任务的权重可通过计算内核的 FLOPs 得出。</font>
<p>基于双层稀疏结构，我们实施了静态负载平衡策略，即<strong>在数值因式分解前进行预处理，通过计算每个时间片上不同进程的权重（每个权重对应一个任务）来平衡负载</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205121522.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图 6(c) 和 6(d) 分别显示了多进程下 LU 数值因式分解的五个时间片和子矩阵块的依赖图，其中彩色的子矩阵块代表需要计算的子矩阵块，里面的数字代表进程编号，内核图标旁边的数字表示特定计算的权重。</p>
<p>例如，在第一个时间片中，需要计算子矩阵块 1、2、9、12、13 和 16，其中子矩阵块 1 执行 GETRF，子矩阵块 2、9 和 13 执行 GESSM 或 TSTRF，子矩阵块 12 和 16 执行 SSSSM，这些子矩阵块之间的依赖关系如依赖关系如上图所示。整个 LU 因式分解按时间片顺序运行完成。</p>
<p>图 6(c)和图 6(d)的上下图分别表示负载平衡前后的子矩阵块分布。我们根据<font color="red"><b>每个进程的总权重</b></font>和<font color="red"><b>每个进程在不同时间片上的权重</b></font>，对第一层结构执行细粒度负载平衡。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205152230.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="5"> 负载平衡的计算 </font> </center>
在第二个时间片中，我们在总权重最高的进程 1 和任务数最少的进程 2 之间平衡负载。为此，我们交换了该时间片中分配给这两个进程的所有任务，从而使子矩阵块 4 的 GESSM 从进程 2 转移到进程 1，如图 6（c）和图 6（d）下部的子图所示。由于子矩阵块 4 的 GESSM 权重，这种负载平衡使进程 1 的权重增加了 4，而进程 2 的权重则减少了相同的数量。</p>
<p>同样，在第三个时间片中，我们进行了负载平衡，改变了每个进程的总计算权重。如图所示，我们计算了每个进程的总权重进行比较，结果显示本例中的负载已达到一定的平衡水平。这种静态策略由预处理完成，主要开销是计算权重，与数值因式分解相比，时间开销很小。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sparse-kernels-and-algorithm-selection">Sparse Kernels and Algorithm Selection<a class="hash-link" aria-label="Direct link to Sparse Kernels and Algorithm Selection" title="Direct link to Sparse Kernels and Algorithm Selection" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#sparse-kernels-and-algorithm-selection">​</a></h3>
<p>稀疏内核的性能对于数值因式分解至关重要，并受到矩阵密度、结构和大小等多种因素的影响。因此，优化稀疏内核并为每种情况选择更好的算法成为实现整体性能提升的一项重要任务。为此，我们在盘古LU中实现了<strong>17个稀疏内核</strong>（3个GETRF、5个GESSM、5个TSTRF和4个SSSSM，如表1所示），然后根据大量性能数据构建了稀疏内核算法选择策略，从而选择出性能更好的内核。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205152442.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="5"> 17个计算内核 </font> </center>
表 1 中，&quot;C_V𝑖 &quot;和 &quot;G_V𝑖 &quot;分别表示 CPU 和 GPU 版本的内核。</p>
<p>寻址方法 &quot;表示如何对计算值进行定位或者更新</p>
<ul>
<li>其中 &quot;直接 &quot;表示在密集空间中直 接更新数据，</li>
<li>&quot;二分搜索 &quot;表示通过在稀疏空间中搜索更新数据</li>
<li>&quot;合并 &quot;表示通过逻辑合并两组稀疏空间更新数据。</li>
</ul>
<p>此外，&quot;稠密映射 &quot;与 &quot;直接 &quot;相对应，表示稀疏结构映射到稠密空间，计算通过稠密空间寻址分配遍历稀疏结构，其中 SSSSM 仅将结果矩阵 𝐶 映射到稠密空间。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205154931.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="5"> 17个运行核的矩阵运行测试 </font> </center></p>
<p>我们在盘古模型中演示了所有这些稀疏内核的性能，运行表 3 所示矩阵时，GETRF 产生 4550 个子矩阵，GESSM 和 TSTRF 产生 18786 个子矩阵，SSSSM 产生 86982 个子矩阵（实验平台详情见第 5.1 节）。</p>
<p>这些<strong>内核的性能各不相同，没有一个能始终保持最佳性能</strong>，但如果根据矩阵特性以适当的方式组合这些内核，整体性能就会得到极大提高。</p>
<p>我们从大量数据中汲取养分，并<strong>专注于为每个矩阵块选择更合适的稀疏内核</strong>，开发出<font color="red"><b>四种决策树来指导我们的算法选择过程</b></font>。这些决策树如图 8 所示。对于属于面板因式分解的 GETRF、GESSM 和 TSTRF，必须<font color="red"><b>主要根据矩阵中存在的非零（nnz）数量来选择最合适的算法</b></font>。对于 SSSSM，则主要基于计算中涉及的 FLOP。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205155150.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="5"> 指导17种算法选择的4个决策树 </font> </center></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="44-synchronisation-free-scheduling">4.4 Synchronisation-Free Scheduling<a class="hash-link" aria-label="Direct link to 4.4 Synchronisation-Free Scheduling" title="Direct link to 4.4 Synchronisation-Free Scheduling" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#44-synchronisation-free-scheduling">​</a></h3>
<p>在本节中，我们将介绍 PanguLU 提出的无同步调度策略。它使用<strong>稀疏内核作为最小调度单元</strong>，以优化分布式系统内的并行效率。</p>
<p>我们<font color="red"><b>通过在进程间传输无同步数组的值来实现细粒度进程调度，从而使尽可能多的进程处于工作状态</b></font>。这项工作中的无同步调度策略旨在减少舒尔补码中（除了 LU 同步的数据依赖性而导致的隐式同步（比如，树节点之间的同步）之外）的冗余同步开销，以实现更高的并行性。这一策略包括两个主要部分。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="无同步数组的构造">无同步数组的构造<a class="hash-link" aria-label="Direct link to 无同步数组的构造" title="Direct link to 无同步数组的构造" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#无同步数组的构造">​</a></h4>
<p>第一部分是构建无同步数组。在预处理阶段进行处理。</p>
<p><strong>一个子矩阵块可以执行多个内核，包括 GETRF、GESSM、TSTRF 和 SSSSM，其中 SSSSM 可以多次执行</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205161819.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="5"> 无同步数组的创建 </font> </center></p>
<p>负责一个子矩阵块的进程的工作状态会受到其他相关子矩阵块状态的影响。我们  构建了<font color="red"><b>一个无同步数组来记录每个子矩阵块的剩余工作量</b></font>，其值等于该子矩阵块仍需执行 GESSM、TSTRF 或 SSSSM 的次数，每次执行时减去 1。</p>
<p>对角矩阵需要进行一般的LU分解，因此，当它的对角线矩阵块对应的数组数值为0时，需要执行GETRF操作，在完成后将该值减去1，当子对角线上的值变为-1时，则对角线所对应的行子矩阵块的 TSTRF 依赖关系和相应列的 GESSM 依赖关系将被打破，然后会将这些打破依赖关系的进程会将<strong>相对应的计算内核</strong>添加到该进程的计算队列中。</p>
<p>需要注意的是，由于对角矩阵的特殊性，当对角子矩阵块对应的数组数据值为 0 时，需要执行 GETRF 操作，并在完成后将该值减去 1。</p>
<ul>
<li>如果<strong>对角子矩阵块</strong>对应的数组值为-1，则相应行子矩阵块的 TSTRF 依赖关系和相应列的 GESSM 依赖关系将被打破。</li>
<li>如果<strong>非对角线子矩阵块</strong>的数组值为 0，则其对应行或列子矩阵块的 SSSSM 依赖关系将被打破。</li>
</ul>
<font color="red"><b>与依赖关系被打破的子矩阵块相对应的进程会将相应的内核添加到计算队列中。</b></font>
<p>箭头方向表示子矩阵块之间的依赖关系，数字表示子矩阵块的剩余工作量，数字的颜色表示其所属进程。</p>
<p>这里的工作量表示子矩阵块仍需执行 GESSM、TSTRF 或 SSSSM 的次数。子矩阵块 1 的 GETRF 不带箭头，数组上的值为 0。对于有三个箭头的子矩阵块 16，无同步数组上的变量值为 3。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="更新无同步数组管理进程的计算和通信">更新无同步数组，管理进程的计算和通信<a class="hash-link" aria-label="Direct link to 更新无同步数组，管理进程的计算和通信" title="Direct link to 更新无同步数组，管理进程的计算和通信" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#更新无同步数组管理进程的计算和通信">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205174137.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>(1) 每个进程开始时都会将无同步数组中变量为 0 的内核标记为可执行，并将内核添加到任务队列中。然后，进程会检查当前是否有可执行内核。如果是，它将开始计算稀疏内核。否则，它会等待其他进程发送所需的子矩阵块。</p>
<p>(2)进程开始计算可执行内核。如果有多个可执行内核，则按优先级顺序选择。计算结束后，进程更新自己的无同步数组，并将子矩阵块发送给其他需要的进程。在图 10 中，(2a) 表示内核的计算，(2b) 表示该进程无同步数组的更新和新内核的添加，(2c) 表示向其他进程发送子矩阵块。</p>
<p>(3)进程将等待来自其他进程的子矩阵块。当进程收到来自其他进程的子矩阵块时，就可以添加新的可执行内核，然后更新无同步数组。如图 10 所示，（3a）表示进程正在等待来自其他进程的子矩阵块，（3b）表示进程正在接收来自其他进程的子矩阵块，释放可执行内核并更新无同步数组。</p>
<p>PanguLU提出的无同步策略可以在一定程度上重新降低同步成本。在计算过程中，每个进程总是选择要计算的最关键的任务进行计算，使关键路径上的任务的计算速度尽可能快，从而使更多的进程处于计算状态。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experimental-results">EXPERIMENTAL RESULTS<a class="hash-link" aria-label="Direct link to EXPERIMENTAL RESULTS" title="Direct link to EXPERIMENTAL RESULTS" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#experimental-results">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="51-experimental-setup">5.1 Experimental Setup<a class="hash-link" aria-label="Direct link to 5.1 Experimental Setup" title="Direct link to 5.1 Experimental Setup" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#51-experimental-setup">​</a></h3>
<p>我们在两个不同的 32 节点 128个 GPU 分布式集群上进行了实验，一个是英伟达 A100 GPU，另一个是 AMD MI50 GPU。两个平台的硬件信息见表 2。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205175508.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>NVIDIA GPU 平台使用 CUDA 11.3.0 和驱动程序 510.85.02。AMD GPU 平台使用 ROCm-4.3.1。对于这两个平台，我们使用 gcc- 9.3.0、OpenMPI-4.1.2 和 cmake-3.23.1 编译 SuperLU_DIST 和 PanguLU。</p>
<p>我们在每个节点上使用了四个 MPI 进程，每个进程独立占用一个英伟达 A100 或一个 AMD MI50 GPU。</p>
<p>第 5.2、5.4、5.5 和 5.6 节中的实验基于 A100 GPU 平台，而第 5.3 节中的实验基于 A100 GPU 和 MI50 GPU 平台。</p>
<p>关于数据集，我们使用了SuiteSparse Matrix Collection[22]中不同领域的16个代表性稀疏矩阵，大部分测试矩阵选自SuperLU_DIST论文[67, 69]中常用的矩阵。这些矩阵的详细信息如表 3 所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205175738.png" alt="image.png|center|600" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-symbolic-factorisation-time">5.2 Symbolic Factorisation Time<a class="hash-link" aria-label="Direct link to 5.2 Symbolic Factorisation Time" title="Direct link to 5.2 Symbolic Factorisation Time" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#52-symbolic-factorisation-time">​</a></h3>
<p>我们首先比较了 SuperLU_DIST 和 PanguLU 的<strong>符号因式分解时间</strong>。两个求解器都使用串行符号因式分解算法。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205181104.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>不同之处在于，<font color="red"><b>SuperLU_DIST 采用剪枝和超级节点相结合的方式进行符号因式分解</b></font>，而 <font color="red"><b>PanguLU 则将矩阵对称化，并使用对称剪枝来加快符号因式分解的速度</b></font>。与 SuperLU_DIST 相比，PanguLU 的几何平均速度快 4.45 倍，在 cage12 矩阵中最高快 6.80 倍。特别是在一些结构化矩阵上，如 audikw_1 和 nlpkkt80，PanguLU 的速度显著提高，分别提高了 3.51 倍和 4.59 倍。我们还注意到，<strong>虽然对称剪枝会带来额外的填充，尤其是对于高度非对称矩阵，但与 SuperLU_DIST 相比，我们的方法在测试矩阵上平均减少了约 11% 的填充</strong>，表 3 显示了较低的填充数量。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="53-scalability-of-numeric-factorisation">5.3 Scalability of Numeric Factorisation<a class="hash-link" aria-label="Direct link to 5.3 Scalability of Numeric Factorisation" title="Direct link to 5.3 Scalability of Numeric Factorisation" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#53-scalability-of-numeric-factorisation">​</a></h3>
<p>在使用 1、2、4、8、16、32、64 和 128 个 A100 GPU 和 MI50 GPU 进行的实验中，评估了 SuperLU_DIST 和 PanguLU 在数值因式分解中的性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205181225.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>与 SuperLU_DIST 相比，PanguLU 在 NVIDIA GPU 平台和 AMD GPU 平台上的平均速度分别提高了 2.53 倍和 2.79 倍，速度范围分别为 1.10 倍 - 11.70 倍和 1.12 倍 - 17.97 倍。此外，对于 SuperLU_DIST 可以很好处理的结构化 audikw_1 矩阵，盘古鲁班在英伟达和 AMD GPU 平台上分别实现了 1.10 倍和 1.12 倍的性能优势。对于 ASIC_680k 等不规则矩阵，PanguLU 的性能优势尤为显著，在两个 GPU 平台上的速度分别提高了 11.70 倍和 17.97 倍。该实验还证明了<strong>盘古LU在分布式异构系统上的良好可扩展性</strong>。例如，随着 GPU 数量的增加，PanguLU 在 Ga41As41H72 矩阵上实现了良好的性能。与单个 GPU 相比，PanguLU 在 128 个 A100 GPU 和 128 个 MPI50 GPU 上的性能分别提高了 47.51 倍和 74.84 倍。但对于一些矩阵，如 apache2 和 ecology1，SuperLU_DIST 和 PanguLU 的可扩展性会随着 128 个 GPU 的增加而降低。<strong>这种下降主要是由于通信成本的增加，尽管使用更多的 GPU 可以加快计算速度。</strong></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="54-kernel-time-on-a-single-gpu">5.4 Kernel Time on a Single GPU<a class="hash-link" aria-label="Direct link to 5.4 Kernel Time on a Single GPU" title="Direct link to 5.4 Kernel Time on a Single GPU" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#54-kernel-time-on-a-single-gpu">​</a></h3>
<p>我们比较了 SuperLU_DIST 和 PanguLU 在单个 A100 GPU 上的内核时间。表 4 显示，在整个计算内核中，PanguLU 的减少平均时间是 SuperLU_DIST 的 6.54 倍。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205181822.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>SuperLU_DIST 和 PanguLU 都是<strong>基于原始块进行面板因式分解</strong>，性能差异主要是计算方法造成的。</p>
<p>在舒尔补法中，SuperLU_DIST 需要将<strong>子矩阵块聚集在一起，执行矩阵乘法，将它们分散到相应的位置，然后执行减法。</strong></p>
<p>PanguLU 直接在原始矩阵块上执行舒尔补码，大大减少了数据移动开销。此外，PanguLU 使用稀疏内核进行计算，而 SuperLU_DIST 使用密集内核。因此，在处理 ASIC_680k 等不规则矩阵时，PanguLU 使用稀疏计算的优势非常明显，能带来更显著的速度提升。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="55-synchronisation-cost-on-128-gpus">5.5 Synchronisation Cost on 128 GPUs<a class="hash-link" aria-label="Direct link to 5.5 Synchronisation Cost on 128 GPUs" title="Direct link to 5.5 Synchronisation Cost on 128 GPUs" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#55-synchronisation-cost-on-128-gpus">​</a></h3>
<p>我们还比较了 SuperLU_DIST 和 PanguLU 在 128 个 A100 GPU 上的同步时间。PanguLU 采用<strong>无同步调度策略来减少同步开销</strong>，实验结果（图 13）表明，它对大多数矩阵都很有效，与 SuperLU_DIST 相比，平均同步时间缩短了 2.20 倍。此外，对于 Hook_1498 和 audikw_1 等结构化矩阵，SuperLU_DIST 更容易形成超级节点，使计算更有规律，同步开销与 PanguLU 相当。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205181948.png" alt="image.png|center|800" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="56-effects-of-different-optimisations">5.6 Effects of Different Optimisations<a class="hash-link" aria-label="Direct link to 5.6 Effects of Different Optimisations" title="Direct link to 5.6 Effects of Different Optimisations" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#56-effects-of-different-optimisations">​</a></h3>
<p>在第4.3节和4.4节中，我们描述了PanguLU中用于提高性能的两种优化，即稀疏内核选择和无同步调度策略。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205182150.png" alt="image.png|center" class="img_ev3q"></p>
<p>在这里，我们通过实验分析我们的优化效果。图14显示了三个版本的PanguLU在128 A100 gpu上的性能比较。与基线版本相比，PanguLU通过基于矩阵结构选择更有效的内核，实现了1.0到2.2倍(平均1.7倍)的速度提升。对于cage12和Hook_1498矩阵，稀疏ker通道选择非常有效，速度分别提高了2.2倍和2.1倍。特别是，ASIC_680k矩阵具有1.0倍的加速。由于该矩阵固有的稀疏性和不规则的非分布，使用基稀疏核可以获得较高的计算性能。</p>
<p>我们还使用稀疏内核选择和无同步调度策略在128 A100 gpu上测试了PanguLU的性能。最终，PanguLU实现了从2.3倍到5.4倍(av平均3.8倍)的提速。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="57--preprocessing-cost">5.7  Preprocessing Cost<a class="hash-link" aria-label="Direct link to 5.7  Preprocessing Cost" title="Direct link to 5.7  Preprocessing Cost" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#57--preprocessing-cost">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231205182213.png" alt="1|center|800" class="img_ev3q">
最后，为了充分展示我们工作的整体性能，我们还比较了SuperLU_DIST和PanguLU的预处理时间，结果如图15所示。</p>
<p>与SuperLU_DIST相比，PanguLU对大多数测试矩阵的预处理阶段都更快，平均提高了1.61倍，最高可达3.16倍。特别是对于G3_circuit和inline_1等稀疏矩阵，PanguLU的预处理速度分别提高了3.16倍和2.40倍。然而，对于Serena和Si87H76 ma版本，由于<strong>矩阵结构和转换2D块布局的更高开销</strong>，PanguLU比SuperLU_DIST略慢，速度分别为0.91x和0.89x</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="related-work">Related work<a class="hash-link" aria-label="Direct link to Related work" title="Direct link to Related work" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#related-work">​</a></h2>
<p>在过去的几十年里，人们做了很多工作来加速稀疏直接求解。例如，通过旋转来保持LU分解的数值稳定性[24,31,35,37,38,54]，通过重新排序[5,6,19,20,51]来减少稀疏LU分解的计算量，加速符号分解[40,41,41,445]，提高数值面分解的并行性[14,16,29,56,63,64,70,76]，以及实现更高的稀疏三角形求解性能[12,26,58 - 60]。无论如何，稀疏直接求解器的并行性仍然有提高的空间，主要是由于以下三个挑战。</p>
<p><font color="red"><b>稀疏直接求解器面临的第一个挑战是如何保持稀疏 LU 因子分解的稀疏特性，并充分利用现代超级计算机的可扩展性。</b></font>Duff 和 Reid [36] 提出了多前沿方法，Demmel 等人 [24] 和 Li 等人 [53, 55] 发展了超节点方法。这些方法要求将输入矩阵转换成相对规则的模式，方法是收集相似的列，将它们组合成密集子矩阵，并使用密集 BLAS 进行计算。很多工作 [4, 10, 21, 28, 39, 42, 43, 77, 80] 都在这两种方法的基础上进行了优化，因为它们不仅具有保留稀疏特性的优势，还能有效提高处理规则矩阵时的可扩展性。此外，Gupta [47, 48] 通过使用任务并行引擎偷取任务，实现了更好的负载平衡。Amestoy 等人[7]利用基于多前沿算法的动态任务调度来实现分布式系统的负载平衡。Duff 等人[34]综合利用新的负载平衡和通信最小化技术来提高可扩展性。Sao 等人[65-67]提出了一种避免通信的三维算法，以平衡超级节点的负载，提高求解器的可扩展性。然而，多前沿和超节点方法在很大程度上依赖于矩阵结构，这可能导致在不规则矩阵上的性能不理想。在本文中，PanguLU提出了分布式求解器设计的新思路，即使用更简单的规则二维分块方法来利用矩阵的稀疏特性，并通过将计算任务映射到不太繁忙的进程来平衡负载。</p>
<p><font color="red"><b>第二个挑战是如何更好地利用异构处理器来加速稀疏LU因式分解。</b></font>Ren等 ［62］基于GPU架构优化工作分区以加速LU因式分解，Chen等 ［13］结合GPU任务级和数据级并行的特点，优化了电路仿真中的稀疏LU因式分解。He等 ［49］、Lee等 ［52］、Peng和Tan ［61］开发了GLU，在GPU上使用级集方法执行稀疏LU因式分解。然而，这种方法在内核调用之间往往需要大量的同步时间。为了降低同步成本，Zhao等人［81］开发了SFLU，它使用一种无同步算法来提高GPU上的并行性。然而，这些优化都是基于单个 GPU 的 LU 因式分解优化，而这通常会受到内存限制。因此，Xia 等人 ［78］ 提出了一种端到端的方法来解决单个 GPU 的内存限制问题。随着大规模超级计算机的发展，这推动了许多将LU因式分解扩展到分布式异构系统的工作，如Gaihre等人［44］利用GPU的高吞吐量加速符号因式分解。Sao 等人［69］开发了将小的密集 BLAS 运算聚合成大的 BLAS 运算以利用 GPU 的能力。Tian等人[75]在Sunway多核架构的层次结构上优化计算内核，以提高并行效率和缓存利用率。所有这些研究都基于异构架构设计了更好的并行方法。 与他们相比，我们设计了一种具有 17 个稀疏内核的分块稀疏 BLAS，以及一种根据矩阵结构选择稀疏内核的决策树方法，以提高 GPU 上的并行效率。</p>
<p><font color="red"><b>第三个挑战是如何减少大规模分布式系统中的同步开销。</b></font>通信成本一直是制约分布式求解器性能的主要瓶颈之一。现有的分布式求解器使用了很多方法来降低通信成本。例如，Amestoy 等人[9]采用了一种利用异步通信的动态调度策略，通过在 MUMPS 中重叠通信和计算，有效避免了通信成本。Schenk 等人[71]在 PARDISO 中设计了一种动态两级调度方案，以减少缓存冲突和处理器间通信成本。在 SuperLU_DIST 中，Sao 等人[68]提出了一种 HALO 算法，以隐藏分布式 Xeon Phi 系统中的通信成本。此外，Agullo 等人[2]和 Tan 等人[74]使用流水线方法重叠计算和通信，以提高分布式求解器的性能。Grigori 等人[46]提出的 CALU 是一种避免通信的 LU 因式分解算法，可尽可能避免通信成本。然而，<strong>很少有人关注如何有效减少分布式系统中 LU 因式分解的同步开销</strong>。在这项工作中，我们提出了无同步调度策略，允许每个进程尽可能多地计算，减少同步开销，从而提高分布式求解器的性能。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#conclusion">​</a></h2>
<p>在本文中，我们提出了PanguLU，一个可扩展的规则二维块循环稀疏直接求解器在分布式异构平台形式。在PanguLU中，设计了一种映射方法用于负载平衡，选择了多种块稀疏BLAS方法以提高GPU上的效率，并开发了一种无同步通信通信策略以降低  总体延迟成本。我们的实验结果表明，PanguLU比最新的SuperLU_DIST在128个NVIDIA A100 GPU和128个AMD MI50 GPU上的速度提高了11.70倍和17.97倍，在单个GPU上的速度分别提高了47.51倍和74.84倍。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/paper_notes/2_LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/Kernel/intro"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">说明</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#abstract">Abstract</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#1-introduction">1-Introduction</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#2-background">2-Background</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#21-dense-lu-and-its-block-algorithm">2.1 Dense LU and its Block Algorithm</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#22-sparse-lu-and-its-multi-frontal--super-nodal-algorithms">2.2 Sparse LU and its Multi-frontal / Super-nodal Algorithms</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#3-motivation">3-Motivation</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#31-uneven-block-sizes">3.1 Uneven Block Sizes</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#32-redundant-zero-fill-ins">3.2 Redundant Zero Fill-ins</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#33-high-synchronization-costs">3.3 High Synchronization Costs</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#4-pangu-lu">4-PanGu LU</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#42-data-layout-and-mapping">4.2 Data Layout and Mapping</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#sparse-kernels-and-algorithm-selection">Sparse Kernels and Algorithm Selection</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#44-synchronisation-free-scheduling">4.4 Synchronisation-Free Scheduling</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#experimental-results">EXPERIMENTAL RESULTS</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#51-experimental-setup">5.1 Experimental Setup</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#52-symbolic-factorisation-time">5.2 Symbolic Factorisation Time</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#53-scalability-of-numeric-factorisation">5.3 Scalability of Numeric Factorisation</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#54-kernel-time-on-a-single-gpu">5.4 Kernel Time on a Single GPU</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#55-synchronisation-cost-on-128-gpus">5.5 Synchronisation Cost on 128 GPUs</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#56-effects-of-different-optimisations">5.6 Effects of Different Optimisations</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#57--preprocessing-cost">5.7  Preprocessing Cost</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#related-work">Related work</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/LU/Pangu LU A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems/阅读笔记#conclusion">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper-notes-intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs-intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>