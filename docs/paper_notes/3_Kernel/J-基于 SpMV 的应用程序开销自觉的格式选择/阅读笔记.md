# 阅读笔记

## Abstract

稀疏矩阵向量乘法(SpMV)是许多应用中的一个重要核心，往往是性能的主要瓶颈。稀疏矩阵的存储格式严重影响了 SpMV 的性能。

尽管以往的研究都是为给定的矩阵选择合适的格式，但是<font color='red'><b>他们忽略了运行时预测开销和格式转换开销的影响</b></font>。对于 SpMV 的许多常见用途，这种开销是执行时间的一部分，可能超过新格式的好处。忽略它们使得以前的解的预测经常是次优的，有时是次优的。另一方面，<font color='red'><b>开销是很难考虑的</b></font>，因为它连同拥有一个新格式的好处，因矩阵而异，因应用而异。

这项工作提出了一个解决方案。首先探讨了<font color='red'><b>在格式选择问题中各种可能的处理方法对开销的利弊</b></font>。然后，提出了一个显式的方法，其中包括几个回归模型，以<font color='red'><b>捕捉格式转换的开销和好处对整体程序性能的影响</b></font>。它提出了一个两阶段的惰性和轻量级方案，以**帮助控制格式预测中的风险，同时最大限度地提高总体格式转换的好处**。实验表明，该技术的性能明显优于以往的技术。它将应用程序的整体性能提高了1.14 X 至1.43 X，明显大于0.82 X 至1.24 X 的上行加速开销-遗忘方法可以给出的结果。

## Introduction

稀疏矩阵向量乘(SpMV)是在许多科学应用(如线性方程组求解器)中最重要、最广泛使用的核之一。这也常常是这些应用程序的性能瓶颈。最大化 SPMV 的性能是至关重要的。人们观察到，<font color='red'><b>影响 SpMV 性能的一个重要因素是选择合适的格式来表示内存中的稀疏矩阵</b></font>。针对不同的应用场景和计算机体系结构，提出了不同的存储格式。正如在许多研究中所观察到的，<font color='red'><b>不同的格式可能会大大影响数据本地化，缓存性能，并最终影响 SpMV 的端到端性能</b></font>(多达几倍)。同时，**对于所有的稀疏矩阵，没有找到最佳的单一格式**。矩阵的正确格式取决于许多因素，包括稀疏矩阵的特性、硬件结构、 SpMV 库的实现、应用等。

已经有一些工作致力于为SpMV创建自动格式选择器。例如，Li等人开发了基于决策树的分类器，针对给定的稀疏矩阵，预测SpMV在哪种存储格式上运行最快。后续研究通过其他机器学习模型构建了类似的预测器。尽管这些研究提供了一些希望和宝贵见解，但它们都受到一个重要限制。它们是<font color='red'><b>开销不可知</b></font>的——也就是说，**在使用这些预测器和采纳其预测时没有考虑开销的影响，包括所需格式转换的实质性开销成本。**

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240320220458.png)
<center> <font face='华文宋体' size='4'> 图 1 一个受益于改进矩阵格式应用程序的典型工作流程 </font> </center>
图1说明了这个原则性问题。在实际设置中，基于 SpMV 的应用程序的输入矩阵通常只有一种默认存储格式。要使用更好的格式，必须执行两个步骤: **预测使用哪种格式**，以及**将矩阵转换为新格式**。在许多情况下，这两个步骤需要在应用程序执行期间发生。因此，总时间是这些开销(预测的$T_p$和转换的$T_c$)和新格式上 SpMV 的执行时间($T_e$)的总和。也就是下面的公式：
$$
\texttt{Overall Time: }T(G,A,f)=T_p(A)+T_c(A,f)+T_e(G,A,f)
$$
<mark> <b>先前的研究都试图构建预测因子来预测最小化 Te 的格式，忽略了 Tp 和 Tc 的影响，这两者加起来可能比 SpMV 的执行时间更长</b></mark>。因此，尽管以前的预测器具有很好的预测精度，但是它们所预测的格式在实际应用中往往表现出较差的性能。即使先验方法可以达到理想的预测精度，但由此得到的结果仍然会导致整体执行速度的显著减慢。如下图2所示：
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240403100207.png)
<center> <font face='华文宋体' size='4'> 图 2 : 程序 PageRank 使用以前的基于决策树的预测器时的整体加速度的直方图，该预测器具有理想化的100% 准确性(图1中用于最小化 Te)。注释的数字分别表示加速比 小于1，等于1，大于1的样本的百分比; 小于1表示减速。CSR 是默认格式。 </font> </center>

这项工作的目标是通过考虑开销来解决问题，以预测SpMV存储格式。<font color='red'><b>解决方案需要创建能够准确预测新存储格式的整体效果（而不仅仅是SpMV性能）的预测器</b></font>。

创建这样一个预测器是具有挑战性的，它面临着一系列新的复杂性。
- 首先，它需要考虑更多因素。（不仅仅是矩阵的特征，还有程序使用该矩阵的频率等因素）
	- 以前的预测模型只根据输入矩阵的特征进行预测，因为这些特征是决定哪种格式使得 SpMV 在给定架构上运行最快的唯一因素。然而，当目标变为<font color='red'><b>最小化总体时间</b></font>时，仅凭矩阵特性已不足以进行预测，因为我们<font color='red'><b>需要将新格式带来的益处与运行时开销进行比较</b></font>。这时，在考虑采用新的存储格式对稀疏矩阵向量乘法（SpMV）性能的提升时，就不能只考虑矩阵的计算效率，还需要考虑矩阵在特定程序中被操作的次数（**也就是说，当矩阵在程序中被调用次数比较少时，可以不用预测，因为，有可能花费很多时间预测出来的结果可能只会使用一次，而这一次提升的时间只有一点点，这时，新格式带来的益处就小于运行时的开销了**）。不同的程序对SpMV的调用频率不同，这直接影响了新存储格式带来的性能提升的实际价值。因此，要全面评估一个新格式的好处，必须同时考虑矩阵的特性和它在特定应用程序代码中的使用情况。稀疏矩阵已经很难描述了; 添加程序代码使得解决方案的开发更加困难。
- 其次，创建**注重开销的预测器需要适当的设计策略来处理开销**。（如何计算开销：分开计算&&整体计算）
	- 可以通过显式地处理开销来解决问题，例如为每种类型的开销建立一个预测器，然后从预期收益中减去它。
	- 也可以通过隐式地处理开销来解决问题，例如构建一个单一的预测器，该预测器考虑输入矩阵和程序的特征，并预测哪种格式提供了整体最佳性能。
	- 不同策略有不同的优缺点。理解它们并找到合适的策略是第二个待解决研究问题。
- 最后，无论使用何种策略，最终都会创建某种类型的预测器，以便它可以预测对于给定的稀疏矩阵使用哪种最佳格式。问题在于，**由于这样的预测器通常必须在程序运行时运行，并且其开销是非常重要的（因为它通常需要提取矩阵特征），其自身的开销也可能成为障碍**。
	- 如果其自身的开销已经超过了新格式带来的益处，则程序将遭受减速。如果我们创建另一个预测器Y来预测是否值得运行格式预测器，那么如何处理新预测器Y的开销呢？再创造另一个预测器Y2？那它自己的开销呢？这可能使我们陷入鸡生蛋还是蛋生鸡的困境中。如何有效地解决这个困境是第三个研究问题。

本文的其余部分介绍了应对这些挑战的解决方案。在第二部分介绍了一些背景知识之后，第三部分分析了创建开销意识预测器的不同策略。它指出了它们的优点和缺点，并给出了我们设计的解决方案的概述。该<font color='red'><b>解决方案通过三个预测器明确地处理开销</b></font>，分别是转换开销、对 SpMV 计算的益处和循环行程计数预测。它列出了有效实现这种设计的主要挑战。

第四节详细描述了解决方案。它提出了在构造三个预测因子过程中克服各种困难的方法。它还提出了一种延迟和轻量级的方法，通过一个延迟方案和一个轻量级的循环行程计数预测，开发了一种简单的方法来解决前面提到的“先有鸡还是先有蛋”的困境。

第五部分报告了对构造的预测器质量的详细评估，以及该技术在执行一些实际应用程序时所带来的加速效果。在大多数情况下，我们的预测器预测归一化格式转换时间和 SpMV 时间的平均准确率大于88% 。提出的开销意识方法提高了应用程序的整体性能1.14 X 至1.43 X，显著大于之前的加速spmv计算-无视开销方法所实现的加速度0.82 X 至1.24 X 。

总之，本文作出了以下主要贡献:
- 它指出了稀疏矩阵格式选择的重要性和挑战。
- 它分析了不同设计选择的利弊，以便创建一个将预测和转换开销考虑在内的解决方案。
- 它为稀疏矩阵格式的选择提供了首个端到端考虑预测和转换开销的解决方案，包括一系列预测 成本-收益分析 的模型，以及一个预防减速的懒散轻型计划。它在2757个矩阵和四个真实世界应用程序上进行了评估，展示了所提出的注重开销的方法带来的显著好处。

## Background

在提出解决方案之前，首先介绍一些稀疏矩阵格式及其在 SpMV 中的应用背景。

为了有效地存储和处理稀疏矩阵，使用了压缩数据结构(也称为存储格式) ，它只存储非零条目。如今，已经提出了多种存储格式。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240403105800.png)
<center> <font face='华文宋体' size='4'> 图 3 稀疏矩阵存储格式及其相应的 SpMV 伪码 </font> </center>

作为示例，图3分别显示了以三种格式表示的稀疏矩阵及其对应的SpMV算法。符号m、n和nnzs用于分别表示稀疏矩阵的行数、列数和非零条目数量。

坐标（COO）格式明确存储行索引、列索引和所有非零条目值在行、列和数据数组中单独存储。

压缩稀疏行（CSR）格式保留了COO的相同列和数据数组，但将行索引压缩到ptr中，其中元素是cols/data中所有行的起始位置。对角线（DIA）格式沿着对角线方向（从左上到右下）存储非零值。

在图3中DIA示例中，数据的第一行包含A矩阵左下对角线上两个元素，第二行是A主对角线，第三行是该矩阵右上对角线。数组**offsets记录每个对角线与主要对角线之间的偏移量**。

## Design choices and challenges

正如图1所提到的，基于SpMV的程序执行时间包括<font color='red'><b>预测矩阵格式</b></font>、<font color='red'><b>将矩阵转换为该格式</b></font>以及<font color='red'><b>在新格式下运行SpMV程序所需的时间</b></font>。前两部分是运行时开销。

以下是已经考虑的各种设计，以处理最小化整体执行时间的开销。

### 显式处理和隐式处理

---

- 可以通过显式地处理开销来解决问题，例如为每种类型的开销建立一个预测器，然后从预期收益中减去它。
- 可以通过隐式地处理开销来解决问题，例如构建一个单一的预测器，该预测器考虑输入矩阵和程序的特征，并预测哪种格式提供了整体最佳性能。

---

这部分考虑的第一组设计隐式地处理开销。也就是说直接预测基于 SpMV 的程序的整体执行时间。（构建一个单一的预测器，该预测器考虑输入矩阵和程序的特征，并预测哪种格式提供了<font color='red'><b>整体最佳性能</b></font>）

例如，我们设计的一个方案是训练一个预测器 p，它接受程序代码、原始矩阵和特定矩阵格式作为输入，并预测程序的总运行时间。它可以表示为以下形式 $T_{overall} = p(G, A, f)$。困难在于预测器必须同时理解程序 G、矩阵 A 和格式 f 的特征对结果的影响。这三个组件都可能有许多要考虑的维度，其中程序是最复杂的组件之一。

另一种设计是构建一个针对每个给定程序 G 的预测模型 pG。由于它特定于特定程序，因此只需要学习关于 A 和 f 的影响：$T_{overall} = pG(A, f)$，这简化了构建过程。然而，问题在于所构建的预测器失去了通用性。人们需要为每个程序经历耗时的预测器构建过程。

总的来说，进行隐式（将所有开销看成一种开销）处理开销的方法在模型普适性和构建复杂性之间存在密切的关系。

为了解决这个问题，本文采用了一种设计方案，对<font color='green'><b>每种开销进行了明确的处理</b></font>。此设计基于对整个程序运行时的更详细的视图。对于程序中一个或多个 SpMV 语句所使用的矩阵，如果允许基于某个格式选择器对矩阵进行格式转换，则整个程序的执行时间可以看作是:
$$\begin{aligned}T_{overall}=T_{predict}+T_{convert}+(\sum_iT_{spmv(i)}*N_i)+T_{other}\end{aligned}$$
- $T_{overall}$：整个程序的总执行时间。
- $T_{predict}$：预测给定矩阵使用什么格式的时间。
- $T_{convert}$：将矩阵转换为所需格式的时间。
- $T_{spmv(i)}$：矩阵上第 i 个 SpMV 语句的运行时间。
- $N_i$：在矩阵上调用 SpMV 语句的次数
- $T_{other}$：程序的其他部分所花费的时间

在检查过的所有基于SpMV的应用程序中，Tother与矩阵格式大致独立，因为这些代码部分倾向于使用SpMV结果而不是矩阵本身。对于它们来说，在格式选择中可以忽略Tother；因此只需要考虑Toverall右侧的前三项。

$$\begin{aligned}T_{affected}=T_{predict}+T_{convert}+(\sum_iT_{spmv(i)}*N_i)\end{aligned}$$
我们的设计是<font color='red'><b>构建单独的预测器</b></font>，直接预测开销、单个SpMV时间$T_{spmv(i)}$和$N_{i}$。它们可以跨程序、矩阵和格式工作，具有很好的通用性。同时，它们避免了许多隐式设计所面临的复杂性。例如：
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240403114945.png)
- 预测开销和$T_{spmv(i)}$不受程序G特征影响；
- $T_{convert}$仅由矩阵和格式决定；
- 对于给定的SpMV库，$T_{spmv(i)}$仅由矩阵和使用的格式决定；
- $N_i$受程序G特征和矩阵影响，但与矩阵格式无关。

由于显式设计（每部分开销对应单独的预测器）在简单性和通用性方面的优势，将其用作开发解决方案的基础。

### 挑战

要有效地实现上面所提到的显式设计，有三个主要的挑战：

- 首先，与以往提供定性预测结果的预测器不同（即哪种格式最有效），我们需要构建的四个预测器都是定量预测器，提供数值预测。因此，在以前的预测器中显示出效果的机器学习方法无法应用于我们的问题，并且在同一思路上，以前研究中发现有用的矩阵/格式/程序特征可能并不适合我们的预测器。
	- **确定要使用的合适机器学习方法和特征是我们必须回答的第一个问题**。这一挑战涉及到所有我们所构建的预测器。
- 第二个挑战是**特定于预测时间的预测**。这就是导言中提到的鸡蛋和鸡蛋的困境。预测时间可能很长，因为它通常需要提取矩阵特征。因为预测发生在运行时期间，如果预测结果是保持格式不变，那么预测只会产生运行时开销，并导致程序执行速度减慢。如果我们添加一个预测器来预测 T 预测，那么增加的预测本身也会遇到同样的问题。
- 第三个挑战是**针对Ni的预测**。 **Ni的值通常由围绕SpMV调用的循环的迭代次数确定**。 预测循环的迭代次数并不容易，因为它取决于循环中实现的算法和参与循环执行的数据。 前者因程序而异，后者甚至在同一程序的不同运行之间也会有所变化。 如何自动建模程序和循环迭代次数之间的关系是一个困难问题——这基本上等同于停机问题，其答案是不可判定的。

## Overhead-conscious predictor in detail

本节首先描述了我们为**构建预测器所选择的机器学习方法**，然后介绍了我们的**两阶段懒散和轻松方案**以及**它如何帮助进行风险控制**，最后解释了**构建预测器中的其他一些重要细节**。

### 学习方法

**以前的格式选择系统不考虑开销项，只需要进行定性预测**(例如，哪种格式给出最短的 SpMV 时间)。因此，它们都将问题形式化为一个分类问题。相反，正如前一节所解释的，**当考虑到开销时，我们需要预测器来提供定量预测。我们不能再把它作为一个分类问题来建模了**。相反，<font color='red'><b>我们需要建立回归模型来预测数值</b></font>

（📒：以前关于SpMV优化机器学习的方法，都是建立一个分类模型，以此来预测选择什么样的格式才能使得执行的时间最短。而在本文中，作者采用的是**回归模型**来预测具体的数值）

回归模型是<font color='red'><b>吸收一些特征值(可以是数值或分类)并输出一些数值预测的模型</b></font>。建立回归模型的机器学习算法有很多，例如线性回归、支持向量回归(SVR)等。我们根据以下原则选择解决问题的学习方法:
- 1）算法应该给出良好的预测结果；
- 2）由于稀疏矩阵的复杂性，模型在处理具有复杂特征的数据时应该是健壮且灵活的；
- 3）由于我们的预测器用于**在线预测**，算法应该高效；
- 4）如果生成的模型具有可解释性，那就更好了。

在实践中使用的机器学习方法中，<font color='red'><b>基于回归树的模型很好地满足了四个要求</b></font>。它们在简单数据准备、对非线性关系的稳健性能以及易于解释结果方面具有优势（因为创建的树由输入特征上的问题组成）。它们产生的回归模型也运行速度快，因为只涉及少量关于数据特征和几个线性代数操作的问题（树中叶节点通常是数据特征的线性函数）。此外，当与提升方法结合时，在各种问题中显示出最佳预测结果和稳健性。

在我们的工作中，我们选择了高效树提升系统XGBoost 这一开源软件包来构建我们的模型。XGBoost是最广泛使用的树提升软件包之一，并已证明其在许多先前机器学习任务中有效。

---

**XGBoost**（极限梯度提升）是一种高效的机器学习算法，常用于分类、回归和排序问题。这种算法是<font color='red'><b>梯度提升决策树（GBDT）</b></font>的一种实现，其设计目的是在计算效率和模型性能方面进行优化。

XGBoost的主要特点包括：
1. **计算速度和性能**：XGBoost在处理大规模数据集时表现出高效的运行速度和良好的可扩展性。
2. **正则化**：XGBoost引入了正则化项来控制模型的复杂度，有助于减少过拟合，提高模型的泛化能力。
3. **灵活性**：XGBoost支持用户自定义优化目标和评估标准，增加了模型灵活性。
4. **缺失值处理**：XGBoost可以自动处理数据中的缺失值。
5. **剪枝**：XGBoost在树的生成过程中引入了剪枝技术，减少不必要的分支，避免过拟合。
6. **并行处理**：虽然树的构建本身是顺序的，XGBoost通过并行化在特征层面的分裂来增加速度。

这些特点使得XGBoost在许多数据科学竞赛和实际应用中成为了一个非常流行的选择。

---

### Lazy and Light 两阶段策略

正如前一节所提到的，<font color='red'><b>在运行时期间部署格式预测器的障碍之一是：如果在给定矩阵上只调用SpMV几次，那么预测器本身的开销可能已经导致总体执行速度大幅下降。</b></font>这主要是由于预测器从给定矩阵中提取特征所需的时间（运行预测器所需的时间很少，如前一小节所述）。

我们的解决方案是一个两阶段的懒惰和轻量级方案。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240416105431.png)

如图4所示，该方案由两个预测阶段组成。
- 第一个是矩阵上调用SpMV次数的轻量级预测器。
	- 第一个预测器充当网关；通过比较预测值LC与阈值TH，它决定是否值得调用第二个预测阶段
	- 如果LC < TH，则不会进行进一步的预测，程序将以默认格式运行；
- 第二阶段进行更复杂的预测，并决定使用哪种格式最佳。
	- 根据预测结果，矩阵可能保持原样或转换为新格式并在程序执行的其余部分中使用。

这样的方案是为了防止大的预测开销造成重大的减速时，执行是短期运行的执行。为了使该方案有效地工作，**必须确保第一阶段几乎不需要花费时间，但仍能提供合理的预测精度，同时尽可能控制其预测误差的影响。**

我们已经探索了几种实现第一阶段预测器的方法。一种方法是通过对矩阵的特征和包含spmv的循环数之间的关系进行建模来构建它，这样该模型就可以预测给定给该环路的任意矩阵的循环数。它们之间的关系太过复杂，难以捕捉；我们基于XGBoost的结果显示出令人失望的预测精度。该方法还会产生大量的运行时开销，因为它需要收集矩阵特征。

我们最终决定使用以下基于时间序列的 lazy 预测器，发现它很好地满足了我们的需求。在基于 SpMV 的应用程序中，围绕 SpMV 的循环往往是一个收敛的循环。例如，在线性求解器中，循环的每次迭代计算当前解的误差，当误差小于预定义的阈值时循环终止。我们称这个错误为循环的进度指示器。其他类型的应用程序可能有其他类型的进度指示器。我们的解决方案是建立一个预测器，它基于循环的第一个 k 次迭代的进度指示器的序列来预测迭代的总次数。只有在循环的第一个 k 次迭代完成并且它们的进度指示器显示出来之后，才会在目标程序的执行中调用它，从这个意义上说，它的使用将是惰性的。

（📒：基于时间序列的懒惰预测器的设计和使用。首先，提到的应用环境是围绕着**稀疏矩阵向量乘法（Sparse Matrix-Vector Multiplication, SpMV）的应用**，这种**应用通常包含一个用于收敛的循环结构**。在这样的循环中，例如在一个线性求解器中，每次迭代都会计算当前解的误差，并且当误差小于预定义的阈值时循环终止。这里的“误差”被称为循环的进度指示器。在不同的应用中，进度指示器的形式可能不同。基于这样的观察，他们建立了一个预测器，<font color='red'><b>这个预测器可以根据循环的前k次迭代中进度指示器的序列来预测整个循环所需的迭代总次数</b></font>。这种预测器的使用被称为“懒惰”，因为它只在目标程序的循环执行超过前k次迭代之后才被调用，这时候才会揭示出这些迭代的进度指示器。“懒惰”的特点在于预测器不是在程序开始时就立即工作，而是等到有足够的数据（即前k次迭代的数据）后，才开始预测未来的行为。这样可以在不影响程序初始执行效率的情况下，为后续的执行提供决策支持，比如调整资源分配或预测执行时间等。这种方法非常适合于那些迭代次数可能不确定或者对性能优化有较高需求的场景。）

----

在机器学习中，所谓的“lazy 预测器”或者“**懒惰学习模型**”通常指的是<font color='red'><b>那些不在训练阶段进行显著计算，而是将大部分计算推迟到预测阶段的算法</b></font>。这类算法**在训练数据上基本不进行学习，而是在需要进行预测时才使用完整的训练数据来做决策**。

最典型的懒惰学习模型是K最近邻（K-Nearest Neighbors, K-NN）算法。在K-NN中，模型存储所有的训练数据。当需要对新的样本进行分类时，K-NN算法会查看训练数据中与新样本最近的K个点，并根据这些最近邻的类标来预测新样本的类别。因此，K-NN在训练阶段的计算成本几乎为零，但在预测阶段需要进行大量的距离计算和排序，特别是在数据集很大的情况下，这会使得预测变得比较耗时。

懒惰学习模型的一个主要优势是模型的训练非常快，因为它们几乎不需要进行任何计算。但缺点是预测速度可能很慢，且存储需求可能很高，因为需要保留整个训练数据集。此外，懒惰学习模型通常对新的数据点或异常值非常敏感。

----

这样懒惰的设计有三个好处。
- 首先，它避免了预测（和预测错误）可能对循环造成的减速，如果循环迭代次数非常少（小于k）。对于这种短循环，即使是小的运行时开销也可能产生一些显著影响。
- 其次，由于收集到的进度指示器反映了当前执行的动态行为，它们为预测器提供了特定于此运行的线索。
- 最后，构建的预测器运行速度快。<font color='red'><b>它不需要从矩阵中提取特征</b></font>。它只需要记录进度指示器的几个值然后进行几次线性代数计算。与SpMV执行相比，这些计算所需时间几乎可以忽略不计。预测器采用自回归积分滑动平均（ARIMA）机器学习模型构建，这是一个简单但高效的<font color='red'><b>时间序列分析模型</b></font>。

⭐️⭐️：如果以后要在论文中，动态的获取当前的系统状态，然后去进行预测最佳的进程或线程分配，或许也可以使用这个时间序列分析模型，因为这个是实时性的去进行训练的。

我们做三个笔记。
- 首先，两阶段方案的目标不是确保没有减速（通过避免任何预测或格式转换很容易实现），而是在<font color='red'><b>避免不利情况下大幅度减速的同时最大化整体加速</b></font>。
	- 如果第一阶段在循环的前k次迭代后预测到循环至少还会运行另外TH次迭代，则才会使用预测的第二阶段。我们根据经验将k和TH都设置为15。
- 其次，我们并不声称**时间序列方法对于循环迭代计数预测具有新颖性**。
	- 这种方法与许多其他基于时间序列的程序行为预测共享许多相似之处。
	- 这部分主要贡献在于<font color='red'><b>通过这种懒惰轻量级的两阶段设计绕过了预测开销困境</b></font>。
- 最后，我们讨论收敛循环问题。
	- 对于常规for循环来说，问题更容易解决；可以直接从运行时的循环边界获取循环迭代计数值。


### 第二阶段的预测与选择

第二阶段预测使用的最佳格式。

最初的目标是找到方程2中最小化 Taf 的格式。
$$\begin{aligned}T_{affected}=T_{predict}+T_{convert}+(\sum_iT_{spmv(i)}*N_i)\end{aligned}$$
此时，第一阶段预测已决定运行第二阶段预测。因此，无论预测器选择何种格式，都会发生相同时间长度的$T_{predict}$。因此，最初的目标相当于最小化后面两个式子。
$$T_{convert}+(\sum_iT_{spmv(i)}*N_i)$$
可以观察到，如果用一个常数(标准化)来划分目标公式，使标准化值最小化的结果等价于使原始公式最小化。

这个观察结果很有用，因为在我们的探索中，我们发现直接预测$T_{convert}$和$T_{spmv(i)}$并不像预测它们的规范化值（例如，通过原始矩阵格式上的$T_{spmv(0)}$）那么容易。貌似合理的原因是，这三种情况下的一些共同的环境偏差被除法抵消了。

因此，第二阶段预测构建了两个预测器。它们分别预测每种矩阵格式上的**归一化转换时间**和**归一化SpMV时间**。对于给定的旧矩阵格式和新格式，<font color='red'><b>这两个归一化时间主要由矩阵特征决定</b></font>。**这些预测器是基于矩阵特征的回归模型，使用XGBoost构建而成。**

进行训练的过程如下：例如，对于从给定的旧格式到新格式的规范化转换的预测器，我们收集许多矩阵上的转化时间$T_{convert}$。对于每个元组，创建一个元组(Feature1，Feature2，... ，Featurem，标准化 $T_{convert}$) ，其中 Featurei 是矩阵的第i个特性的值。然后，XGBoost 将这些元组作为训练数据，并自动构造预测器，该预测器根据任意给定矩阵的特征来预测标准化的 T 转换。

📒：也是先利用已经存在的矩阵，进行格式转换时间的计算，然后，利用这些矩阵的特征作为X向量和计算所得的时间作为y向量，从而得到训练的样本。

建立回归模型的主要挑战是<font color='red'><b>确定稀疏矩阵的重要特征</b></font>。该特征应能很好地反映所研究问题的矩阵特征。另一方面，更多的特征可能会增加特征提取的开销，人为地增加所需的训练数据量，从而形成预测器。因此，特性的最佳选择是在表达性、成本和简单性之间的权衡。

先前的研究提出了60多个特征来存储矩阵的元信息。找到那些对我们的预测者很重要的因素是很重要的。幸运的是，<font color='red'><b>使用像 XGBoost 这样的决策树集成方法的一个好处是，它们可以从训练好的预测模型中自动确定特征的重要性。</b></font>具体来说，XGBoost 模型是使用表 I 中的整个特性集构建的。作为一个副产品，**该算法可以计算每个特征的重要性得分，允许特征进行排序和比较**。重要性得分表明每个特征在构建树增强模型中的有用程度。**在不牺牲预测性能的情况下，可以自动删除低重要性得分的特征，直到保留最小特征集为止**。

本文中选择的训练的矩阵特征如下：

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240416231543.png)

⭐️⭐️：XGBoost，可以**从训练好的预测模型中自动确定特征的重要性**，从而可以将一些不重要的矩阵特征进行剔除。从而，降低预测时间。（上一篇北理工那篇关于SpMV的机器学习论文，也是使用的集成环境，也可以自动确定特征的重要性。）

除了特征选择，我们的预测器构造中还使用了其他一些标准方法，包括**网格搜索参数自整定**和**交叉验证过拟合预防**。开销意识方法的部署目前是通过 **依赖包** 进行的。对于给定的应用程序，要使用该方法进行运行时格式选择和转换，用户只**需将原始的 SpMV 调用替换为我们自定义的 SpMV 调用**，并插入代码来记录周围循环的进度指示器的值。定制的 SpMV 调用为 SpMV 添加了一个包装器，当满足适当的条件时，它调用 Stage-1预测器的构造，或者调用 Stage-2预测器(只需要在感兴趣的系统上构建一次) ，并在必要时进行格式转换。

## Evaluation

在本节中，我们报告了针对基于SpMV的应用程序提出的注重开销的格式选择方案效果的评估。简要总结是，在大多数情况下，它能够以平均准确度高于88%来预测标准化格式转换时间和SpMV时间。它将应用程序的整体性能提高了1.14倍至1.43倍，远远超过了0.82倍至1.24倍上限速度增益无视开销方法可能带来的改进。接下来我们将描述方法论和完整结果。

### 实验设置

#### A)硬件 

评估采用 CPU-GPU 平台，详见表二。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240416232514.png)

#### B)库、格式、应用程序

如图3所示，不同的格式要求对 SpMV 进行不同的编码。为了评估格式预测带来的 SpMV 加速，需要使用一个可以处理多种矩阵格式的 SpMV 库。

在我们的评估中，我们重点介绍了基于 CUDA 的 NVIDIA 图形处理器上的 SpMV 库。我们采用 NVIDIA CUSP 库 ，它支持 COO、 CSR、 DIA、 ELL、 HYB 格式。我们用 cuSPARSE 库对其进行补充，以支持 BSR 格式。以前的工作报告了**新格式 CSR5在一些替代格式上的一些有希望的性能**，并发布了实现。我们包括其 CUDA 实现，以支持 CSR5格式。格式转换是通过在 GPU 上运行的 CUSP 中包含的函数进行的。
- COO
- CSR
- DIA
- ELL
- HYB
- BSR （cuSPARSE 库中）
- CSR 5 格式
⭐️⭐️：CSR5一定要去读一下。

本研究涵盖的格式集仅限于这些现有库支持的格式。 这些库对这些受支持的格式的支持表明它们具有竞争力和普遍适用性。 该集合不可避免地会留下一些未覆盖的格式。 验证了这个想法后，该方法可以轻松扩展到选择其他格式。

CSR 是基于 SpMV 的应用程序中最常用的默认格式。因此，在我们的实验中，它被用作默认格式。

我们创建了一个简单的<font color='red'><b>软件框架</b></font>，命名为 <font color='red'><b>SpMV 框架</b></font>，以帮助集中研究 SpMV 的性能。

它包含一个具有可调上限的循环，该循环围绕对 SpMV 的调用。此外，我们还评估了四个基于 SpMV 的实际应用: 
 - PageRank是流行的网页排名算法
 - BiCGSTAB实现了双共轭梯度稳定方法
 - CG 是一个共轭梯度法
 - GMRES 是一个基于广义最小残差方法的线性方程系统求解器。

#### C)数据集 

我们的实验使用来自 SuiteSparse 矩阵集合的数据集。这些矩阵包括2757个真实世界的矩阵(这些矩阵也在以前的研究中使用)。

在我们对预测模型的评估中，我们在所有格式的所有矩阵上运行 SpMV。但是，并非所有运行都是有效的，因为某些格式对矩阵施加了额外的限制。例如，DIA 和 ELL 要求填充比率(在存储中填充的零的比率)在某个阈值内。有些应用(例如，线性求解器)只对满足某些条件的矩阵有效。在性能比较中只考虑有效的运行; 更多细节将在下面的结果讨论中给出。

#### D)交叉验证

对于 SpMV 格式预测的评估，我们通过5次交叉验证将测试数据与训练数据分离。这是一种常用于统计学习的评价方法。它采取20% 的有效矩阵形成一个测试集，并使用其余的有效矩阵进行训练。它重复这个过程5次，取出数据集的不同子集作为测试集。

### 开销对格式选择的影响

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240416233750.png)

我们首先测量格式转换开销对格式选择的影响。这部分不使用预测，而是实际性能测量。正如表III所示，将矩阵转换为不同的格式需要很长时间，相当于9-270次SpMV调用。而且在不同的格式之间时间有所差异。因此，最小化SpMV的格式通常并不能给出最佳整体性能。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240416235430.png)

📒：在忽略开销时，可以看出，得到最佳计算时间最多的矩阵格式是：BSR，但是，一旦计入转换开销和循环等要求，则得到最佳计算时间最多矩阵格式就发生了变化，变为CSR。则说明，在选择矩阵存储格式时，计算开销的意识是非常重要的！（这里也可以加入到论文中，在进行格式的选择时，需要计算转换开销以及循环次数的预测等因素来进行最佳矩阵格式的选择）。

这反映在表IV中显示的矩阵在关注开销（OC）和忽略开销（OO）情况下**选择的最优格式**上具有明显不同的分布情况中。表IV也显示当考虑到开销时，**最佳格式随着 SpMV 周围循环的迭代次数而变化**(对于运行中的矩阵，格式转换只执行一次)。这些结果<font color='red'><b>证实了在选择矩阵存储格式时有开销意识的重要性</b></font>。

### 主要预测因子的性能比较

如前所述，我们的开销意识解决方案由两个阶段组成。第一阶段是一个主要基于循环行程计数预测的网关。它是特定于应用程序的。第二个阶段由我们的主要预测器组成，它们处理格式转换开销和转换效益之间的权衡。在这一部分中，我们对**主要预测因子的质量**进行了重点研究，并将它们选择的格式与以前的忽略开销的方法进行了比较。下一节将报告整个开销意识解决方案在实际应用程序中的性能。

我们使用我们的 SpMV 框架进行这项研究，通过允许轻松改变循环边界，它使得检查转换开销和收益之间的权衡变得方便。

#### 预测精度和加速比较:

回想一下，**主要预测因子预测新格式上的归一化格式转换时间和归一化 SpMV 时间**。我们使用相对误差作为度量，定义为

$$ \frac{|predicted \ value - actual \ value|}{actual \ value}$$

表五报告了主要预测因子对所研究的每种矩阵格式的预测的相对误差。在大多数情况下，准确率超过88% 。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240417000427.png)

图5显示，在大多数情况下，<font color='red'><b>预测结果足以使主要预测因子正确选择最佳矩阵格式</b></font>，并产生显著的加速效果。图5中的条形图报告了以三种方式获得的加速。
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240417001454.png)

- 第一种是：没有感知开销，只使用忽略开销方法进行预测最佳存储格式所能取得的加速比上限。
- 第二种是：采用本文的方法--感知开销预测最佳存储格式（将转换、计算、预测时间最小化），所能取得的加速比。
- 第三种是：取得最佳预测结果，也就是假设都预测正确，所能取得到加速比上限。

SpeedupOC 条是我们主要预测者的加速条。TBOC 条是开销意识方法的上界ーー也就是说，当主要预测因子具有完美的预测精度时。TBOO 条是来自忽略开销方法结果的上界，这些方法通过**选择实际上最小化 SpMV 时间的格式(不考虑格式转换时间)获得**。

如图5中的结果所示，由于转换开销的影响，当 SpMV-enclosing 循环有少量迭代时，来自 TBOO 的决策会导致很大的减速。

当迭代次数变大时，该方法的加速比开销意识方法的加速要低。SpeedupOC 条和 TBOC 条之间的差异表明，在所有不同数量的循环迭代中，由于主预测器的预测错误导致的加速比损失很小。

研究结果显示了开销意识的重要性，并且表明来自我们主要预测因子的预测足够准确，可以保持开销意识矩阵格式选择的最大好处。

#### 整个应用程序的性能

在这一部分中，我们报告了我们的解决方案给四个实际应用程序带来的总体加速，以及我们的第一阶段预测器的评估。

这些应用程序中的收敛检查语句为阶段1预测器提供了进度指示器，用于预测循环次数。这四个应用程序在循环次数中表现出不同的模式。PageRank具有相当稳定的模式，循环次数在$[1，93]$的范围内，而BiCGSTAB显示的范围要大得多$[1，100000]$（100000是预设的上限）。

预测循环迭代的准确次数的误差各不相同，从PageRank的平均17%到BiCGSTAB的62%、CG的78%和GMRES的102%。**需要注意的是，我们的最终目标是决定是否进行预测和格式转换，而不是获得精确的循环次数。因此，在容忍行程数预测误差方面有相当大的余地**。例如，即使2次迭代循环的预测值为10意味着预测误差为400%，预测器仍然会做出正确的决定，即不应该进行进一步的预测或转换，因为循环太小（小于阈值）。对于一个循环，访问次数为1000和2000可以为我们的最终问题得出相同的结论，因为它们都非常大，与收益相比，预测和格式转换的开销微不足道。更具体地说，对于我们的阶段1预测器，将预测的循环数与阈值TH=15进行比较，以决定是否值得进行更昂贵的阶段2预测。因此，尽管预测的访问次数有时会出现相当大的误差，但我们的**第一阶段预测器在大多数情况下正确地预测了循环的访问次数（在第一阶段之后）是否超过阈值：PageRank 93%， BiCGSTAB 82%， CG 76%， GMRES 65%**。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240417001837.png)
预测误差对预测的总体效益有一定的影响，但总体结果仍然是积极的。表 VI (SpeedupOC 列)显示了我们的方法给整个程序执行带来的平均加速(所有运行时开销都计算在内)当没有预测错误时，我们还报告了我们的方法的上限加速(TBOC 列) ，以及开销遗忘方法的上限加速(TBOO 列)。同样，使用默认 CSR 格式的性能作为基线。预测误差在一定程度上降低了开销意识方法的速度。在预测精度最低的 GMRES 上最为明显。然而，即使有这种影响，开销意识方法仍然明显优于开销遗忘方法的上限。平均加速是显著的，从1.14 X 到1.43 X 不等。
![image.png|center|800](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240417002436.png)
表七显示了所选格式的分布情况。图6显示了 PageRank 加速的直方图。比例表示：该软件执行某个矩阵，在该矩阵下使用该方法，所取得的加速比，位于的区间。 54.5%则表示有54.5%的矩阵在执行PageRank应用时取得了加速比大于1.0的加速。
与图2相比，我们的选择器在很大程度上避免了不必要的格式转换导致的 performance 减速。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240417003003.png)

表VIII报告了对几个不同大小和密度矩阵的预测细节。考虑到开销，我们的预测器在五个矩阵中有四个选择了与理想的无视开销方法完全不同的格式。例如，在shallow_water2矩阵上，尽管HYB可以使SpMV运行更快，但我们的第一阶段预测器正确地预测到这并不值得，因为运行时开销可能会超过收益。通过保持格式不变，它避免了无视开销方法所造成的显著减速。由于第一阶段预测器几乎没有时间消耗，它对程序执行没有明显影响。第二阶段预测器具有较大的开销（约为2倍至4倍SpMV时间），因为它需要提取矩阵特征。然而，两级设计和懒惰轻量级方案确保在短程序执行中不会调用该功能，就像在shallow_water2情况下一样。

总的来说，以前的开销不明方法所能带来的加速上限只有0.82 X-1.24 X。(回想一下，少于1意味着减速。)相比之下，我们的方法平均提高了应用程序的整体性能1.14 X-1.43 X。实验结果表明，该方法有效地克服了现有方法在选择基于 SpMV 应用的存储格式方面的局限性。实验集中在 GPU 上，但是由于 SpMV 的选择对 CPU 也很重要 ，我们期望该技术也能帮助 CPU 执行; 探索留给未来的研究。

关于预测开销，时间序列模型和 XGBoost 模型的时间是常数，分别为2ms 和5ms。特征提取开销随 SpMV 调用的2X-4X 范围而变化。

## Related work

对于SpMV的格式选择已经进行了许多研究。例如，SMAT工作建立了一个决策树来选择稀疏矩阵存储的最佳存储格式。类似基于分类树的模型在中使用过，并且在中使用了SVM分类模型。这些研究都没有考虑预测最佳格式时的开销。

最近一项工作讨论了“盈亏平衡点”，即需要转换收益超过开销所需的最小SpMV调用次数。这个概念是有关开销意识的，但该工作并未将其整合到预测模型中，而是留给用户做决定。

还有其他一些努力试图优化稀疏矩阵上的计算，包括构建自动性能调优系统（auto-tuning）、设计新稀疏格式, 以及手动调整输入或与架构相关特征。

在更广泛范围内, 已经有大量关于应用机器学习技术解决程序优化难题方面 的工作. 例如, 一些涉及算法选择方面的研究, 一些改进底层编译器优化方面的研究, 和 动态编译和适应性 方面 的 研究.

## Conclusion

本文首次系统地探讨了如何为基于spmv的程序构建考虑开销的矩阵选择器。SpMV很重要，但是稀疏矩阵还有许多其他用途。我们预见到，所提出的技术和方法的潜力（例如，两个阶段的lazy与light方案，在线开销的明确处理）可能远远超出SpMV格式的选择（例如，为给定矩阵选择最佳线性求解器）。如何释放潜力，有待未来探索。


