# 阅读笔记

## Abstract

稀疏矩阵-向量乘法（SpMV）是许多应用程序的基本构建块。本文提出了CSR5，这是一种新的存储格式，可以<font color='red'><b>在包括CPU、GPU和Xeon Phi在内的各种平台上实现高吞吐量的SpMV</b></font>。

首先，CSR5格式对输入矩阵的稀疏结构不敏感。因此，单个格式可以支持一个既适用于常规矩阵又适用于不规则矩阵的高效SpMV算法。此外，我们展示了从CSR转换为CSR5的开销可能仅相当于几次SpMV操作成本。

📒：
- 【<font color='red'><b>CSR5对稀疏结构不敏感</b></font>】，即，CSR5这个格式既适用于常规矩阵的高效SpMV算法也适用于不规则矩阵的高效SpMV算法。
- 【<font color='red'><b>CSR5格式转换的开销低</b></font>】，对迭代次数少的矩阵来说，实用性更高。（如果一个新的稀疏矩阵结构转换时间太长，在迭代次数较少时，可能会导致计算产生的增益小于转化的开销。）

本文将基于CSR5的SpMV算法与11种最先进的格式和算法在四种主流处理器上进行比较，使用14个常规矩阵和10个不规则矩阵作为基准套件。对于套件中的14个常规矩阵，我们实现了与以前工作相当或更好的性能。对于10个不规则矩阵，CSR5获得了平均性能提升分别为17.6％、28.5％、173.0％和293.3%（高达213.3％、153.6％、405.1%和943.3%），超过了双插槽英特尔CPU、nVidia GPU、AMD GPU 和英特尔Xeon Phi 上最佳现有工作。**对于只有数十次迭代的求解器等真实应用程序来说，由于其格式转换开销较低，CSR5格式可能更加实用**。

## Introduction

在过去的几十年中，由于稀疏矩阵向量乘法(SpMV)在许多科学应用中的重要性，它可能是研究最多的稀疏 BLAS 程序。SpMV 运算将一个大小为 m × n 的稀疏矩阵 A 乘以一个大小为 n 的稠密向量 x，得到一个大小为 m 的稠密向量 y。但是为了加速大规模计算，**并行 SpMV 仍然需要用特定的数据存储格式和算法进行手工优化**。因此，**SpMV 的需求和其他稀疏矩阵运算(如预处理运算和稀疏矩阵乘法)之间可能会出现冲突**。原因是这些操作通常需要存储在基本格式(如压缩的稀疏行(CSR))中的矩阵。因此，当用户构建一个真实的应用程序时，他们需要考虑在面向 SpMV 基本格式之间进行格式转换的成本。不幸的是，这种转换开销可能会抵消使用这些特殊格式的好处，特别是当一个解决方案只需要很少的（几十次）次迭代时。

（📒：在面向真实的程序时，由于可能一个解决方案只需要很少的迭代，因此，此时的转换成本会超过计算的计算的加速优点。）

**转换成本主要来自昂贵的存储格式的结构相关参数调整**。例如，<font color='red'><b>一些基于块的格式需要找到一个良好的2D 块大小</b></font>。此外，一些混合格式对于不同的输入矩阵可能需要完全不同的分区参数。

为了避免格式转换开销，一些算法集中于通过**行块方法**或**分段求和**方法加速基于CSR的SpMV。然而，这两种类型的方法各有其缺点。
- 就行块方法而言，尽管它们在常规矩阵上表现良好，但由于不可避免的负载不平衡，在非规则矩阵上可能提供非常低的性能。
- 相反，分段求和方法可以实现接近完美的负载平衡，但由于更多全局同步和全局内存访问而导致高开销。
此外，以上**任何工作都无法避免预处理带来的开销**，因为**必须生成某些辅助数据以获得更好的负载平衡或建立原始数据结构**。

因此，实用的高效格式必须满足两个条件: 
- (1)通过避免依赖于结构的参数调整来限制格式转换成本; 
- (2)同时支持正则和非正则矩阵的快速 SpMV。

为了满足这两个标准，在本文中，设计了CSR5（Compressed Sparse Row 5），这是一种新的格式，直接扩展了经典的CSR格式。

CSR5格式**保持了CSR格式的三个数组中的一个不变**，**将另外两个数组以原地 tile 转置顺序存储**，**并添加了两组额外辅助信息**。

从CSR到CSR5的格式转换仅需要两个调整参数：
- 一个是硬件相关的
- 另一个是稀疏相关但与结构无关的。

由于添加的**两组信息通常比CSR格式中原始三组要短得多**，因此只需要非常有限额外空间。此外，CSR5格式对SIMD友好，因此可以轻松在所有具有SIMD单元的主流处理器上实现。由于结构无关性和SIMD利用率高，基于CSR5 的SpMV算法可以为正规和不规则矩阵带来稳定且高吞吐量。

在本文中，我们做出了以下贡献: 
- 提出了 CSR5，一种低转换成本、高并行度的高效存储格式。
- 提出了一个基于 CSR5的 SpMV 算法，该算法基于重新设计的低开销分段和算法。
- 在四种主流设备上实现这项工作: CPU、 nvidia GPU、 AMD GPU 和 Intel Xeon Phi。
- •在孤立的 SpMV 测试和基于迭代的场景中评估 CSR5格式。

📒：主要贡献：存储格式、算法、实验、评测

本文将CSR5与11种最先进的格式和算法在双插槽英特尔CPU、一块nvidia GPU、一块AMD GPU和一颗英特尔Xeon Phi上进行比较。通过使用14个常规矩阵和10个不规则矩阵作为基准套件，我们展示了CSR5对于常规矩阵获得了可比较或更好的性能，对于不规则矩阵可以大幅超越之前的工作。至于这10个不规则矩阵，CSR5在四个平台上分别获得了17.6%、28.5%、173.0%和293.3%（最高达213.3%、153.6%、405.1%和943.3%）的平均性能提升，相对第二优秀工作而言。此外，在基于迭代的真实场景中，由于<font color='red'><b>快速格式转换，CSR5格式实现了更高的加速效果</b></font>。据我们所知，这是首次单一存储格式能够在所有四种现代多核处理器上胜过最先进工作。

## Preliminaries

### CSR格式

稀疏矩阵的 CSR 格式由三个数组组成:
- (1) `row_ptr` 数组，它保存行的非零元素的起点和终点。它的大小为 m + 1，其中 m 是矩阵的行数
- (2)大小为 `nnz` 的 colidx 数组存储非零元素的列索引，其中 nnz 是矩阵的非零元素个数
- (3)大小为 `nnz` 的 val 数组存储非零元素的值。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240418233236.png)
<center> <font face='华文宋体' size='4'> 图 1 稀疏矩阵和CSR存储 </font> </center>

### 基于 CSR 的 SpMV 并行算法研究

#### 行块方法

在给定的稀疏矩阵中，<font color='red'><b>行之间是相互独立的</b></font>。因此，在分解的行块上可以并行化SpMV操作。逻辑处理单元负责一个行块，并将矩阵行与向量x的点积结果存储到结果y中对应位置。当物理处理单元的SIMD单元可用时，SIMD减少求和操作可用于提高效率。这两种方法分别称为**CSR-标量**和**CSR-向量**算法，并已在CPU 和GPU上实现。算法1展示了一种并行CSR-标量方法。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240418233509.png)
<center> <font face='华文宋体' size='4'> 图 2 并行CSR的标量方法 </font> </center>

#### 分段求和方法

Blelloch 等指出，<font color='red'><b>分段和</b></font>对基于 CSR 的 SpMV 可能更有吸引力，因为它对 SIMD 友好，**对输入矩阵的稀疏结构不敏感**，从而克服了行块方法的缺点。分段求和(这是反向分段扫描的一种特殊情况)<font color='red'><b>对数组中每个分段中的条目执行求和运算</b></font>。一个段的第一个条目标记为 TRUE，其他条目标记为 FALSE。

算法2列出了一个串行分段求和算法。

![image.png|600|center](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240419000622.png)

<center> <font face='华文宋体' size='4'> 图 3 串行分段求和的思想 </font> </center>

在 SpMV 操作中，<font color='red'><b>分段和将每个矩阵行视为一个段，并为每行中生成的逐项积计算部分和</b></font>。这里面的每个非零元素都是可以进行并行计算的？？？？引入flag数组的作用，就是确定了之后**分段和**要放在**结果向量y**中的位置？？？？

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240419001300.png)
<center> <font face='华文宋体' size='4'> 图 4 在SpMV中的分段求和方法 </font> </center>

在稀疏矩阵-向量乘法中，每一行的非零元素可以视为一个段（segment）。在分段求和操作中，每个段内的元素被并行处理：
1. **生成辅助数组**：首先，基于矩阵的`row_ptr`数组（指示每行开始和结束位置的指针数组）生成一个辅助的`bit_flag`数组。在这个数组中，每行的第一个非零元素位置被标记为`TRUE`，其余为`FALSE`。
2. **计算中间结果**：对每个非零元素与对应向量元素的乘积进行计算，结果存储在一个中间数组中。
3. **执行并行分段求和**：使用并行算法处理中间结果数组，根据`bit_flag`数组中的标记，对每个段内的元素进行累加，得到每个段的求和结果。
4. **收集结果**：将每个段的求和结果存储到最终结果向量的相应位置。

为什么会出现这种情况？我们可以看到，步骤1是一个散列操作，而步骤4是一个聚集操作，都来自大小为m的行空间。这阻止了两个步骤与大小为nnz的非零条目空间中的步骤2和3融合。在这种情况下，更多全局同步和全局内存访问可能会降低整体性能。先前的研究发现分段求和可能更适用于基于COO（坐标存储格式）的SpMV，因为完全存储的行索引数据可以将步骤1和4转换为非零条目空间：bit_flag数组可以通过比较相邻行索引生成，并且乘积数组中的部分总数可以直接保存到y中，因为它们最终位置很容易从行索引数组知道。此外，Yan等人和Tang等人报告称COO格式的一些变体也可能受益于分段求和。

然而众所周知，<font color='red'><b>在COO模式中访问行索引会带来更高级别离片内存压力，而CSR格式正试图避免这种情况</b></font>。

（📒：与COO格式相比，CSR格式减少了对行索引的存储，因为它只需在新行开始时记录位置，从而减少内存使用并提高访问效率。**离片内存压力**：所谓的离片内存压力指的是<font color='green'><b>数据访问需要频繁地从主内存（而非CPU寄存器或GPU缓存等更快速的内存）加载数据的情况</b></font>。高的离片内存访问压力会导致性能瓶颈，因为主内存的访问速度远慢于缓存。）

![center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240419001633.png)
<center> <font face='华文宋体' size='4'> 图 5 单精度 SpMV 性能 </font> </center>

接下来我们将展示基于CSR5 的 SpMV 可以利用分段求和实现负载平衡以及压缩后数据提升加载/存储效率. 这样, 基于 CSR5 的 SpMV 可以比使用 segmented sum primitive 的 CSR-based SpMV 获得高达 4x 的加速度 (见 图5) 。

## The CSR5 storage format

### 基本数据布局

为了实现具有任何稀疏结构的矩阵的近乎最佳负载平衡，我们首先**将所有非零条目均匀分割到多个相同大小的二维tile中**。因此，在执行并行SpMV操作时，计算核心可以消耗一个或多个二维tile，并且核心的每个SIMD通道可以处理一个tile的一列。然后CSR5格式的主要骨架只是一组二维tile。CSR5格式有两个调整参数：ω和σ，其中ω是一个tile的宽度，σ是tile的高度。事实上，CSR5格式只有这两个调整参数。
- $ω$：一个tile的宽度
- $σ$：一个tile的高度

此外，还需要额外的信息来有效地计算SpMV。对于每个tile，引入一个tile指针`tile_ptr`和一个tile描述符`tile_desc`。同时，将经典CSR格式的行指针`row_ptr`、列索引`col_idx`和值`val`这三个数组直接集成。

唯一的区别是，每个完整块中的`col_idx`数据和`val`数据被就地调换（即，从行为主顺序到列为主顺序），以便从连续的SIMD通道进行合并内存访问。如果矩阵的最后一项没有填满一个完整的2D贴图（即：nnz mod （ωσ） = 0），它们就保持不变并丢弃它们的`tile_desc`。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240421163644.png)
<center> <font face='华文宋体' size='4'>图 6 : 8 × 8的稀疏矩阵 A 的 CSR5存储格式。这五组信息包括 row _ ptr、 tiles _ ptr、 col_ idx、 val 和 tiles _ desc。 </font> </center>

在图6中，以CSR5格式存储大小为8 × 8、包含34个非零条目的示例矩阵A。

当ω = 4， σ = 4时，矩阵被划分为3个tile，包括两个大小为16的完整tile和一个大小为2的不完整tile。两个完整块中的数组col_idx和val现在以块级列主顺序存储。此外，只有前两个块具有tile_desc，因为它们是完整的。

### 自动调谐参数 ω 和 σ

由于现代多核或多核处理器的计算能力主要来自 SIMD 单元，因此我们设计了一种能够提高 SIMD 利用率的自动调优策略。首先，<font color='red'><b>将tile宽度 ω 设置为所使用处理器的 SIMD 执行单元大小。然后，一个 SIMD 单元可以在 σ 步内消耗 2D tile 而无需任何显式同步，并且可以充分利用向量寄存器</b></font>。

对于双精度 SpMV，我们总是<font color='red'><b>设置 ω = 4 适用于具有 256 位 SIMD 单元的 CPU，ω = 32 适用于 nVidia GPU，ω = 64 适用于 AMD GPU，以及 ω =8 对于具有512位SIMD单元的Intel Xeon Phi</b></font>。因此，**在已知所使用处理器类型之后, 可以自动决定 ω 的值**。

📒：在nvidia GPU 中，他的SIMD执行单元的大小为：32个，在AMD GPU中，它的SIMD的执行单元的大小为64个。

另一个参数σ是通过稍微复杂的过程决定的。对于给定的处理器，我们考虑其芯片内存策略，如缓存容量和预取机制。如果实验发现使用大小为ω×σ的2D tile 可以带来比使用其他大小更好的性能，则简单选择σ。我们发现 x86 处理器属于这一类别。对于在CPU和Xeon Phi上进行双精度SpMV运算，我们分别将σ设置为16和12。

就GPU而言，tile 高度σ还取决于矩阵的稀疏性。请注意，“稀疏性”并不等同于“稀疏结构”。我们定义“稀疏性”为**每行非零条目的平均数量**（或简称nnz/row）。相比之下，“稀疏结构”更加复杂，因为它包括所有非零条目的二维空间布局。

在GPU上，有几个性能考虑因素来将值nnz/row映射到σ。**调整σ的目的是在提升计算性能和减少内存访问成本之间找到平衡**。
- 首先，σ应该足够大，以暴露更多线程级本地工作，并摊销分段求和算法的基本成本。
	- 这意味着，通过增加每个瓦片处理的元素数量，可以使**每个GPU线程有更多的连续计算任务，从而提高计算效率和线程利用率**。
- 其次，它不应该太大，因为较大的tile可能产生更多的部分和（即要存储到y中的条目），这会给最后一级缓存写入带来更高的压力。
	- 如果σ太大的话，会使得**每列所具有的元素所处在的行有多个**（因为进行了转置了嘛。），这就会使得该tile对应产生的部分和更多，因此在进行写入时，会具有更高的压力。
- 此外，对于具有较大nnz/row的矩阵，σ可能需要很小。原因是一旦整个tile位于一个矩阵行内（即仅一个段位于tile中），分段求和就转换为快速归约求和。
	- 在这种情况下，如果σ比较大的话，就会使得一个tile存储了一整行的非零元素，如果σ较小，瓦片将只覆盖行的一小部分，使得每个瓦片的处理更加可控和高效。
	- 因此，在这种情况下，σ需要比较小，来使得把一整行的非零元素分配到不同的tile中去进行计算。


因此，对于在GPU上的nnz/row到σ映射，我们定义了三个简单的边界：r、s和t。第一个边界r旨在防止σ过小。第二个边界s用于防止σ过大。但是当nnz/row进一步大于第三个边界t时，将把σ设置为一个小值u。
$$
\left.\sigma=\left\{\begin{array}{lll}r&\text{if}&nnz/\text{row}\leq r\\nnz/\text{row}&\text{if}&r<nnz/\text{row}\leq s\\s&\text{if}&s<nnz/\text{row}\leq t\\u&\text{if}&t<nnz/\text{row}.\end{array}\right.\right.
$$
三个界限 r、 s 和 t 以及值 u 是依赖于硬件的，这意味着对于给定的处理器，它们可以固定使用。例如，为了在 nvidia Maxwell GPU 和 AMD GCN GPU 上执行双精度 SpMV，我们总是分别设置 < r，s，t，u > = < 4,32,256,4 > 和 < 4,7,256,4 > 。

对于具有新体系结构的未来处理器，我们可以在初始化期间通过一些简单的基准测试来获得这四个值，然后将它们用于以后的运行。因此，一旦知道矩阵形成的基本原理和底层硬件，就可以确定参数 σ。因此，我们可以看到，参数调整时间可以忽略不计，因为 ω 和 σ 很容易得到。这可以节省大量的预处理时间。

### Tile 指针 信息

添加的Tile指针信息`tile_ptr`**存储每个Tile中第一个矩阵行的行索引，表示存储其部分和到向量y的起始位置**。

📒：也就是说这个数组用来存储与每个2D Tile 相关的行索引信息。简单来说，`tile_ptr`帮助确定每个 Tile 在结果向量中的起始位置。

通过引入`tile_ptr`，每个Tile可以找到自己的起始位置，从而允许Tile并行执行。`tile_ptr`数组的大小为p + 1，其中$p=\lceil nnz/(\omega\sigma)\rceil$是矩阵中的Tile数量。对于图4中的示例，Tile 1 的第一个条目位于矩阵的第4行，因此将4设置为其Tile指针。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240421201358.png)
<center> <font face='华文宋体' size='4'> 图 7 算法 4 生成 tile_ptr数组 </font> </center>

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240421202827.png)
<center> <font face='华文宋体' size='4'> 图 8 生成tile_ptr数组示意图 </font> </center>

为了构建该数组，在`row_ptr`数组上二进制搜索每个Tile第一个非零条目的索引。算法4中1-4行展示了这一过程。

在这里，如果相应Tile中包含任何空行，则将tile_ptr中的条目设置为其负值。算法4中的5-12行展示了这个操作。

如果第一个Tile有任何空行，需要为其存储一个`-0`（负零）。为了记录-0，在这里使用无符号32位或64位整数作为`tile_ptr`数组的数据类型。因此，我们有1位用于显式存储符号，31或63位用于索引。

例如，在我们的设计中，Tile指针`-0`被表示为二进制样式`1000 ... 000`，而Tile指针0则被存储为`0000 ... 000`。据我们所知，31或63位的索引完全兼容大多数数字库，如英特尔MKL。此外，最近高性能共轭梯度（HPCG）基准测试的参考实现也使用32位带符号整数来处理维度不超过$2^{31}$的问题，并且对于维度大于该值的问题，则使用64位带符号整数。因此**将1位保存为空行提示以及其他31或63位作为“真实”行索引是安全的**。

### Tile 介绍信息

仅有 Tile 指针对于快速的 SpMV 操作是不够的。对于每个Tile ，还需要四个额外的提示：

- （1）大小为 ω × σ 的 `bit_flag`，用来标记 Tile 中每个元素是否是其所在行的第一个非零元素。
	- 通过`bit_flag`，可以快速识别出哪些元素是行的开始，**这对于分段求和和其他并行操作至关重要**，因为它允许算法只在需要的地方进行同步和数据合并。
- （2）大小为 ω 的 `y_offset` 用于存储每个 Tile 中**每一列的非零元素应该存储到结果向量y中的起始位置偏移**。
	- 它帮助确定每列数据在结果向量y中的存储位置，通过累加前一列的`bit_flag`中TRUE的数量（即新行的开始）来计算。
- （3）大小为 ω 的 `seg_offset` 用于加速Tile内部局部分段和计算
	- 它存储每列可以跳过的连续FALSE标记的数量，用于快速进行局部分段求和计算。
	- 这种优化减少了不必要的同步和计算，提高了SpMV的效率。
- （4）不固定大小的 `empty_offset` （但不超过 ω × σ），处理包含空行（没有非零元素的行）的Tile。
	- 当Tile包含一个或多个完全为空的行时，这些行的数据会被忽略，而`empty_offset`提供了必要的索引信息，以**确保这些空行的数据能正确地映射到结果向量y中的正确位置**。

Tile 描述符 tile_desc 被定义来表示上述四组数据的组合。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240421224752.png)
<center> <font face='华文宋体' size='4'> 图 9 Tile的信息介绍 </font> </center>

#### bit_flag

<font color='red'><b>生成bit_flag很简单。该过程与算法3中的第3-5行非常相似。</b></font>主要区别在于，位标志以列为主序保存，这与原地转置的col_idx和val匹配。此外，每个Tile的bit_flag的第一个条目设置为TRUE，用于密封从顶部开始的第一段，并使2DTile彼此独立。

#### y_offset

大小为ω的数组y_offset用于帮助每个Tile中的列知道存储其部分和到y的起始点在哪里。换句话说，每个列在数组y_offset中有一个条目作为同一列中所有段的起始点偏移量。我们为y_offset中的每个列保存了行索引偏移（即相对行索引）。

因此，在第 tid th瓦片中的第i列，通过计算`tile_ptr[tid] + y_offset[i]`，该列就知道自己在y中的起始位置。因此，**这些列可以以高度并行化地工作而无需等待同步**。

<font color='red'><b>生成y_offset很简单：每个列统计其前几列bit_flag数组中TRUE值的数量。</b></font>以图4中Tile 1为例：由于第1列有3个TRUE值，所以第2列对应的y_offset值是3。此外，由于前三列表示、2和3列表示bit_flag总共有4个TRUE值，则Tile 1 的 y_offset[3]= 4. 算法5说明了如何以SIMD方式生成单个二维Tile的y_offset。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422010055.png)
<center> <font face='华文宋体' size='4'> 图 10  算法5：生成y_offset和seg_offset数组 </font> </center>
`y_offset`使得每个处理单元（如GPU上的线程）能够<font color='red'><b>独立地计算出其结果应该存储到结果向量y的哪个位置，无需额外的同步或通信</b></font>。

#### seg_offset

第三个数组 seg _ offset 的大小 ω 用于加速每个Tile的工作负载中的局部分段和。局部分段和是同步2D Tile 中的部分和的基本步骤(假设Tile中的多个列来自同一矩阵行)。在先前的分段和(或分段扫描)方法中，局部分段和是复杂的，不够有效。因此我们准备了 seg 偏移量作为辅助阵列，**通过前缀和扫描实现分段和，这是一个优化的 SIMD 单元的基本原语**。

为了生成seg_offset，<font color='red'><b>让每一列搜索其右侧相邻的列，并计算连续的没有TRUE值在它们的bit_flag中的列数</b></font>。以图4中的Tile 0为例，它的第2列只有一个右侧相邻列（第3列）在其bit_flag中没有任何TRUE值。因此第2列的seg_offset值为1。相反，因为其他三列（第1、3和4）没有任何“全FALSE”右侧相邻项，它们在seg_offset中的值是0。算法5展示了如何使用SIMD友好方法生成seg_offset。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422011649.png)
<center> <font face='华文宋体' size='4'> 图 11 使用seg_offset和包含前缀和扫描的快速分段求和 </font> </center>
算法6和图5展示了使用seg_offset和包含前缀和扫描的快速分段求和。该操作的原则是前缀和扫描本质上是一个增量操作。一旦一个段知道其头部与尾部之间的距离（即偏移量），它的部分总和可以从其前缀和扫描结果中推导出来。因此，**以前论文中更复杂的分段求和操作可以转换为更快速的前缀和扫描操作（第5行）以及少数算术运算**（第6-8行）。


#### empty_offset
数组最后一个空偏移量出现的情况是当且仅当2D Tile 包含任何空行时（即，其Tile指针为负）。因为空矩阵的一行与其最右边的非空邻居行具有相同的行指针（参见图1中矩阵A中的第二行），y_offset将记录它的不正确偏移量。我们通过为Tile内部段存储正确的偏移量来纠正这个问题。因此，**empty_offset 的长度是一个Tile中段数（即 bit_flag 中 TRUE 总数）** 。例如，在图4中，Tile 0 的 empty_offset 具有4个条目，因为其 bit_flag 包括 4 个 TRUE。算法7列出了生成至少包含一行空白行的Tile empty_offset 的伪代码。

### 存储细节

为了以节省空间的方式存储`tile_desc`数组，我们找到条目的上界并利用位域模式。首先，由于y_offset中的条目存储2DTile内的偏移距离，它们具有ωσ的上界。因此，每个y_offset中的条目需要$\lceil\log_2\left(\omega\sigma\right)\rceil$位就足够了。例如，当ω = 32且σ = 16时，每个条目需要9位。其次，由于seg_offset包括小于ω的偏移量，在这个数组中一个条目只需要$\lceil\log_2\left(\omega\right)\rceil$位就足够了。例如，当ω = 32时，每个条目只需5位。第三，在bit_flag中为2D瓦片的每一列存储σ个1比特标志位。当σ = 16时，每列需要16位。所以在示例中对于每一列来说30（即9 + 5 + 16）位就足够了。

因此对于一个Tile来说, 这三个数组可以被存储在由 ω 32-bit无符号整数组成紧凑型二进制字段里. 如果以上示例矩阵具有32-bit整数行索引和64-bit双精度值, 那么仅额外约需多大约百分之二左右空间是被这三种新添加数组所要求. empty_offset 的大小取决于连续空行组数量, 因为我们仅记录最右边非空行及其所有左邻居为空行数量作为偏移量.

### CSR5对于其他的矩阵操作

由于我们对CSR数组col_idx和val进行了原地转置，因此需要将CSR5转换为CSR以便使用CSR格式执行其他稀疏矩阵操作。<font color='red'><b>从CSR5转换为CSR格式只需移除tile_ptr和tile_desc，并将col_idx和val重新转置为行主序</b></font>。因此，这种转换可以非常快速。

另外，由于CSR5是CSR的超集，任何条目访问或轻微更改都可以直接在CSR5格式中完成，而无需将其转换为CSR格式。此外，一些应用程序（如有限元方法）可以直接从数据源中组装采用CSR5格式的稀疏矩阵。


## The CSR5-Based SpMV Algorithm

因为**2D Tile 的信息（tile_ptr、tile_desc、col_idx和val）的所有计算都彼此独立，它们可以并发执行**。在GPU上，我们为<font color='red'><b>每个Tile分配一组线程</b></font>（即nvidia GPU中的warp或AMD GPU中的wave front）。在CPU和Xeon Phi上，<font color='red'><b>使用OpenMP pragma将Tile分配给可用的x86核心</b></font>。此外，在一个Tile内部，列也是相互独立的。因此，可以为<font color='red'><b>每个列分配一个GPU核心上的线程或者x86核心上的SIMD通道</b></font>。

在运行基于CSR5的SpMV时，**每个Tile中的列可以从bit_flag提取信息，并将其本地数据中段标记为三种颜色**：
- （1）<font color='red'><b>红色</b></font>表示从顶部未封闭子段
- （2）<font color='green'><b>绿色</b></font>表示存在完全封闭段位于中间位置
- （3）<font color='blue'><b>蓝色</b></font>表示从底部未封闭子段。
有一个例外情况是如果某一列既从顶部又从底部未封闭，则会被着以红色。

算法8展示了基于CSR5 的SpMV算法伪代码。图6描绘了这个过程的示例。我们可以看到，<font color='red'><b>由于索引可以通过使用tile_ptr和y_offset来计算，在不需要任何同步操作下直接将其局部总和保存到y 中</b></font>。（如果不分块的话，行就会很长，如果使用一个线程去进行处理，就会出现负载不均衡的现象，但是如果使用多个线程去进行处理，又会出现需要同步的情况，所以，才会想出分块的办法吧～）

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422020121.png)
<center> <font face='华文宋体' size='4'> 图 12 基于CSR5的SpMV算法 </font> </center>
与之相反，**红色和蓝色子段必须进一步将它们各自局部总和相加起来, 因为它们不是完整段位**。例如, 图6 中B2、R2 和 R3 子段对同一行有贡 献, 因此需要进行加法操作. 这种加法操作需要快速分割求和如图5所示. 此外, **如果一个 tile 具有任何空行，则访问 empty_offset 数组以获取 y 中正确全局索引**.

考虑Tile之间的同步，因为相同的矩阵行可能会受到多个同时运行的2DTile的影响，所以需要通过原子加法将Tile的第一个和最后一个段存储到y中（或者在设备级别减少、扫描或分段扫描中使用全局辅助数组）。在图6中，原子加法操作用带有加号箭头线标记。

对于不完整瓦片中的最后条目（例如，在图4中矩阵的最后两个非零条目），**在所有完整2D Tile 被消耗之后执行传统CSR-vector方法**。请注意，即使最后一个Tile（即不完整的那个）没有tile_desc数组，它也可以从tile_ptr提取起始位置。在算法8中，可以看到主要计算（第5至21行）仅包含非常基本的算术和逻辑操作，这些操作可以很容易地编程到所有具有SIMD单元的主流处理器上。作为我们算法中最复杂部分，快速分段求和运算（第22行）只需要前缀和扫描，这已经得到了深入研究，并且可以通过使用CUDA、OpenCL或x86 SIMD指令高效实现。

## Experimental Results

### 实验设置

我们在四个主流平台上评估了基于CSR5的SpMV和11种最先进的格式和算法：双插槽英特尔CPU、一款nvidia GPU、一款AMD GPU和一款Intel Xeon Phi。表1显示了这些平台和参与方法。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422020552.png)
<center> <font face='华文宋体' size='4'> 图 13 测试平台和参与的格式和算法 </font> </center>
两个GPU的主机是配备AMD A10-7850K APU、双通道DDR3-1600内存以及64位Ubuntu Linux v14.04系统的计算机。Xeon Phi的主机是配备Intel Xeon E5-2680 v2 CPU、四通道DDR3-1600内存以及64位Red Hat Enterprise Linux v6.5系统的计算机。两个GPU平台使用g++编译器v4.8.2。两台英特尔计算机始终将Intel C/C++编译器15.0.1设置为默认值。

在这里，我们评估双精度SpMV。因此，cuDPP库、clSpMV和yaSpMV不包括在内，因为它们仅支持单精度浮点作为数据类型。由于最近发布的两种方法 的源代码尚不可用，因此未进行测试。我们使用OpenCL分析方案来对AMD平台上的SpMV进行定时，并记录其他三个平台上的挂钟时间。**对于所有参与格式和算法，我们评估了10次SpMV（每次包含1000次运行并记录平均值），并报告观察到的最佳结果**。


### 基准套件

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422020833.png)
<center> <font face='华文宋体' size='4'> 图 14 测试用的稀疏矩阵集 </font> </center>

在表2中，我们列出了24个稀疏矩阵作为所有平台的基准测试套件。前20个矩阵在以前的 SpMV 研究中被广泛采用。选择其他4个矩阵，因为它们具有更多样化的稀疏结构。除 Dense 以外的所有矩阵都可以在佛罗里达大学稀疏矩阵集合下载。

为了达到高度的微分，我们将表2中的24个矩阵分为两组: (1)上14个矩阵的正则组，(2)下10个矩阵的不规则组。这种分类主要基于行的最小、平均和最大长度。矩阵 dc2是不规则矩阵群的代表。其最长的单行包含114K 非零项，即117K 行的整个矩阵的15% 非零项。这种稀疏模式对高效的存储格式和 SpMV 算法的设计提出了挑战。

### 单独的 SpMV 性能

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422021015.png)
<center> <font face='华文宋体' size='4'> 图 15 14个正则矩阵(nGPU = nVidia GPU，aGPU = AMD GPU)的 SpMV 性能 </font> </center>

上图显示了四个平台上14个正则矩阵的双精度 SpMV 性能。我们可以看到，平均而言，所有参与的算法都能提供类似的性能。在 CPU 平台上，英特尔 MKL 平均获得了最好的性能，其他3种方法也有类似的性能。在 nvidia 图形处理器上，CSR5提供了最高的吞吐量。ACSR 格式比其他格式慢，因为它的分组策略导致不合并的内存访问。在 AMD 图形处理器上，CSR5获得了最好的性能。**虽然 CSR-自适应方法中的动态分配比 CSR-向量方法具有更好的可扩展性，但仍不能实现近乎完美的负载平衡**。在至强 Phi 上，CSR5比 Intel MKL 和 ESB 格式慢。主要原因是当前的 Xeon Phi 每个核心最多只能发出4个相对较慢的线程(也就是说，在所使用的设备上总共最多可以发出4 × 60个线程) ，因此从向量 x 收集条目的延迟成为主要的瓶颈。然后，基于列索引对非零条目进行重新排序或分区，以获得更好的缓存本地性，这在基于 ESB 的 SpMV 中表现良好。然而，在5.6节中我们将展示这种策略导致非常高的预处理成本。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422021159.png)
<center> <font face='华文宋体' size='4'> 图 16 10个不规则矩阵的 SpMV 性能(nGPU = nVidia GPU，aGPU = AMD GPU) </font> </center>

上图显示了10个不规则矩阵的双精度 SpMV 性能。我们可以看到，不规则性可以显着影响 SpMV 的吞吐量的一些方法。

在 CPU 平台上，基于 Intel MKL 的行块方法现在比其他方法慢。CSR5的性能优于其他的，因为更好的 SIMD 效率从 AVX2的内在。

在 nVidia GPU 上，CSR5带来了最好的性能，因为它具有近乎完美的负载平衡。另外两种面向不规则性的格式 HYB 和 ACSR 表现良好，但仍然存在工作分解不平衡的问题。请注意，ACSR 格式是基于 Dy namic Parallelism 的，这是一个只能在最近发布的 nVidia GPU 上使用的技术特性。在 AMD GPU 上，CSR5使用行块方法的性能大大优于其他两种算法。由于 CSR 自适应方法的最小工作单元是一行，所以该方法对于行数很长的矩阵来说性能降低了。

在 Xeon Phi 上，CSR5可以大大优于其他两种方法，特别是当矩阵太不规则以至于不能通过 ESB 格式暴露 x 的缓存区域时。此外，由于 ESB 是在 ELLPACK 格式的基础上设计的，因此对于一些不规则矩阵不能获得最佳的性能。

总的来说，CSR5为14个常规矩阵实现了更好的性能(在两个 GPU 设备上)或可比性能(在两个 x86设备上)。对于10个不规则矩阵，CSR5的平均性能增益分别为17.6% 、28.5% 、173.0% 和293.3% (分别达到213.3% 、153.6% 、405.1% 和943.3%)。

### 自动调整的效果

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422021720.png)
<center> <font face='华文宋体' size='4'> 图 17 自动调优在两个GPU上的对比 </font> </center>
在3.2节中，讨论了 GPU 上参数 σ 的一个简单的自动调整方案。图9显示了它的效果(x 轴是矩阵 id)。我们可以看到，与在 σ = 4到48的范围内选择的最佳性能相比，自调优 σ 没有明显的性能损失。在 nVidia GPU 上，性能损失平均为 -4.2% 。在 AMD 图形处理器上，平均值为 -2.5% 。

### 格式转换损失

从 CSR 到 CSR5的格式转换包括四个步骤:
- (1)内存分配
- (2)生成 `tiles_ptr`
- (3)生成 `tiles_desc`
- (4) `colidx` 和` val `数组的转换

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markd![image.png|center](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422022005.png)own_images@master/images-2/20240422022005.png)
<center> <font face='华文宋体' size='4'> 图 18 格式转换的开销 </font> </center>
图10显示了四个使用平台上24个矩阵(x 轴是矩阵 id)的四个步骤的成本。一个 SPMV 操作的成本用于规范每个平台上的格式转换成本。我们可以看到，**转换成本可以平均低至两个 GPU 上的一些 SpMV 操作的开销**。在两个 x86平台上，转换时间更长(最高可达10-20个 SpMV 操作的成本)。原因是转换代码是在 GPU 上使用 CUDA 或 OpenCL 手动 SIMDized 的，但是只能在 x86处理器上由 OpenMP 自动并行化。

### 基于迭代的场景

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240422022204.png)
<center> <font face='华文宋体' size='4'> 图 19 预处理成本及其对基于迭代的场景的影响 </font> </center>
可以看到，由于预处理开销非常低，CSR5在执行50次迭代和500次迭代时可以进一步优于以前的方法。虽然 ACSR 格式和 CSR 自适应两种 GPU 方法通常具有较短的预处理时间，但它们的 SpMV 性能较差，不能获得最佳的加速比。在所有平台上，CSR5总能获得最高的整体加速。此外，当只需要50次迭代时，CSR5是唯一比 mat 的 CSR 获得更高性能的格式。

## Related work

在加速 SPMV 运行方面已经出版了大量的著作。基于块的稀疏矩阵构造受到了广泛的关注，主要原因有两个: 
- (1)由一些实际问题(如有限元离散化)产生的稀疏矩阵自然具有块子结构; 
- (2)使用块指数代替入口指数可以减少片外负载操作。
然而，对于许多不具有自然块结构的矩阵来说，尝试提取块信息是非常耗时的，而且效果有限。

另一方面，混合格式 ，比如 HYB，是为不规则矩阵设计的。然而，较高的内核启动开销和内核启动之间失效的缓存往往会降低它们的整体性能。而且，很难保证每个子矩阵都能使整个器件饱和。此外，一些相对简单的操作，如求解三角形系统变得复杂，而输入矩阵存储在两个或多个独立的部分

最近的行块方法对于正则矩阵或不规则矩阵都表现出良好的性能，但对于两者都不是。相比之下，CSR5可以为正则矩阵和不规则矩阵提供更高的吞吐量。

分段求和方法已经在最近发表的两篇论文中用于 GPU 或 Xeon Phi 上的 SpMV。但是，它们都需要将矩阵存储为类似于 COO 的格式，以利用分段和。相比之下，CSR5格式以紧凑的方式保存有用的行索引信息，因此对于格式转换和 SpMV 操作都更有效。

Sedaghati 等构造了机器学习分类器，用于在目标 GPU 上自动选择给定稀疏矩阵的最佳格式。由于 CSR5格式对输入稀疏矩阵的稀疏结构不敏感，因此可以进一步简化这种选择过程。

此外，据我们所知，CSR5是唯一一种同时支持 CPU、 nvidia GPU、 AMD GPU 和 Xeon Phi 上的高吞吐量跨平台 SpMV 的格式。这一优势可以简化为具有大规模片上并行性的处理器开发科学软件的工作。

## Conclusions

在本文中，我们提出了 CSR5格式，以便在 CPU、 GPU 和 Xeon Phi 上实现高效的跨平台 SpMV。<font color='red'><b>由于该格式对输入矩阵的稀疏结构不敏感，因此从 CSR 到 CSR5的格式转换非常快</b></font>。基于 CSR5的 SPMV 算法是<font color='red'><b>通过重新设计的分段和算法实现的，与经典算法相比，该算法具有更高的 SIMD 利用率</b></font>。实验结果表明，CSR5在孤立的 SpMV 测试和基于迭代的场景中都提供了高吞吐量。









