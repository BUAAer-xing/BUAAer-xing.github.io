<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.2.0">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="论文原文地址：“Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner” (pdf)"><meta data-rh="true" property="og:description" content="论文原文地址：“Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner” (pdf)"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.b2f6c615.css">
<script src="/assets/js/runtime~main.dba0c1d3.js" defer="defer"></script>
<script src="/assets/js/main.29f83266.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper-notes-intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs-intro">个人博客</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper-notes-intro">笔记说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/Kernel/intro">Kernel</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/未分类/intro">未分类</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/未分类/intro">说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/论文原件">Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/未分类/大规模线性问题求解算法的高可扩展性研究/论文原件">大规模线性问题求解算法的高可扩展性研究</a></div></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">未分类</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">阅读笔记</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>阅读笔记</h1>
<p>论文原文地址：“Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner” (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=1&amp;annotation=IJIXDC86" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract">​</a></h2>
<p>对于求解该线性方程<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax=b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>，当<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>矩阵是对称且正定时，通常的解决办法是使用：共轭梯度法（Conjugate Gradient） ，可以简称为CG。</p>
<p>而CG的求解效率和A矩阵的特征值分布有关，为了加速该方程的求解，可以考虑对A进行线性变换，使得矩阵A的特征值分布的更为密集，这里就引入了一个方法，就是使用某种矩阵对A进行线性变换，从而得到更为密集的特征值分布。 ^42dc2d</p>
<p>“Part of its effectiveness relies on finding a suitable pre-conditioner that accelerates its convergence.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 1</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=1&amp;annotation=4TW5ZLCR" target="_blank" rel="noopener noreferrer">pdf</a>) CG的效率部分取决于找到一个加速其收敛的适当预处理器。也就是这个矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span>。</p>
<p>⭐️寻找这个矩阵的方法：<strong>Factorized Sparse Approximate Inverse (FSAI) pre-conditioners</strong> are a prominent and easily parallelizable option. ， 这个和利用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> 进行变换的方法类似，但在计算机上运行更为快速也便于进行并行计算。因为这个不需要进行求逆运算。</p>
<p>⭐️这篇文章主要贡献：“we introduce <strong>complementary architecture-aware criteria</strong> to increase the numerical effectiveness of the <strong>pre-conditioner</strong>. In particular, <strong>we define cache-aware pattern extensions</strong> that do not trigger additional cache misses when accessing vector 𝑥 in the 𝑦 = 𝐴𝑥 Sparse Matrix-Vector (SpMV) kernel.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 1</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=1&amp;annotation=D8N6NFT5" target="_blank" rel="noopener noreferrer">pdf</a>) ”我们引入互补的面向架构的标准，以增加预条件器的数值效果。特别是我们定义了缓存感知的模式扩展，在使用矢量x访问y = Ax<strong>稀疏矩阵-向量(SpMV)核</strong>时不触发附加的缓存未命中。 ^1de814</p>
<p>Sparse Matrix-Vector (SpMV) kernel 是指执行稀疏矩阵向量乘法的计算核心。它是一种常见的计算机科学和数值计算中的操作，用于将稀疏矩阵与向量相乘。SpMV kernel 的目标是高效地执行这种乘法运算，以便在处理大规模稀疏矩阵时能够提供较快的计算速度和较低的内存占用。SpMV kernel 的实现方式可以根据具体的硬件架构和优化目标而有所不同。</p>
<ul>
<li>introduce <strong>complementary architecture-aware criteria</strong></li>
<li>define <strong>cache-aware pattern extensions</strong></li>
</ul>
<p>⭐️论文的改进效果：“As a result, we obtain very significant reductions in terms of average solution time ranging between 12.94% and 22.85% on three different architectures - Intel Skylake, POWER9 and A64FX - over a set of 72 test matrices.” (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=1&amp;annotation=CHL8QXC6" target="_blank" rel="noopener noreferrer">pdf</a>) 因此，我们在三种不同架构（Intel Skylake、POWER9和A64FX）上对72个测试矩阵进行了评估，得出了平均解决时间的显著减少，范围在12.94%至22.85%之间。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>在求解线性方程时</p>
<ul>
<li>“Direct methods like the sparse LU factorizations are not useful in this context due to their memory requirements and the significant number of steps they take.” (Laut 等, 2021, p. 1) 🔤直接的方法，如稀疏LU分解，在这种情况下不太有用，因为它们需要大量的内存，并  且需要相当多的步骤。🔤</li>
<li>“Thus, iterative methods are the best option and, in particular, Krylov methods are very commonly applied due to their excellent convergence properties.” (Laut 等, 2021, p. 1) 🔤因此，迭代方法是最佳选择，特别是由于其优异的收敛性质，Krylov方法非常常用。🔤</li>
</ul>
<p>⭐️特别的：当线性方程<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>x</mi><mo>=</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Ax=b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">b</span></span></span></span>中的A矩阵为对称正定矩阵时，“When dealing with symmetric and positive definite matrices a popular Krylov method, Conjugate Gradient (CG), is typically applied.” (Laut 等, 2021, p. 1) 🔤当处理对称和正定矩阵时，通常会使用一种流行的克里洛夫方法——<strong>共轭梯度法（CG）</strong>。🔤</p>
<p>“The performance of the SpMV is significantly influenced by irregular memory access patterns on 𝑥 driven by the locations of the sparse matrix non-zero coefficients.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 1</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=1&amp;annotation=4MU3PQ4H" target="_blank" rel="noopener noreferrer">pdf</a>) 🔤稀疏矩阵向量乘法（SpMV）的性能受<strong>稀疏矩阵非零系数的位置</strong>所驱动，进而显著受到在 x 上的不规则内存访问模式  影响。🔤
![[Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner##^42dc2d]]</p>
<p>除了每个单独核心的性能特性外，另一个强烈影响CG解线性方程组容量的因素是矩阵A的条件数。</p>
<p>在这个背景下，<strong>预条件器通常用于改善CG的收敛性</strong>。从简单的Block-Jacobi [34]到复杂的多网格技术[18]，已提出大量旨在实现有效预处理的方法。</p>
<p>稀疏近似逆(SAI)预处理器包括一种近似的逆矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>≈</mo><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">M≈A^{−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>，并受到某种稀疏模式的限制[11, 12]。</p>
<p>⭐️随后，求解等价和更好条件的系统<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>A</mi><mi>x</mi><mo>=</mo><mi>M</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">MAx = Mb</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">b</span></span></span></span>。</p>
<p>实际上，应用SAI预处理器包括使用额外的SpMV核，使其高度并行化。在CG的上下文中，对称正定问题应用因式分解稀疏近似逆(FSAI)，这意味着通过因式分解<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mi>T</mi></msup><mi>G</mi></mrow><annotation encoding="application/x-tex">G^TG</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">G</span></span></span></span>来逼近<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A^{−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>，而不是单一矩阵。</p>
<p>⭐️FSAI的一个非常重要的方面是其<strong>相应稀疏模式的定义</strong>。尽管目前最先进的解决方案只考虑数值方面，但本文证明，在定义FSAI稀疏模式时，低层架构相关的概念也应该被考虑进去。“While state-of-theart solutions define this pattern by exclusively taking into account numerical considerations, we demonstrate in this paper that low-level architecture-aware concepts should also be taken into account when defining the FSAI sparse pattern.”(<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=1&amp;annotation=6CKVTN5P" target="_blank" rel="noopener noreferrer">pdf</a>) 🔤当今最先进的解决方案仅通过考虑数字因素来定义这一模式，而我们在本文中展示，<strong>当定义FSAI稀疏模式时，还应考虑低级架构意识的概念</strong>。🔤</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="本文的贡献">本文的贡献<a href="#本文的贡献" class="hash-link" aria-label="Direct link to 本文的贡献" title="Direct link to 本文的贡献">​</a></h3>
<p>本文<strong>提出并评估了一种扩展基于FSAI的稀疏模式的方法</strong>。</p>
<p>该方法基于两个基本概念：</p>
<ul>
<li>首先，<strong>一种缓存感知算法</strong>用于扩展稀疏模式，从而降低CG迭代次数，同时保持每次迭代的成本较低。<!-- -->
<ul>
<li>这种缓存感知优化依赖于缓存层次体系结构的底层细  节，如索引机制或虚拟内存管理方法。</li>
</ul>
</li>
<li>其次，一种<strong>过滤缓存感知FSAI模式扩展中最小条目</strong>的方法，而不降低其收敛性能。</li>
</ul>
<p>本文相对于现有技术的贡献如下：</p>
<ol>
<li>We propose a technique to obtain cache-friendly FSAI sparse patterns.<!-- -->
<ul>
<li>By considering some low-level aspects of the cache hierarchy architecture, <strong>our algorithm is able to extend sparsity patterns in a way the number of iterations is reduced while the cost per iteration remains low enough to increase performance</strong>.</li>
<li>Our approach is architecture independent as it just requires the cache line size as architecture input.</li>
</ul>
</li>
<li>We propose a robust approach to <strong>filter out small entries of the inverse approximation</strong> without degrading the numerical properties of the FSAI pre-conditioner.</li>
<li>We <strong>evaluate our proposals via an extensive evaluation campaign considering 72 matrices of the SuiteSparse Collection</strong> [13] that fit in the available memory resources of a single node.<!-- -->
<ul>
<li>Our experiments consider three high-end systems: a 48-core Skylake machine, a 40-cores POWER9, and a 48-cores A64FX.</li>
<li>In Skylake, our approach reduces timeto-solution by 15.02% on average.</li>
<li>In POWER9 and A64FX, these improvements are 12.94% and 22.85%, respectively.</li>
</ul>
</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="conjugate-gradient-cg">Conjugate Gradient （CG）<a href="#conjugate-gradient-cg" class="hash-link" aria-label="Direct link to Conjugate Gradient （CG）" title="Direct link to Conjugate Gradient （CG）">​</a></h3>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="sparse-approximate-inverse-pre-conditionersai">Sparse Approximate Inverse Pre-conditioner（SAI）<a href="#sparse-approximate-inverse-pre-conditionersai" class="hash-link" aria-label="Direct link to Sparse Approximate Inverse Pre-conditioner（SAI）" title="Direct link to Sparse Approximate Inverse Pre-conditioner（SAI）">​</a></h3>
<p>稀疏近似逆（Sparse Approximate Inverse，SAI）预条件器基于逆矩阵中有许多可以忽略的小元素的假设，只保留最大的元素，并因此达到稀疏逼近的有效性。</p>
<p>在SAI方法的设置过程中，寻找一个满足固定稀疏模式S的逆矩阵的近似<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>≈</mo><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">M≈A^{−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>。考虑等效但条件更好的系统<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mi>A</mi><mi>x</mi><mo>=</mo><mi>M</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">MAx=Mb</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">b</span></span></span></span>。</p>
<p>“When dealing with symmetric and positive definite problems, to preserve the system symmetry, the Factorized Sparse Approximate Inverse (FSAI) preconditioner is applied and 𝐴−1 is approximated by a factorization 𝐺𝑇 𝐺 instead of a single matrix 𝑀, which means that two SpMV products are necessary instead of one. 𝐺 is a sparse lower triangular matrix approximating the inverse of the Cholesky factor, 𝐿, of 𝐴.” (Laut 等, 2021, p. 2)</p>
<p>🔤当处理对称且正定问题时，为了保持系统的对称性，我们采用了Factorized Sparse Approximate Inverse（FSAI）预处理器，并且用⭐️因式分解<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mi>T</mi></msup><mi>G</mi></mrow><annotation encoding="application/x-tex">G^TG</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">G</span></span></span></span>来逼近<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A^{−1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> ⭐️，而不是单独的矩阵M，这意味着需要两个SpMV乘积而不是一个。G是一个稀疏的下三角矩阵，近似表示<strong>A的Cholesky分解因子L的逆</strong>。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>≈</mo><msup><mi>L</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">G≈L^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">G</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>🔤</p>
<p>![[Cholesky分解因子]]</p>
<p>如何寻找G：
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑚</mi><mi>𝑖</mi><msub><mi>𝑛</mi><mrow><mi>𝐺</mi><mo>∈</mo><mi>S</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>𝐼</mi><mo>−</mo><mi>𝐺</mi><mi>𝐿</mi><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mi>𝐹</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">𝑚𝑖𝑛_{𝐺 ∈ S} ||𝐼 − 𝐺𝐿||^2_𝐹 </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">mi</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0894em;vertical-align:-0.2753em"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">L</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">F</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span></span></span></span>
其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>L</mi><msup><mi>L</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A=LL^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord mathnormal">L</span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mo>≈</mo><msup><mi>L</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">G≈L^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">G</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>“We apply state-of-the-art techniques [11] to find 𝐺 without explicitly evaluating 𝐿, i. e., only using the initial matrix 𝐴.” (Laut 等, 2021, p. 2) 🔤我们使用最先进的技术[11]来找到没有明确评估L的G，即只使用初始矩阵A。🔤</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230811190257.png" alt="image.png|center|800" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="accelerating-fsai">Accelerating FSAI<a href="#accelerating-fsai" class="hash-link" aria-label="Direct link to Accelerating FSAI" title="Direct link to Accelerating FSAI">​</a></h2>
<p>“This section describes a high-level view of our cache-aware sparse pattern extension strategy to boost the FSAI performance.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 2</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=2&amp;annotation=MIPAEIIK" target="_blank" rel="noopener noreferrer">pdf</a>) 🔤本节描述了我们的<strong>高级缓存感知稀疏模式扩展策略，以提高FSAI的性能</strong>。🔤</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230811190947.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>算法2显示了通过添加一个步骤，即增加<strong>the cache-friendly extension of the sparse pattern</strong>(稀疏模式的缓存友好扩展)，并通过一个<strong>更复杂的过滤处理应用于G的近似预计算结果</strong>，来替换G的筛选和重新缩放步骤的FSAI的重新制定。</p>
<ul>
<li><strong>The step</strong> added in line 3 <strong>extends the sparse pattern</strong> of 𝐺 considering architecture-aware criteria <strong>to add additional entries</strong> that reduce the CG iteration count while incurring a minimal overhead in terms of iteration cost.<!-- -->
<ul>
<li>Note that we propose an extension of the sparse pattern, therefore <strong>the set of matrices</strong> considered in the Frobenius minimization problem of Equation 3 <strong>increases</strong>. Consequently, <strong>the new inverse approximation is more accurate.</strong></li>
<li>在第四部分进行解释</li>
</ul>
</li>
<li><strong>The step</strong> added in line 4 <strong>replaces the filtration</strong> that Algorithm 1 performs after the computation of 𝐺.<!-- -->
<ul>
<li>In this new filtration strategy, entries of the sparse pattern are filtered out based on an approximate pre-calculation of 𝐺.</li>
<li>在第五部分进行解释</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cache-friendly-fill-in">Cache-Friendly Fill-in<a href="#cache-friendly-fill-in" class="hash-link" aria-label="Direct link to Cache-Friendly Fill-in" title="Direct link to Cache-Friendly Fill-in">​</a></h2>
<p>“In this section we propose a <strong>cache-friendly fill-in approach</strong> to <strong>extend the sparse pattern of the FSAI pre-conditioner</strong>. We propose <strong>architecture-aware techniques</strong> to extend the sparse pattern in a way that we achieve significant reductions in terms of iteration count while minimizing the iteration cost overhead. In particular, we propose a method to extend the FSAI sparse pattern without increasing the number of cache misses.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 3</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=3&amp;annotation=KA4BIUZ4" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<p>🔤在本节中，我们提出了一种缓存友好的填充方法来扩展FSAI预处理器的稀疏模式。我们提出了一种架构感知技术，以在减少迭代计数的同时最小化迭代成本开销的方式来扩展稀疏模式。具体而言，我们提出了一种在不增加缓存未命中次数的情况下扩展FSAI稀疏模式的方法。🔤</p>
<p>Since FSAI is applied via the SpMV kernel 𝑦 = 𝐴𝑥, we must consider the <strong>access patterns</strong> for all the involved data structures containing 𝑦, 𝐴, and 𝑥.</p>
<ul>
<li>访问A矩阵：<!-- -->
<ul>
<li>Assuming that we traverse the sparse matrix 𝐴 <strong>in row order</strong> and that we <strong>store it using the Compressed Sparse Row (CSR) format</strong>, the accesses on the data structures containing 𝐴 display a very simple stride-1 pattern. Since <strong>this pattern is easily predictable</strong> by hardware pre-fetchers, there is some flexibility for extending 𝐴 without suffering a prohibitive performance penalty。</li>
</ul>
</li>
<li>对于y：<!-- -->
<ul>
<li>和访问A类似</li>
</ul>
</li>
<li>对于x：<!-- -->
<ul>
<li>The most problematic accesses are those coming from accesses to <strong>vector 𝑥</strong>, which follow a random pattern and thus <strong>can not be easily predicted by the pre-fetcher</strong>.</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cache-alignment-of-vector-𝑥">Cache Alignment of Vector 𝑥<a href="#cache-alignment-of-vector-𝑥" class="hash-link" aria-label="Direct link to Cache Alignment of Vector 𝑥" title="Direct link to Cache Alignment of Vector 𝑥">​</a></h3>
<p>Our approach drives the extension of the FSAI sparse pattern by taking into account <strong>the cache alignment of vector 𝑥.</strong></p>
<p>“In other words, the idea is to add new coefficients in 𝐴 that fully exploit the spatial locality on memory accesses to vector 𝑥.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 3</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=3&amp;annotation=Y6NHCKMD" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<p>换句话说，意思是在矩阵A中添加新的系数，充分利用对向量x的内存访问的空间局部性。 该方法依赖于通过使用相应的虚拟地址来确定缓存行中存储的向量元素xi的相对位置</p>
<p>我们可以通过虚拟地址的偏移位来确定某个xi所在cache行的相对位置</p>
<p>比如：64B的cache行，存储double变量（8B），可以存储8个，当我们需要确定xi所在cache行的相对位置时，就可以将虚拟地址mod8来进行计算，从而得出相对位置。而当cache行的大小变大时，我们需要动态调整这个mod的数值，比如，当cache行大小变为256B时，存储double变量，可以存储64个，故此时mod的大小就应该为：64。</p>
<p>Our approach is <strong>architecture independent</strong>  架构无关性
因为：</p>
<ul>
<li>i) it can be adapted to any cache line size by simply <strong>adjusting this value</strong> before applying the cache-friendly fill-in procedure;</li>
<li>ii) it can be adapted to any cache indexing mechanism <strong>using virtual addresses</strong>; and, finally,</li>
<li>iii) it can be applied to <strong>any Instruction</strong> Set Architecture (ISA).</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="algorithm-for-cache-friendly-fill-in">Algorithm for Cache-Friendly Fill-In<a href="#algorithm-for-cache-friendly-fill-in" class="hash-link" aria-label="Direct link to Algorithm for Cache-Friendly Fill-In" title="Direct link to Algorithm for Cache-Friendly Fill-In">​</a></h3>
<p>我们提出了一种算法，用于生成一个通用FSAI稀疏模式的缓存友好的填充。</p>
<p>我们算法的输入是初始稀疏模式S和将在[[Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner##^1de814|SpVM]]操作中使用的数组x。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230823214637.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>算法3显示了我们的缓存友好填充算法的伪代码。</p>
<p>主循环迭代初始模式行，并且对于每一行，遍历其所有非零条目（行4-13）。</p>
<p>对于每个条目j，它通过使用第4.1节中描述的过程来标识相应的xj组件的缓存行（行9），然后通过插入以前不存在的条目来扩展稀疏模式，这些条目对应于存储在同一缓存行中的向量x的部分（行10和11）。</p>
<p>该算法可以使用基于线程的方法（如OpenMP或Posix线程）轻松并行化。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="applying-the-cache-friendly-fill-in-to-fsai">Applying the Cache-Friendly Fill-In to FSAI<a href="#applying-the-cache-friendly-fill-in-to-fsai" class="hash-link" aria-label="Direct link to Applying the Cache-Friendly Fill-In to FSAI" title="Direct link to Applying the Cache-Friendly Fill-In to FSAI">​</a></h3>
<p>the FSAI pre-conditioner approximates <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mrow><mo> −</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">A^{-1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span> by the factorization <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>𝐺</mi><mi>T</mi></msup><mi>𝐺</mi></mrow><annotation encoding="application/x-tex">𝐺^T𝐺</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">G</span></span></span></span></p>
<p>The sparse pattern of the original 𝐺 matrix is extended using the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>l</mi><mi>g</mi><mi>o</mi><mi>r</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>m</mi><mn>3</mn></mrow><annotation encoding="application/x-tex">algorithm 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal" style="margin-right:0.02778em">or</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">hm</span><span class="mord">3</span></span></span></span> to obtain an extended 𝐺𝑒𝑥𝑡 matrix.</p>
<p>“Therefore, when multiplying by 𝐺𝑇 𝑒𝑥𝑡 , the entries generated by the extension are accessed in consecutive rows. In conclusion, the spatial locality optimization for the 𝐺𝑒𝑥𝑡 product results in a temporal locality optimization of the 𝐺𝑇 𝑒𝑥𝑡 product.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 4</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=4&amp;annotation=A9T4KEJU" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<p>⭐️⭐️因此，当通过<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>G</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">G^T_{ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0883em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span></span></span></span>进行乘法运算时，扩展产生的条目是按连续行访问的。总之，对于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>乘积的空间局部性优化导致了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>G</mi><mrow><mi>E</mi><mi>x</mi><mi>t</mi></mrow><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">G^T_{Ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1167em;vertical-align:-0.2753em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em">E</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span></span></span></span>乘积的时间局部性优化。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cache-friendly-fill-in-process-example">Cache-Friendly Fill-In Process Example<a href="#cache-friendly-fill-in-process-example" class="hash-link" aria-label="Direct link to Cache-Friendly Fill-In Process Example" title="Direct link to Cache-Friendly Fill-In Process Example">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://jsd.cdn.zzko.cn/gh/NEUQer-xing/Markdown_images@master/images-2/%E6%88%AA%E5%B1%8F2023-09-01%2011.09.35.png" alt="截屏2023-09-01 11.09.35.png" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="filtering-out-small-g-entries">Filtering Out Small G Entries<a href="#filtering-out-small-g-entries" class="hash-link" aria-label="Direct link to Filtering Out Small G Entries" title="Direct link to Filtering Out Small G Entries">​</a></h2>
<p>为了使得得到的近似结果更加高效，一种比较常见的方法是通过滤除一些在G中绝对值较小的条目。</p>
<p>但这个方法虽然可以使得近似结果计算更加高效，但是它同样也降低了该前处理器的数字质量。</p>
<p>而且，通过过滤掉小的条目，该稀疏矩阵状态即被修改，所以得到的式子并不一定可以最小化式子<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑚</mi><mi>𝑖</mi><msub><mi>𝑛</mi><mrow><mi>𝐺</mi><mo>∈</mo><mi>S</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>𝐼</mi><mo>−</mo><mi>𝐺</mi><mi>𝐿</mi><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mi>𝐹</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">𝑚𝑖𝑛_{𝐺 ∈ S} ||𝐼 − 𝐺𝐿||^2_𝐹</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">mi</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0894em;vertical-align:-0.2753em"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">L</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">F</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span></span></span></span></p>
<p>本篇文章提出了一个过滤的新的方法，新方法基于对G的近似预先计算。To generate this low-cost approximation, we solve Eq. 3 （上面那个最小化的式子）via several iterations of the CG method with a relatively high tolerance to obtain an approximate solution.</p>
<p>这个cache-friendly extension和 the new filtration 方法 可以用于任何一个给定的稀疏状态</p>
<p>在任何情况下，在利用本文提到的优化方法对稀疏矩阵进行优化时，基本的优化过程如下：</p>
<ol>
<li>利用cache-friendly 方法来对给定的稀疏模式进行扩展。 此过程对应于算法2的第三行。<!-- -->
<ul>
<li><img decoding="async" loading="lazy" src="https://jsd.cdn.zzko.cn/gh/NEUQer-xing/Markdown_images@master/images-2/20230901161450.png" alt="image.png|600" class="img_ev3q"></li>
</ul>
</li>
<li>对扩展模式上的G进行预计算</li>
<li>过滤掉具有较低绝对值特征的条目</li>
<li>使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝑚</mi><mi>𝑖</mi><msub><mi>𝑛</mi><mrow><mi>𝐺</mi><mo>∈</mo><mi>S</mi></mrow></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>𝐼</mi><mo>−</mo><mi>𝐺</mi><mi>𝐿</mi><mi mathvariant="normal">∣</mi><msubsup><mi mathvariant="normal">∣</mi><mi>𝐹</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">𝑚𝑖𝑛_{𝐺 ∈ S} ||𝐼 − 𝐺𝐿||^2_𝐹</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">mi</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right:0.05764em">S</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0894em;vertical-align:-0.2753em"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">L</span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">F</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span></span></span></span>方程来计算上面步骤生成的稀疏模式G的系数。 该步骤对应于算法2的第五行。<!-- -->
<ul>
<li><img decoding="async" loading="lazy" src="https://jsd.cdn.zzko.cn/gh/NEUQer-xing/Markdown_images@master/images-2/20230901161450.png" alt="image.png|600" class="img_ev3q"></li>
</ul>
</li>
</ol>
<p>这些步骤应用于一个64x64的稀疏矩阵。过程如下图所示。
<img decoding="async" loading="lazy" src="https://jsd.cdn.zzko.cn/gh/NEUQer-xing/Markdown_images@master/images-2/20230901162624.png" alt="image.png" class="img_ev3q"></p>
<p>左侧图像显示了初始矩阵的下三角部分。</p>
<p>在中间的图中，我们展示了模式如何在假设缓存大小为64B和以双精度存储的条目下成为缓存友好的扩展。</p>
<p>右侧图片中的红色部分显示了高速缓存友好扩展的最终条目，而初始条目以黑色表示。</p>
<p>请注意，不同的缓存大小会导致不同的扩展模式。在这个扩展模式上预先计算出了一个逆近似值。在这个扩展模式上预先计算了反向逼近。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="exploiting-spatial-and-temporal-locality-in-the-g_p-and-gt_p-products">Exploiting Spatial and Temporal Locality in the <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mi>P</mi></msub></mrow><annotation encoding="application/x-tex">G_P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>G</mi><mi>P</mi><mi>T</mi></msubsup></mrow><annotation encoding="application/x-tex">G^T_P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1167em;vertical-align:-0.2753em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4247em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2753em"><span></span></span></span></span></span></span></span></span></span> Products<a href="#exploiting-spatial-and-temporal-locality-in-the-g_p-and-gt_p-products" class="hash-link" aria-label="Direct link to exploiting-spatial-and-temporal-locality-in-the-g_p-and-gt_p-products" title="Direct link to exploiting-spatial-and-temporal-locality-in-the-g_p-and-gt_p-products">​</a></h2>
<p>本节主要介绍利用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>p</mi></mrow><annotation encoding="application/x-tex">Gp</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Gp</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mi>T</mi></msup><mi>p</mi></mrow><annotation encoding="application/x-tex">G^T p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">p</span></span></span></span>提高空间局部性和时间局部性的方法。</p>
<p>前面的部分主要介绍的是如何扩展稀疏模式矩阵G从而得到一个扩展的稀疏模式矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>G</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">G_{ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，这个扩展的稀疏模式矩阵，在与向量p进行向量乘法时候，导致缓存未命中的次数不会增加。这个扩展基于G的空间局部性进行优化，并产生<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">G^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>的时间局部性优化。</p>
<p>提高FSAI的时间局部性和空间局部性方法如下：</p>
<ol>
<li>将初始的下三角状态下的矩阵S进行cache-friendly扩展，扩展到缓存友好的条目，从而优化G乘积中对x的访问。</li>
<li>提前计算扩展模式上的近似值</li>
<li>过滤掉扩展位置的条 目，从而得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>S</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">S_{ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></li>
<li>将<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">(S_{ext})^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 利用cache-friendly进行扩展，得到扩展条目，从而优化<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>G</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">G^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">G</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>乘积中x的访问。</li>
<li>提前计算扩展后的近似值</li>
<li>过滤掉扩展位置的条目，从而得到<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><msub><mo stretchy="false">)</mo><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">((S_{ext})^T)_{ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mopen">((</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></li>
<li>使用转置的稀疏状态（模式）矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><msub><mo stretchy="false">)</mo><mrow><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">((S_{ext})^T)_{ext}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em"></span><span class="mopen">((</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 来计算最终的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi></mrow><annotation encoding="application/x-tex">G</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">G</span></span></span></span></li>
</ol>
<p>具体的算法步骤如下所示：
<img decoding="async" loading="lazy" src="https://jsd.cdn.zzko.cn/gh/NEUQer-xing/Markdown_images@master/images-2/20230901190351.png" alt="image.png|center|800" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation">Evaluation<a href="#evaluation" class="hash-link" aria-label="Direct link to Evaluation" title="Direct link to Evaluation">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="实验设置">实验设置<a href="#实验设置" class="hash-link" aria-label="Direct link to 实验设置" title="Direct link to 实验设置">​</a></h3>
<p>评估考虑到了最先进的FSAI方法，以及使用缓存友好方法扩展稀疏模式的另外两个预处理器。</p>
<ol>
<li>FSAI - Factorized Sparse Approximate Inverse pre-conditioner.<!-- -->
<ul>
<li><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230904141947.png" alt="image.png|800" class="img_ev3q"></li>
<li>不进行阈值处理并且仅仅对空白目录进行过滤</li>
</ul>
</li>
<li>FSAIE(sp) - Factorized Sparse Approximate Inverse preconditioner with a sparse pattern extension exploiting spatial locality.<!-- -->
<ul>
<li><img decoding="async" loading="lazy" src="https://jsd.cdn.zzko.cn/gh/NEUQer-xing/Markdown_images@master/images-2/20230901190351.png" alt="image.png|800" class="img_ev3q"></li>
<li>在算法4中不包含第5和第6步骤</li>
<li>在第一次乘法时只用到空间局部性，在第二次乘法时，用到时间局部性</li>
</ul>
</li>
<li>FSAIE(full) -Factorized Sparse Approximate Inverse preconditioner with pattern extension exploiting spatial and temporal locality.<!-- -->
<ul>
<li>算法4</li>
<li>在所有的乘法中，都要用到空间局部性和时间局部性。</li>
</ul>
</li>
</ol>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="performance-improvement-on-skylake">Performance Improvement on Skylake<a href="#performance-improvement-on-skylake" class="hash-link" aria-label="Direct link to Performance Improvement on Skylake" title="Direct link to Performance Improvement on Skylake">​</a></h3>
<p>这部分介绍了FSAIE（sp）和FSAIE（full）相对于FSAI的性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/%E6%88%AA%E5%B1%8F2023-09-04%2014.29.57.png" alt="截屏2023-09-04 14.29.57.png" class="img_ev3q"></p>
<p>表1显示了Skylake系统中使用三种技术和<strong>过滤器= 0.01</strong>的结果。</p>
<p>第6至8列报告了FSAI的设置时间、求解时间和收敛所需的迭代次数。</p>
<p>这些是我们用来比较我们的模式扩展方法的Skylake基准结果。</p>
<p>第9至12列分别报告了设置时间、求解时间、收敛迭代次数以及FSAIE（sp）添加到A的下三角形模式中的条目百分比。第13至16列报告了关于FSAIE（full）的这些相同度量指标。</p>
<p>“many cases we observe both FSAIE(sp) and FSAIE(full) to successfully <strong>decrease iteration count and solve tim</strong>e. FSAIE(full) obtains larger pattern extensions than FSAIE(sp), which <strong>produces larger iteration count and solution time decreases</strong>.”(<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=7&amp;annotation=E8NR63S8" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<p>“In all cases, our new filtration strategy <strong>avoids convergence degradation</strong> while providing a higher degree of robustness to the method”  (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=8&amp;annotation=VWPIZAEW" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="effects-on-data-cache-misses-and-flops">Effects on Data Cache Misses and FLOPS<a href="#effects-on-data-cache-misses-and-flops" class="hash-link" aria-label="Direct link to Effects on Data Cache Misses and FLOPS" title="Direct link to Effects on Data Cache Misses and FLOPS">​</a></h3>
<p>该部分描述了在Skylake上使用其扩展的稀疏模式时，FSAIE（full）方法在数据缓存未命中和每秒浮点操作（flop/s）方面的优势。</p>
<p>FSAIE（FULL）在两个方面上提高了效率：</p>
<ul>
<li>首先，通过扩展预处理稀疏模式来实现迭代次数的减少；</li>
<li>其次，保持使用了模式扩展之后带来的额外迭代成本仍然处于较低水平。</li>
</ul>
<p>7.2节展示了相对于Skylake系统中的FSAI而言，FSAIE(full)<strong>在解决时间和迭代次数方面</strong>的优势。</p>
<p>这一节展示了FSAIE(full)在第二个方面的效果。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230904153901.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>“These results clearly indicate how our cache-friendly sparse pattern extensions successfully <strong>minimize the average data cache misses per 𝐺 non-zero entry</strong>.”</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230904153917.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>“Figure 4 clearly shows how the cache-aware extensions of the FSAIE(full) method significantly <strong>improve the floating-point throughput achieved</strong> by the sparse patterns of baseline FSAI.”</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="setup-phase-overhead">Setup Phase Overhead<a href="#setup-phase-overhead" class="hash-link" aria-label="Direct link to Setup Phase Overhead" title="Direct link to Setup Phase Overhead">​</a></h3>
<p>尽管该文章提出的方法显著加速了共轭梯度法的求解阶段，但相对于FSAI，在稀疏模式的扩展阶段会带来一些<strong>额外开销</strong>，这主要是由于<strong>计算G矩阵条目的成本更高</strong>。</p>
<p><strong>Such overhead becomes negligible in a practical numerical simulation context</strong></p>
<ul>
<li>since the <strong>setup phase</strong> is performed <strong>only once</strong> while the <strong>solve phase is repeated</strong> several times for the same matrix.</li>
<li>Furthermore, even when the setup is to be repeated on each time step, some of its parts, such as the definition of the final pattern, do not need to be repeated on each time step.</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-on-power9">Evaluation on POWER9<a href="#evaluation-on-power9" class="hash-link" aria-label="Direct link to Evaluation on POWER9" title="Direct link to Evaluation on POWER9">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/%E6%88%AA%E5%B1%8F2023-09-04%2016.02.33.png" alt="截屏2023-09-04 16.02.33.png|center|800" class="img_ev3q"></p>
<p>“For most of matrices 𝑓 𝑖𝑙𝑡𝑒𝑟 = 0.01 is the best option.” (<a href="zotero://select/library/items/WHYB98JZ" target="_blank" rel="noopener noreferrer">Laut 等, 2021, p. 10</a>) (<a href="zotero://open-pdf/library/items/M7WDJ8JS?page=10&amp;annotation=9LC3CJ79" target="_blank" rel="noopener noreferrer">pdf</a>)</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="evaluation-on-a64fx">Evaluation on A64FX<a href="#evaluation-on-a64fx" class="hash-link" aria-label="Direct link to Evaluation on A64FX" title="Direct link to Evaluation on A64FX">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230904160715.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>这些<strong>大幅度的迭代次数减少</strong>带来了明显的性能改善。</p>
<p>FSAIE（完全）方法在filter = 0.01时带来了平均性能提升20.08％，使用最佳filter per matrix时为22.85％。</p>
<p>不过滤任何条目，即filter = 0.0，性能会下降，因为<strong>迭代成本增加超过了迭代次数的减少</strong>。</p>
<p>We show the results of the best performing 𝑓 𝑖𝑙𝑡𝑒𝑟 value (blue columns) for each matrix and the results for the best general 𝑓 𝑖𝑙𝑡𝑒𝑟 value (orange columns), <strong>which is 0.01</strong>. Many matrices display much larger performance improvements on A64FX than POWER9 and Skylake.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="comparing-results-on-different-architectures">Comparing Results on Different Architectures<a href="#comparing-results-on-different-architectures" class="hash-link" aria-label="Direct link to Comparing Results on Different Architectures" title="Direct link to Comparing Results on Different Architectures">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20230904161403.png" alt="image.png" class="img_ev3q"></p>
<p>虽然 Skylake 和 POWER9 的结果显示出类似的趋势，因为它们具有基本相同的模式扩展，但当 FSAIE (full) 应用于 A64FX 时，它获得了更丰富的稀疏模式，这显著提高了实验集中所有矩阵的平均改善。</p>
<p>这是因为 A64FX 的缓存行大小比 Skylake 或 POWER9 大4倍。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="related-work-on-approximate-inverse-methods">Related work on approximate inverse methods<a href="#related-work-on-approximate-inverse-methods" class="hash-link" aria-label="Direct link to Related work on approximate inverse methods" title="Direct link to Related work on approximate inverse methods">​</a></h2>
<p>有几种先前提出的方法来为稀疏近似逆问题生成模式。根据稀疏近似逆的模式如何评估，它们被认为是静态或动态方法。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="static-approach">Static approach<a href="#static-approach" class="hash-link" aria-label="Direct link to Static approach" title="Direct link to Static approach">​</a></h3>
<p>对于静态方法（本文考虑的方法），模式是事先确定的，并在逆近似计算期间保持不变，无论是M还是G的分解方法。</p>
<p>常见的一种是使用矩阵A的稀疏模式的幂次方，通常是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>或<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mi>A</mi></msup><mn>3</mn></mrow><annotation encoding="application/x-tex">^A3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span></span></span></span><span class="mord">3</span></span></span></span> (10, 16, 20)。</p>
<p>其他技术会重新塑造初始模式(23)。</p>
<p>通过<strong>阈值化</strong>和<strong>后处理过滤</strong>或<strong>自适应入口丢弃策略</strong>(5, 6, 11, 15, 27, 29)可以将生成的模式变为<strong>稀疏模式</strong>。</p>
<p>寻找最佳的阈值化和过滤准则通常是一项具有挑战性的任务。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="dynamic-approximate-inverse-methods">Dynamic approximate inverse methods<a href="#dynamic-approximate-inverse-methods" class="hash-link" aria-label="Direct link to Dynamic approximate inverse methods" title="Direct link to Dynamic approximate inverse methods">​</a></h3>
<p>动态的近似逆方法通过自适应程序<strong>从初始猜测（例如对角线模式）开始，并使用某种策略扩大该模式，直到满足特定的标准</strong>，从而计算出逆模式。</p>
<p>An example of a dynamic approach, SPAI, was proposed by Grote and Huckle [17]. There is also a factorized formulation, FSPAI [21]. Other dynamic strategies have been developed more recently, such as, its generalization to block form, BSAI [22], and others like PSAI and RSAI [25, 26].</p>
<p>通常，动态近似逆比其静态的方法更为有效。然而，高效地将它们并行化并且它们的预处理阶段通常比静态方法更昂贵并非易事。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="总述">总述<a href="#总述" class="hash-link" aria-label="Direct link to 总述" title="Direct link to 总述">​</a></h3>
<p>所有引用的近似逆方法，无论是静态的还是动态的，共同的一个因素是它们都没有考虑到准则来定义稀疏模式。</p>
<p>基于缓存友好模式扩展的概念，我们的方法与提到的任何替代方法互补。最常见的静态方法FSAI在这里被用作参考。然而，无论使用何种其他具有数值评估标准的模式，我们的方法都能带来潜在的显著性能提升。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusions">Conclusions<a href="#conclusions" class="hash-link" aria-label="Direct link to Conclusions" title="Direct link to Conclusions">​</a></h2>
<p>This paper demonstrates the benefits of a <strong>FSAI sparse pattern extension</strong> based on two fundamental concepts:</p>
<ul>
<li>一个能够生成缓存感知的稀疏模式扩展的算法，该算法可以显著降低CG迭代次数并且带有较低迭代时间开销。</li>
<li>一个强大的过滤策略，最大程度地利用了缓存感知扩展的好处。</li>
</ul>
<p>尽管最先进的方法<strong>仅基于数值考虑来定义稀疏模式</strong>，但本文首次展示了考虑计算机体系结构概念的好处。</p>
<p>实际上，所提出的缓存感知模式扩展是对用于定义稀疏模式的任何数值策略的补充。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/paper_notes/100_未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/未分类/Cache-aware Sparse Patterns for the Factorized Sparse Approximate Inverse Preconditioner/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/未分类/大规模线性问题求解算法的高可扩展性研究/论文原件"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">论文原件</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#abstract" class="table-of-contents__link toc-highlight">Abstract</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a><ul><li><a href="#本文的贡献" class="table-of-contents__link toc-highlight">本文的贡献</a></li></ul></li><li><a href="#background" class="table-of-contents__link toc-highlight">Background</a><ul><li><a href="#conjugate-gradient-cg" class="table-of-contents__link toc-highlight">Conjugate Gradient （CG）</a></li><li><a href="#sparse-approximate-inverse-pre-conditionersai" class="table-of-contents__link toc-highlight">Sparse Approximate Inverse Pre-conditioner（SAI）</a></li></ul></li><li><a href="#accelerating-fsai" class="table-of-contents__link toc-highlight">Accelerating FSAI</a></li><li><a href="#cache-friendly-fill-in" class="table-of-contents__link toc-highlight">Cache-Friendly Fill-in</a><ul><li><a href="#cache-alignment-of-vector-𝑥" class="table-of-contents__link toc-highlight">Cache Alignment of Vector 𝑥</a></li><li><a href="#algorithm-for-cache-friendly-fill-in" class="table-of-contents__link toc-highlight">Algorithm for Cache-Friendly Fill-In</a></li><li><a href="#applying-the-cache-friendly-fill-in-to-fsai" class="table-of-contents__link toc-highlight">Applying the Cache-Friendly Fill-In to FSAI</a></li><li><a href="#cache-friendly-fill-in-process-example" class="table-of-contents__link toc-highlight">Cache-Friendly Fill-In Process Example</a></li></ul></li><li><a href="#filtering-out-small-g-entries" class="table-of-contents__link toc-highlight">Filtering Out Small G Entries</a></li><li><a href="#exploiting-spatial-and-temporal-locality-in-the-g_p-and-gt_p-products" class="table-of-contents__link toc-highlight">Exploiting Spatial and Temporal Locality in the G_P and G^T_P Products</a></li><li><a href="#evaluation" class="table-of-contents__link toc-highlight">Evaluation</a><ul><li><a href="#实验设置" class="table-of-contents__link toc-highlight">实验设置</a></li><li><a href="#performance-improvement-on-skylake" class="table-of-contents__link toc-highlight">Performance Improvement on Skylake</a></li><li><a href="#effects-on-data-cache-misses-and-flops" class="table-of-contents__link toc-highlight">Effects on Data Cache Misses and FLOPS</a></li><li><a href="#setup-phase-overhead" class="table-of-contents__link toc-highlight">Setup Phase Overhead</a></li><li><a href="#evaluation-on-power9" class="table-of-contents__link toc-highlight">Evaluation on POWER9</a></li><li><a href="#evaluation-on-a64fx" class="table-of-contents__link toc-highlight">Evaluation on A64FX</a></li><li><a href="#comparing-results-on-different-architectures" class="table-of-contents__link toc-highlight">Comparing Results on Different Architectures</a></li></ul></li><li><a href="#related-work-on-approximate-inverse-methods" class="table-of-contents__link toc-highlight">Related work on approximate inverse methods</a><ul><li><a href="#static-approach" class="table-of-contents__link toc-highlight">Static approach</a></li><li><a href="#dynamic-approximate-inverse-methods" class="table-of-contents__link toc-highlight">Dynamic approximate inverse methods</a></li><li><a href="#总述" class="table-of-contents__link toc-highlight">总述</a></li></ul></li><li><a href="#conclusions" class="table-of-contents__link toc-highlight">Conclusions</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper-notes-intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs-intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>