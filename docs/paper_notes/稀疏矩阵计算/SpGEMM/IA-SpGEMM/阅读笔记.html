<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="0-Abstract"><meta data-rh="true" property="og:description" content="0-Abstract"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"阅读笔记","item":"https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.98cc3bd4.css">
<script src="/assets/js/runtime~main.b1a1434e.js" defer="defer"></script>
<script src="/assets/js/main.8b44110d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper_notes_intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs_intro">个人博客</a><a class="navbar__item navbar__link" href="/docs/my_papers_intro">发表论文</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper_notes_intro">目录</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">稀疏矩阵计算</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">SpMV</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">SpMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件">SpGEMM</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件">IA-SpGEMM</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/Spada-SpGEMM/阅读笔记">Spada-SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/TileSpGEMM/论文原件">TileSpGEMM</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Stencil/ConvStencil/阅读笔记">Stencil</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Other/HPC加速体系结构中Linpack优化/论文原件">Other</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/TCU相关/RT-GNN/阅读笔记">TCU相关</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/z-模版/论文原件">z-模版</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">稀疏矩阵计算</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">SpGEMM</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">IA-SpGEMM</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">阅读笔记</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0-abstract">0-Abstract<a href="#0-abstract" class="hash-link" aria-label="Direct link to 0-Abstract" title="Direct link to 0-Abstract">​</a></h2>
<p>稀疏矩阵-矩阵相乘(SpGEMM)是一种稀疏核，在许多科学应用中得到了广泛的应用。虽然已经提出了一些 SpGEMM 算法，但是它们几乎都局限于压缩的稀疏行(CSR)格式，并且没有很好地研究利用其他格式可能带来的性能增益。能够为 SpGEMM 提供最佳性能的特定格式和算法也尚未确定。</p>
<p>本文对特定格式的并行 SpGEMM 算法进行了前瞻性研究，分析了它们的优缺点。然后，我们提出了 <font color="red"><b>IA-SpGEMM</b></font>，<font color="red"><b>一个输入感知的 SpGEMM 自动调优框架，它以 CSR 格式提供一个统一的编程接口，并自动确定任意稀疏矩阵的最佳格式和算法</b></font>。为此，我们建立了一个算法集，并设计了一个名为 MatNet 的深度学习模型，该模型由来自 SuiteSparse Matrix Collection 的2700多个矩阵进行训练，通过使用稀疏特征和密度表示来快速准确地预测最佳解。我们在 CPU 和 GPU 上评估了我们的框架，结果显示 IA-SpGEMM 在 Intel 和 AMD 平台上分别比 MKL 平均快3.27倍和13.17倍，在 NVIDIA GPU 上比 cuSPARSE 快2.23倍。</p>
<p>📒：以CSR格式提供一个统一的编程接口，并自动确定任意稀疏矩阵的最佳格式和算法。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction">​</a></h2>
<p>稀疏矩阵-矩阵相乘(SpGEMM)是许多应用中的一个关键核。例如，在代数多重网格方法(AMG)中，它通常占用设置阶段约束和插值矩阵成本的一半以上。许多图处理操作，例如广度优先搜索、马尔可夫聚类、图收缩、子图提取、同行压力聚类和循环检测， 都可以表示为 SpGEMM。GraphBLAS 还定义了基于矩阵的图算法。因此，高效的 SpGEMM 算法对于这些应用程序实现更高的性能至关重要</p>
<p>几个 SpGEMM 库被广泛使用：</p>
<ul>
<li>Intel MKL</li>
<li>基于向量的稀疏累加器(SPA)</li>
<li>基于散列的方法</li>
<li>基于堆的方法</li>
<li>cuSPARSE 和针对 Nvidia 和 NSPARSE 提出的 CUSP。</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240502190323.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 1 ：不同算法的性能比较及其开销 </font> </center>
然而，这些库对稀疏的输入矩阵很敏感，因此表现出显著的性能波动。</p>
<p>在图1(a)中，通过在 Intel CPU 上计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∗</mo><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A * A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 来比较各种算法的性能。很明显，<font color="red"><b>不同的算法在不同的矩阵  上提供它们的最佳性能，并且没有单一的算法在所有数据集的性能方面占主导地位</b></font>。这个问题将识别最佳库的负担转移到应用程序员身上，并对自动库选择器提出了特殊的挑战。</p>
<p>相反，图1(b)显示了两个开销来源: SpGEMM 算法在<strong>稀疏计算</strong>和<strong>内存访问</strong>上花费的时间比例。显然，<font color="red"><b>内存访问占用了大量的执行时间</b></font>。然而，<font color="green"><b>该领域的研究很大程度上忽视了通过优化内存访问来提高性能的潜力，并且更倾向于继续为计算部分开发新的稀疏累积算法</b></font>。在一定程度上，SpGEMM 类似于稀疏矩阵向量乘(SpMV)和稀疏三角解(SpTRSV)的不规则和间接存储器访问模式。<strong>SpMV 和 SpTRSV 的大部分研究都致力于通过挖掘经典存储格式来优化内存访问，并取得了有希望的结果</strong>。回到 SpGEMM，像 <strong>DIA、 COO 和 ELL 这样的经典存储格式可以减少内存需求或加速向量架构上的内存访问，改变计算过程的顺序，甚至可以减少稀疏计算操作的数量</strong>。这项工作的另一个动机是<font color="red"><b>探索几种经典存储格式对 SpGEMM 的影响</b></font>。</p>
<p>📒：</p>
<ul>
<li>自动识别最佳结构以及算法，应用于SpGEMM</li>
<li>在SpGEMM领域，人们忽视了通过优化内存访问来提高性能，但是在SpMV领域，大部分研究都致力于通过存储格式来优化内存访问，因此，这篇文章，探究了在SpMV上有效的存储格式迁移到SpGEMM中，对SpGEMM的影响。</li>
</ul>
<p>本文设计了基于广泛使用的多种稀疏存储格式的 SpGEMM 算法，并分析了有利于提高性能的条件。因此，为了将该实现与现有的 SpGEMM 库集成并选择最优算法，本文提出了一个<font color="red"><b>支持输入感知的 SpGEMM 自动调优框架(IA-spGEMM) </b></font>，该框架通过使用 一种称为 MatNet 的新卷积神经网络，将两个输入矩阵分类为（组装后的 SpGEMM 算法集）中最合适的类别。因此，本文使用当前版本的 SuiteSparse Matrix Collection 中的所有矩阵来<strong>构建大量的矩阵乘法对</strong>，并收集 SpGEMM 算法集的<strong>性能数据作为给定架构上的训练数据的输出</strong>。此外，还提取了两个输入矩阵的<strong>稀疏特征</strong>和<strong>密度</strong>表示作为训练数据的输入。然后使用<font color="red"><b>收集的性能数据</b></font>、<font color="red"><b>提取的特征</b></font>和<font color="red"><b>密度</b></font>表示生成 MatNet。与传统的机器学习或经验模型相比，MatNet 更适合于解决这一问题，并且可以以几乎等效的预测精度迁移到其他体系结构。</p>
<p>![[Revisiting thread configuration of SpMV kernels on GPU：A machine learning based approach#^2d373c | 在ML-SpMV文章中使用的训练模型]]</p>
<p>另外，作为一个轻量级的 SpGEMM 库，IA-SpGEMM 提供了一个 <strong>CSR 格式的统一接口</strong>，<strong>可以快速预测两个输入矩阵的最佳格式和算法</strong>，并最终通过相应的实现进行格式转换。我们评估了 IA-SpGEMM 在三个处理器(一个英特尔 CPU，一个 AMD CPU 和一个 NVIDIA GPU)上的性能，结果显示它取得了明显更好的性能，平均比英特尔 MKL 在双 Intel 至强 E5-2620和双 AMD EPYC 7501上的性能分别快3.27倍和13.17倍，交流准确率为93% ，比P100上的 NVIDIA cuSPARSE 库快2.23倍，准确率为91% 。</p>
<p>本文的主要贡献如下:</p>
<ul>
<li>提出了基于多种广泛应用的稀疏存储格式的多种 SpGEMM 算法，并重新设计了稀疏计算和内存访问方法，这些方法代表了 SpGEMM 中的两个主要开销。还分析了各种特定于格式的算法的优缺点。通过运行 SuitSparse Matrix Collection 中的所有矩阵，将其与当前库进行比较，会出现明显的性能 差异，这自然会导致采用自动调优模型。</li>
<li>提出一个名为 MatNet 的卷积神经网络，从一个大型算法集中选择最佳格式和算法。在对8000多对矩阵乘法进行基准测试时，MatNet 的预测准确率超过93% 。它大大避免了繁琐的手工选择工作，提高了可伸缩性，受益于所有算法与可接受的开销。</li>
<li>为 SpGEMM 开发了一个输入感知的自动调优框架(IA-SpGEMM) ，该框架具有<strong>基于 CSR 格式的通用接口。因此，用户可以透明地获得最好的性能</strong>。我们在三个处理器上实现了框架，平均加速比分别为3.27 x、13.17 x 和2.23 x。（也就是说，也是屏蔽了硬件的差异，然后提供了统一的CSR接口？？？？）</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-background">2-Background<a href="#2-background" class="hash-link" aria-label="Direct link to 2-Background" title="Direct link to 2-Background">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-稀疏矩阵存储格式">2.1-稀疏矩阵存储格式<a href="#21-稀疏矩阵存储格式" class="hash-link" aria-label="Direct link to 2.1-稀疏矩阵存储格式" title="Direct link to 2.1-稀疏矩阵存储格式">​</a></h3>
<p>稀疏存储格式定义了用于存储稀疏矩阵的分布和值的结构，其目标是通过仅存储非零元素来平衡存储空间的减少，并通过将被访问的数据放入连续的存储空间来实现有效的存储访问。为了在稀疏的例程中获得更高的效率，自20世纪70年代以来至少开发了数十种格式。特别是，大多数都是从下面描述的四种经典格式中派生出来的。图2显示了矩阵 A 上多种格式的示例。</p>
<p>📒：大多数稀疏矩阵存储格式都是从：COO、CSR、DIA和ELL格式演变而来的。</p>
<ul>
<li>坐标(COO)格式: 坐标格式是最灵活和最简单的格式。只存储非零元素，并显式给出每个非零元素的坐标。</li>
<li>压缩稀 疏行(CSR)格式: 最流行的表示包含三个数组: 每行的开始位置存储在“ ptr”中，每个非零元素的列索引和值分别存储在“ col_ ind”和“ data”中。</li>
<li>对角线(DIA)格式: 对角线的值存储为密集矩阵中的列。另一个“偏移量”数组保存主对角线上的偏移量。</li>
<li>ELLPACK (ELL)格式: 它使用两个矩阵，将左侧的所有非零打包为相同数量的行。第一个“ colind”矩阵存储列索引，第二个“ data”矩阵存储值。</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240502200912.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 2 ：四种稀疏矩阵格式的示例，其中斜体表示小的更改。 </font> </center>
COO 格式添加了一个行偏移量数组，DIA 格式添加了一个对角位置数组，ELL 格式添加了一个计算每行 nnzs 的数组。所有格式都按行顺序排序。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-并行spgemm算法">2.2 并行SpGEMM算法<a href="#22-并行spgemm算法" class="hash-link" aria-label="Direct link to 2.2 并行SpGEMM算法" title="Direct link to 2.2 并行SpGEMM算法">​</a></h3>
<p>设矩阵 A 的大小为 m × n，B 的大小为 n × k。矩阵乘积是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">C = AB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>。矩阵 C 中第 i 行和第 j 列的元素可以表示为: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msubsup><msub><mi>a</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>b</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">c_{ij} = \sum^{n-1}_{k = 0}a_{ik}b_{kj}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7167em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.2537em;vertical-align:-0.2997em"></span><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.954em"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2997em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">kj</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240502203127.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图3 算法1 SpGEMM算法：并行的将A的行乘以整个B矩阵来计算C的行 </font> </center></p>
<p>并行 SpGEMM 方法由 Gustavson 提出，Gilbert 等人在 MATLAB 上进行了改进。该算法(算法1)通过将所有非零元素的乘积作为稀疏积累运算，<font color="red"><b>并行地将 A 的行乘以整个 B 矩阵来计算 C 的行</b></font>。类似地，许多 GPU SpGEMM 算法通过使用分布式存储器 ，哈希表或“扩展，排序和压缩”(ESC)方法来改进稀疏累积操作以累积部分结果。其中一些算法包含在我们的算法集中。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-spgemm-算法">3-SpGEMM 算法<a href="#3-spgemm-算法" class="hash-link" aria-label="Direct link to 3-SpGEMM 算法" title="Direct link to 3-SpGEMM 算法">​</a></h2>
<p>本文以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∗</mo><msup><mi>A</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">A * A^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.9425em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em"><span style="top:-2.9425em;margin-right:0.05em"><span class="pstrut" style="height:2.5795em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 为例，介绍了三种特殊格式的 SpGEMM 算法及其优缺点。还通过运行 SuiteSparse Matrix Collection 中的所有矩阵比较了六种 CPU 算法和三种 GPU 算法，从而自然而然地产生了自动调优的Motivation。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503194355.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 4 示例矩阵 </font> </center></p>
<p>💡：在TileGEMM中，它没有使用多种存储格式，去对子块的稀疏矩阵进行存储，而是直接使用统一的格式，使用CSR存储格式，去存储稀疏子块去进行GEMM的计算。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-diacoo和ell三种格式在spgemm中的算法">3.1-DIA、COO和ELL三种格式在SpGEMM中的算法<a href="#31-diacoo和ell三种格式在spgemm中的算法" class="hash-link" aria-label="Direct link to 3.1-DIA、COO和ELL三种格式在SpGEMM中的算法" title="Direct link to 3.1-DIA、COO和ELL三种格式在SpGEMM中的算法">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="dia存储格式的spgemm方法">DIA存储格式的SpGEMM方法<a href="#dia存储格式的spgemm方法" class="hash-link" aria-label="Direct link to DIA存储格式的SpGEMM方法" title="Direct link to DIA存储格式的SpGEMM方法">​</a></h4>
<p>💡：在TileSpMV中，它没有使用DIA存储格式来进行存储稀疏  矩阵，而是使用的ELL稀疏矩阵存储格式来存储的和对角矩阵类似的子块矩阵。</p>
<p>因为 DIA 格式连续存储对角线元素，所以看起来不可能直接将两条对角线相乘。为了连接这些对角线，我们首先将一个“ pos”数组附加到原始的 DIA 格式中，以记录每条对角线的顺序，这可以用来<strong>快速而方便地将对角线坐标转换为实际坐标</strong>。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503223345.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 5 DIA 的 SpGEMM方法 </font> </center>
如图5所示，乘法通常如下:</p>
<ul>
<li>步骤1: 通过坐标转换，首先将对角线的每个元素转换为实际坐标，以获得被乘的行数(图中给出了 A 的第二个对角线的例子)。</li>
<li>步骤2: 将输出的实际坐标映射到对应的对角数，并将对角数所在的位图标记为“ T”。</li>
<li>步骤3: 根据位图中“T”的数量分配 C 的内存，并将部分结果按照与第一步相同的方式添加到相应的位置。</li>
</ul>
<p>算法2显著降低了对角矩阵的内存访问开销，并且在不增加内存消耗的情况下直接将中间结果添加到目标地址。请注意，基于行的线程调度以行为最小单元，因此它可以实现负载平衡，并避免线程之间的写-写冲突。这种“无锁调度”方法可以完全避免使用锁。我们称这种方法为“ DIA 方法”。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="coo存储格式的spgemm方法">COO存储格式的SpGEMM方法<a href="#coo存储格式的spgemm方法" class="hash-link" aria-label="Direct link to COO存储格式的SpGEMM方法" title="Direct link to COO存储格式的SpGEMM方法">​</a></h4>
<p>COO 格式分别存储同一行的非零元素，因此灵活的格式可以更容易地进行拆分和合并。算法3首先将矩阵 A 按行划分为 k 部分，将矩阵 B 按列划分为 k 部分(k 为2或4)。对于 C 的一部分，用 SPA 方法先后计算 A 和 B 的每个分区，最后合并所有的部分结果。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503224943.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 6 COO的SpGEMM方法 </font> </center>
如图6所示，矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 首先被划分为四个行矩阵，矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">A^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9425em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em"><span style="top:-2.9425em;margin-right:0.05em"><span class="pstrut" style="height:2.5795em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 被划分为四个列矩阵。以两个分区为例，四个线程分别执行每个部分的乘法运算。给定矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><msup><mrow></mrow><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></msup></mrow><annotation encoding="application/x-tex">A^{&#x27;}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9425em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9425em"><span style="top:-2.9425em;margin-right:0.05em"><span class="pstrut" style="height:2.5795em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8278em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span> 的列数被分成 SPA 算法的四分之一，每个线程的内存消耗是 SPA 算法的四分之一。最后，将线程间的部分结果合并到结果矩阵中。该算法的最大优点是大大减少了密集向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>B</mi><mi mathvariant="normal">_</mi><mi>c</mi><mi>o</mi><mi>l</mi></mrow><mi>k</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{B\_col}{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3581em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0131em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.527em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05017em">B</span><span class="mord mtight" style="margin-right:0.02778em">_</span><span class="mord mathnormal mtight">co</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>时间的长度，提高了高速缓存的效率，但是在矩阵的分割和合并方面带来了额外的开销。我们称之为“ COO 方法”</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="ell存储格式的spgemm方法">ELL存储格式的SpGEMM方法<a href="#ell存储格式的spgemm方法" class="hash-link" aria-label="Direct link to ELL存储格式的SpGEMM方法" title="Direct link to ELL存储格式的SpGEMM方法">​</a></h4>
<p>ELL 格式将原始矩阵打包成两个大小相同的矩形矩阵，将所有非零元素向左移动，以便更有效地访问内存。因为 ELL 格式的每一行包含相同数量的非零数字，这种格式可以减少 SpGEMM 算法的符号阶段的开销。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503225611.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 7 ELL 存储格式的SpGEMM算法 </font> </center>
在步骤1中，首先将矩阵行相等地分配给线程，并使用两个矩阵的 Col_ind 通过位图计算每行 C 的最大非零元素(给出了 A 的第一行的一个例子)。然后确定 C 的存储器。在步骤2中，C 的内存是按照每一行中非零元素的最大数量来分配的，新分配的内存用作哈希表来存储和累积中间结果。通过计算列索引的哈希值或在发生冲突时保持加1，将所有部分结果映射到相应的位置。最后，对无序矩阵 C 进行排序。算法4有两个主要的优点: (1)由于 Col _ ind 位于连续的存储空间中，符号阶段可以充分利用 SIMD 指令，提高数据加载和分配的效率。(2)在数值计算阶段，将预先分配给 C 语言的内存空间作为哈希表使用，这不仅有利于哈希表作为稀疏累加器的优势，而且避免了内存消耗。我们称之为“ ELL 方法”</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-算法集概述">3.2 算法集概述<a href="#32-算法集概述" class="hash-link" aria-label="Direct link to 3.2 算法集概述" title="Direct link to 3.2 算法集概述">​</a></h3>
<p>到目前为止，已经构建了多个特定于格式的算法。通过将它们与当前可用的流行算法库集成，如表1所示，为 CPU 开发了七个 SpGEMM 算法，为 GPU 开发了三个。作为基准，我们使用 SuiteSparse Matrix Collection 中的所有矩阵来构建<strong>8000多个矩阵乘法对</strong>，并比较这些算法的性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503230456.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 8 表1 为CPU开发的七个SpGEMM算法以及为GPU开发的三个SpGEMM算法 </font> </center></p>
<ul>
<li>性能统计: “Dominance”和“Percentage”代表各种算法中最好的和优于baseline(MKL算法)的数量和比例。</li>
<li>“平均加速”:计算在特定算法上获得最佳性能的情况下的平均加速</li>
<li>“理想工具”使用最佳性能在三个平台上获得全局加速。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="33-性能比较">3.3 性能比较<a href="#33-性能比较" class="hash-link" aria-label="Direct link to 3.3 性能比较" title="Direct link to 3.3 性能比较">​</a></h3>
<p>我们比较了不同算法在三种架构上的性能。为了获得准确的结果并在可控的时间内完成任务，运行时间平均为10次试验，并且由于格式转换，我们将内存扩展限制为不超过5次。所有算法的执行时间不能超过 MKL 或 cuSPARSE 的5倍，这也意味着这些矩阵对不适合特定的格式或算法。</p>
<p>如表2所示，实验的总体观察清楚地显示了在不同输入、格式、算法和平台下性能存在显著差异。此外，<strong>并没有单一的格式和算法能够始终在所有矩阵对上提供最佳性能</strong>。</p>
<p>以Intel CPU为例，将MKL的性能标记为基准线，它仅在35%的矩阵对上提供最佳性能。</p>
<ul>
<li>DIA方法优于基准线，在1,107个矩阵对上比基准线更好，并且在491个矩阵对中表现最佳，例如dw256A*dwa512和qpband*Trefethen_20000。这些矩阵几乎由一个或多个对角线组成。</li>
<li>COO方法优于基准线，在506个矩阵对上提供最佳结果，并且大约一半情况下表现最佳，例如human_gene2*appu和msc10848*crystk02。这些矩阵的非零率（≈8%）和列数较大。</li>
<li>ELL方法超过了基准线，在2,879个矩阵对上表现出色，并且在1,496个中达到最佳效果，例如G48*G49和ch7-9-b3*ch7-9-b2。</li>
<li>基于向 量、哈希和堆排序的方法比基准线更好地处理了7,006个矩阵，在3,051个矩阵对中是所有方法中效果最好的。</li>
</ul>
<p>针对AMD平台，使用相同方法来排序算法性能时，七种算法分别在20.96％、9.14％、4.20％、24.40％、10.18％、21.56％ 和 9.56% 的情况下表现最佳。与之相比，<font color="red"><b>AMD从各种格式和算法的多样性中受益更多</b></font>。</p>
<p>至于GPU，则两种算法（cuSPARSE 和 NSPARSE）适用于近一半左右的矩阵对。NSPARSE 在大型矩阵上具有较高性能优势，而ESC 算法只适用于少数部分情况下取得有效结果。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="34-性能分析">3.4 性能分析<a href="#34-性能分析" class="hash-link" aria-label="Direct link to 3.4 性能分析" title="Direct link to 3.4 性能分析">​</a></h3>
<p>流行的 SpGEMM 库并不能在所有矩阵对上产生最佳性能。</p>
<p>在 Intel 架构中，MKL 在大约35% 的数据集上提供了最佳性能，并且几乎所有的矩阵对都可以在合理的时间内执行。性能的提高与数据大小高度相关，但是 MKL 框架的开销是不可预期的，特别是对于小矩阵对。</p>
<ul>
<li>当输入矩阵对满足对角分布时，我们的“ DIA 方法”修改了存储器访问的顺序，减少了稀疏累积操作的次数和内存消耗。因此，它展示了令人印象深刻的性能，平均加速比为72.04 x。</li>
<li>“ ELL 方法”基于最有效的稀疏格式进行内存访问。它显著提高了存储器访问的效率，在符号阶段节省了时间，平均加速比为9.92 x。但是这种格式仍然会引入开销，因为在矩阵对中不平衡的行分布需要填充数据。因此，这种方法适用于约35% 的数据集。</li>
<li>“ COO 方法”适用于特定的情况，一些矩阵对仍然突出。</li>
<li>此外，基于向量、散列和堆的方法在它们的“最佳”矩阵对上运行，分别获得1.31 x、6.37 x  和6.21 x 的平均加速。</li>
</ul>
<p>与英特尔相比，AMD 的性能有相同的比例，但其绝对性能略低于英特尔。此外，由于 AMD 架构需要更高的内存带宽，“ DIA”和“ ELL”算法提供了更好的性能。</p>
<p>在 GPU 平台上，与 cuSPARSE 库相比，“ ESC”方法和 NSPARSE 算法在各自“最佳”情况下的平均加速时间分别为6.27 x 和3.71 x。</p>
<p>理想情况下，我们假设有一个“绝对完美”的工具，可以<strong>准确地预测最佳选择没有任何开销</strong>。对于三个平台上的所有矩阵对，它将实现8.94 x、46.16 x 和2.40 x 的平均加速。<font color="red"><b>这样的性能改进迫切要求我们设计一个自动调优框架</b></font>。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-ia-spgemm-概述">4-IA-SPGEMM 概述<a href="#4-ia-spgemm-概述" class="hash-link" aria-label="Direct link to 4-IA-SPGEMM 概述" title="Direct link to 4-IA-SPGEMM 概述">​</a></h2>
<p>在上一节中，实验结果展示了利用各种格式和算法的巨大潜力。因此，本文为 SpGEMM 开发了<font color="red"><b>一个输入感知的自动调优框架(IA-SpGEMM) </b></font>，<strong>以便在多个体系结构上选择最佳的格式和算法</strong>。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503231936.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 9 IA-SpGEMM的框架图 </font> </center></p>
<ul>
<li>实线表示收集和培训阶段，虚线表示用户界面的执行流程。</li>
<li>收集阶段包括提取两种输入模式和所有算法的执行时间。</li>
<li>训练阶段采用双向策略生成 MatNet 模型。</li>
</ul>
<p>框架如图9所示。它考虑了 SpGEMM 内核中矩阵模式和机器配置对性能的影响，并通过数千个矩阵对进行评估。为了实现这一目标，需要一个学习模型，结合大量的矩阵模式 ，算法和机器配置，以找到最佳匹配解决方案。然而，对于一般算法来说，在大搜索空间中寻找最合适的解是一个挑战。因此，本文<font color="red"><b>首先将自动校正问题转换为特征和图像分类问题，并选择一个优秀的卷积神经网络进行分类，以达到这个目的</b></font>。</p>
<p>识别最佳格式和算法是一项复杂的任务，需要大量的数据进行训练。本文使用来自 SuitSparse Matrix Collection 的全部2,726 ma trices 来构建8000多个矩阵乘法对，并提取<strong>矩阵特征</strong>和<strong>密度表示</strong>(第4.1和4.2节)作为训练数据的输入。然后，收集各种格式和算法的执行时间作为训练数据的输出。因此，<font color="red"><b>该方法结合矩阵特征和算法一起自动生成一个高精度的分类器</b></font>。如图9所示，IA-SpGEMM 系统分为两部分: <strong>训练</strong>和<strong>预测</strong>。</p>
<p>首先<strong>利用收集到的训练数据对神经网络 MatNet (第4.3节)进行训练</strong>，<strong>预测部分指出每种算法生成最佳 SpGEMM 核的概率</strong>。</p>
<p>方便的是，IA-SpGEMM 提供了一个<strong>基于 CSR 格式的统一接口</strong>，使其具有可用性和可移植性。它可以快速替换 IA-SpGEMM 框架中的库。</p>
<p>它还支持两种使用方法来满足独特的需求。第一种是框架自动选择最优算法，而另一种支持检查器-执行器方法。这种差异带来了两个好处。首先，开发人员可以透明地从多种格式和算法中受益。其次，该框架通过自动调整节省了程序员选择最佳算法以及格式的时间，并在同一矩阵上重用已知的最佳算法，大大降低了神经网络特征提取和前向传播的开销。可扩展性也是 IA SpGEMM 的一个优点。鉴于神经网络的固有特性，它可以通过添加新的算法和训练数据来提高性能和鲁棒性。</p>
<p>现在介绍 IA-SpGEMM 的三个组 成部分: 特征提取、密度表示和神经网络的设计。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-特征提取">4.1-特征提取<a href="#41-特征提取" class="hash-link" aria-label="Direct link to 4.1-特征提取" title="Direct link to 4.1-特征提取">​</a></h3>
<p>作为一个自动输入调优系统，IA-SpGEMM 首先考虑了与四种 CPU 格式的分布和特性有关的13个细粒度特性，以及两种 GPU 格式的8个特性。其中一些因素直观地影响了 SpGEMM 的性能，如非零元素的数量和比例。其他特性反映了存储结构导致的内存消耗和算法性能。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503233030.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 10 表3 稀疏特征以及介绍 </font> </center>
表3总结了 IA-SpGEMM 中使用的所有稀疏特性。前八个特性表示最常见的结构，包括行和列的数量，以及适合所有四种格式的非零元素。第九至第十一部分描述了 DIA 格式的对角线特征，包括对角线的数量和添加的零元素的填充率。第12个表示对齐内存访问的 ELL 格式的填充率。第13个特性代表了在中用于评估每行非零元素数量多样性。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-密度表示">4.2-密度表示<a href="#42-密度表示" class="hash-link" aria-label="Direct link to 4.2-密度表示" title="Direct link to 4.2-密度表示">​</a></h3>
<p><strong>稀疏矩阵通常具有高稀疏性和不同大小，而卷积神经网络(CNN)通常需要固定大小的输入数据</strong>。</p>
<p>这种差异导致了两个问题：</p>
<ul>
<li>首先，稀疏矩阵通常非常大，如果使用完全矩阵作为输入，则会给神经网络带来很大的推理开销。</li>
<li>第二个问题是，矩阵对包含大量不同数量的行和列，需要将这些行和列转换为相同的大小。</li>
</ul>
<p>对于图像领域，一般的方法是<strong>缩小较大的像素</strong>或<strong>放大较小的像素</strong>来调整图像大小。该方法还可以用于<strong>将稀疏矩阵转换为小密度</strong>表示，以表示原始矩阵的<font color="red"><b>粗粒度模式</b></font>，并具有可接受的大小。作为 CNN 主要图像输入的密度表示代表了一个抽象出大多数稀疏模式的快照矩阵。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503233624.png" alt="image.png|center|400" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 11 密度表示的转换过程 </font> </center>
如图11所示，我们应用此方法将一个8 * 8矩阵映射到一个4 * 4矩阵作为示例。原始矩阵分为4 * 4个块，每个块由填入相应新矩阵的非零元素计数。然后，原来的8 * 8矩阵和4 * 4密度表示都包含几个对角线，并且有一些不规则的非零元素。块计数与矩阵上的非零元素有关，归一化将它们的数量限制在合理的范围内(0 ~ 255)。</p>
<p>为了保证神经网络足够的准确性和可接受的开销，定义128 * 128(通过与64 * 64,128 * 128和256 * 256的大小进行比较，并选择最佳的一个)作为密度表示的大小，并<font color="red"><b>应用缩放方法将稀疏矩阵映射到密度表示</b></font>。请注意，任何抽样方法(如距离直方图表示)也可能失去潜在的特征，这可能会影响格式和算法的选择。因此，<font color="red"><b>需要一种方法来充分或系统地利用这些来自不同维度(细粒度和粗粒度)的数据，并补充抽象化(特征提取和缩放方法)造成的精度损失</b></font>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="43-matnet-设计">4.3-MatNet 设计<a href="#43-matnet-设计" class="hash-link" aria-label="Direct link to 4.3-MatNet 设计" title="Direct link to 4.3-MatNet 设计">​</a></h3>
<p>传统 的 CNN 在图像分类方面取得了令人印象深刻的成果。其中使用了几个卷积层和池化层来提取高级特征。应用前馈神经网络(FFNN)对多维数据进行分类。标准的 FFNN 是一个具有输入层、隐层和输出层的多层前馈网络。它可用于学习和存储输入层和输出层之间的大量映射。</p>
<p>关于本文的问题，发现这两个输入，分别在第4.1节和第4.2节，是不完美的，有缺点。特征只捕获矩阵的细粒度模式，而密度表示从粗粒度模式中抽象出来，但忽略了细节。因此，将探索一种结合这两种模式的学习模型，下面将对此进行描述。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240503234716.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 12 MatNet 模型 </font> </center>
基于神经网络强大的分类能力，本文设计了 MatNet 模型，将 CNN 和 FFNN 结合起来，提高了图像和特征同时分类的能力。如图11所示，这种结构由四个独立的输入组成，其中两个是<font color="red"><b>矩阵 A 和 B 的密度表示</b></font>，分别标记为 A_DR 和 B_DR，另一个是<font color="red"><b>矩阵 A 和 B 的特征</b></font>，分别标记为 A_F 和 B_F。这样，CNN 就可以通过使用 conv1层和使用 conv2/conv3层(一些核可视化)的整体特征来产生大量的过滤器来区分局部特征。扩展的 FFNN 可以聚集稀疏特征。</p>
<p>然后我们定义训练数据，包括特征(CPU 为13，GPU 为9)、密度表示(128 * 128)和每个算法的概率。例如，如果五个算法的执行时间是 T1、 T2、 T3、 T4和 T5，则每个算法的概率可以计算为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><mfrac><mn>1</mn><msub><mi>T</mi><mi>i</mi></msub></mfrac><mrow><mfrac><mn>1</mn><msub><mi>T</mi><mn>1</mn></msub></mfrac><mo>+</mo><mfrac><mn>1</mn><msub><mi>T</mi><mn>2</mn></msub></mfrac><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mfrac><mn>1</mn><msub><mi>T</mi><mn>5</mn></msub></mfrac></mrow></mfrac></mrow><annotation encoding="application/x-tex">P_i = \frac{\frac{1}{T_i}}{\frac{1}{T_1}+\frac{1}{T_2}+...+\frac{1}{T_5}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.0908em;vertical-align:-0.7916em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.2992em"><span style="top:-2.599em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.1389em;margin-right:0.1em"><span class="pstrut" style="height:2.6444em"></span><span class="mord mtight">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2996em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.558em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.1389em;margin-right:0.1em"><span class="pstrut" style="height:2.6444em"></span><span class="mord mtight">2</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2996em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.558em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mbin mtight">+</span><span class="mord mtight">...</span><span class="mbin mtight">+</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.1389em;margin-right:0.1em"><span class="pstrut" style="height:2.6444em"></span><span class="mord mtight">5</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2996em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.558em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.7082em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8443em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em"><span style="top:-2.3448em;margin-left:-0.1389em;margin-right:0.1em"><span class="pstrut" style="height:2.6595em"></span><span class="mord mathnormal mtight">i</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3147em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5688em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7916em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>，分别(如果一个特定的算法不能在合理的时间内执行，那么<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msub><mi>T</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{T_i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2902em;vertical-align:-0.4451em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8451em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 被设置为零)。然后，<strong>“最佳选择”对应于概率最高的算法</strong>。与过去在训练学习模型方面的工作完全不同，过去的工作可能会在提供类似性能的算法之间造成混淆，<strong>输出的概率相当保留了对选择至关重要的差异</strong>。</p>
<p>从2,726个矩阵中，本文随机选择5,000条记录作为训练数据(内存有限的 GPU 记录较少)。这些数据有两个特点:</p>
<ul>
<li>1)训练数据来自两个可能完全不相关的矩阵。</li>
<li>2)相似的密度代表可能导致完全不同的结果。
此外，两种类型的输入(特征和密度表示)之间的关系并不明显。这些不相关的数据在训练阶段相互影响，影响网络的准确性，因此我们采用双向策略来消除干扰。因此，训练分为两个独立的阶段。
第一阶段分别训练两种神经网络(CNN 和 FFNN)。第二阶段维护以前培训的所有参数，并合并所有组件以在最后一级更新参数参数。这样，特征和密度表示的相互影响可以显著减少。随着训练信息的逐步增加，预测的准确性可以逐步提高。</li>
</ul>
<p>此模型的另一个主要优点是<strong>可伸缩性</strong>。采用相同的训练方法，IA-SpGEMM 可以很容易地部署在新的平台上，并且可以添加新的算法来提高其分集性。由于所选平台的配置完全不同，所收集的训练数据和“最佳结果”在不同的平台之间可能有很大的差异。<font color="red"><b>通过再训练，MatNet 也可以在这些平台上实现高精度。</b></font></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-评估">5-评估<a href="#5-评估" class="hash-link" aria-label="Direct link to 5-评估" title="Direct link to 5-  评估">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="51-环境设置">5.1-环境设置<a href="#51-环境设置" class="hash-link" aria-label="Direct link to 5.1-环境设置" title="Direct link to 5.1-环境设置">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240504003451.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 13 表 4 用于评估的两个 CPU 和一个 GPU </font> </center></p>
<ul>
<li><strong>平台</strong>: 我们比较了 IA-SpGEMM 在三种体系结构上的性能，如表4所示。其中两个是 x86多核处理器，另一个是大规模多核心处理器处理器。</li>
<li><strong>基线</strong>: 将 IA-SpGEMM 与几种最先进的 SpGEMM 库进行比较，例如用于 CPU 的 Intel MKL v19.0.0.117和基于散列的方法，以及用于 GPU 的 NVIDIA cuSPARSE v8.0.61和 NSPARSE 。我们在<strong>两个 CPU 平台上启用 OpenMP 线程模型</strong>，双 Intel E5-2690 v4上有28个线程，双 AMD EPYC 7501上有64个线程，带有“-O3”选项。</li>
<li><strong>数据集</strong>: 总共使用来自 SuiteSparse 矩阵集合的2,726个矩阵随机构造8,195个用于评估的矩阵对，总共为220GB。其中，60% 用于培训，20% 用于验证，20% 用于测试。矩阵的大小从56KB 到33GB 不等，非零元素的数量从4000到20亿不等。数据集包括在实践中出现的大型且活跃增长的稀疏矩阵集。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-训练结果">5.2 训练结果<a href="#52-训练结果" class="hash-link" aria-label="Direct link to 5.2 训练结果" title="Direct link to 5.2 训练结果">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240504003705.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 14  MatNet 的丢失和准确性  ，以及训练阶段各种格式和算法的详细信息 </font> </center></p>
<p>图14 概述了4.2节中讨论的 MatNet 的损失和准确性，MatNet 将矩阵对分类为三个平台上的最佳格式和算法。下面对几个方面进行了比较。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="521-loss-和-accuracy">5.2.1-Loss 和 Accuracy<a href="#521-loss-和-accuracy" class="hash-link" aria-label="Direct link to 5.2.1-Loss 和 Accuracy" title="Direct link to 5.2.1-Loss 和 Accuracy">​</a></h4>
<ul>
<li>损失函数(分类交叉分类)用来表示预测偏离目标值的程度。在训练阶段，权重是根据这个数量更新的。</li>
<li>另一个指标是准确性，它监测有多少例子被正确预测。在网络训练过程中，网络损耗减小，精度提高。</li>
</ul>
<p>图7的上半部分比较了训练、验证和测试数据的损失和准确性。</p>
<p>对于 Intel 平台，随着独立训练(第一阶段)迭代步数的增加，MatNet 的损失逐渐减少。经过2000次迭代，网络收敛到近85% 的准确率。然后我们合并两个独立的训练和调整学习率(第二阶段)。损失继续下降，准确性缓慢增加，最终训练过程在4,000次迭代中稳定下来。训练集的准确率达到93% ，验证和测试集的准确率分别为91% 和90% 。</p>
<p>在 AMD 平台上，网络表现出类似的学习能力，最终准确率分别为92% ，90% 和89% 。</p>
<p>对于 GPU 平台，MatNet 带来的损失略高，但具有更高的准确性。该网络在近2000次迭代中收敛。此时，干预被插入，训练继续进行。经过3,000步之后，准确率值稳定在92% 、90% 和87% 。</p>
<p>结果表明，MatNet 能够快速地学习矩阵的特征，并在三个平台上保持连续收敛，<font color="red"><b>这也表明密度表示和特征包含与最佳格式和算法的潜在联系</b></font>。通过使用双向策略结合两种类型的训练数据，从而进一步升级了 MatNet。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="522-最好的格式和算法">5.2.2 最好的格式和算法<a href="#522-最好的格式和算法" class="hash-link" aria-label="Direct link to 5.2.2 最好的格式和算法" title="Direct link to 5.2.2 最好的格式和算法">​</a></h4>
<p>现在通过 MatNet 提供各种格式以及算法的汇聚详情。很明显，随着网络的整体准确度逐渐提高，各种格式及演算法呈现不同的汇聚趋势。其主要原因是这些格式和算法占训练数据记录的不平衡比例。例如，Intel 平台的 MKL 算法和 AMD 平台的 ELL 方法首先通过占据最大比例的训练数据收敛到高精度，而 GPU 的 cuSPARSE 和 NSPARSE 算法通过使用相似数量的记录表现出相似的收敛速度。最后，所有格式和算法的准确率都达到90% 以上。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240504005140.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 15 表 5 ： 两种机器学习分类方法预测结果的比较 </font> </center></p>
<p>此外，本文使用一个广泛使用的传统决策树算法(CART 方法)与 MatNet 进行比较。利用这两个矩阵的特征构造决策树。表5显示了两个分类器在两个指标上的表现，pre.表示准确率召回率测量返回的正确结果的数量。结果表明，MatNet 在两个指标上均优于决策树，平均准确率为91.50% ，召回率为86.57% ，而决策树的准确率为74.19% ，召回率为67.79% 。在三个平台上的精度结果也表明我们的 MatNet 是一个有效的跨平台模型。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="53-加速以及开销">5.3-加速以及开销<a href="#53-加速以及开销" class="hash-link" aria-label="Direct link to 5.3-加速以及开销" title="Direct link to 5.3-加速以及开销">​</a></h3>
<p>IA-SpGEMM 的加速比结果如图16所示。预测的格式和算法由 MatNet 模型生成，IA-SpGEMM 的每次执行都包括由特征提取、预测和格式转换(如果需要)引起的完整开销。X 轴表示增量非零的矩阵对序列，左侧的 y 轴表示 SpGEMM 的 GFLOPS，右侧的 y 轴计算各种优化方法中提供最佳性能的比例。与 MKL 和 cuSPARSE 方法相比，该算法的平均加速度分别为3.27 x，13.17 x 和2.23 x。此外，我们还测试了 IA-SPGEMM 的加速度，并与最先进的方法进行了比较，平均加速度分别为2.45 x，8.22 x 和1.94 x。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240504005500.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 16 ：三种体系结构上不同格式和算法的性能和比例 </font> </center></p>
<p>用于 CPU 的 MKL 和基于散列的方法，以及用于 GPU 的 cuSPARSE 和 NSPARSE 都是最先进的库。</p>
<p>每个性能增益由以下几部分组成:</p>
<ul>
<li>(1)各种格式大大减少了信号响应矩阵对的内存访问所需的时间。</li>
<li>(2)这三种算法改变了稀疏计算的个数或减少了内存消耗。</li>
<li>(3)框架还充分利用了现有的算法。
与3.4节中提到的“理想工具”相比，IA-SpGEMM 在没有开销的情况下达到了94% 的准确率，在同一数据集上达到了37% 的最佳性能。</li>
</ul>
<p>加速比降低的主要原因是预测最佳格式和算法的固定时间较为昂贵，特别是对于小矩阵对。</p>
<p>本文还讨论了开销问题。请注意，在收集训练数据之后，需要大约27分钟的时间在两个 NVIDIA P100图形处理器上为4,900条记录培训完整的 MatNet。</p>
<p>此外，使用 IA-spGEMM 框架的 spGEMM 具有多个阶段:</p>
<ul>
<li>1)提取两个矩阵的密度表示和稀疏特征;</li>
<li>2)利用 MatNet 预测最佳格式和算法;</li>
<li>3)转换成各种格式(如有需要) ;</li>
<li>4)执行相应的矩阵乘法内核。</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240504010038.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 17 ：几组不同大小的矩阵的性能分解 </font> </center></p>
<p>在图9中，一个比例图显示了12组矩阵的平均性能分解，这些矩阵的大小不断增加。第一部分和第三部分的开销与矩阵对的大小成正比，而第二部分每个矩阵对大约需要0.18毫秒。显然，随着矩阵对的增大，前三个性能间接费用在总时间中所占的比例越来越小。IA-SpGEMM 产生的大部分额外开销低于20% 。因此，我们<strong>建议不要在非常小的矩阵对上使用我们的框架</strong>，这样自动调谐器产生的开销就不会成为另一个系统瓶颈。此外，检查者-执行者方法将 SpGEMM 分为两个阶段: 分析和执行。<font color="red"><b>检查器检查矩阵模式并应用格式更改，执行器通过重用预测结果来调用例程</b></font>。随着计算次数的增加，这些间接费用几乎完全被稀释，间接费用的比例显著降低。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="54-使用">5.4-使用<a href="#54-使用" class="hash-link" aria-label="Direct link to 5.4-使用" title="Direct link to 5.4-使用">​</a></h3>
<p>在这一部分，开源的 IA-SpGEMM 为 SPGEMM 内核提供了一个统一的接口，并提供了一个测试用例来计算 A * B，以验证 MatNet 的预测结果。源代码可在 <a href="https://github.com/zhen-xie/ia-spgemm.git" target="_blank" rel="noopener noreferrer">https://github.com/zhen-xie/ia-spgemm.git</a> 下载。此外，通过收集更多的训练记录和微调 MatNet 模型，模型可以很容易地扩展到更多的平台和算法。</p>
<p>📒：现在这个库已经没有了</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-相关工作">6-相关工作<a href="#6-相关工作" class="hash-link" aria-label="Direct link to 6-相关工作" title="Direct link to 6-相关工作">​</a></h2>
<p><strong>稀疏内核</strong>在许多应用中被广泛用于提高效率。为了优化数据依赖性和非平衡稀疏计算，人们提出了各种方法。Venkat 等在编译阶段为稀疏计算开发了几种依赖性分析和数据转换优化技术，Arash 等使用性能模型和阻塞机制解决负载不平衡问题。本文主要研究 SpGEMM 内核的格式、算法和自动调谐器。</p>
<p><strong>在 CPU 上对 SpGEMM 进行并行化和优化</strong>。这些算法之间最显著的区别是所使用的<font color="red"><b>非零累加方法</b></font>。与本文中使用的 COO 算法一样，密集累加器是一种通用解决方案，而其他方法涉及对堆排序或合并行。此外，已经提出了一些 GPU 算法，CUSP使用扩展排序压缩(ESC)算法预先分配和收集所有中间结果，并通过排序和压缩操作积累它们。CuSPARSE、 NSPARSE 和 Kokkos 使用哈希表来组合全局内存中的中间结果。BhPARSE首先根据中间结果和输出的大小将行分配到容器中，然后启动各种内核。混合算法、多级算法和行合并算法也能在部分矩阵上表现出良好的性能。这些算法可以添加到我们的 IA-SpGEMM 产生更好的性能。此外，我们当前的系统在 CPU 上选择四种主要格式，在 GPU 上选择两种格式(COO 和 CSR)。但是有10种流行的格式 ，包括 Com 压缩的稀疏列(CSC) ，Sliced ELL (SELL) ，Block CSR (BCSR) ，混合(HYB)和 CSR5。然而，<font color="red"><b>这项工作的重点是建立一个 IA-SpGEMM 框架兼容各种格式和算法。利用这个框架，我们仍然可以为这些格式设计新的算法来加速这个内核，并且 SpGEMM 算法可以推进 IA-SpGEMM 系统。</b></font>此外，本文提出的 IA-SpGEMM 框架解决了单个节点上的问题，在许多情况下，控制了整个开销。我们希望看到下面的工作可以将我们的框架集成到分布式  的 SpGEMM 实现中。</p>
<p><strong>最佳格式和算法的选择</strong>近年来受到了广泛的关注。最接近这项研究的工作是赵等人，他们首次使用 CNN 来选择 SpMV 的矩阵格式，并获得了93% 的准确率。一些研究已经致力于通过自动调优方法获得最佳存储格式，但是由于所应用模型的学习能力，一些方法可能会受到限制。此外，选择最佳的格式可以看作是一个分类问题，类似于识别手写数字，这是 CNN 的首批应用之一。LeNET-5就是为这项任务而开发的。FFNN 也被广泛用于分类模型。与 SpMV 自动调谐器不同，我们的算法需要同时考虑两个任意矩阵的模式，并将它们分类到适当的目录中。因此，<strong>我们将这两个神经网络引入自动调谐</strong>，并设计了一个新的卷积神经网络(MatNet)将它们连接到 spGEMM。<font color="red"><b>我们发现稀疏核可以从神经网络方法中得到很好的拟合。将神经网络扩展到更稀疏的内核也有助于揭示优化方法和特定参数之间的联系。</b></font></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-总结">7-总结<a href="#7-总结" class="hash-link" aria-label="Direct link to 7-总结" title="Direct link to 7-总结">​</a></h2>
<p>在这项工作中，<strong>我们提出了各种 SpGEMM 算法的 DIA，COO 和 ELL 格式</strong>，并<strong>提出了一个输入感知的自动调整框架 SpGEMM (IA-SpGEMM) ，可以自动确定最佳格式和算法的任何稀疏矩阵对</strong>。它收集了一组 SpGEMM 算法，自然地允许使用深度学习模型(MatNet)通过使用特征和密度表示来预测最佳选择。</p>
<p>结果表明，IA-SpGEMM 的性能优于其他四个最先进的库。我们也期望通过我们的方法可以启发更多的稀疏和输入敏感的算法。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/paper_notes/2-稀疏矩阵计算/3-SpGEMM/IA-SpGEMM/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/Spada-SpGEMM/阅读笔记"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">阅读笔记</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#0-abstract" class="table-of-contents__link toc-highlight">0-Abstract</a></li><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1-Introduction</a></li><li><a href="#2-background" class="table-of-contents__link toc-highlight">2-Background</a><ul><li><a href="#21-稀疏矩阵存储格式" class="table-of-contents__link toc-highlight">2.1-稀疏矩阵存储格式</a></li><li><a href="#22-并行spgemm算法" class="table-of-contents__link toc-highlight">2.2 并行SpGEMM算法</a></li></ul></li><li><a href="#3-spgemm-算法" class="table-of-contents__link toc-highlight">3-SpGEMM 算法</a><ul><li><a href="#31-diacoo和ell三种格式在spgemm中的算法" class="table-of-contents__link toc-highlight">3.1-DIA、COO和ELL三种格式在SpGEMM中的算法</a></li><li><a href="#32-算法集概述" class="table-of-contents__link toc-highlight">3.2 算法集概述</a></li><li><a href="#33-性能比较" class="table-of-contents__link toc-highlight">3.3 性能比较</a></li><li><a href="#34-性能分析" class="table-of-contents__link toc-highlight">3.4 性能分析</a></li></ul></li><li><a href="#4-ia-spgemm-概述" class="table-of-contents__link toc-highlight">4-IA-SPGEMM 概述</a><ul><li><a href="#41-特征提取" class="table-of-contents__link toc-highlight">4.1-特征提取</a></li><li><a href="#42-密度表示" class="table-of-contents__link toc-highlight">4.2-密度表示</a></li><li><a href="#43-matnet-设计" class="table-of-contents__link toc-highlight">4.3-MatNet 设计</a></li></ul></li><li><a href="#5-评估" class="table-of-contents__link toc-highlight">5-评估</a><ul><li><a href="#51-环境设置" class="table-of-contents__link toc-highlight">5.1-环境设置</a></li><li><a href="#52-训练结果" class="table-of-contents__link toc-highlight">5.2 训练结果</a></li><li><a href="#53-加速以及开销" class="table-of-contents__link toc-highlight">5.3-加速以及开销</a></li><li><a href="#54-使用" class="table-of-contents__link toc-highlight">5.4-使用</a></li></ul></li><li><a href="#6-相关工作" class="table-of-contents__link toc-highlight">6-相关工作</a></li><li><a href="#7-总结" class="table-of-contents__link toc-highlight">7-总结</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper_notes_intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs_intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>