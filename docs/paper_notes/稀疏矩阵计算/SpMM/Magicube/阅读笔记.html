<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="pdf"><meta data-rh="true" property="og:description" content="pdf"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"阅读笔记","item":"https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.98cc3bd4.css">
<script src="/assets/js/runtime~main.b1a1434e.js" defer="defer"></script>
<script src="/assets/js/main.8b44110d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper_notes_intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs_intro">个人博客</a><a class="navbar__item navbar__link" href="/docs/my_papers_intro">发表论文</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper_notes_intro">目录</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">稀疏矩阵计算</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">SpMV</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">SpMM</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">Acc-SpMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记">FlashSparse</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记">Magicube</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/RoDE/阅读笔记">RoDE</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/SpInfer/阅读笔记">SpInfer</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记">Sparse GPU kernel for Deep-Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/TC-GNN/阅读笔记">TC-GNN</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/z-Sparkle-FPGA/阅读笔记">z-Sparkle-FPGA</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件">SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Stencil/ConvStencil/阅读笔记">Stencil</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Other/HPC加速体系结构中Linpack优化/论文原件">Other</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/TCU相关/RT-GNN/阅读笔记">TCU相关</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/z-模版/论文原件">z-模版</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">稀疏矩阵计算</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">SpMM</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Magicube</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">阅读笔记</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header><p><a href="zotero://open-pdf/library/items/FN57TEAG" target="_blank" rel="noopener noreferrer">pdf</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0-abstract">0-Abstract<a href="#0-abstract" class="hash-link" aria-label="Direct link to 0-Abstract" title="Direct link to 0-Abstract">​</a></h2>
<p>模型规模的指数增长推动了深度学  习的持续成功，但也带来了难以承受的计算和内存成本。<strong>从算法的角度来看，模型稀疏化和量化已被研究以缓解这一问题</strong>。从架构的角度来看，硬件供应商提供Tensor核心以加速计算。然而，<strong>由于对数据布局的严格要求以及缺乏有效操作低精度整数的支持，从稀疏的低精度矩阵运算中获得实际加速是非常具有挑战性的</strong>。</p>
<p>我们提出了Magicube，一个针对Tensor核心的<font color="red"><b>低精度整数</b></font>的高性能稀疏矩阵库。Magicube支持SpMM和SDDMM，这两个在混合精度下的深度学习中的主要稀疏操作。在NVIDIA A100 GPU上的实验结果表明，Magicube在稀疏内核上平均实现了1.44倍（最高可达2.37倍）速度提升，相比于供应商优化库，而在端到端的稀疏Transformer推理中，Magicube则实现了1.43倍的速度提升，且具有可比的准确性。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction">​</a></h2>
<p>在最先进的深度学习中，近期的进展是由计算、数据和模型规模的不断增加推动的，这一扩展趋势预计将持续下去。这些大规模深度学习模型在训练时需要大量的能源和碳排放，并且在有限的计算和内存资源下评估推理是具有挑战性的。<strong>减少内存占用和推理延迟的主要技术是矩阵运算的<font color="red"><b>稀疏化和量化</b></font></strong>。</p>
<p>虽然这些压缩方法在理论上减少了操作数量，加速了每个操作，并提高了内存带宽，但在加速器上获得实际加速并不容易。在深度学习中，<strong>为了保持模型的预测准确性，能够实现的矩阵稀疏度相对较小</strong>（例如，50-90%）。因此，利用如cuSPARSE提供的以高稀疏度为目标的稀疏内核（例如  ，&gt; 99%），很难超越其稠密对应物（例如，cuBLAS）的性能。为了在加速器上获得实际加速，<font color="red"><b>cuSPARSELt</b></font>利用Tensor Cores稀疏性，并在几种低精度数据类型（例如，fp16、int8、int4）中实现了与稠密对应物的双峰性能。然而，<strong>该库对数据布局施加了严格的限制（即，2:4结构稀疏性），稀疏度限制为50%</strong>。Gale等人提出了<font color="red"><b>Sputnik</b></font>，这是一个用于稀疏矩阵-矩阵乘法（SpMM）和采样稠密-稠密矩阵乘法（SDDMM）的库，支持fp32和fp16数据类型，<strong>利用深度学习中矩阵的特性（例如，每行的非零元素较多），并采用细粒度稀疏数据布局</strong>。在中等稀疏度（例如，70%）下，Sputnik在NVIDIA V100 GPU上的fp32深度学习工作负载中优于cuSPARSE。Chen等人指出，在使用低精度时，现有的稀疏内核无法在稠密对应物上实现加速，<strong>因为缺乏数据重用</strong>。此外，他们还表明，cuSPARSE中的块稀疏矩阵乘法的SpMM内核需要块大小大于8才能实现加速。这使得保持模型准确性变得更加困难。为了解决这些问题，他们提出了<font color="red"><b>vectorSparse</b></font>，这是一个使用稀疏编码的库，采用形状为例如8 × 1、4 × 1的稠密一维块，能够在保持数据布局灵活性的同时提高fp16中的数据重用。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221235745.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>这些结果是一个更大问题的一部分：哪些低精度数据类型和稀疏性组合应该在硬件中得到支持，哪些则可以在软件中得到支持。结合<font color="red"><b>稀疏性和量化在深度学习中已被证明是极其有效的</b></font>。然而，两者有不同的权衡，硬件供应商必须在这个昂贵的设计空间中为每个产  品选择一种配置。此外，由于缺乏对低精度整数（例如，int4）的高效操作支持，在Tensor核心上实现高性能的稀疏和量化矩阵操作面临挑战。在我们的工作中，我们为NVIDIA A100 Tensor核心定义了两个额外的软件设计点，使用我们的Magicube1库：</p>
<ul>
<li>（1）具有低精度整数类型的小型一维块稀疏操作，</li>
<li>（2）具有混合精度的小型一维块稀疏操作。
需要注意的是，在这项工作中，我们将混合精度定义为矩阵乘法的两个输入矩阵具有不同的精度。在深度学习中，为不同类型的量（例如，权重、激活）分配不同精度的数据类型，考虑到对量化的不同敏感性，已被证明<strong>在减少精度下降和提高硬件效率方面都是有效的</strong>。表I总结了各种数据类型在GPU上的最先进的稀疏矩阵库。</li>
</ul>
<p>我们在这些类型组合上，通过高效地将输入传递到张量核心并代数地模拟低精度和混合精度整数操作，始终比现有所有库的性能提高了超过40%。我们还展示了<strong>这些优化转化为Transformer网络端到端性能提升超过40%</strong>，这是当今及未来大规模深度学习系统中最有前景的候选者。我们的主要贡献是：</p>
<ul>
<li>我们设计了一种针对低精度整数在Tensor核心上友好的<strong>稀疏矩阵格式SR-BCRS</strong>。</li>
<li>我们引入了高度优化的SpMM和SDDMM内核。具体而言，我们提出了<strong>一种新颖的在线转置策略</strong>，以高效处理细粒度数据并满足数据布局要求。</li>
<li>Magicube<strong>支持混合精度</strong>，使用高效的代数类型模拟，通过操作堆叠提高了Tensor核心的利用率。</li>
<li>Magicube在最新的稠密和稀疏库上实现了显著的加速，<strong>适用于微基准测试和实际深度学习应用</strong>，同时模型的准确性也得到了验证。</li>
</ul>
<p>我们评估了在1536个不同大小  和稀疏度的稀疏矩阵上稀疏内核的性能。在NVIDIA A100 GPU上的结果表明，Magicube在SpMM上相对于<strong>cuSPARSE</strong>平均实现了1.44倍的加速。对于端到端稀疏Transformer推理，Magicube相对于<strong>vectorSparse</strong>（在Tensor核心上使用fp16的最先进稀疏库）实现了1.43倍的加速，相对于使用cuDNN的<strong>PyTorch</strong>（fp16稠密库）实现了1.50倍的加速，并且具有可比的准确性。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-background-and-related-work">2-Background and Related Work<a href="#2-background-and-related-work" class="hash-link" aria-label="Direct link to 2-Background and Related Work" title="Direct link to 2-Background and Related Work">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-深度学习中的压缩">2.1-深度学习中的压缩<a href="#21-深度学习中的压缩" class="hash-link" aria-label="Direct link to 2.1-深度学习中的压缩" title="Direct link to 2.1-深度学习中的压缩">​</a></h3>
<p><font color="red"><b>稀疏化</b></font>和<font color="red"><b>量化</b></font>是压缩深度神经网络的常见方法，以降低训练和推理的能耗和性能成本。</p>
<ul>
<li><strong>稀疏化</strong>通过忽略对学习和预测贡献较小的操作数中的冗余元素，减少工作负载中的操作数量（例如，矩阵乘法、卷积）。</li>
<li><strong>量化</strong>通过使用低位表示操作数，例如fp16、8位和4位整数，加快每个操作的速度并提高内存带宽。
两者都通过压缩神经网络权重、输入和中间表示（激活和反向传播误差）来减少存储要求。</li>
</ul>
<p>近年来，基于注意力机制的Transformer模型在各种领域应用中逐渐成为主流，例如自然语言处理和计算机视觉。由于使用大型Transformer模型（例如BERT，GPT-3）进行预训练和微调范例的有效性已被证明，减少训练和推理过程中的碳排放、能源消耗以及计 算和内存成本的重要性日益增加。为了减少内存占用和推理延迟，<font color="red"><b>针对巨型Transformer模型的权重剪枝和量化已被研究</b></font>。还研究了注意力图稀疏化，以降低自注意力的计算和内存复杂性，这些复杂度与序列长度的平方成正比。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-稀疏和量化操作的优化">2.2-稀疏和量化操作的优化<a href="#22-稀疏和量化操作的优化" class="hash-link" aria-label="Direct link to 2.2-稀疏和量化操作的优化" title="Direct link to 2.2-稀疏和量化操作的优化">​</a></h3>
<p>压缩导致稀疏和量化操作，但需要适当的硬件和/或一系列性能优化来实现实际的加速。<strong>科学计算中稀疏矩阵操作的性能优化已被研究。然而，这些领域中假设的矩阵稀疏度通常超过99%，而在深度学习中，为了保持神经网络的预测精度，稀疏度通常在50-90%之间</strong>。因此，在深度学习工作负载上实现相对于密集操作的加速更具挑战性。</p>
<p>AI加速器，如Tensor核心，带来了前所未有的深度学习工作负载低精度（浮点和定点）的性能。但这主要针对密集矩阵乘法。<strong>结构稀疏性在Tensor核心上也原生支持，但对非零元素的分布有严格的要求</strong>，例如50%的稀疏率，以及稀疏模式，例如1:2或2:4，这可能限制其通用性和可用性。Gale等人提出了<font color="red"><b>Sputnik</b></font>，优化了CUDA核心上深度学习工作负载的性能，支持更一般的细粒度稀疏性，并且相对较低的稀疏性优于cuSPARSE。Chen等人提出了<font color="red"><b>vectorSparse</b></font>，以提升Tensor核心上<strong>结构稀疏性的性能</strong>（约束更少）。但Sputnik和vectorSparse都针对半精度下的稀疏工作负载。与之前的工作不同，我们专注于低精度整数的量化稀疏矩阵运算（SpMM和SDDMM），并呈现出卓越的  性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="23-nvidia-图形处理器的张量核与低精度整数的数据布局">2.3-NVIDIA 图形处理器的张量核与低精度整数的数据布局<a href="#23-nvidia-图形处理器的张量核与低精度整数的数据布局" class="hash-link" aria-label="Direct link to 2.3-NVIDIA 图形处理器的张量核与低精度整数的数据布局" title="Direct link to 2.3-NVIDIA 图形处理器的张量核与低精度整数的数据布局">​</a></h3>
<p>NVIDIA GPU由一系列流处理多处理器(SM)组成，每个SM包含小的处理组件(如CUDA核心和Tensor核心)。CUDA( NVIDIA GPU编程模型)内核通过多线程执行。GPU内核中的线程通过线程块的网格组织，每个线程块由warp组成(每个warp有32个线程)。warp是CUDA中的基本调度单位。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250222112411.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>自Volta架构以来，NVIDIA GPUs增加了张量核心单元（TCU），该单元专门为深度学习设计，提供比CUDA核心上的浮点运算单元（FPU）高出8倍的峰值FLOPs（pf16）。在新架构如Ampere和Hopper上，张量核心支持低精度整数（8位、4位甚至1位）的矩阵乘法，这提供了比fp16更高的双倍、四倍或更高的峰值性能。如表II所示，张量核心几乎提供了NVIDIA GPUs上低精度整数的所有计算能力。因此，我们针对张量核心优化深度学习的量化稀疏内核。在后续内容中，我们使用intx表示x位的整数。</p>
<p>为了在张量核心上编程，CUDA提供了具有矩阵乘法-累加（MMA）语义的warp级API，其中32个线程的warp协同执行一个或多个密集矩阵乘法并累加输出。从编程的角度来看，CUDA提供了两个具有MMA语义的API，包括（高级）C++中的<code>WMMA</code>和（低级）NVPTX（准汇编语言）中的<code>mma</code>。在Magicube 中，我们使用mma API。关于深度学习的极低精度（int2或甚至int1）密集操作已在相关文献中进行研究。在本研究中，我们关注适度精度（例如int4、int8）与稀疏性。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250222112714.png" alt="image.png|center|600" class="img_ev3q"></p>
<p><font color="red"><b>在Tensor核心上，对于每种精度，支持几种形状的mma。</b></font>int4和int8的支持形状如表III所示。在Magicube中，我们选择使用最小的形状（如表III中突出显示）以<strong>在小稀疏粒度下发挥性能</strong>，因为在相同稀疏比的情况下，较小的粒度通常能够获得更好的准确性结果。对于int8和int4的mma，我们分别使用m8n8k16和m8n8k32的形状。形状为m8n8k16的int8 mma的数据布局如图1所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250222113939.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>输出矩阵C的形状（每个元素为int32）为m*n（即8*8），而还原维度为k=16。左侧矩阵A的形状为8*16，右侧矩阵B的形状为16*8，A和B的每个元素都是int8。如图1所示，<font color="red"><b>A、B和C的元素均匀分布在一个warp（32个线程）的寄存器中</b></font>。请注意，A必须是行主序，B必须是列主序。每个线程向A和B提供4个int8元素。<font color="red"><b>程序员必须将整个工作负载分解为小的MMA（例如，m8n8k16），并匹配对A、B和C的数据布局的限制要求</b></font>。形状为m8n8k32的int4 mma的数据布局与形状为m8n8k16的int8相似，只是A和B的每个元素为int4，还原维度k增加到32，而每个线程向A和B提供8个int4元素。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-implementation-and-optimization-for-spmm-in-deep-learning">4-Implementation and Optimization for SpMM in Deep Learning<a href="#4-implementation-and-optimization-for-spmm-in-deep-learning" class="hash-link" aria-label="Direct link to 4-Implementation and Optimization for SpMM in Deep Learning" title="Direct link to 4-Implementation and Optimization for SpMM in Deep Learning">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-稀疏格式">4.1-稀疏格式<a href="#41-稀疏格式" class="hash-link" aria-label="Direct link to 4.1-稀疏格式" title="Direct link to 4.1-稀疏格式">​</a></h3>
<p>稀疏矩阵在科学计算和深度学习领域是重要的工作载体。压缩行存储（CRS）格式是压缩稀疏矩阵的最流行方法，因为它简单。块压缩行存储（BCRS）格式进一步提出，以改善对L1缓存或寄存器的数据重用。在<strong>vectorSparse中使用的列向量稀疏编码是BCRS的一种特殊情况</strong>，其中每个密集块是一个一维块。BCRS与一维块的示例如图2所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250222125326.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>由于具有1-D稠密块的BCRS足以在稀疏深度学习工作负载中利用数据重用，且小的稀疏粒度对模型精度有利，因此我们也<font color="red"><b>将重点放在结构稀疏性和1-D稠密块上，而不是2-D稠密块</b></font>。不同于之前的工作，为了利用在Tensor核心上的低精度整数稀疏工作负载的性能，我们提出了一种<strong>跨步行主序BCRS（SR-BCRS）格式</strong>。现在我们通过与BCRS格式的比较来介绍SR-BCRS的细节。</p>
<p>BCRS由行指针、稠密（非零）向量的列索引以及存储在连续数组中的稠密向量组成。相比之下，SR-BCRS中的稠密向量采用跨步行主序方式存储，如图2底部所示。如果向量行中的稠密向量数量不是跨步长度的整数倍，则最后一个向量行会填充零值。对应地，列索引也填充无效值（*）。这  里跨步大小等于我们使用的mma操作的缩减（即k）维度。例如，int8的mma操作的跨步为16。通过这种方式，<strong>warp中的线程可以连续加载LHS矩阵的数据到寄存器中</strong>，数据布局要求（如图1所示）得以直接满足。这里SR-BCRS支持的1-D稠密块长度（V）小于等于8（即mma的m维度）。如果V=8，mma操作将得到充分利用；如果V=4，mma的利用率为50%。为了支持这种跨步格式，我们需要2M（M为稀疏矩阵的行数）行指针。对于每一行，我们需要一个指针指示第一个稠密向量的地址，另一个指针指示当前向量行中的最后一个稠密向量。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-magicube下的spmm">4.2-Magicube下的SpMM<a href="#42-magicube下的spmm" class="hash-link" aria-label="Direct link to 4.2-Magicube下的SpMM" title="Direct link to 4.2-Magicube下的SpMM">​</a></h3>
<p>稀疏矩阵-矩阵乘法（SpMM）是深度学习中的一个主要稀疏工作负载。例如，在一个经过剪枝的模型的前向传播中，稀疏权重矩阵将与稠密激活矩阵相乘。在稀疏Transformer中，自注意力通过将稀疏注意力权重矩阵与稠密值矩阵相乘来计算。这些都导致了一个SpMM操作。图3(a)显示了一个具有结构稀疏性的SpMM示例（即1-D块），其中矩阵A可以被视为一个带有结构稀疏性的剪枝权重矩阵或稀疏注意力掩码。注意，<font color="red"><b>稠密向量的列索引用于加载稠密矩阵B的相应行</b></font>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250222130410.png" alt="image.png|center|600" class="img_ev3q"></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="421-spmm中的线程块">4.2.1-SpMM中的线程块<a href="#421-spmm中的线程块" class="hash-link" aria-label="Direct link to 4.2.1-SpMM中的线程块" title="Direct link to 4.2.1-SpMM中的线程块">​</a></h4>
<p>  图 3(b) 显示了在 Magicube 中 SpMM 在线程块级别的实现。由于我们关注量化稀疏矩阵运算，这里假设矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 的元素均为 int8 类型。假设每个线程块包含 2 个 warp，每个线程块负责计算一个大小为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>m</mi></msub><mo>×</mo><mi>B</mi><msub><mi>S</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">BS_m \times BS_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 的输出块。其中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>m</mi></msub><mo>=</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">BS_m = V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span>（即向量长度）。<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>m</mi></msub></mrow><annotation encoding="application/x-tex">BS_m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 可以设为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span> 的倍数，但这并不能有效提高数据复用率，因为每行向量可能具有不同的列索引。在每个计算步骤中，每个线程块通过归约维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 计算部分结果。这里，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 等于 SR-BCRS 格式中的步幅大小，同时也等于 mma（矩阵乘加）运算的归约维度。总体而言，每个线程块需要 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>n</mi><mi>z</mi><mi mathvariant="normal">/</mi><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">nnz / BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">nn</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 步（累积部分结果）以获得最终结果。得益于 SR-BCRS 格式，mma 计算中左手边（LHS : Left-Hand-Side）矩阵的数据布局需求可以通过连续地以步幅方式加载数据直接满足。<font color="red"><b>LHS 矩阵从全局内存到共享内存的加载是 合并（coalesced） 方式进行的，并且数据在 warp 之间共享。</b></font></p>
<blockquote>
<p>[! warning] 💡:通过统计访 问B矩阵中稠密行对应的次数，选出前<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">x\%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em"></span><span class="mord mathnormal">x</span><span class="mord">%</span></span></span></span>的稠密行，提前加载到L2 Cache中，来提升访问的效率？</p>
</blockquote>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="422-具有int8的密集矩阵b的有效在线转置">4.2.2-具有int8的密集矩阵B的有效在线转置<a href="#422-具有int8的密集矩阵b的有效在线转置" class="hash-link" aria-label="Direct link to 4.2.2-具有int8的密集矩阵B的有效在线转置" title="Direct link to 4.2.2-具有int8的密集矩阵B的有效在线转置">​</a></h4>
<blockquote>
<p>[! error] 对共享内存中的bank冲突理解还不是很明白！</p>
</blockquote>
<p>接下来，我们讨论如何将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 的数据块馈送到 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span> 的右侧矩阵（RHS）。在这里，我 们使用行主序存储稠密矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>。然而，<strong>回想一下，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span> 的右侧矩阵必须是列主序的，这就导致了布局的不匹配。预先将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 转置为列主序并没有帮助，因为稠密向量的列索引并不连续</strong>。因此，我们提出了一种高效的<font color="red"><b>在线转置策略</b></font>，适用于行主序的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 块，该策略包含三个主 要步骤：</p>
<ul>
<li>首先，线程块中的线程协作加载 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 的行数据，从全局内存加载到共享内存的填充缓冲区。例如，图 4 显示了一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>n</mi></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">BS_n = 64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">64</span></span></span></span> 的示例。每行 64 个 int8 值被合并为一个单独的 64B 内存事务，从而提升了全局内存访问效率。 请注意，我们可以设置 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>n</mi></msub><mo>=</mo><mn>128</mn></mrow><annotation encoding="application/x-tex">BS_n = 128</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">128</span></span></span></span>，以将其合并为一个 128B 的内存事务，从而在大规模 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span></span> 下提高效率。<!-- -->
<ul>
<li><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225193434.png" alt="image.png|left|400" class="img_ev3q"></li>
</ul>
</li>
<li>第二，每个线程将从共享内存加载 4 个 int32 项到局部寄存器中。线程通过对局部寄存器进行转置，按 int8 粒度进行操作，如图 5 所示。转置后，寄存器块中的每一行包含来自矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 列的 4 个连续的 int8 值，满足 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span> 的数据布局需求。请注意，每个线程在转置后的寄存器块中有 4 行数据，这些数据分别送入 4 个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span> 运算的右侧矩阵。因此，对于两个 warp 线程块，每个步骤需要执行 8 次 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span> 运算，如图 6 所示。<!-- -->
<ul>
<li><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225193543.png" alt="image.png|left|400" class="img_ev3q"></li>
<li><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225193801.png" alt="image.png|left|400" class="img_ev3q"></li>
</ul>
</li>
</ul>
<p>在 NVIDIA GPU 上，<font color="red"><b>共享内存被划分为多个存储 bank，每个 bank 宽度为 32 位</b></font>。<strong>在一个 warp 内，访问不同 bank 的线程可以在一个周期内服务；否则，访问不同 bank 的线程会发生 bank 冲突，从而影响性能</strong>。通过在每 64 个 int32 项之后填充 8 个 int32 项，可以避免每个 warp 内的 bank 冲突。</p>
<hr>
<p>![[8-第八章：共享内存的合理使用#8.3 避免共享内存的bank冲突 ⭐️]]</p>
<hr>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="423-带-int4-矩阵-b-的高效在线转置">4.2.3-带 int4 矩阵 B 的高效在线转置<a href="#423-带-int4-矩阵-b-的高效在线转置" class="hash-link" aria-label="Direct link to 4.2.3-带 int4 矩阵 B 的高效在线转置" title="Direct link to 4.2.3-带 int4 矩阵 B 的高效在线转置">​</a></h4>
<p>在线转置策略在使用int8的B矩阵时效果良好。然而，对于使用int4的B矩阵，它可能仍然会导致较高的开销。在采用图4中所示的类似无冲突共享内存访问方法后，每个线程在本地寄存器中存储8*8=64个int4值。由于CUDA中没有对应于4位整数的数据类型，在本地寄存器上转置这64个int4值会导致大量的位运算。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225200745.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>因此，我们提出了一种新的列索引打散策略，以实现int4值的高效转置，如图7所示。❶我们通过以块的方式（块大小=8）打散左侧稀疏矩阵的列索引，修改SR-BCRS格式。这种打散的目的是在最后一步中得到体现。❷将相应的右侧数据块加载到寄存器中，类似于int8。在❸和❹中，局部寄存器上的数据以int8（char）为粒度进行转置。❺转置后的每一行被划分为两个int32值。在❻和❼中，经过掩码、位移和逐位或操作，我们得到一个只包含低4位值的int32和另一个只包含前面两个int32值高4位值的int32。每个int32中包含8个int4值，而每个int4值上的数字表示对应列索引的ID。令人惊讶的是，相关的列索引被恢复到打散前的状态，转置也完成了。这个过程的关键好处在于，<font color="red"><b>位运算仅在int32粒度下进行，而非int4。仅使用8个位运算，就完成了16个int4值的转置</b></font>，这显著减少了与直接使用int4值转置相比的开销。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="424-rhs-矩阵-b-的预取">4.2.4-RHS 矩阵 B 的预取<a href="#424-rhs-矩阵-b-的预取" class="hash-link" aria-label="Direct link to 4.2.4-RHS 矩阵 B 的预取" title="Direct link to 4.2.4-RHS 矩阵 B 的预取">​</a></h4>
<p>如在第IV-B2节中讨论的，<strong>右侧矩阵B的数据块被加载到共享内存中以进行转置</strong>。然而，<font color="red"><b>由于矩阵A是稀疏的，矩阵B在共享内存中的数据没有重用。因此，为了减轻矩阵B内存流量的成本，我们建议使用数据预取策略</b></font>，如算法1所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225201506.png" alt="image.png|center|400" class="img_ev3q"></p>
<blockquote>
<p>[! warning] 💡：流水线的设计！！！</p>
</blockquote>
<p>回想一下，每个线程块需要<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>n</mi><mi>z</mi><mi mathvariant="normal">/</mi><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">nnz/BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">nn</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>个累加步骤来获得最终结果。此外，从全局内存加载数据到共享内存时，有两个阶段：</p>
<ul>
<li>a) 从全局内存加载数据到寄存器</li>
<li>b) 将寄存器中的数据存储到共享内存。
因此，我们将从全局到共享的加载分为两个阶段，并组成一个pipeline。在for循环的第一次迭代中，第7-9行和第11行是pipeline的冷启动，此后来自矩阵A和B的第一个块被加载到共享内存中。然后，for循环中的第11-16行形成pipeline的主体。第12行加载左侧稠密向量及其对应的列索引到共享内存以供下一次迭代。在第14行中，使用列索引将右侧数据块预取到寄存器中，这与第15行当前步骤的mma计算重叠。因此，右侧 数据块的全局内存访问延迟被隐藏。请注意，线程块级的同步被插入到管道中以实现线程安全。</li>
</ul>
<hr>
<p>在CUDA编程中，这种基于共享内存（<strong>shared</strong>）、寄存器（<strong>registers</strong>）以及__syncthreads()的流水线（Pipeline）设计确实能够提高计算效率，特别是对于**稀疏矩阵乘法（SpMM）**或其他涉及数据复用的计算场景。：</p>
<ol>
<li><strong>减少全局内存访问延迟</strong>
<ul>
<li>该算法将LHS和RHS数据分别加载到共享内存和寄存器中，通过Load_LHS_values_and_indices_to_shared(i)和Prefetch_RHS_values_to_registers(i)的预取操作，减少了直接从全局内存访问数据的次数。这种技术可以显著降低全局内存访问的延迟，从而提高计算吞吐量。</li>
</ul>
</li>
<li><strong>隐藏数据加载延迟（Latency Hiding）</strong>
<ul>
<li>该流水线采用了<strong>双缓冲（Double Buffering）</strong> 的方式，每次计算时都会预取下一步计算需要的数据。这种策略可以通过并行化计算与数据传输，使得计算核心（CUDA Cores）在执行MMA_compute_tiles(i-1)计算的同时，预取下一个时间步的数据，避免因等待数据加载而导致的计算停滞。</li>
</ul>
</li>
<li><strong>同步（Synchronization）控制流水线阶段</strong>
<ul>
<li>__syncthreads()保证了不同线程块（Thread Blocks）在共享内存数据加载完成后再进行计算，避免了竞争条件（Race Condition）。这对于保持数据一致性至关重要，尤其是当多个线程需要共享LHS和RHS数据时。</li>
</ul>
</li>
<li><strong>寄存器数据预取优化</strong>
<ul>
<li>Prefetch_RHS_values_to_registers(i)将部分RHS数据提前加载到寄存器中，使得计算时可以直接从寄存器读取数据，而不必频繁访问共享内存或全局内存。由于寄存器是CUDA设备上最快的存储层级，这种优化可以减少访问延迟，提高吞吐量。</li>
</ul>
</li>
<li><strong>计算与数据加载交错执行</strong>
<ul>
<li>for循环中的操作顺序使得前一步的计算可以在下一步的数据加载完成之前进行，形成类似流水线的效果：<!-- -->
<ul>
<li>先存储前一轮的RHS数据到共享内存</li>
<li>加载当前LHS和索引数据</li>
<li>预取下一轮RHS数据到寄存器</li>
<li>执行MMA（矩阵乘累加）计算</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>这种模式使得计算任务与数据搬运任务相互交错，从而提高整体计算效率。</p>
<p><strong>可能的优化方向</strong></p>
<ul>
<li><strong>利用CUDA的异步流水线</strong>（如cudaMemcpyAsync + cudaStream）来进一步隐藏数据传输的开销</li>
<li><strong>调整BSk的大小</strong>，选择合适的批大小，使得共享内存和寄存器的使用能达到最佳平衡，避免浪费。</li>
</ul>
<hr>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="43-在magicube中的sddmm">4.3-在Magicube中的SDDMM<a href="#43-在magicube中的sddmm" class="hash-link" aria-label="Direct link to 4.3-在Magicube中的SDDMM" title="Direct link to 4.3-在Magicube中的SDDMM">​</a></h3>
<p>采样稠密-稠密矩阵乘法（SDDMM）是深度学习中的另一种主要稀疏工作负载。SDDMM的输出是一个稀疏矩阵。例如，在剪枝模型的前向传播中，稀疏权重梯度的计算就是一个SDDMM操作。<font color="red"><b>在稀疏Transformers中，稀疏注意力权重的计算也是一个SDDMM操作</b></font>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225202301.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图8(a)展示了一个SDDMM的例子，其中输出矩阵C具有结构稀疏性（即1-D块）。稠密向量的列索引用于加载矩阵B的相应列。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="431-sddmm的线程块">4.3.1-SDDMM的线程块<a href="#431-sddmm的线程块" class="hash-link" aria-label="Direct link to 4.3.1-SDDMM的线程块" title="Direct link to 4.3.1-SDDMM的线程块">​</a></h4>
<p>图8(b)展示了在Magicube中在线程块级别实现SDDMM的过程。我们对A使用行主存储，对B使用列主存储。假设我们在一个线程块中有2个warp。每个线程块负责一个大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>m</mi></msub><mo>∗</mo><mi>B</mi><msub><mi>S</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">BS_m*BS_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>的稠密输出块。与SpMM类似，我们设置<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>m</mi></msub><mo>=</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">BS_m=V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span>且<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>&lt;</mo><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">V&lt;=8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>。在每一步中，每个线程块使用归约维度<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>计算部分结果。这里<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>等于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span>的归约维度。总体来说，每个线程块需要<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>n</mi><mi>z</mi><mi mathvariant="normal">/</mi><mi>B</mi><msub><mi>S</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">nnz/BS_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">nn</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>步（部分结果被累加）来获得最终结果。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225231753.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>LHS块被加载到共享内存中，并在多个warp之间共享。我们还使用类似于算法1的策略来预取LHS数据块。由于在共享内存中RHS块没有数据重复使用，并且B以列主序存储，每个线程直接将相应的数据加载到本地寄存器中，并满足mma的数据布局要求。mma操作的warp级视图如图9所示。注意，<strong>输出稀疏矩阵C的格式由后续操作决定。如果后续操作是SpMM，则C输出为SR-BCRS格式；如果后续操作是softmax，则C输出为BCRS格式</strong>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="44-混合精度仿真">4.4-混合精度仿真<a href="#44-混合精度仿真" class="hash-link" aria-label="Direct link to 4.4-混合精度仿真" title="Direct link to 4.4-混合精度仿真">​</a></h3>
<p>对于SpMM，Magicube支持矩阵A的精度高于矩阵B的情况，例如，A是int8而B是int4。<font color="red"><b>混合精度的量化方案在机器学习领域得到了广泛研究</b></font>。由于A已经是稀疏的，A的更高精度可能带来更高的模型准确性。Magicube还支持A和B都是int16的情况（在Tensor核心上不原生支持），适用于SpMM和SDDMM。<strong>这个想法是将高精度值划分为若干低精度值，然后从数学上模拟矩阵乘法</strong>。使用1位mma原语对无符号整数进行GEMM（密集矩阵乘法）的任意精度仿真已在相关研究中探讨，这需要进行x * y次1位整数的矩阵乘法，其中x和y分别是左侧和右侧矩阵中值的位数。为了在混合精度和低仿真开销之间进行权衡，我们只考虑位数是4或8的倍数的精度。与以前的工作不同，我们支持无符号和有符号整数的精度仿真。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="441-无符号整数仿真">4.4.1-无符号整数仿真<a href="#441-无符号整数仿真" class="hash-link" aria-label="Direct link to 4.4.1-无符号整数仿真" title="Direct link to 4.4.1-无符号整数仿真">​</a></h4>
<p>这里我们以矩阵乘法 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> (无符号 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>n</mi><mi>t</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">int8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">in</span><span class="mord mathnormal">t</span><span class="mord">8</span></span></span></span>) * <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> (无符号 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>n</mi><mi>t</mi><mn>4</mn></mrow><annotation encoding="application/x-tex">int4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">in</span><span class="mord mathnormal">t</span><span class="mord">4</span></span></span></span>) 为例。假设 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mo>=</mo><mn>11101101</mn><mo>=</mo><mn>237</mn></mrow><annotation encoding="application/x-tex">a = 11101101 = 237</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">11101101</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">237</span></span></span></span> (十进制) 是从矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 中随机选择的一个标量。然后，我们可以直接将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span></span></span></span> 分解为两个无符号 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>n</mi><mi>t</mi><mn>4</mn></mrow><annotation encoding="application/x-tex">int4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">in</span><span class="mord mathnormal">t</span><span class="mord">4</span></span></span></span> 值，包括 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>0</mn></msub><mo>=</mo><mn>1101</mn><mo>=</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">a_0 = 1101 = 13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1101</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">13</span></span></span></span> (十进制) 代表低4位和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mn>1</mn></msub><mo>=</mo><mn>1110</mn><mo>=</mo><mn>14</mn></mrow><annotation encoding="application/x-tex">a_1 = 1110 = 14</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1110</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">14</span></span></span></span> (十进制) 代表高4位。通过数学仿真，原始的8位值 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span></span></span></span> 可以通过以下方式恢复：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>a</mi><mo>=</mo><msub><mi>a</mi><mn>0</mn></msub><mo>+</mo><msup><mn>2</mn><mn>4</mn></msup><mo>⋅</mo><msub><mi>a</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">
a = a_0 + 2^4 \cdot a_1
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8641em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
<p>因此，矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 可以分解为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">A_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 包含所有低4位的值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 包含所有高4位的值，如图10(a)所示。将 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">A_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">A_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 相乘，生成两个中间矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">C_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">C_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>。由于标量 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">a</span></span></span></span> 的数学仿真是线性函数，最终输出矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span> 可以相应地仿真，即</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>C</mi><mo>=</mo><msub><mi>C</mi><mn>0</mn></msub><mo>+</mo><msup><mn>2</mn><mn>4</mn></msup><mo>⋅</mo><msub><mi>C</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">
C = C_0 + 2^4 \cdot C_1
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8641em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord">+</span></span></span></span> 表示逐元素相加。需要注意的是，在没有混合精度仿真的情况下，矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 必须转换为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mi>n</mi><mi>t</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">int8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">in</span><span class="mord mathnormal">t</span><span class="mord">8</span></span></span></span>，这会显著增加内存消耗。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="442-有符号整数仿真">4.4.2-有符号整数仿真<a href="#442-有符号整数仿真" class="hash-link" aria-label="Direct link to 4.4.2-有符号整数仿真" title="Direct link to 4.4.2-有符号整数仿真">​</a></h4>
<p>深度学习模型也可以通过对称量化将其量化为有符号整数。在计算机中，签名整数是以二补码表示的。例如，8位签名整数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>19</mn></mrow><annotation encoding="application/x-tex">-19</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">19</span></span></span></span>（十进制）编码为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>11101101</mn></mrow><annotation encoding="application/x-tex">11101101</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">11101101</span></span></span></span>。我们直接将其分解为两个4位整数（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1110</mn></mrow><annotation encoding="application/x-tex">1110</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1110</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1101</mn></mrow><annotation encoding="application/x-tex">1101</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1101</span></span></span></span>）。然而，为了保证数学正确性，必须将高4位视为有符号整数（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">-2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">2</span></span></span></span>），而将低4位视为无符号整数（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>13</mn></mrow><annotation encoding="application/x-tex">13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">13</span></span></span></span>）。然后，数学仿真 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>2</mn><mo>×</mo><mn>16</mn><mo>+</mo><mn>13</mn></mrow><annotation encoding="application/x-tex">-2 \times 16 + 13</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">2</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">13</span></span></span></span> 将恢复两个4位整数为原始的8位整数（即 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>19</mn></mrow><annotation encoding="application/x-tex">-19</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">−</span><span class="mord">19</span></span></span></span>）。这意味着，在矩阵乘法的混合精度仿真中（图10(a)），左侧（LHS）和右侧（RHS）矩阵具有不同类型的整数（即，签名和无符号）。幸运的是，Tensor 核上的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>m</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">mma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">mma</span></span></span></span> 原语支持左侧是有符号，右侧是无符号，反之亦然。通过将最高4位视为有符号整数，其他位视为无符号整数，Magicube 支持混合精度仿真，用于带符号整数的矩阵乘法。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="443-magicube中的支持精度">4.4.3-Magicube中的支持精度<a href="#443-magicube中的支持精度" class="hash-link" aria-label="Direct link to 4.4.3-Magicube中的支持精度" title="Direct link to 4.4.3-Magicube中的支持精度">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225232653.png" alt="image.png|center|500" class="img_ev3q"></p>
<p>Magicube 中支持的精度列在表 IV 中，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>x</mi></msub><mo>−</mo><msub><mi>R</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">L_x - R_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.9694em;vertical-align:-0.2861em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">y</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span></span></span></span> 表示一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span> 位的左侧（LHS）矩阵与一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span> 位的右侧（RHS）矩阵相乘。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-evaluation">5-Evaluation<a href="#5-evaluation" class="hash-link" aria-label="Direct link to 5-Evaluation" title="Direct link to 5-Evaluation">​</a></h2>
<p>我们在NVIDIA A100 GPU (A100-SXM4-40GB GPU)上评估性能。A100 GPU具有108个SM，每个SM拥有总共192KB可配置的L1缓存和共享内存，以及256KB寄存器。我们将Magicube的性能与稀疏库（cuSPARSE、vectorSparse）和稠密库（cuBLAS、cuDNN）进行比较。我们使用<strong>深度学习矩阵集合(DLMC)稀疏矩阵数据集</strong>构建基准测试，该数据集类似于稀疏矩阵通过用1-D向量（V = 2、4、8）替换每个标量进行扩展。VectorSparse使用BCRS格式（即列向量稀疏编码）。Magicube使用如图2所示的SR-BCRS格式。由于cuSPARSE支持基于Blocked-ELL格式的SpMM，因此生成与BCRS和SR-BCRS具有相同稀疏性和问题大小的BlockedELL格式。对于SpMM，稀疏矩阵用于LHS矩阵；在SDDMM中，稀疏矩阵用于输出矩阵。</p>
<p>我们评估不同稀疏性的性能，包括0.5、0.7、0.8、0.9、0.95和0.98。对于每个稀疏性，我们从DLMC选择256个不同大小的矩阵，涵盖了ResNet-50模型中的所有稀疏矩阵以及Transformer模型中的部分稀疏矩阵。总的来说，评估中使用了来自DLMC的1,536个稀疏矩阵，使用不同的向量长度进行扩展（即V = 2、4、8）。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="51-评估-magicube-的优化策略">5.1-评估 Magicube 的优化策略<a href="#51-评估-magicube-的优化策略" class="hash-link" aria-label="Direct link to 5.1-评估 Magicube 的优化策略" title="Direct link to 5.1-评估 Magicube 的优化策略">​</a></h3>
<p>首先，我们使用来自DLMC的一个稀疏矩阵（M=256，N=512，K=2304）来评估为SpMM提出的优化方法。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250225235621.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>结果如图11所示，其中Lx-Ry表示x位LHS矩阵和y位RHS矩阵。通过这项<font color="red"><b>消融研究</b></font>，我们可以看到在第IV-B节中讨论的所有优化方法（包括无冲突的共享内存访问、对RHL数据块的数据预取以及针对4位整数的列索引洗牌）都非常有效。特别是，针对4位整数提出的列索引洗牌显著提高了性能。在L4-R4的情况下，V=8且稀疏度=0.7，列索引洗牌策略在所有其他优化被使用后，进一步提高了1.45倍的性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250226000236.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>在第四节D中讨论过，Magicube支持精度仿真。图12展示了混合精度下的SpMM性能。一方面，主要趋势是我们使用的精度越低，能够达到的性能越高。但也有一些例外，例如，当稀疏度为0.98时，L16-R4的性能低于L8-R8，这是因为在稀疏度高时，内存节省的好处无法抵消仿真开销。另一方面，当LHS精度相同时，RHS矩阵的更高精度并不会显著降低性能，这显示了Magicube中精度仿真策略的效率。回忆一下，我们还为SDDMM的LHS数据块使用了数据预取。但图13中的结果显示，为SDDMM预取LHS数据并没有好处。这是因为SDDMM中的LHS数据块在不同warp之间是共享和重用的。因此，即使没有预取，它也已经展现出良好的性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-与现有稠密和稀疏矩阵库的比较">5.2-与现有稠密和稀疏矩阵库的比较<a href="#52-与现有稠密和稀疏矩阵库的比较" class="hash-link" aria-label="Direct link to 5.2-与现有稠密和稀疏矩阵库的比较" title="Direct link to 5.2-与现有稠密和稀疏矩阵库的比较">​</a></h3>
<p>接下来，我们将Magicube的性能与其他稠密和稀疏库进行比较。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250226003143.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图14显示了SpMM的性能。我们将Magicube与不同精度的cuBLAS（fp16，int8）、vectorSparse（fp16）和cuSPARSE（fp16，int8）进行比较。图中显示的加速比是以cuBLAS（fp16）为基准进行归一化的。我们可以看到，Magicube显著优于所有稀疏库。Magicube在稀疏度超过0.7的情况下，甚至在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>&lt;</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">V&lt;8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span> 时也能比cuBLAS（fp16）实现实际加速。有一个有趣的点是，cuBLAS（int8）的表现甚至比cuBLAS（fp16）更差。在V=8和N=256的情况下，Magicube（L8-R8）在所有1,536个矩阵中平均（几何平均）比cuSPARSE（int8）快1.44倍（最高可达2.37倍），并且在所有1,536个矩阵中平均比cuBLAS（int8，稠密）快2.88倍（最高可达15.26倍）；Magicube（L16-R8）在所有1,536个矩阵中平均比vectorSparse（fp16）快2.50倍（最高可达5.27倍）。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250226003158.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图15显示了SDDMM的性能。我们将Magicube与不同精度的cuBLAS（fp16，int8）和vectorSparse（fp16）进行比较。图中显示的加速比是以cuBLAS（fp16）为基准进行归一化的。与SpMM类似，Magicube的SDDMM在稀疏度超过0.7时开始实现相对于cuBLAS（fp16）的实际加速。在V=8和K=256的情况下，Magicube（L16-R16）在所有1,536个矩阵中平均比vectorSparse（fp16）快1.58倍（最高可达2.15倍）。Magicube在较低精度下实现了更高的加速。这些结果表明了Magicube中色化稀疏内核的高效性。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="53-端到端稀疏transformer推理的案例研究">5.3-端到端稀疏Transformer推理的案例研究<a href="#53-端到端稀疏transformer推理的案例研究" class="hash-link" aria-label="Direct link to 5.3-端到端稀疏Transformer推理的案例研究" title="Direct link to 5.3-端到端稀疏Transformer推理的案例研究">​</a></h3>
<p>Transformer模型已广泛应用于自然语言处理和计算机视觉领域，并展现出优秀的学习能力，这得益于多头注意力等技术。目前，Transformer是大规模模型工作负载的典型代表。<font color="red"><b>Transformer模型通常具有重复的结构（即相同的块重复多次）</b></font>。网络架构和模型大小主要由<strong>头部维度</strong>、<strong>头部数量</strong>和<strong>层数</strong>决定。此外，自注意力的工作负载随着输入序列长度的平方增长。通过改变上述参数，我们的评估涵盖了不同的Transformer架构和工作负载。</p>
<p>我们评估了Magicube在真实应用中的性能，以及使用来自长程竞技场（LRA）的稀疏Transformer模型进行端到端推理。该模型有4个编码器层。稀疏Transformer在自注意力操作中具有SDDMM和SpMM的工作负载，使用稀疏注意力掩码。</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo>⊙</mo><mi>M</mi></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">
Attention(Q,K,V) = \text{softmax} \left( \frac{QK^T \odot M}{\sqrt{d_k}} \right) V
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.95em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em"><span style="top:-2.2528em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></span>
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>是头部维度（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo>=</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">d_k = 64</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">64</span></span></span></span>），<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>∈</mo><msup><mrow><mn>0</mn><mo separator="true">,</mo><mn>1</mn></mrow><mrow><mi>L</mi><mo>×</mo><mi>L</mi></mrow></msup></mrow><annotation encoding="application/x-tex">M \in {0, 1}^{L \times L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0701em;vertical-align:-0.1944em"></span><span class="mord"><span class="mord"><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">1</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8757em"><span style="top:-3.0973em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight">L</span></span></span></span></span></span></span></span></span></span></span></span>是稀疏注意力掩码矩阵，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">L</span></span></span></span>是序列长度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding="application/x-tex">\odot</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord">⊙</span></span></span></span>表示逐元素乘法。对于稀疏注意力掩码矩阵，我们遵循Chen等人的做法，加入8x1向量稀疏性约束。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250226003757.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图16展示了我们实现的一个量化的自注意力层，带有稀疏掩码。首先，我们对<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span>矩阵进行量化（这里<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span>是投影的输出）。接下来，稀疏掩码矩阵决定了<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>输出的稀疏性。然后，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>将进行量化的SDDMM操作。我们将去量化与SDDMM操作融合。接下来，SDDMM的输出将是半精度的（fp16）。接着，我们在fp16下进行softmax核的计算，并将量化与softmax核融合，因此softmax的输出是一个稀疏的int8矩阵。最后，我们将int8的稀疏注意力权重与密集矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span>（int8格式）相乘，这是一个SpMM操作。在这里，我们将去量化与SpMM操作融合，输出一个密集矩阵（fp16格式），这个矩阵将作为输入进一步传递到接下来的MLP层。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250226004129.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图17展示了针对不同稀疏性、序列长度、头数、批量大小和精度的稀疏Transformers的端到端推理延迟结果。我们将编码器层的数量保持为4，因为总工作量与层数成正比，并将头维度保持为64，这在Transformer模型中常见。对于Magicube，xb-yb表示将softmax的输出量化为x位整数，并将Q、K、V量化为y位整数。我们将我们的实现与fp16稠密对应物（PyTorch 1.9与cuDNN版本8005）和vectorSparse（fp16）进行比较。我们对每个配置进行了256次迭代，直方图上的绿色条形表示95%的置信区间。对于稀疏性=90%，seq_len=4,096，num_heads=4的端到端推理，Magicube在vectorSparse（在Tensor核心上使用fp16的最先进稀疏库）上实现了1.43x-1.63x的加速，并在PyTorch与cuDNN（稠密）上实现了1.50x-1.70x的加速。在将序列长度增加到8,192时，fp16稠密对应物在batchsize=8时内存耗尽，因为自注意力的内存开销随序列长度的增加而呈平方增长。当稀疏性=90%，seq_len=8,192，num_heads=4时，Magicube在vectorSparse上实现了1.62x-1.92x的加速，这表明Magicube在较长序列上能够实现更高的加速。通过将num_heads从4增加到8，所有方案的运行时间增加了约2倍。通过将稀疏性从90%增加到95%，稀疏库（vectorSparse和Magicube）相比于稠密对应物进一步降低了延迟。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250226004238.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>表V展示了使用稀疏Transformer进行文本分类的测试准确性结果，num_heads=4和seq_len=4,096。LRA的代码库使用的是过时的FLAX版本，我们无法运行，因此在PyTorch中重新实现了它。我们使用相同的超参数对模型进行了稠密和稀疏注意力掩码的训练，并进行了量化的微调。与使用cuDNN的PyTorch（稠密）和稀疏（稀疏率=90%）模型的fp16相比，稀疏（稀疏率=90%）的量化模型（16位softmax输出和8位Q、K、V）达到了相当的准确性。通过将softmax输出的精度降低到8位，准确性略有下降，这表明更高的softmax精度有助于保持准确性。在进一步将稀疏率增加到95%后，稀疏模型的准确性降至可接受范围内。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-discussion">6-Discussion<a href="#6-discussion" class="hash-link" aria-label="Direct link to 6-Discussion" title="Direct link to 6-Discussion">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="61-对其他ai加速器的通用性">6.1-对其他AI加速器的通用性<a href="#61-对其他ai加速器的通用性" class="hash-link" aria-label="Direct link to 6.1-对其他AI加速器的通用性" title="Direct link to 6.1-对其他AI加速器的通用性">​</a></h3>
<p>虽然Magicube是基于NVIDIA GPU和Tensor核心设计的，但Magicube的关键洞察可以轻松适应其他AI加速器。例如，AMD MI250X GPU提供383.0 TOP/s的峰值性能，适用于int8，通过Matrix Core技术实现。为了在Matrix核心上进行编程，AMD提供了具有Matrix Fused Multiply-Add（MFMA）语义的wavefront级指令。与NVIDIA GPU上的mma类似，MFMA指令（例如V_MFMA_I32_16X16X16I8）也对数据布局有特定要求。Magicube的技术，如SR-BCRS格式、在线转置和数据预取，也可以在这些加速器上使用。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="62-与分布式深度学习系统协作">6.2-与分布式深度学习系统协作<a href="#62-与分布式深度学习系统协作" class="hash-link" aria-label="Direct link to 6.2-与分布式深度学习系统协作" title="Direct link to 6.2-与分布式深度学习系统协作">​</a></h3>
<p>高效的大规模深度学习通常通过数据、操作符和流水线并行的组合在分布式系统上实现。Magicube可以作为后端计算库在这些分布式深度学习系统中使用，以加速每个（子）操作符并缓解计算瓶颈。如何在引入稀疏性和量化的同时保持收敛质量是我们未来的工作。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="63-更多应用">6.3-更多应用<a href="#63-更多应用" class="hash-link" aria-label="Direct link to 6.3-更多应用" title="Direct link to 6.3-更多应用">​</a></h3>
<p>在本研究中，我们专注于基于Transformer的超大规模模型，其中通过稀疏注意力掩码引入稀疏工作负载。我们的方案也可能对深度学习中的其他稀疏工作负载有所裨益。例如，模型剪枝训练导致前向传播中的SpMM和反向传播中的SDDMM。此外，我们的实证观察表明，二阶优化中的曲率矩阵也可能通过稀疏性来近似。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-conclusion">7-Conclusion<a href="#7-conclusion" class="hash-link" aria-label="Direct link to 7-Conclusion" title="Direct link to 7-Conclusion">​</a></h2>
<p>在本文中，我们提出了Magicube，一种在Tensor核心上使用低精度（8位、4位）整数的高性能稀疏矩阵库，旨在加速深度学习中的稀疏和量化矩阵运算，主要用于SpMM和SDDMM。为了压缩低精度整数的量，我们设计了一种<font color="red"><b>跨行主序BCRS（SR-BCRS）格式</b></font>。</p>
<p>通过对超过1536个各异大小和稀疏度（50-98%）的稀疏矩阵进行性能评估，数据来源于DLMC数据集，在NVIDIA A100 GPU上，我们证明Magicube在SpMM上相比cuSPARSE实现了平均1.44倍（最高可达2.37倍）的加速。我们还展示了在稀疏（90%）注意力图的<font color="red"><b>Transformer模型</b></font>的端到端推理中，Magicube在准确性相当的情况下，相比于vectorSparse（当前最先进的fp16稀疏库）实现了1.43倍的加速，相比于与cuDNN一起使用的PyTorch（fp16稠密库）实现了1.50倍的加速。</p>
<p><strong>我们稀疏内核对数据布局的唯一限制是，每个非零块为1维块，形状例如8×1、4×1、2×1</strong>。在此限制下，Magicube成功地从深度学习工作负载中的稀疏性和量化中获得了实际的加速。我们预见该工作将激励未来对深度学习模型的稀疏化和量化方法的研究，从而更有效地利用现代加速器。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/paper_notes/2-稀疏矩阵计算/2_SpMM/Magicube/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">阅读笔记</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/稀疏矩阵计算/SpMM/RoDE/阅读笔记"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">阅读笔记</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#0-abstract" class="table-of-contents__link toc-highlight">0-Abstract</a></li><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1-Introduction</a></li><li><a href="#2-background-and-related-work" class="table-of-contents__link toc-highlight">2-Background and Related Work</a><ul><li><a href="#21-深度学习中的压缩" class="table-of-contents__link toc-highlight">2.1-深度学习中的压缩</a></li><li><a href="#22-稀疏和量化操作的优化" class="table-of-contents__link toc-highlight">2.2-稀疏和量化操作的优化</a></li><li><a href="#23-nvidia-图形处理器的张量核与低精度整数的数据布局" class="table-of-contents__link toc-highlight">2.3-NVIDIA 图形处理器的张量核与低精度整数的数据布局</a></li></ul></li><li><a href="#4-implementation-and-optimization-for-spmm-in-deep-learning" class="table-of-contents__link toc-highlight">4-Implementation and Optimization for SpMM in Deep Learning</a><ul><li><a href="#41-稀疏格式" class="table-of-contents__link toc-highlight">4.1-稀疏格式</a></li><li><a href="#42-magicube下的spmm" class="table-of-contents__link toc-highlight">4.2-Magicube下的SpMM</a></li><li><a href="#43-在magicube中的sddmm" class="table-of-contents__link toc-highlight">4.3-在Magicube中的SDDMM</a></li><li><a href="#44-混合精度仿真" class="table-of-contents__link toc-highlight">4.4-混合精度仿真</a></li></ul></li><li><a href="#5-evaluation" class="table-of-contents__link toc-highlight">5-Evaluation</a><ul><li><a href="#51-评估-magicube-的优化策略" class="table-of-contents__link toc-highlight">5.1-评估 Magicube 的优化策略</a></li><li><a href="#52-与现有稠密和稀疏矩阵库的比较" class="table-of-contents__link toc-highlight">5.2-与现有稠密和稀疏矩阵库的比较</a></li><li><a href="#53-端到端稀疏transformer推理的案例研究" class="table-of-contents__link toc-highlight">5.3-端到端稀疏Transformer推理的案例研究</a></li></ul></li><li><a href="#6-discussion" class="table-of-contents__link toc-highlight">6-Discussion</a><ul><li><a href="#61-对其他ai加速器的通用性" class="table-of-contents__link toc-highlight">6.1-对其他AI加速器的通用性</a></li><li><a href="#62-与分布式深度学习系统协作" class="table-of-contents__link toc-highlight">6.2-与分布式深度学习系统协作</a></li><li><a href="#63-更多应用" class="table-of-contents__link toc-highlight">6.3-更多应用</a></li></ul></li><li><a href="#7-conclusion" class="table-of-contents__link toc-highlight">7-Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper_notes_intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs_intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>