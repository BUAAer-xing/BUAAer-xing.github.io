<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="pdf"><meta data-rh="true" property="og:description" content="pdf"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"阅读笔记","item":"https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.98cc3bd4.css">
<script src="/assets/js/runtime~main.b1a1434e.js" defer="defer"></script>
<script src="/assets/js/main.8b44110d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper_notes_intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs_intro">个人博客</a><a class="navbar__item navbar__link" href="/docs/my_papers_intro">发表论文</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper_notes_intro">目录</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">稀疏矩阵计算</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">SpMV</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">SpMM</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">Acc-SpMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记">FlashSparse</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记">Magicube</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/RoDE/阅读笔记">RoDE</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/SpInfer/阅读笔记">SpInfer</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记">Sparse GPU kernel for Deep-Learning</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/TC-GNN/阅读笔记">TC-GNN</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/z-Sparkle-FPGA/阅读笔记">z-Sparkle-FPGA</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件">SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Stencil/ConvStencil/阅读笔记">Stencil</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Other/HPC加速体系结构中Linpack优化/论文原件">Other</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/TCU相关/RT-GNN/阅读笔记">TCU相关</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/z-模版/论文原件">z-模版</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">稀疏矩阵计算</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">SpMM</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Sparse GPU kernel for Deep-Learning</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">阅读笔记</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header><p><a href="zotero://open-pdf/library/items/TMGX4DNV" target="_blank" rel="noopener noreferrer">pdf</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0-abstract">0-Abstract<a href="#0-abstract" class="hash-link" aria-label="Direct link to 0-Abstract" title="Direct link to 0-Abstract">​</a></h2>
<p>科学工作负载传统上利用高水平的稀疏性来加速计算和减少内存需求。虽然深度神经网络可以变得稀疏，但在GPU上实现实际的加速是困难的，因为这些应用的稀疏性相对适中，不足以使现有的稀疏内核超越其密集对应物。</p>
<p>在本研究中，我们<font color="red"><b>研究来自深度学习应用的稀疏矩阵，并识别出可以利用的有利特性来加速计算</b></font>。基于这些见解，我们开发了针对两种在神经网络中广泛应用的稀疏矩阵操作的高性能GPU内核：SPMM和SDDMM。我们的内核在Nvidia V100 GPU上达到了27%的单精度峰值。使用我们的内核，我们展示了稀疏Transformer和MobileNet模型，实现了1.2至2.1倍的加速和高达12.8倍的内存节省，而不牺牲准确性。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250217212755.png" alt="image.png|center|400" class="img_ev3q"></p>
<center> <font face="华文宋体" size="3"> 稀疏矩阵-矩阵乘法在权重稀疏长短期记忆网络问题上的运行时间。输入大小8192，隐藏大小2048，批量大小128，在Nvidia V100 GPU上使用单精度和CUDA 10.1。使用我们的方法，稀疏计算在仅71%的稀疏度下就超过了密集计算的性能。现有厂商库需要14倍更少的非零元素才能实现相同的性能。这项工作为突出区域内的所有问题提供了加速。 </font> </center>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction">​</a></h2>
<p>深度神经网络架构由用于矩阵乘法和卷积的大型密集矩阵组成。这些矩阵可以通过使其稀疏而几乎不损失模型质量，从而导致在实现给定准确性所需的浮点操作（FLOPs）和参数方面更加高效的模型。</p>
<p><strong>稀疏性在深度神经网络中最常见的应用是加速推理</strong>。除了标准训练过程外，还应用稀疏化算法来生成一个高比例权重为零的神经网络。然后，权重矩阵可以以压缩格式存储，并且可以使用稀疏线性代数内核来加速计算。<font color="red"><b>在生成模型的背景下，稀疏性已被应用于降低Transformer架构中自注意力的计算要求</b></font>。除了这些应用，稀疏性还可以通过为固定的计算成本训练一个更大且稀疏的模型来实现更高的预测准确性。为了使训练大型稀疏模型成为可能，训练期间的所有计算需要直接在模型权重的压缩稀疏表示上操作。</p>
<p>稀疏性在深度学习中的潜在应用有很多。然而，由于缺乏高效的内核用于核心稀疏矩阵计算，例如稀疏矩阵-矩阵乘法（SpMM）和采样密集-密集矩阵乘法（SDDMM），因此在实际应用中实现稀疏性的好处是困难的。</p>
<p>在并行架构上，稀疏线性代数核的性能可能会因稀疏矩阵的特性而大幅变化，例如非零值的拓扑和稀疏程度。<strong>现有的用于稀疏线性代数的GPU核主要针对科学应用进行了优化，在这些应用中，矩阵的稀疏度极高（99%以上）。</strong> 由于深度神经网络中稀疏度相对适中，这些核无法超越其稠密版本。</p>
<p>为了解决这个问题，可以对非零元素的拓扑结构施加约束，使非零值被分组到块中。虽然这种方法能够恢复密集计算所取得的性能，但对非零元素位置的限制可能会显著降低相对于无结构稀疏性的模型质量。</p>
<p>在这项工作中，我们开发了<font color="red"><b>一种针对深度学习应用的在GPU上计算SpMM和SDDMM的方法</b></font>。我们的方法<strong>直接在标准压缩稀疏行（CSR）格式上操作</strong>，并且不对非零值的拓扑结构施加任何限制。我们做出了以下具体贡献：</p>
<ul>
<li>我们<strong>对深度学习中的稀疏 矩阵进行了大规模研究</strong>，识别出可利用的有利特性以加速稀疏计算。</li>
<li>我们引入了一种<strong>一维tiling方案</strong>，用于在处理单元之间分解计算，这有助于操作数的重用并且适合扩展实现。</li>
<li>我们开发了两种技术，<strong>sub-warp tiling</strong> 和 <strong>reverse-offset memory alignment</strong>，使得在稀疏数据结构中可以在未对齐的内存地址上使用<font color="red"><b>向量内存指令</b></font>。</li>
<li>我们引入了<strong>row swizzle 负载平衡</strong>，一种在处理单元之间进行负载平衡的计算方法，该方法与并行化方案解耦。</li>
</ul>
<p>在来自最先进深度神经网络的大型稀疏矩阵数据集上，</p>
<ul>
<li>我们在Nvidia V100 GPU上展示了SpMM和SDDMM相对于Nvidia cuSPARSE的几何平均加速比为3.58×和2.19×。</li>
<li>在表现最优的问题上，我们的内核达到了单精度峰值的27%。</li>
<li>在稀疏Transformer和MobileNet模型上，使用我们的内核，分别实现了1.22×到1.1×的端到端加速和12.8×的内存使用减少，同时保持与其稠密计算相同的精度。</li>
</ul>
<p><a href="https://github.com/google-research/sputnik" target="_blank" rel="noopener noreferrer">开源地址</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-sparse-matrices-in-deep-learning">2-Sparse Matrices in Deep Learning<a href="#2-sparse-matrices-in-deep-learning" class="hash-link" aria-label="Direct link to 2-Sparse Matrices in Deep Learning" title="Direct link to 2-Sparse Matrices in Deep Learning">​</a></h2>
<p>为了理解深度学习中稀疏矩阵的特性，我们基于大规模研究构建了一个稀疏深度神经网络权重矩阵的数据集。该数据集由在ImageNet上训练的ResNet-50模型和在WMT14英德翻译任务上训练的Transformer模型组成，并包括使用四种不同算法诱导神经网络稀疏性训练的模型。对于Transformer，我们将分析限制在WMT14英 德测试集上达到20以上BLEU分数的模型。对于ResNet-50，我们包括在ImageNet验证集上达到70%以上top-1精度的模型。总共，该数据集包含来自49个不同模型的3,012个矩阵。</p>
<p>我们的分析集中在矩阵的三个特性上：行长变异系数 (CoV)、平均行长和稀疏度。。</p>
<ul>
<li><strong>矩阵行长度的CoV</strong>是行长度的标准差除以其均值。高CoV表示稀疏矩阵的行之间存在负载不平衡。</li>
<li><strong>平均行长度</strong>捕获了在稀疏矩阵的每一行上将要完成的平均工作量。较长的行长度是理想的，因为启动开销和一次性成本可以在更多的有效工作中摊销。</li>
<li><strong>稀疏性</strong>衡量矩阵中零值的比例。根据具体实现，较低的稀疏性水平可以增加不同行中非零值落入相同列的可能性，从而为通过缓存重用操作数提供机会。</li>
</ul>
<p>我们对比了深度学习工作负载与来自SuiteSparse矩阵集合的矩阵特性，该集合由2,833个稀疏矩阵组成，这些矩阵涵盖了广泛的科学工作负载，包括电路仿真、计算流体动力学、量子化学等。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250217213043.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>我们的深度学习矩阵和SuiteSparse矩阵集合的统计数据如图2所示。来自科学工作负载和深度学习的稀疏矩阵之间的差异相当显著：平均而言，深度学习矩阵的稀疏度低13.4倍，行长度长2.3倍，并且矩阵内行长度的变化量低25倍。我们认为，这些差异主要是由于保持高准确度的需求，这需要具有大量参数的深度神经网络。这反过来导致每行的非零元素数量增加，以及较低的变异系数，而变异系数与平均行长度成反比。<strong>我们研究的每个指标中，深度学习矩阵展现出有利的特性，我们可以利用这些  特性来加速稀疏矩阵计算</strong>。</p>
<hr>
<p>📒：有利的特征：</p>
<ol>
<li><strong>较低的稀疏度（Less Sparsity）</strong>
<ul>
<li>深度学习中的稀疏矩阵通常<strong>稀疏度较低</strong>，平均比科学计算矩阵<strong>稠密13.4倍</strong>（即包含更多非零元素）。</li>
<li>这意味着在深度学习中的稀疏矩阵仍然具有较高的计算密度，使得优化后的稀疏计算可以达到较高的性能，而传统科学计算的稀疏矩阵通常过于稀疏，难以利用GPU的计算能力。</li>
</ul>
</li>
<li><strong>较长的平均行长度（Longer Average Row Length）</strong>
<ul>
<li>深度学习的稀疏矩阵中，<strong>每行的非零元素数量平均是科学计算矩阵的2.3倍</strong>。</li>
<li>这意味着每个线程在执行稀疏矩阵运算时，每行包含的计算量较大，可以更好地<strong>摊销（amortize）</strong> 启动开销，提高计算效率。</li>
</ul>
</li>
<li><strong>较低的行长度变异系数（Lower Row Length Variation, i.e., More Balanced Workload）</strong>
<ul>
<li>在深度学习的稀疏矩阵中，各行的长度变化较小，<strong>行长度的变异系数（CoV, Coefficient of Variation）比科学计算矩阵低25倍</strong>。</li>
<li>这意味着计算任务在GPU上更加<strong>负载均衡（Load Balancing）</strong>，减少了线程之间的计算不均衡（warp divergence）问题，提高了并行效率。</li>
</ul>
</li>
</ol>
<p>深度学习的稀疏矩阵相比传统科学计算展现了<strong>较低的稀疏度、更长的平均行长度以及更均匀的行长度分布</strong>。这些特征使得本文提出的<strong>优化稀疏计算内核</strong>可以充分利用GPU的计算能力，提高SpMM和SDDMM运算的吞吐量，从而实现<strong>高效的稀疏计算加速</strong>。</p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-gpu-background">3-GPU Background<a href="#3-gpu-background" class="hash-link" aria-label="Direct link to 3-GPU Background" title="Direct link to 3-GPU Background">​</a></h2>
<p>本节提供了GPU架构和术语的基本描述。我们的实现使用CUDA编写，因此我们采用Nvidia使用的术语。</p>
<p>GPU由一组流处理器(SM)组成，GPU内核由一组线程组成，线程按32个一组聚集称为warp。warps再被聚集成称为线程块的更大线程集合。构成内核的线程块集合称为网格。当内核被启动到GPU进行执行时，每个线程块被调度到一个SM上。一组线程块称为一波线程块，该组线程块在GPU上同时运行。线程块内的所有线程可以通过快速的、程序员管理的、局部于SM的共享内存进行通信。所有线程还可以访问线程局部寄存器。并发执行在一个SM上的线程块数量被称为内核的占用率。较高的占用率通常是可取的，因为可以利用线程级并行性来隐藏内存和算术操作的延迟。GPU拥有一个较大但延迟高的全局内存，对所有SM都是可访问的，还有一个由所有SM共享的L2缓存，以及每个SM局部的L1缓存。当一个warp线程访问全局内存时，GPU会尝试将访问合并为尽可能少的事务。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-sparse-matrix-computation">4-Sparse Matrix Computation<a href="#4-sparse-matrix-computation" class="hash-link" aria-label="Direct link to 4-Sparse Matrix Computation" title="Direct link to 4-Sparse Matrix Computation">​</a></h2>
<p>本节解释由我们的 SpMM 和 SDDMM 内核实现的操作。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-spmm">4.1-SPMM<a href="#41-spmm" class="hash-link" aria-label="Direct link to 4.1-SPMM" title="Direct link to 4.1-SPMM">​</a></h3>
<p>我们的SpMM内核实现了计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>B</mi><mo>⇒</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">AB \Rightarrow C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 是稀疏矩阵，并存储在标准的压缩稀疏行（CSR）格式中。在接下来的章节中，我们将矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span> 分别称为稀疏矩阵、稠密矩阵和输出矩阵。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-sddmm">4.2-SDDMM<a href="#42-sddmm" class="hash-link" aria-label="Direct link to 4.2-SDDMM" title="Direct link to 4.2-SDDMM">​</a></h3>
<p>SDDMM 操作被定义为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>B</mi><mo>⊙</mo><mi>C</mi><mo>⇒</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">AB \odot C \Rightarrow D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span> 是稀疏矩阵，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊙</mo></mrow><annotation encoding="application/x-tex">\odot</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord">⊙</span></span></span></span> 表示两个矩阵的<font color="red"><b>逐元素乘法</b></font> 。由于采用了稀疏矩阵的逐元素缩放，可以跳过输出中零值位置的点积运算，从而加速计算。</p>
<p>在稀疏深度神经网络中，SDDMM 在多个关键计算中起着重要作用。例如，在权重稀疏的神经网络中，前向传播计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mi>X</mi><mo>⇒</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">W X \Rightarrow Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span> 是稀疏矩阵。在反向传播过程中，相对于稀疏权重的梯度计算为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi><mi>Y</mi><msup><mi>X</mi><mi>T</mi></msup><mo>⊙</mo><mi mathvariant="double-struck">I</mi><mo stretchy="false">[</mo><mi>W</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>δ</mi><mi>W</mi></mrow><annotation encoding="application/x-tex">\delta Y X^T \odot \mathbb{I}[W] \Rightarrow \delta W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9247em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathbb">I</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03785em">δ</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="double-struck">I</mi><mo stretchy="false">[</mo><mi>W</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathbb{I}[W]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathbb">I</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mclose">]</span></span></span></span> 是一个指示函数，在稀疏矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span> 的非零值位置返回 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>。在具有稀疏注意力的 Transformer 模型中，前向传播同样计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup><mo>⊙</mo><mi mathvariant="double-struck">I</mi><mo stretchy="false">[</mo><mi>Y</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>Z</mi></mrow><annotation encoding="application/x-tex">Q K^T \odot \mathbb{I}[Y] \Rightarrow Z</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathbb">I</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">Z</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span></span></span></span> 分别是注意力机制的查询和键输入，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Y</mi></mrow><annotation encoding="application/x-tex">Y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">Y</span></span></span></span> 是描述注意力机制连接性的稀疏矩阵。</p>
<p>这些计算在两个方面与严格定义的 SDDMM 不同。首先，它们不需要对稀疏矩阵值进行逐元素缩放。其次，作为 SDDMM 输入的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 通常是转置的。考虑到这些应用，我们的 SDDMM 实现计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msup><mi>B</mi><mi>T</mi></msup><mo>⊙</mo><mi mathvariant="double-struck">I</mi><mo stretchy="false">[</mo><mi>C</mi><mo stretchy="false">]</mo><mo>⇒</mo><mi>D</mi></mrow><annotation encoding="application/x-tex">A B^T \odot \mathbb{I}[C] \Rightarrow D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9247em;vertical-align:-0.0833em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⊙</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathbb">I</span><span class="mopen">[</span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span>。尽管我们专注于深度学习中的计算，但我们的方法可以轻松扩展到一般的 SDDMM 计算。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="43-数据组织形式">4.3-数据组织形式<a href="#43-数据组织形式" class="hash-link" aria-label="Direct link to 4.3-数据组织形式" title="Direct link to 4.3-数据组织形式">​</a></h3>
<p>为了实现对所有输入和输出矩阵的合并内存访问，我们将稠密矩阵存储为行主（row-major）布局，并将稀疏矩阵存储为 CSR 格式。我们注意到，按照 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>A</mi><mo>⇒</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">BA \Rightarrow C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span> 计算 SpMM 也是同样高效的，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 是以压缩稀疏列（CSC）格式存储的稀疏矩阵，而 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span> 以列主（column-major）格式存储。
📒：这里估计是作者在写文章的时候写错了？？？？？？？？？？？</p>
<hr>
<p><strong>行主布局（Row-Major Order）</strong>：<strong>按行优先存储</strong>，即 <strong>一行的数据是连续存储的</strong>。
例如，一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span> 矩阵：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mrow><mo fence="true">[</mo><mtable rowspacing="0.16em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>11</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>12</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>13</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>21</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>22</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>23</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>31</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>32</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>a</mi><mn>33</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex">A = \begin{bmatrix}
a_{11} &amp; a_{12} &amp; a_{13} \\
a_{21} &amp; a_{22} &amp; a_{23} \\
a_{31} &amp; a_{32} &amp; a_{33}
\end{bmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:3.6em;vertical-align:-1.55em"></span><span class="minner"><span class="mopen"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M403 1759 V84 H666 V0 H319 V1759 v0 v1759 h347 v-84
H403z M403 1759 V0 H319 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">11</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">21</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">31</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em"></span><span class="arraycolsep" style="width:0.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.21em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.01em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-1.81em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">33</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span><span class="mclose"><span class="delimsizing mult"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.05em"><span style="top:-4.05em"><span class="pstrut" style="height:5.6em"></span><span style="width:0.667em;height:3.600em"><svg xmlns="http://www.w3.org/2000/svg" width="0.667em" height="3.600em" viewBox="0 0 667 3600"><path d="M347 1759 V0 H0 V84 H263 V1759 v0 v1759 H0 v84 H347z
M347 1759 V0 H263 V1759 v0 v1759 h84z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.55em"><span></span></span></span></span></span></span></span></span></span></span></span>
<p>在 <strong>行主布局</strong>（如 C 语言的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mi>l</mi><mi>o</mi><mi>a</mi><mi>t</mi><mi>A</mi><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo><mo stretchy="false">[</mo><mn>3</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">float A[3][3]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">A</span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span><span class="mopen">[</span><span class="mord">3</span><span class="mclose">]</span></span></span></span>）中的内存存储顺序为：
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>a</mi><mn>11</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>12</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>13</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>21</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>22</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>23</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>31</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>32</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>33</mn></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{ a_{11}, a_{12}, a_{13}, a_{21}, a_{22}, a_{23}, a_{31}, a_{32}, a_{33} \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">11</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">21</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">31</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">33</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></p>
<p><strong>列主布局（Column-Major Order）</strong>：<strong>按列优先存储</strong>，即 <strong>一列的数据是连续存储的</strong>。</p>
<p>在 <strong>列主布局</strong>（如 Fortran、MATLAB 的默认存储方式）中的内存存储顺序为：
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mi>a</mi><mn>11</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>21</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>31</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>12</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>22</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>32</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>13</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>23</mn></msub><mo separator="true">,</mo><msub><mi>a</mi><mn>33</mn></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{ a_{11}, a_{21}, a_{31}, a_{12}, a_{22}, a_{32}, a_{13}, a_{23}, a_{33} \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">11</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">21</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">31</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">32</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">33</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></p>
<hr>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-spmm-design">5-SpMM Design<a href="#5-spmm-design" class="hash-link" aria-label="Direct link to 5-SpMM Design" title="Direct link to 5-SpMM Design">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="51--分层-1-维-tiling">5.1- 分层 1-维 Tiling<a href="#51--分层-1-维-tiling" class="hash-link" aria-label="Direct link to 5.1- 分层 1-维 Tiling" title="Direct link to 5.1- 分层 1-维 Tiling">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250217220403.png" alt="image.png|center|1000" class="img_ev3q"></p>
<center> <font face="华文宋体" size="3"> SpMM的分层分解使用一维 Tiling。为了简洁起见，采用4个warp在一个线程块中进行可视化。在每个分解级别中，矩阵A是以压缩稀疏行格式存储的稀疏矩阵，标记为绿色并显示在左侧。矩阵B是密集矩阵，标记为蓝色并显示在输出矩阵的顶部。输出矩阵C是密集的，标记为橙色并显示在每个级别的右下角。每个级别的深色区域表示下一个级别使用的数据。最左侧：每个线程块计算输出矩阵的一个一维 Tile。稀疏矩阵A的一行中的所有值都需要所有线程。我们使用线程块中的所有线程协作将A中的值和索引加载到共享内存，这样可以快速访问进行计算。对于从A加载的每个列索引，线程块将从矩阵B加载一个连续向量（标记为深蓝色横条）。中间左侧至最右侧：线程处理独立的输出，因此需要来自密集矩阵B的不同列子集。每个线程加载计算其输出所需的B中的值，并将其存储在线程局部寄存器中。 </font> </center>
<p>我们在GPU上进行SpMM的方案如图3所示，并在图4中以CUDA伪代码的形式呈现。该分解遵循行分割方案，但有一个关键不同之处：<font color="red"><b>我们将输出划分为一维Tile，并将独立的线程块映射到每个Tile，而不是将线程块映射到输出矩阵的整个行</b></font>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250217223435.png" alt="image.png|center|400" class="img_ev3q"></p>
<center> <font face="华文宋体" size="3"> CUDA伪代码用于具有一维分块的稀疏乘稠密矩阵（SpMM）。输出矩阵在静态分区中被划分为一维分块。独立的线程块被启动来计算每个输出分块。在主循环的每次迭代中，我们加载稀疏矩阵的一维条带和稠密矩阵的二维分块，并累加向量矩阵乘积。在处理完该行中的所有非零值后，结果被写入输出矩阵。 </font> </center>
<p>这种方法的动机源于这样一个事实：在深度学习应用中，稠密矩阵的列数可能会有很大变化。考虑具有稀疏权重矩阵和稠密激活的各种神经网络架构。</p>
<ul>
<li>在训练RNN时，这个维度对应于批大小，通常在16到128个元素之间。</li>
<li>在Transformer架构中，这个维度是批大小和序列长度的乘积，可以从256变化到超过2048个元素。</li>
<li>在1×1卷积中，这个维度是图像高度和宽度与批大小的乘积。在EfficientNet架构中，空间维度的乘积范围从64到14,400。</li>
</ul>
<p>1维-Tile 有三个主要优点。首先，我们可以很容易地为不同的Tile大小模板化我们的实现，并为问题空间的不同区域生成专门的内核变体。其次，对于M和K维度较小的问题，我们启动的线程块数量比通常可能的要多，从而实现更高的占用率和更高的峰值吞吐量的比例。最后，处理固定大小的块使我们能够积极展开循环，并在编译时计算偏移和常量。我们同样通过固定大小的步长迭代缩减维度，从而实现进一步的循环展开和静态评估。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-向量化内存访问">5.2-向量化内存访问<a href="#52-向 量化内存访问" class="hash-link" aria-label="Direct link to 5.2-向量化内存访问" title="Direct link to 5.2-向量化内存访问">​</a></h3>
<p>向量内存指令是缓解带宽瓶颈和减少表达计算所需指令数量的重要工具。然而，在稀疏矩阵内核中使用这些操作并非易事。</p>
<blockquote>
<p>[! warning] 💡
向量化内存访问，这个是不是可以添加到框架中？？？？</p>
</blockquote>
<p>首先，<strong>使用向量内存指令会增加线程块同时加载的值的数量</strong>。例如，一个使用4宽向量加载的单个warp的线程块会在一次指令中请求128个浮点数。在我们的1D分块方案中，这意味着来自长度小于128的稀疏矩阵行的一些加载需要被条件化。同样，稠密矩阵中列数少于128的问题在内核执行的整个过程中，会有一些线程在每个线程块中被条件化关闭。这些约束限制了向量内存访问的实用性，特别是在未加处理的情况下，仅适用于非常大的问题。</p>
<p>其次，<strong>向量内存访问要求目标值按照向量宽度对齐（2或4个32字节值）</strong>。对于稠密矩阵或输出矩阵的访问，这要求列数能够被向量宽度整除，以确保每行值的起始位置正确对齐。更大的问题出在从稀疏矩阵加载数据。通过一维分块或行拆分方案，线程块内的访问从稀疏矩阵中一行值的起始位置开始。由于稀疏矩阵中的行可以具有任意长度，这些初始地址没有对齐保证，无论问题的维度如何。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="521-subwarp-tiling">5.2.1 SubWarp Tiling<a href="#521-subwarp-tiling" class="hash-link" aria-label="Direct link to 5.2.1 SubWarp Tiling" title="Direct link to 5.2.1 SubWarp Tiling">​</a></h4>
<p>为了解决第一个问题，我们将我们的方案扩展为允许将一个warp的子集（即subwarp）映射到输出的独立一维tiles上。这通过使用的subwarp数量减少了访问宽度限  制。这也使我们可以在输出矩阵的更多行中分散线程，以应对稠密矩阵和输出矩阵列数较少的问题。</p>
<p>通过subwarp平铺，我们的方案在warp级别上与标准的二维平铺方案有一些相似之处。重要的区别在于，处理输出矩阵不同行的subwarps无法重用从稠密矩阵加载的值。然而，根据稀疏程度，来自不同subwarp的访问很可能会表现出局部性，可以通过缓存来服务。</p>
<p>该方法的主要缺点是不同长度的行可能导致warp负载不均。我们在第五节C部分解决了warp中线程之间负载不平衡的问题。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="522-reverse-offset-内存对齐">5.2.2 Reverse Offset 内存对齐<a href="#522-reverse-offset-内存对齐" class="hash-link" aria-label="Direct link to 5.2.2 Reverse Offset 内存对齐" title="Direct link to 5.2.2 Reverse Offset 内存对齐">​</a></h4>
<p>📒：<strong>Reverse Offset Memory Alignment（ROMA）</strong> 通过 <strong>调整行起始地址</strong> 使其对齐，从而 <strong>启用GPU向量化内存访问</strong>，并在<strong>第一轮计算中掩盖错误数据</strong>以确保正确性。</p>
<p>解决第二个问题的一个简单方法是用零对稀疏矩阵的行进行填充，使得所有行的长度都是四的倍数。然而，这限制了内核的普适性。为了在任意稀疏矩阵上启用向量内存指令的使用，我们在内核的设置部分引入了一个简单的技巧（即前言）：<strong>在加载行偏移并计算行长度之后，每个线程块将其行偏移减少到最近的向量宽度对齐地址，并更新需要处理的非零元素数量</strong>。为了保持正确性，线程在主循环第一次迭代中累加结果之前会屏蔽从上一行加载的任何值。</p>
<p>我们将这个技巧称为反向偏移内存对齐（ROMA）。相对于显式填充方案，ROMA并没有改变每个线程块所做的工作量。主要区别在于，ROMA不是显式填充  矩阵数据结构，而是<strong>有效地用前一行的值对稀疏矩阵的行进行填充</strong>。</p>
<hr>
<p>注意，稀疏矩阵的第一行保证是向量对齐的，因为<font color="red"><b>所有 CUDA 内存分配例程都以至少 256 字节的对齐方式分配内存</b></font>。</p>
<p>GPU的向量化内存访问要求数据起始地址必须按照向量宽度（如2个或4个32-bit数）对齐。但是，在<strong>压缩稀疏行（CSR）格式</strong>下，稀疏矩阵的每一行长度是<strong>不固定的</strong>，不同行的起始地址可能是<strong>非对齐的（misaligned）</strong>。</p>
<hr>
<p>ROMA可以非常高效地实现。对齐过程在内核前奏中添加了6条<font color="red"><b>PTX指令</b></font>：2条位运算(<code>and</code>)、1条加法(<code>add</code>)、1条设置谓词(<code>setp</code>)和2条基于谓词选择指令(<code>selp</code>)。掩蔽过程在主循环的第一次迭代中添加了1条设置谓词(<code>setp</code>)和2条共享内存存储指令(<code>str.shared</code>)。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218150158.png" alt="image.png|center|400" class="img_ev3q">
<center> <font face="华文宋体" size="3"> 用于在稀疏矩阵数据结构上启用向量内存操作的技术。上部分：子块铺助将一个warp的子集映射到输出的独立一维块。通过将<font color="red"><b>warp访问分散到多行</b></font>，我们减少了浪费的工作量。分配给warp/subwarp的行用蓝色标记。加载地址用箭头表示，条件加载用“X”表示。哈希区域表示通过warp/subwarp的一组加载加载的值。下部分：反向偏移内存对齐将<font color="red"><b>每行的地址备份到最近的对齐地址</b></font>。前一行的值在第一次循环迭代中被掩码以保持正确性。未对齐的地址用下划线标出。修改后的行起始地址用圆圈和行索引标记。 </font> </center></p>
<p> 这些使得向稀疏矩阵中使用向量内存指令的技术在图5中得以可视化。图8展示了我们SpMM内核的CUDA伪代码，其中包含了用于subwarp tiling和ROMA的必要修改。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="53-row-swizzle-负载均衡">5.3 Row Swizzle 负载均衡<a href="#53-row-swizzle-负载均衡" class="hash-link" aria-label="Direct link to 5.3 Row Swizzle 负载均衡" title="Direct link to 5.3 Row Swizzle 负载均衡">​</a></h3>
<p>已经提出了一些处理稀疏计算中负载不平衡的方法。然而，<strong>现有的方法将负载均衡与并行化方案紧密耦合。虽然这些方案在负载不平衡显著时能够实现良好的性能，但它们通常会引入计算不规律性，这可能会对更规律的问题的性能造成损害</strong>。然而，尽管在深度神经网络中发现稀疏矩阵的规律性，我们的内核仍然面临负载不平衡。</p>
<p>当将稀疏矩阵操作映射到GPU时，可能存在两个负载不平衡的来源。</p>
<ul>
<li>(a) <strong>线程组或线程块之间的负载不平衡</strong>：某些线程组/线程块可能分配的工作少于其他线程组/线程块。这可能导致一些流处理器闲置，而其他则在执行有用的工作。</li>
<li>(b) <strong>线程组或线程块内的负载不平衡</strong>：某些线程在一个线程组内的工作量可能少于其他线程。这可能导致线程组分歧，并在流处理器内造成数学单元和内存带宽的低效使用。</li>
</ul>
<p>为了解决这些问题，我们有两个观察。</p>
<ol>
<li>首先，在内核执行过程中，许多不同大小的工作单元将被调度到每个SM上。</li>
<li>其次，我们可以通过改变每个工作单元被分配给哪个线程来控制分配给哪个SM的工作。
基于这些观察，我们可以通过<strong>重新映射工作调度的位置来确保工作负载在处理单元之间平衡</strong>，从而<font color="red"><b>使每个处理单元（SM）分配到大致相等的工作量</b></font>。我们将这个<strong>重新映射过程称为行混洗</strong>。</li>
</ol>
<p>为了应对这两种负载不平衡的来源，我们引入了两级工作重新排序：</p>
<ul>
<li>(a) <strong>Row Binning</strong>：在了解线程块如何映射到SM之后，调整 tile 映射，使每个SM接收大约相同的工作量。这有助于<strong>解决warp/线程块之间的负载不平衡</strong>。</li>
<li>(b) <strong>Row Bundling</strong>：对于跨多个稀疏矩阵行的warp进行分割的内核，调整tile映射，使每个子warp接收大约相同的工作量。这有助于<strong>解决warp内部的负载不平衡</strong>。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="531--volta线程块调度器">5.3.1- Volta线程块调度器<a href="#531--volta线程块调度器" class="hash-link" aria-label="Direct link to 5.3.1- Volta线程块调度器" title="Direct link to 5.3.1- Volta线程块调度器">​</a></h4>
<p>实现Row Binning方法，以使各个SM接收大致相同数量的工作是复杂的实现，因为这<strong>取决于GPU的线程块调度算法</strong>，这些算法并不公开。我们对Nvidia Volta线程块调度器进行了逆向工程，遵循了相同的一般方法。总体而言，Volta线程块调度器比Fermi线程块调度器简单得多。<strong>第一波中的线程块根据其块索引分配给SM</strong>。
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mi>x</mi><mo>=</mo><mn>2</mn><mo stretchy="false">(</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mi>x</mi><mrow><mtext> </mtext><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi><mtext> </mtext></mrow><mn>40</mn><mo stretchy="false">)</mo><mo>+</mo><mfrac><mrow><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mi>x</mi></mrow><mn>40</mn></mfrac><mrow><mtext> </mtext><mi mathvariant="normal">m</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">d</mi><mtext> </mtext></mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">sm\_idx=2(block\_idx\mathrm{~mod~}40)+\frac{block\_idx}{40}\mathrm{~mod~}2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em"></span><span class="mord">2</span><span class="mopen">(</span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">mod</span><span class="mspace nobreak"> </span></span><span class="mord">40</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.3581em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0131em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">40</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.527em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">b</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">oc</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mord mtight" style="margin-right:0.02778em">_</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mspace nobreak"> </span><span class="mord mathrm">mod</span><span class="mspace nobreak"> </span></span><span class="mord">2</span></span></span></span>
其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">block\_idx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span></span></span></span> 是计算出来的：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mi>x</mi><mo>=</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi>I</mi><mi>d</mi><mi>x</mi><mi mathvariant="normal">.</mi><mi>x</mi><mo>+</mo><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi>I</mi><mi>d</mi><mi>x</mi><mi mathvariant="normal">.</mi><mi>y</mi><mo>×</mo><mi>g</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>D</mi><mi>i</mi><mi>m</mi><mi mathvariant="normal">.</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">block\_idx = blockIdx.x + blockIdx.y \times gridDim.x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mord">.</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord mathnormal" style="margin-right:0.07847em">I</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.03588em">y</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">g</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord mathnormal">im</span><span class="mord">.</span><span class="mord mathnormal">x</span></span></span></span></span>
<p>这个映射以轮询方式将线程块分配到SM上。在第一波之后，线程块按<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>k</mi><mi mathvariant="normal">_</mi><mi>i</mi><mi>d</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">block\_idx</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">oc</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">x</span></span></span></span>的顺序调度，随着资源的可用。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="532-row-binning--row-bundling-heuristics">5.3.2-Row Binning &amp; Row Bundling Heuristics<a href="#532-row-binning--row-bundling-heuristics" class="hash-link" aria-label="Direct link to 5.3.2-Row Binning &amp; Row Bundling Heuristics" title="Direct link to 5.3.2-Row Binning &amp; Row Bundling Heuristics">​</a></h4>
<p>一种简单的Row Binning 启发式是选择第一波最重的N行捆绑，然后将接下来的N个最重的行捆绑与之前的捆绑按重量的反向顺序配对。为了按大小捆绑行，我们可以贪婪地从按大小排列的连续行中创建捆绑。</p>
<p>鉴于Nvidia GPU使用的在线线程块调度算法，这两种启发式方法可以通过<font color="red"><b>按行长度对行索引进行排序来实现</b></font>。给定一个按大小降序排列的行索引的排序数组，捆绑由连续行索引的块组成。第一波捆绑以轮询的方式在SM之间调度，剩余的捆绑按照优先级顺序调度，直到执行完成。我们注意到这种行分组的启发式方法类似于引导自调度。</p>
<p>该方法的一个优点是我们不需要知道目标捆绑大小便可以将相似大小的行分组。这意味着该启发式方法不需要了解底层使用的任何内核选择启发式。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218155603.png" alt="center|600" class="img_ev3q"></p>
<center> <font face="华文宋体" size="3"> Row swizzle 方法用于稀疏  矩阵计算的负载均衡。由同一warp处理的行被标记为相同的模式和颜色。我们引入了一层间接，以便在处理行时重新排序。【线程块内的负载均衡】为了平衡块内线程之间的工作，我们将相似长度的行分组成束。【线程块间的负载均衡】为了平衡SM之间的工作，我们按大小递减的顺序处理行束。 </font> </center>
<p>由于DNN中稀疏矩阵的拓扑通常不常更新，因此按行长度对行索引进行argsort的成本可以在多个训练步骤中摊销。实现内核中的swizzle还需要在内核前奏中添加一个加载操作。<strong>存储矩阵排序索引所需的内存微不足道</strong>，因为对于我们目标应用，矩阵中的行数通常远小于矩阵中的非零元素数量。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218155901.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>图6显示了行swizzle负载均衡的高层方案。图7显示了在负载不平衡增加的情况下，行swizzle负载均衡在样本问题上的性能。图8显示了我们的SpMM内核的CUDA伪代码，包含进行行swizzle负载均衡所需的修改。</p>
<blockquote>
<p>[! warning] 💡后面的工作可以引入块内负载均衡</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="54-实现细节">5.4 实现细节<a href="#54-实现细节" class="hash-link" aria-label="Direct link to 5.4 实现细节" title="Direct link to 5.4 实现细节">​</a></h3>
<p>本节详细介绍了我们为实现良好性能而应用的其他低级优化。</p>
<ol>
<li><strong>Index Pre-Scaling</strong>：在我们的内核主循环的每次迭代中，我们加载稀疏矩阵的值和索引，并将它们存储在共享内存中。每个索引将被所有线程用于从稠密矩阵中加载。为了避免每次加载索引时的重复工作，我们让每个线程在存储到共享内存之前缩放其部分索引。</li>
<li><strong>Residue Handling</strong>：我们的<font color="red"><b>内核尽可能处理多个包含非零值的完整块，然后执行剩余处理程序来累积剩余的乘积</b></font>。<strong>由于稀疏矩阵的行长度很少能被块大小整除，因此剩余处理代码的高效性至关重要</strong>。为了最大化共享内存带宽并最小化bank冲突，我们尽可能使用128位共享内存加载指令。这对于主循环来说很简单，但对于剩余处理代码来说就困难了，因为剩余的非零元素数量不一定能被四整除。为了能够使用宽共享内存指令，我们在加载残余值和索引之前，将用于稀疏矩阵值和索引的共享内存缓冲区清零。然后我们将稠密矩阵加载和计算的循环分为两个，并将内部循环无界展开4倍。</li>
<li><strong>Mixed Precision</strong>：除了标准的32位浮点内核外，我们还扩展了我们的SpMM实现，以支持混合精度计算，这在深度学习中很常见。我们的内核支持16位浮点输入/输出数据，并使用16位整数索引来处理稀疏矩阵的元数据。在我们的内核内部，我们将FP16数据转换为FP32，并发出FP32融合乘加指令，这是标准做法。在写入结果之前，我们将最终输出从FP32转换为FP16。由于16位整数的表示能力降低，我们不对混合精度内核执行索引预缩放优化。</li>
</ol>
<div class="language-cpp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-cpp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">template</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> kBlockItemsK</span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">__global__ </span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">SpmmKernel</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">SparseMatrix a</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Matrix b</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Matrix c</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// 计算线程块对应的矩阵行索引</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> m_idx </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> blockIdx</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">y</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// 读取CSR格式中该行的起始地址和非零元素个数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> m_off </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> a</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">row_offsets</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">m_idx</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">int</span><span class="token plain"> nnz </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> a</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">row_offsets</span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain">m_idx</span><span class="token operator" style="color:#393A34">+</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">-</span><span class="token plain"> m_off</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// **ROMA：对齐行偏移地址**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    MemoryAligner </span><span class="token function" style="color:#d73a49">aligner</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">m_off</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> nnz</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    nnz </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> aligner</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">AlignedNonzeros</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// 计算对齐后仍需处理的非零元素数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    m_off </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> aligner</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">AlignedRowOffset</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// 更新起始地址，确保对齐</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// **第一轮迭代**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    Tile1D </span><span class="token function" style="color:#d73a49">c_tile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token comment" style="color:#999988;font-style:italic">/*init_to=*/</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">if</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">nnz </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Tile1D a_tile </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">LoadTile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">a</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        aligner</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">MaskPrefix</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">a_tile</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// **掩盖因对齐回溯导致的错误数据**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Tile2D b_tile </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">LoadTile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">b</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        c_tile </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> a_tile </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> b_tile</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        nnz </span><span class="token operator" style="color:#393A34">-=</span><span class="token plain"> kBlockItemsK</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// **主计算循环**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">for</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> nnz </span><span class="token operator" style="color:#393A34">&gt;</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"> nnz </span><span class="token operator" style="color:#393A34">-=</span><span class="token plain"> kBlockItemsK</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Tile1D a_tile </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">LoadTile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">a</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        Tile2D b_tile </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">LoadTile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">b</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        c_tile </span><span class="token operator" style="color:#393A34">+=</span><span class="token plain"> a_tile </span><span class="token operator" style="color:#393A34">*</span><span class="token plain"> b_tile</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic">// **存储计算结果**</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token function" style="color:#d73a49">StoreTile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">c_tile</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> c</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-sddmm">6-SDDMM<a href="#6-sddmm" class="hash-link" aria-label="Direct link to 6-SDDMM" title="Direct link to 6-SDDMM">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="61-分层-1维-tiling">6.1-分层 1维 Tiling<a href="#61-分层-1维-tiling" class="hash-link" aria-label="Direct link to 6.1-分层 1维 Tiling" title="Direct link to 6.1-分层 1维 Tiling">​</a></h3>
<p>我们对SDDMM使用与SpMM相同的一维Tiling方案，但有两个主要区别。</p>
<ul>
<li>首先，我们<strong>将线程块映射到连续非零值的一维条带，而不是输出的一维区域</strong>。<!-- -->
<ul>
<li>由于输出是稀疏的，这确保了线程块之间更好的工作分配，并且实现起来更简单。因为每行的非零值数量无法在不检查稀疏矩阵的情况下推断出来，所以我们启动了可能需要的最大线程块数量。在启动时，每个线程块计算是否有工作需要完成，如果不需要则提前返回。一种替代方法是使用动态并行。然而，我们在基准测试中没有观察到启动额外线程块的显著开销。对于目标为非常高稀疏度问题的SDDMM，动态并行可能会导致更好的性能。</li>
</ul>
</li>
<li>我们工作分解的第二个区别是由于需要对右操作数进行转置计算。<!-- -->
<ul>
<li>由于稠密矩阵以行主序布局存储，天真地在各个线程之间划分输出会导致对右矩阵的间隔且未合并的内存访问。为了避免这个问题，我们修改了方案，使得<strong>映射到输出tiling的每个线程计算该tiling所有输出的部分结果。然后，我们使用warp shuffle指令在这些线程之间进行归约，以计算每个线程的最终结果</strong>。</li>
<li>这种方法的一个替代方案是在计算之前对从右矩阵加载的值在共享内存中进行转置。虽然这样每个线程使用的寄存器会更少，但这将使共享内存的使用量翻倍。在Nvidia Volta GPU上，共享内存和L1缓存使用相同的存储。因此，使用更多共享内存会减少L1缓存的大小。对于这些内核，我们发现L1缓存容量对性能很重要，因此决定不进行显式的共享内存转置。</li>
</ul>
</li>
</ul>
<p>📒：对于SPMM，将warp映射的依据是结果矩阵，因为结果矩阵是稠密的，并不需要提前预测非零元的位置。对于SDDMM，映射的依据是非零元，因为结果矩阵是稀疏的，提前预测非 零元的位置，会引入额外的开销。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="62-向量化内存操作">6.2-向量化内存操作<a href="#62-向量化内存操作" class="hash-link" aria-label="Direct link to 6.2-向量化内存操作" title="Direct link to 6.2-向量化内存操作">​</a></h3>
<p>因为两个输入都是稠密的，因此在内维度可以被向量宽度整除的SDDMM问题中使用向量加载/存储是微不足道的。对于所有问题，我们在稀疏矩阵上使用标量加载/存储。这些操作仅在内核的开始和结束时发生，并不会显著影响性能。为了在更广泛的问题上启用向量加载/存储，我们使用subwarps处理输出tiles，如在SpMM的上下文中所解释的。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="63-实现细节">6.3-实现细节<a href="#63-实现细节" class="hash-link" aria-label="Direct link to 6.3-实现细节" title="Direct link to 6.3-实现细节">​</a></h3>
<p>虽然我们确实使用subwarp tiling来使向量内存指令能够应用于更广泛的问题，但由于所有要计算的点积长度相等，SDDMM中的负载平衡并不是特别关键。此外，深度神经网络中的问题通常具有可以被SIMT宽度整除的点积长度，这使得有效的余量处理在SDDMM中不如在SpMM中那么关键。对于SDDMM的余量计算，我们使用与主循环相同的循环结构，并且不对循环进行拆分优化，以启用广泛的共享内存加载。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-experiments">7-Experiments<a href="#7-experiments" class="hash-link" aria-label="Direct link to 7-Experiments" title="Direct link to 7-Experiments">​</a></h2>
<p>本节提供了我们SpMM和SDDMM内核的实证结果和分析。对于SpMM，我们使用了一种内核选择启发式方法，选择n维tile大小为N，向上取整为2的幂，最大为64。对于SDDMM，我们使用n维tile大小为32。对于这两个内核，我们使用了可能的最宽向量内存操作。所有基准测试均在CUDA 10.1下进行。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="71-内核测试">7.1-内核测试<a href="#71-内核测试" class="hash-link" aria-label="Direct link to 7.1-内核测试" title="Direct link to 7.1-内核测试">​</a></h3>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="711-稀疏矩阵数据集">7.1.1-稀疏矩阵数据集<a href="#711-稀疏矩阵数据集" class="hash-link" aria-label="Direct link to 7.1.1-稀疏矩阵数据集" title="Direct link to 7.1.1-稀疏矩阵数据集">​</a></h4>
<p>我们通过在深度神经网络中提取的稀疏矩阵数据集上进行基准测试，评估了我们提出的 <strong>SpMM</strong> 和 <strong>SDDMM</strong> 内核的性能。在数据集中，我们对 <strong>3,012</strong> 个稀疏矩阵分别使用 <strong>训练（training）</strong> 和 <strong>推理（inference）</strong> 的批量大小（batch size）进行测试。对于 <strong>SDDMM</strong>，我们测试了计算<strong>稀疏权重矩阵梯度</strong>相关的问题。对于 <strong>ResNet-50</strong> 中的卷积操作，我们采用 <strong>im2col</strong> 转换将输入数据转换为矩阵形式，并随后应用 <strong>SpMM 或 SDDMM</strong> 进行计算。在基准测试中，我们未将 <strong>im2col 转换时间</strong> 计入测试结果。此外，为了启用 <strong>向量化内存指令（vector memory instructions）</strong>，对于 <strong>ResNet-50 推理批量大小（inference batch size）</strong> 的测试，我们将批量维度填充至最接近的 <strong>4 的倍数</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218165936.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>所有基准测试均在 <strong>Nvidia V100 GPU</strong> 上进行。我们分别使用 <strong>Nvidia cuSPARSE</strong> 的 <code>cusparseSpMM</code> 和 <code>cusparseConstrainedGeMM</code> 作为 <strong>SpMM 和 SDDMM</strong> 测试的基线（baseline）。在 cuSPARSE 实现中，<strong>稠密矩阵</strong> 采用 <strong>列主序（column-major）</strong> 存储格式，而<strong>稀疏矩阵</strong> 采用 <strong>CSR（Compressed Sparse Row）格式</strong>。由于 <code>cusparseConstrainedGeMM</code> 不支持 <strong>右侧操作数的转置</strong>，我们使用 <strong>cuBLAS</strong> 进行显式转置，并将转置时间计入基准测试结果。所有测试均在 <strong>单个 Nvidia V100 GPU</strong> 上运行，测试结果在 <strong>图 9</strong> 中展示，测试统计数据在 <strong>表 I</strong> 中给出。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218164505.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="2"> 在我们的稀疏矩阵数据集上进行的基准测试，数据来自深度神经网络。运行时间（左侧y轴）和吞吐量（右侧y轴）随着每个内核和精度的问题规模增加而绘制。基准测试在Nvidia V100 GPU上进行。左上：单精度下的SpMM基准测试。在所有问题中，我们的方法实现了3.58倍的几何平均加速和14.2倍的峰值加速，超越Nvidia cuSPARSE。左下：单精度下的SDDMM基准测试。在所有问题中，我们的方法实现了2.19倍的几何平均加速和6.58倍的峰值加速，超越Nvidia cuSPARSE。右侧：混合精度下的SpMM基准测试，使用16位数据和32位计算。在所有问题中，我们的方法实现了5.97倍的几何平均加速和297.5倍的峰值加速，超越Nvidia cuSPARSE。 </font> </center></p>
<p>在所有测试中，我们的 <strong>SpMM</strong> 和 <strong>SDDMM</strong> 内核相比 <strong>Nvidia cuSPARSE</strong> 展现出<strong>显著的性能优势</strong>：</p>
<ul>
<li><strong>单精度（single-precision）SpMM</strong>：<!-- -->
<ul>
<li><strong>几何平均加速比（geometric mean speedup）</strong> 达到 <strong>3.58×</strong>。</li>
<li><strong>峰值性能</strong> 达到 <strong>4.29 TFLOPs</strong>，相当于 <strong>单精度计算峰值性能的 27.3%</strong>。</li>
<li><strong>在 99.75% 的测试问题上优于 cuSPARSE</strong>。</li>
</ul>
</li>
<li><strong>单精度 SDDMM</strong>：<!-- -->
<ul>
<li><strong>几何平均加速比</strong> 达到 <strong>2.19×</strong>。</li>
<li><strong>峰值性能</strong> 达到 <strong>4.11 TFLOPs</strong>，相当于 <strong>单精度计算峰值性能的 26.2%</strong>。</li>
<li><strong>在 93.34% 的测试问题上优于 cuSPARSE</strong>。</li>
</ul>
</li>
<li><strong>混合精度（mixed-precision）SpMM</strong>：<!-- -->
<ul>
<li><strong>几何平均加速比</strong> 达到 <strong>5.97×</strong>，<strong>峰值吞吐量</strong> 达 <strong>5.57 TFLOPs</strong>。</li>
<li>我们的 <strong>SpMM 内核</strong> 使用 <strong>16-bit 整数（16-bit integers）</strong> 作为稀疏矩阵的元数据，而 <strong>cuSPARSE 仅支持 32-bit 索引</strong>。我们推测这部分优化<strong>进一步拉开了性能差距</strong>。</li>
<li><strong>在 99.7% 的测试问题上优于 cuSPARSE</strong>。
此外，我们发现 <strong>cuSPARSE 的混合精度 SpMM</strong> 在某些问题上表现不稳定，<strong>相较于我们的内核，性能下降幅度可高达 297.5×</strong>。</li>
</ul>
</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="712-稀疏rnn">7.1.2-稀疏RNN<a href="#712-稀疏rnn" class="hash-link" aria-label="Direct link to 7.1.2-稀疏RNN" title="Direct link to 7.1.2-稀疏RNN">​</a></h4>
<p>本节评估了我们的内核相对于最近提出的技术的性能。由提供的SpMM内核仅支持批量大小为32的可被整除的问题。编写了SpMM和SDDMM内核，分别用于批量大小为32和128，并且还要求稀疏矩阵中的行数为256的倍数。考虑到这些限制，我们选择在来自<strong>循环神经网络的问题数据集</strong>上进行基准测试，其中由和提供的内核支持的问题配置对深  度神经网络是现实的。我们在带有稀疏权重的RNN、门控循环单元（GRU）和长短期记忆网络（LSTM）问题上对每个内核进行基准测试。我们生成了随机均匀稀疏的稀疏矩阵。我们对状态大小为1k、2k、4k和8k，稀疏度为70%、80%和90%以及批量大小为32和128的问题进行了基准测试。所有基准测试均在单精度的Nvidia V100上执行。我们在基准测试中不包括由的自适应稀疏分块（ASpT）方法所需的预处理步骤的时间。我们对的行拆分内核进行基准测试，因为我们所有的基准测试都超过了作者选择行拆分和非零拆分内核所用的平均行长度阈值。基准测试结果见图10。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218165700.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="2"> 在稀疏递归神经网络问题上的基准测试。每个问题标记为 M/K/N/稀疏性。所有基准测试均在Nvidia V100 GPU上以单精度进行。顶部：SpMM基准测试。与ASpt相比，我们的内核实现了1.56倍的几何平均加速和2.4倍的峰值加速。与合并基础的方法相比，我们的内核实现了1.59倍的几何平均加速和2.15倍的峰值加速。与cuSPARSE相比，我们的内核实现了3.47倍的几何平均加速和4.45倍的峰值加速。底部：SDDMM基准测试。我们的内核在与适应性稀疏切片方法的比较中具有竞争力，平均达到92%的吞吐量，同时使用的内存减少了3倍，并且没有重新排序稀疏矩阵。与cuSPARSE相比，我们的内核实现了2.69倍的几何平均加速和3.51倍的峰值加速。 </font> </center></p>
<p>对于SpMM，我们的方法显著优于其他方法。我们的方法在<strong>MergeSpmm</strong>、<strong>ASpT</strong>和<strong>cuSPARSE</strong>上分别实现了几何均值加速比1.56×、1.59×和3.47×。对于SDDMM，我们的方法明显优于cuSPARSE，并且在性能上与ASpT持平。我们的方法在cuSPARSE上实现了2.69×的几何均值加速，并在平均情况下达到了ASpT的92%吞吐量。</p>
<p><font color="red"><b>虽然ASpT在SDDMM上取得了良好的性能，但它也有一些局限性</b></font>。</p>
<ul>
<li>首先，包括原始CSR矩阵，ASpT需要3倍的内存来存储重新排序的矩阵以及进行块执行所需的元数据。</li>
<li>其次，作者的实现对SpMM和SDDMM问题使用了不同的稀疏矩阵重排序。<!-- -->
<ul>
<li>对于深度学习应用，这意味着相对于稀疏矩阵计算的梯度将与在前向传递中使用的稀疏矩阵顺序不同。为了进行梯度更新或继续反向传播，应用必须在每次训练迭代中付出重新排序稀疏矩阵的成本。</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="72-消融实验">7.2-消融实验<a href="#72-消融实验" class="hash-link" aria-label="Direct link to 7.2-消融实验" title="Direct link to 7.2-消融实验">​</a></h3>
<p>表 II 显示了我们对每个内核所提出的优化的消融研究结果。我们在包含训练和推理批量大小的 DNN 稀疏矩阵数据集上对这两个内核进行了基准测试。我们分别报告每个模型和批量大小的统计数据，以显示每种技术对不同问题空间部分的影响。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218170144.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>通过这些基准测试，我们发现像行调换负载均衡和残量展开这样的技术对不同的问题配置具有鲁棒性，而<strong>向量内存指令在计算密集型问题中显示出较大的好处，而在小问题中则收益较小</strong>。一个异常点是标量内存操作在 SDDMM 中的优越性能。在这些模型中发现的小权重矩阵使得这些问题主要受到占用率的限制，因此受益于我们的标量内核每个线程处理更少的输出。在第 10 节研究的 RNN 问题数据集中，我们观察到我们的向量内核相比于标量变体实现了 2.45 倍的几何平均加速。这些结果表明，更好的内核选择启发式方法可以大大改善性能。除了这些技术之外，我们的内核还得益于有利的数据布局和我们的 1D tiling 方案所实现的高效实现。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="73-应用稀疏transformer">7.3-应用：稀疏Transformer<a href="#73-应用稀疏transformer" class="hash-link" aria-label="Direct link to 7.3-应用：稀疏Transformer" title="Direct link to 7.3-应用：稀疏Transformer">​</a></h3>
<p>Transformer模型是一种流行的序列建模架构，已被用于在机器翻译、语言建模和图像生成等任务上取得最先进的结果。Transformer模型由堆叠的层组成，每层包含一个多头注意力机制，后跟一个小型全连接网络。Transformer中使用的注意力机制接受查询Q、键K和值V，并根据Q和K的相似性计算输入值的加权平均：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mrow><mo fence="true">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">Attention(Q, K, V) = Softmax\left(\frac{QK^T}{\sqrt{d_k}}\right)V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal">tt</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mopen">(</span><span class="mord mathnormal">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.95em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em"><span style="top:-2.2528em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></span>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">d_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span> 是序列中每个元素的特征数。尽管这种架构有效，但 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 计算了序列中每个 token 与其他所有 token 之间的相似性，这要求计算和内存随着序列长度的增加而呈二次增长。<strong>为了解决这个问题，最近的工作探索了在注意力机制中引入稀疏性。</strong> 使用稀疏注意力时，我们计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">QK^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0358em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 输出的一个子集，然后将其与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span> 相乘。<font color="red"><b>对于无结构稀疏性，这些操作相当于一个 SDDMM，后跟一个 SpMM</b></font>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218171526.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="2"> Transformer注意力机制的连接性。上三角部分被屏蔽，以便令标记仅关注于其之前的标记。左侧：密集的全连接注意力。右侧：稀疏注意力，具有一个小的密集带和随机的离对角线的稀疏性，其概率与与对角线的距离成反比。 </font> </center></p>
<ul>
<li>实验设置：<!-- -->
<ul>
<li>我们在 ImageNet-64x64 图像生成数据集上训练了带有稀疏注意力的 Transformer，该数据集的序列长度为 12,288。我们的模型由 3 层组成，每层有 8 个注意力头，每个头的隐藏维度为 1,024，且全连接网络中的滤波器大小为 4,096。我们使用批量大小为 8，在 140,000 个训练步骤中训练模型。<strong>对于我们的稀疏模型，我们在训练过程中模拟稀疏性，并转换为稀疏表示用于基准测试</strong>。尽管我们在进行图像生成任务的训练，但我们注意到这一架构可以应用于其他序列学习任务，如语言建模，而无需修改。</li>
<li>对于我们的稀疏模型，我们生成了具有 256 大小密集带的注意力掩码，沿对角线排列，且非对角线部分随机稀疏，且稀疏性与距离对角线的距离成反比。我们将非对角线稀疏性设置为 95%。稀疏注意力掩码在整个训练过程中保持不变，并且被所有注意力头和层共享。我们模型使用的注意力掩码如图 11 所示。我们还额外编写了一个核函数，计算稀疏矩阵上的 softmax 函数。<strong>对于每个模型，我们在单精度下基准测试前向传递</strong>。</li>
</ul>
</li>
<li>结果与分析：<!-- -->
<ul>
<li>基准测试结果如表 III 所示。在 V100 GPU 上，我们的稀疏模型比标准 Transformer 快 2.09 倍，并且节省了 12.8 倍的内存，同时保持了相同的准确度。我们报告了每维度 以比特为单位的准确度。请注意，较低的每维度位数是理想的。除了在 V100 上的结果外，我们还利用我们的稀疏模型在 Nvidia 1080 上进行了内存节省的基准测试。在一个显著较弱的 GPU 上，我们的稀疏模型能够每秒处理 32,039 个 token，而标准 Transformer 则因内存不足而无法继续。稀疏 Transformer 的内存节省还可以用于训练更大规模的模型，从而提高准确性。</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="74-应用稀疏mobilenet-v1">7.4-应用：稀疏MobileNet V1<a href="#74-应用稀疏mobilenet-v1" class="hash-link" aria-label="Direct link to 7.4-应用：稀疏MobileNet V1" title="Direct link to 7.4-应用：稀疏MobileNet V1">​</a></h3>
<p>MobileNetV1 是一种高效的卷积神经网络，用于计算机视觉任务。虽然最初设计用于资源受限的环境，但 MobileNetV1 在各个平台上都被发现具有很高的效率，并对计算机视觉模型的设计产生了重要影响。</p>
<p>MobileNetV1 由交替的深度卷积和 1×1 卷积组成。每个卷积后面都进行批量归一化和 ReLU 非线性处理。MobileNetV1 定义了一系列模型，其尺寸由宽度乘子控制。这些模型中的 1×1 卷积负责大多数的浮点运算，如果输入数据以 CHW 格式存储，则可以作为矩阵乘法进行计算。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218172439.png" alt="image.png|center|600" class="img_ev3q"></p>
<ul>
<li>实验设置：<!-- -->
<ul>
<li>我们<strong>通过幅度剪枝将稀疏性引入 MobileNetV1 的 1×1 卷积中</strong>。我们将所有模型剪枝到 90% 的稀疏度。我们保留第一层为密集层，因为我们发现该层受限于激活矩阵的带宽，因此从权重稀疏中获得的好处较少。我们在 ImageNet 数据集上使用 32 个加速器训练我们的基线模型，共计 100 个周期。由于我们的目标是在推理成本超过训练成本的情况下实现高效推理，我们将稀疏模型的训练时间增加 10 倍，这有助于稀疏模型在剪枝过程中收敛。</li>
<li>在推理时，批量归一化可以与前面的线性操作融合。我们对所有深度卷积和 1×1 卷积都执行此操作。对于深度卷积，我们编写了支持融合偏置和 ReLU 操作的内核。我们同样将偏置和 ReLU 融合到稀疏的 1×1 卷积中。对于我们的密集基线中的 1×1 卷积，我们使用 Nvidia cuBLAS，该库由高度优化的汇编内核支持。我们还编写了一个融合偏置 + ReLU 的内核，在这些线性操作之后使用。对于我们的稀疏模型，我们使用一个针对四个 1×1 卷积的最佳内核选择器，其中我们的启发式方法并不最佳。对于每个模型，我们在 Nvidia V100 GPU 上以单精度进行推理基准测试，批量大小为 1 张图像，这在自动驾驶等在线推理应用中是常见的。</li>
</ul>
</li>
<li>结果与分析：<!-- -->
<ul>
<li>我们的基准测试结果如图 12 和表 IV 所示。总体来看，我们的稀疏模型在给定准确率的情况下提供了 21-24% 的加速，或者在相同吞吐量下，准确率提高了 1.1%。</li>
<li>由于剪枝导致的准确率损失，我们的稀疏模型比其匹配准确率的密集模型更宽。增加的宽度也增加了非稀疏操作相对于密集基线的成本。<strong>更好的剪枝算法将有助于缓解这个问题，并实现进一步的加速</strong>。此外，在 1×1 卷积剪枝后，深度卷积成为一个显著瓶颈。调整这些内核将为我们的稀疏模型相对于其密集 counterparts 带来进一步的收益。</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="8-related-work">8-Related Work<a href="#8-related-work" class="hash-link" aria-label="Direct link to 8-Related Work" title="Direct link to 8-Related Work">​</a></h2>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="discussion-and-conclusion">Discussion and Conclusion<a href="#discussion-and-conclusion" class="hash-link" aria-label="Direct link to Discussion and Conclusion" title="Direct link to Discussion and Conclusion">​</a></h2>
<p>除了我们讨论的核函数外，训练深度神经网络（DNNs）需要计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup><mi>B</mi><mo>⇒</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A^T B \Rightarrow C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 是稀疏矩阵的转置。对于 CSR 矩阵而言，将转置操作直接融合到 SpMM 中是困难的。然而，在 DNN 训练过程中，可以在稀疏矩阵拓扑更新时缓存 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 的行偏移量和列索引，并通过矩阵值的 argsort 操作执行转置。</p>
<p>另一种稀疏矩阵格式是一个有趣的方向，可以支持转置和非转置计算 。</p>
<p>在大规模问题中，我们的核函数的性能受限于共享内存带宽。缓解这一瓶颈的一个方向是重用从右输入矩阵加载的值，使其可被左输入矩阵的多行共享。</p>
<p>尽管我们的核函数非常高效，但它们无法利用专用的矩阵乘法硬件 。对于非结构化稀疏性，通过在共享内存中解压缩稀疏块可能使得这些运算可用。硬件的新进展可能会进一步支持这一点 。尽管会导致模型质量下降，但仍然可以利用该硬件来支持向量和块稀疏性。</p>
<p>在本研究中，我们展示了深度神经网络中的稀疏矩阵具有有利的特性，可用于加速计算。基于这一见解，我们设计了专门针对深度学习应用的高性能 SpMM 和 SDDMM 核函数。利用我们的核函数，我们展示了稀疏 Transformer 和 MobileNet 模型，分别实现了 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.2</mn></mrow><annotation encoding="application/x-tex">1.2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1.2</span></span></span></span>–<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2.1</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">2.1\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">2.1</span><span class="mord">×</span></span></span></span> 的加速，并在不牺牲精度的情况下，实现了高达 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12.8</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">12.8\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">12.8</span><span class="mord">×</span></span></span></span> 的内存节省。我们希望这些发现能促进深度学习框架对稀疏性的更好支持，并更 广泛地推动稀疏性在深度学习中的应用。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/paper_notes/2-稀疏矩阵计算/2_SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/稀疏矩阵计算/SpMM/SpInfer/阅读笔记"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">阅读笔记</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/稀疏矩阵计算/SpMM/TC-GNN/阅读笔记"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">阅读笔记</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#0-abstract" class="table-of-contents__link toc-highlight">0-Abstract</a></li><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1-Introduction</a></li><li><a href="#2-sparse-matrices-in-deep-learning" class="table-of-contents__link toc-highlight">2-Sparse Matrices in Deep Learning</a></li><li><a href="#3-gpu-background" class="table-of-contents__link toc-highlight">3-GPU Background</a></li><li><a href="#4-sparse-matrix-computation" class="table-of-contents__link toc-highlight">4-Sparse Matrix Computation</a><ul><li><a href="#41-spmm" class="table-of-contents__link toc-highlight">4.1-SPMM</a></li><li><a href="#42-sddmm" class="table-of-contents__link toc-highlight">4.2-SDDMM</a></li><li><a href="#43-数据组织形式" class="table-of-contents__link toc-highlight">4.3-数据组织形式</a></li></ul></li><li><a href="#5-spmm-design" class="table-of-contents__link toc-highlight">5-SpMM Design</a><ul><li><a href="#51--分层-1-维-tiling" class="table-of-contents__link toc-highlight">5.1- 分层 1-维 Tiling</a></li><li><a href="#52-向量化内存访问" class="table-of-contents__link toc-highlight">5.2-向量化内存访问</a></li><li><a href="#53-row-swizzle-负载均衡" class="table-of-contents__link toc-highlight">5.3 Row Swizzle 负载均衡</a></li><li><a href="#54-实现细节" class="table-of-contents__link toc-highlight">5.4 实现细节</a></li></ul></li><li><a href="#6-sddmm" class="table-of-contents__link toc-highlight">6-SDDMM</a><ul><li><a href="#61-分层-1维-tiling" class="table-of-contents__link toc-highlight">6.1-分层 1维 Tiling</a></li><li><a href="#62-向量化内存操作" class="table-of-contents__link toc-highlight">6.2-向量化内存操作</a></li><li><a href="#63-实现细节" class="table-of-contents__link toc-highlight">6.3-实现细节</a></li></ul></li><li><a href="#7-experiments" class="table-of-contents__link toc-highlight">7-Experiments</a><ul><li><a href="#71-内核测试" class="table-of-contents__link toc-highlight">7.1-内核测试</a></li><li><a href="#72-消融实验" class="table-of-contents__link toc-highlight">7.2-消融实验</a></li><li><a href="#73-应用稀疏transformer" class="table-of-contents__link toc-highlight">7.3-应用：稀疏Transformer</a></li><li><a href="#74-应用稀疏mobilenet-v1" class="table-of-contents__link toc-highlight">7.4-应用：稀疏MobileNet V1</a></li></ul></li><li><a href="#8-related-work" class="table-of-contents__link toc-highlight">8-Related Work</a></li><li><a href="#discussion-and-conclusion" class="table-of-contents__link toc-highlight">Discussion and Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper_notes_intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs_intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>