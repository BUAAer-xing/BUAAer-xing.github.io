<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="pdf"><meta data-rh="true" property="og:description" content="pdf"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"阅读笔记","item":"https://buaaer-xing.github.io/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.98cc3bd4.css">
<script src="/assets/js/runtime~main.b1a1434e.js" defer="defer"></script>
<script src="/assets/js/main.8b44110d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper_notes_intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs_intro">个人博客</a><a class="navbar__item navbar__link" href="/docs/my_papers_intro">发表论文</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper_notes_intro">目录</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">稀疏矩阵计算</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMV/AlphaSparse/论文原件">SpMV</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">SpMM</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记">Acc-SpMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记">FlashSparse</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/FlashSparse/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记">Magicube</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/RoDE/阅读笔记">RoDE</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/SpInfer/阅读笔记">SpInfer</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Sparse GPU kernel for Deep-Learning/阅读笔记">Sparse GPU kernel for Deep-Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/TC-GNN/阅读笔记">TC-GNN</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpMM/z-Sparkle-FPGA/阅读笔记">z-Sparkle-FPGA</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/SpGEMM/IA-SpGEMM/论文原件">SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Stencil/ConvStencil/阅读笔记">Stencil</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/稀疏矩阵计算/Other/HPC加速体系结构中Linpack优化/论文原件">Other</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/TCU相关/RT-GNN/阅读笔记">TCU相关</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/z-模版/论文原件">z-模版</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">稀疏矩阵计算</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">SpMM</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">FlashSparse</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">阅读笔记</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header><p><a href="zotero://open-pdf/library/items/IWNFV8DW" target="_blank" rel="noopener noreferrer">pdf</a></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0-abstract">0-Abstract<a href="#0-abstract" class="hash-link" aria-label="Direct link to 0-Abstract" title="Direct link to 0-Abstract">​</a></h2>
<p>稀疏矩阵-矩阵乘法（SpMM）和采样稠密-稠密矩阵乘法（SDDMM）是科学计算和深度学习中重要的稀疏运算符。张量核心单元（TCUs）通过卓越的计算能力增强现代加速器，这有望将矩阵运算符的性能提升到更高水平。然而，由于无结构稀疏数据的不规则性，在TCUs上提供实际的加速是困难的。</p>
<p>为此，我们提出了FlashSparse，一种新颖的方法，用于弥合稀疏工作负载与TCU架构之间的差距。具体而言，<font color="red"><b>FlashSparse通过一种新颖的交换-转置矩阵乘法策略，最小化TCUs上SpMM和SDDMM的稀疏粒度。得益于最小的稀疏粒度，计算冗余显著减少，同时TCUs的计算能力得到了充分利用</b></font>。此外，FlashSparse配备了一种内存高效的线程映射策略，以实现<strong>合并数据访问</strong>，并使用一种<strong>稀疏矩阵存储格式以节省内存占用</strong>。</p>
<p>针对H100和RTX 4090 GPU的大量实验结果表明，FlashSparse为稀疏矩阵乘法设定了新的最先进水平（几何平均速度提升5.5倍，相比DTC-SpMM和3.22倍，相比RoDe）。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction">​</a></h2>
<p>稀疏矩阵-矩阵乘法（SpMM）和采样稠密-稠密矩阵乘法（SDDMM）是用于各个领域的两种主要稀疏运算符，如科学计算和图神经网络（GNN）。例如，在GCN中，邻居节点的特征聚合（即图卷积）可以计算为SpMM，而在AGNN和GAT中，图节点之间的注意力可以计算为SDDMM。由于这些稀疏运算符常常导致性能瓶颈，SpMM和SDDMM在GPU上的加速研究已广泛开展。</p>
<p>一类研究工作集中<strong>在GPU CUDA核心上的稀疏运算符加速</strong>。Gale等人提出了<font color="red"><b>Sputnik</b></font>，一种一维平铺方案，用于分层分解稀疏计算并映射到CUDA核心。这个平铺方案大大提高了数据局部性和占用率。RoDe是当前在CUDA核心上最新的工作，旨在解决Sputnik中的负载不均匀问题。<font color="red"><b>RoDe</b></font>首先将稀疏矩阵分为长行和短行。长行进一步划分为更细粒度的组。这种负载平衡方法增强了并发性，特别是针对极度不均匀分布的稀疏矩阵。</p>
<p>另一方面，最近出现的张量核心单元（TCUs）在现代GPU上占据了主要的计算能力（远高于CUDA核心）。TCUs首次是在NVIDIA Volta GPU中引入，以加速矩阵乘法和累加（MMA）操作。TCUs已被广泛应用于加速科学计算和深度学习工作负载，但<strong>主要用于稠密矩阵操作或结构化稀疏矩阵操作</strong>。例如，<code>cuSPARSELt</code>利用TCUs上原生支持的稀疏性实现了与稠密对应物相比的双峰性能。但它对稀疏模式施加了严格的约束（即2:4结构稀疏），稀疏比率限制为50%，这限制了其可用性。</p>
<hr>
<p>结构化稀疏：<font color="red"><b>NVIDIA的2:4剪枝方案</b></font> <a href="https://docs.nvidia.com/cuda/cusparselt/release_notes.html" target="_blank" rel="noopener noreferrer">URL</a></p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218210108.png" alt="image.png|center|600" class="img_ev3q"></p>
<hr>
<p>然而，许多实际应用中的稀疏矩阵展现出高稀疏率（例如，&gt;99%）和非结构化特征，这与TCUs原生支持的结构化稀疏性相差甚远。<strong>利用TCUs加速这些稀疏运算符的主要挑战在于稀疏工作负载与TCU架构之间的不匹配</strong>。一个简单的实现可能在由MMA指令支持的操作数形状的粒度（例如，16×8）下识别稀疏矩阵中的非零块，但这会导致严重的资源浪费，因为这些块中的大多数值都是零。几项研究工作已经投入到设计更高效的稀疏矩阵存储格式和内核优化，以改善资 源利用率。例如，<strong>TC-GNN和最新的DTC-SpMM识别稀疏矩阵中的16×1非零向量，然后将这些向量连接成TCUs指令（MMA或WMMA）支持的块形状。因此，所有零向量从计算中被排除，导致更高的利用率。</strong> 然而，TC-GNN和DTC-SpMM的设计理念要求非零向量大小为16×1，这仍然过大而无法高效，因为非零向量中很大一部分值为零，导致计算能力的浪费。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218210701.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 在SpMM中，16x1和8x1非零向量大小下的MMA调用次数。请注意，IGB-large使用的单位为千万，以便于清晰展示。 </font> </center></p>
<p>为此，我们提出了一种新颖的方法，FlashSparse，它在稀疏工作负载和TCU架构之间架起了桥梁。通过精巧的算法设计和高度优化的实现，<strong>FlashSparse可以将非零向量的粒度最小化到8×1。注意，FlashSparse中较小的向量大小并不是通过牺牲TCU的计算能力来实现的，而是通过复杂的硬件-软件协同设计实现的</strong>。在图1中，我们比较了对于从图数据生成的稀疏矩阵，使用不同向量大小（在TC-GNN和DTC-SpMM中为16×1，在FlashSparse中为8×1）时，SpMM操作的MMA调用次数。稠密矩阵的列数为16。我们观察到，与16×1相比，8×1向量大小可以平均减少43%的MMA调用次数，这可以直接转化为TCU上稀疏操作的计算和数据访问成本显著降低。</p>
<p>我们的主要贡献是：</p>
<ul>
<li>我们识别出使用TCUs加速稀疏运算的最新工作中性能限制的关键因素，即算法设计导致的大型非零向量大小所引起的计算和数据访问的高冗余。</li>
<li>我们提出了FlashSparse，通过一种新颖的交换-转置MMA计算策略，将SpMM和SDDMM的非零向量粒度最小化至8×1。</li>
<li>在以8×1向量大小实现稀疏核心时，FlashSparse采用了一种内存高效的线程映射策略，以实现合并数据访问，从而显著减少了内存事务。</li>
<li>在H100和RTX4090 GPU上的大量实验表明，FlashSparse为稀疏核心（例如，在515个不同稀疏矩阵上，几何均值加速比为5.5倍，最高可达25.26倍，相较于DTC-SpMM）和端到端GNN应用（例如，几何均值加速比为1.79倍，最高可达2.83倍，相较于最新版本的DGL）设定了新的最先进水平。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-background-and-motivation">2-Background and Motivation<a href="#2-background-and-motivation" class="hash-link" aria-label="Direct link to 2-Background and Motivation" title="Direct link to 2-Background and Motivation">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-tcu">2.1-TCU<a href="#21-tcu" class="hash-link" aria-label="Direct link to 2.1-TCU" title="Direct link to 2.1-TCU">​</a></h3>
<p>Tensor Cores是现代GPU中专门的计算单元，用于加速矩阵乘法和累加（MMA）操作。与CUDA核心相比，TCU在MMA方面提供了更强大的计算能力。为了在TCU上编程，CUDA提供了两个用于矩阵乘法和累加的warp级API，包括WMMA（C++ API）和MMA（低级准汇编）。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218211322.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>请注意，在CUDA中，线程以warp为单位调度，每个warp有32个线程。如表1所示，两个API支持不同的操作数形状。<code>WMMA-TF32</code>在<font color="red"><b>TC-GNN</b></font>中使用，而<code>MMA-TF32</code>在<font color="red"><b>DTC-SpMM</b></font>中使用。与WMMA相比，MMA指令使得稀疏操作符的矩阵操作更加细粒度和灵活。TC-GNN使用m16n16k8的WMMA进行TF32，而DTC-SpMM采用m16n8k8的MMA进行TF32。在FlashSparse中，我们利用m16n8k4的MMA进行TF32  ，以及m16n8k8的MMA进行FP16。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-在tcus上的稀疏操作">2.2-在TCUs上的稀疏操作<a href="#22-在tcus上的稀疏操作" class="hash-link" aria-label="Direct link to 2.2-在TCUs上的稀疏操作" title="Direct link to 2.2-在TCUs上的稀疏操作">​</a></h3>
<p>我们以在TCU上进行稀疏矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>与密集矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>相乘（SpMM）为例，描述当前非零向量划分和MMA计算的过程。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218213223.png" alt="image.png|center|600" class="img_ev3q"></p>
<blockquote>
<p>[! warning] 换一种SPMM的计算方式是否可以改善呢？？？？</p>
</blockquote>
<p>在当前的尖端技术中，使用FP16精度，MMA要求矩阵形状为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mn>16</mn><mi>n</mi><mn>8</mn><mi>k</mi><mn>8</mn></mrow><annotation encoding="application/x-tex">m16n8k8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">m</span><span class="mord">16</span><span class="mord mathnormal">n</span><span class="mord">8</span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mord">8</span></span></span></span>。如图2(a)所示，原始的稀疏矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>根据<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span>维度（例如16行和1列）划分成多个向量，这些向量用于MMA运算，类似于TC-GNN和DTC-SpMM。矩阵中的每一行非零向量称为一个窗口。任何包含至少一个非零元素的向量都称为非零向量。每<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>（例如8）个非零向量组合形成一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">16\times8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>的TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>，作为MMA的左操作数，如图2(b)所示。注意，稀疏TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>中的空白空间会用零填充。然后，<strong>根据矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>的TC块中的非零向量的列索引，提取<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>（例如8）行长度为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>（例如8）的矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span></strong>，这将形成一个<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8\times8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>的TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>，作为MMA的右操作数。中间结果（如MMA 0和2的输出）会被累积到输出块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span>，其大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">m\times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>（例如<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">16\times8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>）。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="23-非零向量的影响">2.3-非零向量的影响<a href="#23-非零向量的影响" class="hash-link" aria-label="Direct link to 2.3-非零向量的影响" title="Direct link to 2.3-非零向量的影响">​</a></h3>
<p>在上一部分，我们介绍了现有工作（例如，TC-GNN和DTC-SpMM）如何将SpMM适配到TCU中。特别是，它们的算法设计方法要求非零向量的长度等于MMA的m维度（即16），如图2(b)所示。然而，许多现实世界的应用表现出高度的稀疏性和不规则性，这导致16×1的非零向量中的大多数元素都为零。表2比较了使用现实世界数据集时不同向量大小（16×1和8×1）中非零向量中零值的数量。我们可以观察到，当使用16×1向量大小时，非零向量中的零值数量远高于非零值，从5.6倍到11.4倍不等。由于这些零值对MMA的最终结果没有贡献，因此TCU的大部分计算能力被浪费。相反，如果我们简单地将向量大小减小到8×1而不考虑MMA支持的矩阵形状，那么所有数据集中非零向量中零值的数量将显著减少约50%。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250218213447.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>表2。然而，简单地使用更小的向量大小而不考虑TCU上的计算模式是没有意义的，<font color="red"><b>因为非零向量形成的块形状与MMA支持的矩阵形状之间的不匹配直接导致了严重的计算能力浪费</b></font>。因此，尽管更小的向量大小有望减少零值的数量，但将更小的向量大小与TCU计算模式完美匹配是非常具有挑战性的。接下来，我们将展示FlashSparse如何有效地最小化非零向量的大小，同时充分利用TCU的计算能力。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-flashsparse">3-FlashSparse<a href="#3-flashsparse" class="hash-link" aria-label="Direct link to 3-FlashSparse" title="Direct link to 3-FlashSparse">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-概述">3.1-概述<a href="#31-概述" class="hash-link" aria-label="Direct link to 3.1-概述" title="Direct link to 3.1-概述">​</a></h3>
<p>FlashSparse是一种通过实现最小向量粒度来加速TCUs上SpMM和SDDMM的方法。如图3所示，FlashSparse由几个关键组件组成，旨在最大化稀疏操作在TCUs上的性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219160359.png" alt="image.png|center|600" class="img_ev3q"></p>
<p><font color="red"><b>FlashSparse的工作流程涉及两个主要部分：稀疏矩阵转换和交换-转置MMA计算</b></font>。最初，<strong>稀疏矩阵根据向量大小转换为稀疏TC块。这些稀疏TC块随后被转换为针对TCUs优化的内存有效存储格式</strong>。注意，矩阵转换过程利用CUDA在GPU上进行并行处理。对于内核实现，稀疏操作符（SpMM和SDDMM）采用交换-转置MMA计算策略，以实现最小的向量大小8×1。具体而言，交换-转置策略涉及操作数交换、转置访问、转置计算和转置输出的步骤。得益于最小的8×1向量粒度，FlashSparse显著减少了稀疏操作在使用TCUs时的计算冗余和数据访问成本。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-交换转置mma计算">3.2-交换转置MMA计算<a href="#32-交换转置mma计算" class="hash-link" aria-label="Direct link to 3.2-交换转置MMA计算" title="Direct link to 3.2-交换转置MMA计算">​</a></h3>
<p>如上所述，现有工作的向量粒度等于MMA中左操作数的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span>维度。然而，最小的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span>为16，如表1所示，这对于高效计算来说过大。相比之下，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>维度则是8（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span>的一半）。因此，<strong>我们建议利用数学公式<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>×</mo><mi>B</mi><mo>=</mo><mi>C</mi><mo>⇒</mo><msup><mi>B</mi><mi>T</mi></msup><mo>×</mo><msup><mi>A</mi><mi>T</mi></msup><mo>=</mo><msup><mi>C</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A \times B = C \Rightarrow B^T \times A^T = C^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">⇒</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9247em;vertical-align:-0.0833em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>来执行MMA，从而交换操作数并使得向量大小变为较小的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>维度</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219161608.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>在公式1和图4中，我们展示了交换转置MMA计算策略的概览：
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>×</mo><mi>B</mi><mo>=</mo><msup><mrow><mo fence="true">(</mo><msup><mi>B</mi><mi>T</mi></msup><mo>×</mo><msup><mi>A</mi><mi>T</mi></msup><mo fence="true">)</mo></mrow><mi>T</mi></msup><mo>=</mo><msup><mrow><mo fence="true">(</mo><msup><mi>C</mi><mi>T</mi></msup><mo fence="true">)</mo></mrow><mi>T</mi></msup><mo>=</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">A \times B = \left( B^T \times A^T \right)^T = \left( C^T \right)^T = C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.4312em;vertical-align:-0.35em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0812em"><span style="top:-3.3029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.4312em;vertical-align:-0.35em"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size1">)</span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:1.0812em"><span style="top:-3.3029em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span>
其中，TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>是需要从全局内存访问的目标数据块；TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span>是需要写入全局内存的结果；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>B</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">B^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>C</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">C^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>（转置的TC块）是MMA中实际的操作数。通过利用交换转置策略，稀疏TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>被转置为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>来作为MMA中的右操作数（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">k \times n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span></span></span></span>），而密集的TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>则被转置为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>B</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">B^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>来作为左操作数（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">m \times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span>）。因此，可以利用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">n=8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>作为向量大小来分割稀疏矩阵，同时不牺牲MMA的计算能力。然而，在交换转置计算过程中，两个输入操作数需要进行适当的交换和转置。这会导致寄存器中的要求与全局内存中输入和输出矩阵之间的数据布局不匹配。因此，如何高效地将交换转置MMA计算策略整合到SpMM和SDDMM中是一个重要的问题。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="33-spmm实现">3.3-SpMM实现<a href="#33-spmm实现" class="hash-link" aria-label="Direct link to 3.3-SpMM实现" title="Direct link to 3.3-SpMM实现">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219161759.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>在这一节中，我们详细介绍了采用交换转置MMA计算策略的SpMM内核设计。如图5所示，warp中的线程首先加载来自原始矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>的稀疏TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>和来自原始矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>的密集TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>。得益于交换转置MMA计算，FlashSparse中稀疏TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>的形状为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8 \times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>，而不是<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">16 \times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>（当前SOTA），而密集TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>的形状为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>16</mn></mrow><annotation encoding="application/x-tex">8 \times 16</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">16</span></span></span></span>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219162102.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>为了直观展示交换转置MMA计算在FlashSparse中的优势，我们使用图2(a)中的相同稀疏
矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>作为示例来计算SpMM。图6显示，使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">8 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>的向量大小来划分稀疏矩阵只需2次MMA即可完成FlashSparse中的SpMM计算。相比之下，当前的SOTA工作使用<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">16 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>的向量大小，需要4次MMA，如图2(b)所示。正如图6中所示，形状为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">8 \times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>的稀疏TC块<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>比图2(b)中的<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn><mo>×</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">16 \times 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">16</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span>块更加稠密，<strong>这表明<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>8</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">8 \times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">8</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>的向量大小有助于减少稀疏TC块中的零元素数目，从而降低计算冗余</strong>。此外，数据访问成本在图6中也减少了50%。因此，<font color="red"><b>启用较小向量大小的交换转置策略在计算和数据访问效率上都优于当前的SOTA方法</b></font>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219162601.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>此外，实现用于稀疏矩阵乘法（SpMM）的交换与转置MMA策略需要解决数据访问效率的问题。如图4所示，稀疏TC块A的数据布局要求为行主序，而密集TC块B则为列主序。原始稀疏矩阵A可以预存为行主序格式（如3.5节所示）。然而，<font color="red"><b>TC块B是由密集矩阵B的行通过TC块A中非零向量的列索引形成的</b></font>，<strong>这些在内存地址中是非连续的</strong>。因此，高效地将矩阵B的数据加载到寄存器中是具有挑战性的。</p>
<p>如图7 (a)所示，TC块B的数据布局与官方技术文档中所述的MMA左操作数的转置数据布局一致。图7 (b)展示了根据图7 (a)所示数据布局线程与全局内存的直接映射，每个线程需要从全局内存（行主顺序）加载四个FP16精度的元素（即a0、a1、a2和a3）到寄存器。然而，<strong>这四个元素在全局内存中的位置具有较大的<font color="red"><b>步幅</b></font>，导致内存访问效率低</strong>。例如，对于每个元素访问，{T0、T4、...、T28}（一个包含8个线程的组）访问的数据形成一个16字节的数据块，这仍然小于NVIDIA GPU上支持的最小内存事务大小（即32字节）。<font color="red"><b>需要注意的是，NVIDIA GPU支持三种内存事务大小，包括32 字节、64字节和128字节</b></font>。这意味着尽管仅访问了16字节的数据，但必须传输一个32字节的内存事务。因此，图7 (b)所示的直接映射策略需要总共16个内存事务才能从全局内存访问整个TC块B，导致50%的数据移动浪费。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219175022.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>由于图4中TC块B和C的数据布局要求一致，各线程用于计算的数据位置与结果存储位置对齐。这种对齐使我们能够直接在寄存器中交换TC块B的列。因此，<strong>我们提出了一种高效的线程映射策略，以实现合并数据访问，如图7(c)所示。关键思路是对线程需要访问的列进行重排，其有效性在于使每个线程访问的四个FP16元素形成一个2×2块</strong>。例如，在图7(b)中，线程0 (T0)负责访问TC块B的第0列和第8列的四个元素；相对而言，在图7(c)中，T0访问相邻的第0列和第1列的四个元素。在这个2×2块中，每行的两个FP16元素通过FP32数据类型的单个元素进行访问。以{T0, T4,...,T28}（一个由8个线程组成的组）为例，<strong>这8个线程访问的每行中的16个FP16元素可以合并为一个单独的32字节内存事务，符合最小内存事务粒度</strong>。其他线程组在一个warp中也适用。因此，在图7(c)中，访问TC块B的所有元素只需8个32字节内存事务（与图7(b)中的直接映射相比减少了50%），这对于内存密集的稀疏运算符至关重要。此外，最终的输出结果<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>C</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">C^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>仍需转置并存储回全局内存。由于<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>B</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">B^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05017em">B</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>C</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">C^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>在warp中各线程的寄存器中的数据布局相同，因此最终输出结果可以以类似于TC块B的数据访问方式写回全局内存，从而实现高效的合并数据写回。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="34-sddmm的实现">3.4-SDDMM的实现<a href="#34-sddmm的实现" class="hash-link" aria-label="Direct link to 3.4-SDDMM的实现" title="Direct link to 3.4-SDDMM的实现">​</a></h3>
<p>SDDMM是另一种主要的稀疏操作，其中两个输入矩阵是稠密的，而输出矩阵通过采样变为稀疏。在各个领域，<font color="red"><b>来自SDDMM的稀疏输出矩阵通常用作SpMM的输入矩阵</b></font>。例如，在基于注意力的GNN中，通常首先使用SDDMM计算稀疏注意力矩阵，然后与特征矩阵通过SpMM进行聚合。SDDMM的稀疏输出矩阵通常具有很高的稀疏性和不规则性。交换与转置策略也适用于SDDMM，显著减少计算冗余，通过为稀疏输出矩阵启用更小的向量大小。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219175416.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>如图8所示，通过利用交换与转置MMA计算策略，我们的SDDMM内核中的稀疏TC块C是8×16（FlashSparse与TF32和FP16），而不是16×8（SOTA与TF32）。使用更小的向量大小8×1时，稀疏TC块C的稠密性高于使用向量大小16×1时。此外，矩阵A是行优先的，而矩阵B是列优先的，这与交换与转置MMA计算所需的数据布局完美对齐。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219181004.png" alt="image.png|center|400" class="img_ev3q"></p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219180115.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>然而，稀疏 TC 块 A 在 SpMM 中的形状分别为 FP16 的 8×8 和 TF32 的 8×4。因此，如图 9 所示，我们将稀疏 TC 块 C 拆分为 4 个子块进行存储，以适应后续 SpMM 计算的格式（TF32）。此外，交换转置 MMA 计算中输出 C 的数据布局要求为列主序，而 SpMM 中 TC 块 A 的存储格式为行主序（如图 4 所示）。因此，计算每个线程的目标写入位置并不容易。算法 1 负责计算输出矩阵 C 中目标元素的位置（全局内存）。具体而言，我们根据 tid 计算稀疏矩阵 C 中 c0 的目标位置（第 2-8 行）。最后，从目标位置开始，迭代地将 c0、c1、c2 和 c4 写入稀疏矩阵 C（第 9-15 行）。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="35-存储格式">3.5-存储格式<a href="#35-存储格式" class="hash-link" aria-label="Direct link to 3.5-存储格式" title="Direct link to 3.5-存储格式">​</a></h3>
<p>在与稀疏算子协同进行交换和转置的MMA计算时，高效的稀疏矩阵存储格式是必不可少的。在MMA严格的操作数形状限制下，每个窗口中的向量数量应为k的整数倍。现有工作通过填充零向量解决了这个问题，但这导致了高内存开销，特别是对于高度稀疏的矩阵。然而，<strong>我们观察到零向量填充仅发生在每个窗口的最后一个TC块中。通过对内核侧进行模运算，可以确定填充的零向量数量</strong>。因此，我们提出了一种适合TCU且内存高效的存储格式ME-BCRS，它仅存储非零向量，不进行零向量填充。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219184847.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>如图10所示，ME-BCRS利用三个数组表示每个窗口内的稀疏TC块。为了便于说明，我们以2×4的稀疏TC块形状为例。</p>
<ul>
<li><code>RowPointers</code>表示每个行窗口在<code>ColumnIndices</code>中的起始索引。</li>
<li><code>ColumnIndices</code>存储每个稀疏TC块中非零向量的列索引。</li>
<li><code>Values</code>使用稀疏TC块作为步幅，以行主序存储每个稀疏TC块的元素，以满足swapand-transpose MMA中TC块A的数据布局要求。</li>
</ul>
<p>由于ME-BCRS格式不存储这些填充零向量，ME-BCRS中TC块的列维度变化，但不超过k，如图10所示。此外，以<code>RowPointers</code>的内存空间为例，我们只需存储M个行指针（M是稀疏矩阵的行窗口数），而不是填充基方案中的2M。这是因为我们只记录非零向量的信息。因此，我们需要在内核端实现特定的SpMM和SDDMM算法，以计算每个窗口中的最后一个TC块A。</p>
<p>以SpMM为例，warp中的每个线程首先使用模运算计算每个窗口中最后一个TC块A的剩余向量数量。接下来，我们计算当前线程需要访问的最后一个TC块A中的<code>column_offset</code>。如果<code>column_offset</code>大于剩余向量数量，这意味着<code>column_offset</code>所指示的向量属于下一个窗口。在这种情况下，我们将当前线程为TC块设置的寄存器值设为0。否则，这些值需要通过<code>column_offset</code>从全局内存中访问。总体而言，ME-BCRS通过消除填充和高效的内核实现有效减少了稀疏矩阵存储格式的内存占用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-evaluation">4-Evaluation<a href="#4-evaluation" class="hash-link" aria-label="Direct link to 4-Evaluation" title="Direct link to 4-Evaluation">​</a></h2>
<p><strong>基准和平台</strong>：我们<font color="red"><b>将FlashSparse集成到Pytorch框架中以进行性能评估</b></font>。交换和转置功能内置于稀疏内核中（包括SpMM和SDDMM）。我们的实验平台由一台NVIDIA H100 GPU和一台GeForce RTX4090 GPU组成。1）NVIDIA H100 PCIe具有456个Tensor Core单元 和14592个CUDA核心，80 GB显存。2）NVIDIA GeForce RTX4090具有512个Tensor Core单元和16384个CUDA核心，24 GB显存。</p>
<p><strong>基线</strong>：我们将FlashSparse与最新的稀疏操作方法进行比较，这些方法在GPU和端到端框架中表现优异。</p>
<ul>
<li>首先，对于基于CUDA核心的方法：<!-- -->
<ul>
<li><strong>RoDe</strong>，一种基于行分解的方法，用于优化GPU上的SpMM和SDDMM内核。</li>
<li><strong>Sputnik</strong>，一种一维分块和旋转技术，用于解决稀疏内核的负载不平衡问题。</li>
<li><strong>GNNAdvisor</strong>，一个高效的运行时系统，通过引入二维负载管理，加速各种稀疏工作负载。</li>
<li><strong>GE-SpMM</strong>，引入了合并行缓存（CRC）方法用于SpMM，利用GPU共享内存缓存稀疏矩阵行。</li>
<li><strong>cuSPARSE</strong>，是NVIDIA开发的一个库，用于执行高效的稀疏矩阵操作。</li>
</ul>
</li>
<li>对于Tensor Core上的工作：<!-- -->
<ul>
<li><strong>DTC-SpMM</strong>是一种新的方法，对TCU上的一般SpMM进行了系统优化，以加速计算。</li>
<li><strong>TC-GNN</strong>通过在TCU上使用WMMA指令加速GNN训练。</li>
</ul>
</li>
<li>对于端到端的GNN框架：<!-- -->
<ul>
<li><strong>Deep Graph Library（DGL）</strong> 是一个广泛使用且维护良好的GNN框架，支持高性能的稀疏矩阵计算。</li>
<li><strong>PyTorch Geometric（PyG）</strong> 是另一个流行的GNN框架，基于边缘级并行化。</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219190137.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>我们总结了表 3 中所有baseline支持的精度类型。CUDA 核心上的baseline使用 FP32，而 TCU 上的baseline使用 TF32。FlashSparse 在 TCU 上同时支持 TF32 和 FP16。此外，对于可调baseline，在评估中使用其最佳版本。对于 DGL 和 PyG，我  们使用它们最新的开源版本作为强基线。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250219190234.png" alt="image.png|center|600" class="img_ev3q"></p>
<p><strong>数据集</strong>：我们<strong>从SuiteSparse集合中选择稀疏矩阵</strong>，这些矩阵具有超过1万行、1万列和10万个非零元素，这与RoDe中使用的标准一致。由于TC-GNN只能处理平方矩阵，我们最终<font color="red"><b>选择了500个代表性矩阵的子集</b></font>。除了SuiteSparse矩阵，我们还将评估扩展到包括来自GNN的矩阵。我们<font color="red"><b>选择了15个来自现实应用的经典图数据集</b></font>，例如IGB、AmazonProducts（如表4所示）。总体而言，总共使用了515个不同的稀疏矩阵进行评估。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-spmm-评估">4.1-SpMM 评估<a href="#41-spmm-评估" class="hash-link" aria-label="Direct link to 4.1-SpMM 评估" title="Direct link to 4.1-SpMM 评估">​</a></h3>
<p>我们测量了在不同设置下SpMM的性能，N是稠密矩阵B中的列数，包括128和256（与DTC-SpMM一致）。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221171226.png" alt="image.png|center|1000" class="img_ev3q"></p>
<center> <font face="华文宋体" size="3"> H100和RTX4090 GPU上的SpMM性能结果。(a)(c) FlashSparse和基准与cuSPARSE的加速比分布。(b)(d) 对515个矩阵进行测量的吞吐量，N=256。矩阵根据非零元素的数量按升序排序，每个点代表六个连续矩阵的平均GFLOPS。 </font> </center>
<p>图11展示了FlashSparse与基准的加速比分布和吞吐量（GFLOPS）。我们根据行数（十万）将稀疏矩阵分类为两组：小型和大型。正如图11(a)(c)所示，FlashSparse在<code>FP16</code>和<code>TF32</code>精度下的中位加速比（以cuSPARSE为基准）在所有设置  中都优于所有基准。需要注意的是，为了清晰展示基准加速比的分布，我们将FlashSparse的加速比限制在8倍，这意味着FlashSparse的实际中位加速比可能更高。</p>
<p>同时，图11(b)和(d)显示FlashSparse也实现了最高的计算吞吐量。<strong>TC-GNN在非零元素超过500万的矩阵上表现极差</strong>，因此我们将其GFLOPS标记为0。这是因为TCGNN使用16×1的向量粒度，其算法设计需要对内核中稀疏元素进行广泛的位置检查。对于更大的矩阵，这种开销会更加明显。此外，<strong>在RTX4090上，TCU和CUDA核心之间的性能差距大于H100</strong>。因此，在RTX4090上FlashSparse与RoDe之间的吞吐量差距更加明显。总体而言，FlashSparse在RTX4090 GPU上的几何平均吞吐量为<code>FP16</code>精度4888 GFLOPS（最高可达26 TFLOPS），<code>TF32</code>精度2697 GFLOPS（最高可达16 TFLOPS）。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221171828.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>表5展示了图11的加速分布。实验结果表明，在RTX4090 GPU上，FlashSparse相对于DTC-SpMM（TCUs上的SOTA）和RoDe（CUDA核心上的SOTA）分别实现了5.5倍（最高可达25.26倍）和3.22倍（最高可达14.2倍）的几何平均加速。FlashSparse保持最高加速的原因有多个:</p>
<p>首先，<font color="red"><b>TCUs相比于CUDA核心提供了显著更高的峰值计算性能</b></font>。例如，H100 GPU上FP16的TCUs峰值性能是FP32的CUDA核心的30倍。这个卓越的矩阵运算能力凸显了TCUs加速稀疏运算的潜力。<strong>然而，直接将密集计算单元应用于稀疏运算可能导致严重的计算和数据访问冗余</strong>。解决这个问题的关键在于更精细的向量粒度。DTC-SpMM和TC-GNN的向量粒度都限制在16×1，而我们的交换与转置MMA策略使FlashSparse能够以更精细的8×1向量粒度 运行。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221172148.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图12（a）展示了515个稀疏矩阵在FlashSparse（N=128）中完成一次SpMM计算的数据访问成本。数据访问成本是指从内存层次加载数据的成本，没有区分数据来源（来自全局内存或缓存）。如图12（a）所示，与16×1向量大小相比，8×1向量大小可以将数据访问成本减少多达49%（平均35%）。此外，计算成本也相应减少。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-sddmm-评估">4.2-SDDMM 评估<a href="#42-sddmm-评估" class="hash-link" aria-label="Direct link to 4.2-SDDMM 评估" title="Direct link to 4.2-SDDMM 评估">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221172333.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>图13和表6分别展示了SDDMM性能比较和加速分布。N的设置为32和128，与RoDe一致。实验结果表明，FlashSparse的吞吐量和加速非常显著。具体而言，FlashSparse在H100和RTX4090 GPU上相较于最先进的RoDe工作实现了2.92倍（最高可达18.59倍）和2.18倍（最高可达14.93倍）的几何平均SDDMM加速。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221172406.png" alt="image.png|center|400" class="img_ev3q">
此外，TC-GNN性能差的主要原因也是我们之前提到的16×1向量粒度和位置检查的使用。我们还计算了在FlashSparse中完成一次SDDMM计算的数据访问成本（N = 32）。如图12（b）所示，8×1向量粒度相比16×1向量粒度可以将数据访问成本降低多达49%（平均降低28%）。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="43-消融实验">4.3-消融实验<a href="#43-消融实验" class="hash-link" aria-label="Direct link to 4.3-消融实验" title="Direct link to 4.3-消融实验">​</a></h3>
<p>我们在H100和RTX4090 GPU上进行消融研究，以验证我们优化策略的有效性。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="431-交换转置的mma计算策略">4.3.1-交换转置的MMA计算策略<a href="#431-交换转置的mma计算策略" class="hash-link" aria-label="Direct link to 4.3.1-交换转置的MMA计算策略" title="Direct link to 4.3.1-交换转置的MMA计算策略">​</a></h4>
<p>为了验证交换转置策略所实现的8×1向量大小的有效性，我们实现了一个基线版本，使用16×1向量大小（其他与FlashSparse相同）进行性能比较。我们测量了FlashSparse（8×1向量大小）和基线（16×1向量大小）在SpMM和SDDMM中的吞吐量（GFLOPS）。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221172624.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>如图14所示，FlashSparse在8×1向量大小下在所有515个矩阵中均优于16×1。与16×1版本相比，FlashSparse在H100上在SpMM中实现了1.89倍的几何均值加速（最高可达3.44倍），在SDDMM中实现了2.61倍的加速（最高可达3.85倍）。<font color="red"><b>结果表明，我们的交换转置策略所实现的计算和数据访问冗余的减少带来了实际的性能提升。这进一步确认了更细向量大小在提升稀疏算子在TCUs上性能方面的重要性。</b></font></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="432-面向合并数据访问的内存高效线程映射">4.3.2-面向合并数据访问的内存高效线程映射<a href="#432-面向合并数据访问的内存高效线程映射" class="hash-link" aria-label="Direct link to 4.3.2-面向合并数据访问的内存高效线程映射" title="Direct link to 4.3.2-面向合并数据访问的内存高效线程映射">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221172906.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>我们比较了FlashSparse在非合并（直接线程映射）和合并（内存高效线程映射）数据访问模式下在515个稀疏矩阵上的性能。如图15所示，与非合并模式相比，内存高效线程映射策略所实现的合并数据访问在H100上平均获得1.34倍（最高可达2.0倍）的加速，在RTX4090上平均获得1.18倍（最高可达2.0倍）的加速。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="433-me-bcrs存储格式的有效性">4.3.3-ME-BCRS存储格式的有效性<a href="#433-me-bcrs存储格式的有效性" class="hash-link" aria-label="Direct link to 4.3.3-ME-BCRS存储格式的有效性" title="Direct link to 4.3.3-ME-BCRS存储格式的有效性">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221173459.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>我们测试了515个矩阵，以比较ME-BCRS与SR-BCRS（基于零向量填充的方法）的内存占用。如表7所示，ME-BCRS在515个矩阵中平均降低了存储格式占用的内存占比11.72%（最大50.0%），其中336个矩阵实现了超过10%的减少。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="44-端到端应用的性能">4.4 端到端应用<!-- -->:GNNs<!-- -->的性能<a href="#44-端到端应用的性能" class="hash-link" aria-label="Direct link to 44-端到端应用的性能" title="Direct link to 44-端到端应用的性能">​</a></h3>
<p>我们将FlashSparse集成到Pytorch框架中，并选择了两个流行的GNN模型，即GCN和AGNN进行端到端评估。GNN模型主要由特征聚合（稀疏操作）和特征更新过程（密集操作）组成：</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>a</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mtext>Aggregate</mtext><mrow><mo fence="true">(</mo><mrow><mo fence="true">(</mo><msubsup><mi>h</mi><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>e</mi><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo>∣</mo><mi>u</mi><mo>∈</mo><mi>N</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo><mo fence="true">)</mo></mrow><mo>∪</mo><msubsup><mi>h</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">a_v^{(k+1)} = \text{Aggregate}\left( \left(h_u^{(k)}, e_u^{(k)} \mid u \in N(v) \right) \cup h_v^{(k)} \right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em"></span><span class="mord text"><span class="mord">Aggregate</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">∪</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span></span></span></span></span>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi>h</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo>=</mo><mtext>Update</mtext><mrow><mo fence="true">(</mo><msubsup><mi>a</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><mi>W</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">h_v^{(k+1)} = \text{Update}\left(a_v^{(k+1)}, W\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.185em;vertical-align:-0.247em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.8em;vertical-align:-0.65em"></span><span class="mord text"><span class="mord">Update</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size2">)</span></span></span></span></span></span></span>
<p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">u</span></span></span></span> 是来自 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N(v)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mclose">)</span></span></span></span> 的邻居节点；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>h</mi><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">h_u^{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1614em;vertical-align:-0.1166em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.5834em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1166em"><span></span></span></span></span></span></span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>e</mi><mi>u</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">e_u^{(k)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1614em;vertical-align:-0.1166em"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.5834em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">u</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1166em"><span></span></span></span></span></span></span></span></span></span> 是节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span> 在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span> 层的特征向量和边信息；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>a</mi><mi>v</mi><mrow><mo stretchy="false">(</mo><mi>k</mi><mo>+</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">a_v^{(k+1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1614em;vertical-align:-0.1166em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0448em"><span style="top:-2.5834em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03588em">v</span></span></span><span style="top:-3.2198em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1166em"><span></span></span></span></span></span></span></span></span></span> 是节点 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span> 在第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k+1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span> 层的聚合信息；<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">W</span></span></span></span> 是可训练的权重矩阵。GCN 使用 SpMM 运算符聚合邻居节点的特征。另一方面，AGNN 首先使用 SDDMM 运算符为每条边计算注意力值，然后使用 SpMM 运算符聚合节点特征。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221174039.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>图数据集来自不同领域，如表4所示。我们分别将GNN的隐藏层维度设置为128（GCN）和32（AGNN）。<strong>端到端时间包括格式转换时间、模型的前向和反向传播时间，以及使用梯度进行模型更新的时间</strong>。我们选择最新的高性能DGL和PyG版本，以及使用TCUs的最先进的GNN框架TC-GNN进行性能比较。需要注意的是，TC-GNN并没有在AGNN模型中设置softmax层，但softmax层仍占据了端到端时间的一定比例。如图16所示，FlashSparse在GCN和AGNN模型中均优于所有基线。总结图16，与最新版本的DGL相比，FlashSparse在RTX4090 GPU上为GCN实现了1.57倍（最高可达1.8倍）的几何平均加速，为AGNN实现了1.79倍（最高可达2.83倍）的加速。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250221174228.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>此外，为了验证FP16和TF32相较于FP32确保了可比的准确性，我们选择了DGL收集的几个数据集来评估GCN的端到端准确性。<strong>准确率指的是节点分类的Top-1准确率</strong>，与GCN和AGNN中使用的一致。我们训练了300个周期的5层GCN模型。如表8所示，使用TF32和FP16训练的GCN的准确率与使用FP32通过DGL和PyG训练的GCN相当（没有准确率损失）。此外，我们设计了GPU内核以加速从CSR格式到ME-BCRS格式的转换。<strong>在静态稀疏场景中，预处理只需执行一次。预处理开销仅占端到端GNN运行时间的一小部分，约不到1%</strong>。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-related-work">5-Related Work<a href="#5-related-work" class="hash-link" aria-label="Direct link to 5-Related Work" title="Direct link to 5-Related Work">​</a></h2>
<p>SpMM和SDDMM的优化与加速已经成为广泛研究的主题。首先，<font color="red"><b>Sputnik</b></font>提出了一维Tile方案，用于在处理元素之间分解稀疏计算。在这个方案中，每个线程块计算输出矩阵的一维切分。然而，稀疏矩阵中非零元素的分布是不规则的，导致严重的负载失衡。为了解决这个问题，<font color="red"><b>RoDe</b></font>提出了一种二维策略，通过将稀疏矩阵的行分为规则部分和残余部  分来实现工作负载平衡。此外，RoDe引入了新的负载平衡和细粒度流水线技术以进一步优化。此外，与CUDA核心的编程灵活性不同，TCUs的稀疏加速受到MMA严格数据布局要求的限制。<font color="red"><b>TC-GNN</b></font>提出了SGT技术，将稀疏矩阵划分为非零向量以在TCU上进行计算。然而，目前关于TCU的SOTA工作，<font color="red"><b>TC-GNN</b></font>和<font color="red"><b>DTC-SpMM</b></font>使用16×1向量粒度，仅通过对MMA指令的简单适配。这种算法设计理念给计算和数据访问带来了高冗余，导致TCU计算能力的低利用率。通过复杂的硬件-软件协同设计，Flash-Sparse实现了使用更高效的非零向量大小8×1。与当前的SOTA相比，我们的方法显著降低了计算和数据访问的冗余，因此为TCU上的稀疏操作带来了前所未有的性能。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-conclusion">6-Conclusion<a href="#6-conclusion" class="hash-link" aria-label="Direct link to 6-Conclusion" title="Direct link to 6-Conclusion">​</a></h2>
<p>本文提出了FlashSparse，这是一种新颖的方法，能够实现最小的8×1向量粒度来加速SpMM和SDDMM。其关键创新在于<font color="red"><b>通过交换和转置MMA计算来实现最小向量粒度，从而减少稀疏运算符在TCU上的计算和数据访问冗余</b></font>。此外，FlashSparse还配备了我们提出的内存高效线程映射策略和内存高效数据格式。我们在H100和RTX4090 GPU上的大量实验表明，FlashSparse为SpMM和SDDMM以及端到端GNN性能设定了新的性能记录。我们的方法同样适用于矩阵维度不均衡的其他TCU架构。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/paper_notes/2-稀疏矩阵计算/2_SpMM/FlashSparse/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Acc-SpMM/阅读笔记"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">阅读笔记</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/稀疏矩阵计算/SpMM/Magicube/阅读笔记"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">阅读笔记</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#0-abstract" class="table-of-contents__link toc-highlight">0-Abstract</a></li><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1-Introduction</a></li><li><a href="#2-background-and-motivation" class="table-of-contents__link toc-highlight">2-Background and Motivation</a><ul><li><a href="#21-tcu" class="table-of-contents__link toc-highlight">2.1-TCU</a></li><li><a href="#22-在tcus上的稀疏操作" class="table-of-contents__link toc-highlight">2.2-在TCUs上的稀疏操作</a></li><li><a href="#23-非零向量的影响" class="table-of-contents__link toc-highlight">2.3-非零向量的影响</a></li></ul></li><li><a href="#3-flashsparse" class="table-of-contents__link toc-highlight">3-FlashSparse</a><ul><li><a href="#31-概述" class="table-of-contents__link toc-highlight">3.1-概述</a></li><li><a href="#32-交换转置mma计算" class="table-of-contents__link toc-highlight">3.2-交换转置MMA计算</a></li><li><a href="#33-spmm实现" class="table-of-contents__link toc-highlight">3.3-SpMM实现</a></li><li><a href="#34-sddmm的实现" class="table-of-contents__link toc-highlight">3.4-SDDMM的实现</a></li><li><a href="#35-存储格式" class="table-of-contents__link toc-highlight">3.5-存储格式</a></li></ul></li><li><a href="#4-evaluation" class="table-of-contents__link toc-highlight">4-Evaluation</a><ul><li><a href="#41-spmm-评估" class="table-of-contents__link toc-highlight">4.1-SpMM 评估</a></li><li><a href="#42-sddmm-评估" class="table-of-contents__link toc-highlight">4.2-SDDMM 评估</a></li><li><a href="#43-消融实验" class="table-of-contents__link toc-highlight">4.3-消融实验</a></li><li><a href="#44-端到端应用的性能" class="table-of-contents__link toc-highlight">4.4 端到端应用的性能</a></li></ul></li><li><a href="#5-related-work" class="table-of-contents__link toc-highlight">5-Related Work</a></li><li><a href="#6-conclusion" class="table-of-contents__link toc-highlight">6-Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper_notes_intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs_intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>