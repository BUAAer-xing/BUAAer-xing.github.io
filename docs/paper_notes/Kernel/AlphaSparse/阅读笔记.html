<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/Kernel/AlphaSparse/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/Kernel/AlphaSparse/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="文章笔记提前梳理"><meta data-rh="true" property="og:description" content="文章笔记提前梳理"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/AlphaSparse/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/AlphaSparse/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/AlphaSparse/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.0287982b.css">
<script src="/assets/js/runtime~main.6e1bc470.js" defer="defer"></script>
<script src="/assets/js/main.c1d9f81a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper-notes-intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs-intro">个人博客</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper-notes-intro">笔记说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/Kernel/intro">Kernel</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/intro">说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/Kernel/AlphaSparse/论文原件">AlphaSparse</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/AlphaSparse/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/CSR5/论文原件">CSR5</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/DASP/论文原件">DASP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件">HPC加速体系结构中Linpack优化</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HiCOO/Z-Morton顺序">HiCOO</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/IA-SpGEMM/论文原件">IA-SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/J-基于 SpMV 的应用程序开销自觉的格式选择/论文原件">J-基于 SpMV 的应用程序开销自觉的格式选择</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/ML-SpMV-thread/论文原件">ML-SpMV-thread</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/MSREP/论文原件">MSREP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Spmv任务自动分配/intro">Spmv任务自动分配</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Tile-GEMM/论文原件">Tile-GEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/z-模版/论文原件">z-模版</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Kernel</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">AlphaSparse</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">阅读笔记</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>阅读笔记</h1>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="文章笔记提前梳理">文章笔记提前梳理<a class="hash-link" aria-label="Direct link to 文章笔记提前梳理" title="Direct link to 文章笔记提前梳理" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#文章笔记提前梳理">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="背景">背景<a class="hash-link" aria-label="Direct link to 背景" title="Direct link to 背景" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#背景">​</a></h3>
<ol>
<li><strong>稀疏矩阵-向量乘法(SpMV)的重要性</strong>：SpMV是一种在许多应用场景中至关重要的计算内核，如气候模拟、计算机图形学、分子动力学、数据分析、机器学习和深度学习等。这些领域对稀疏矩阵的高效计算提出了高要求。</li>
<li><strong>现有解决方案的局限性</strong>：在过去的几十年中，已经提出了许多稀疏矩阵格式和实现方法来压缩内存存储并加速SpMV性能。然而，这些方法<font color="red"><b>通常是基于人工设计的特定格式和优化方法，无法应对日益增长的稀疏矩阵种类和复杂性</b></font>。此外，<font color="red"><b>现有的自动调优器也存在局限性，只能在有限的人工设计格式中进行选择，未能充分发掘潜在的高性能格式</b></font>。</li>
<li><strong>高性能需求</strong>：  尽管已经有许多研究致力于提高SpMV性能，但现有的技术在面对高度不规则的稀疏数据时仍然无法达到预期的高性能。</li>
<li><strong>应对多样化的稀疏矩阵模式</strong>：人工设计的矩阵格式往往只能处理特定的矩阵模式，对未覆盖的模式表现不佳。随着实际应用中稀疏数据和模式的不断涌现，需要新的格式和内核实现来应对未来的需求。</li>
<li><strong>处理不规则稀疏性</strong>：<font color="red"><b>不规则性是当前SpMV程序设计中最大的挑战之一</b></font>，<strong>不规则的行长度分布和位置分布会导致并行性和内存访问效率的巨大挑战</strong>。现有的许多格式无法很好地处理不规则稀疏性，导致性能低下。</li>
<li><strong>突破现有自动调优器的局限性</strong>：<strong>现有的自动调优器仅能在有限的人工设计格式和实现中进行选择，无法探索潜在的高性能组合</strong>。AlphaSparse旨在超越这种局限，通过直接从输入稀疏矩阵的稀疏性模式和硬件架构中生成新的机器设计格式和SpMV内核实现，最大化性能。</li>
</ol>
<p>笔记📒：截止到目前，已经提出许多稀疏矩阵格式和实现方法来压缩存储并加速SpMV性能，然而，这些提出的方法通常是基于人工设计的特定格式和优化方法，无法应对日益增长的稀疏矩阵种类和复杂性。而且，现有的自动调优器也存在局限性，只能在有限的人工设计格式中进行选择，无法充分发掘潜在的高性能格式。随着实际应用中稀疏数据和格式的不断涌现，需要新的格式和内核实现来应对未来的需求。</p>
<p>好句子🍊：不规则性是当前SpMV程序设计中最大的挑战之一，不规则的行长度分布和位置分布会导致并行性和内存访问效率的巨大挑战。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="解决措施">解决措施<a class="hash-link" aria-label="Direct link to 解决措施" title="Direct link to 解决措施" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#解决措施">​</a></h3>
<p>开发一个名为AlphaSparse的系统，该系统通过<font color="red"><b>自动生成稀疏矩阵格式和SpMV内核实现，以应对现有方法的局限性</b></font>。AlphaSparse包括以下几个主要组件和方法：</p>
<ol>
<li><strong>设计器 (Designer)</strong>：<!-- -->
<ul>
<li><strong>操作符图 (Operator Graph)</strong>：作者提出了一种新的模型，称为操作符图，模拟SpMV设计的哲学，探索更大的设计空间。操作符图由连接任意数量的操作符组成，每个操作符表示一种设计策略，能够在三维设计空间内同时“移动”（格式、内核、参数）。</li>
<li><strong>操作符</strong>：设计器将现有的格式和内核实现细化为多个设计策略，称为操作符，这些操作符涵盖了整个SpMV程序的设计过程。</li>
</ul>
</li>
<li><strong>格式和内核生成器 (Format &amp; Kernel Generator)</strong>：<!-- -->
<ul>
<li><strong>矩阵元数据集 (Matrix Metadata Set)</strong>：包括当前矩阵状态的多视角描述，记录矩阵如何被转换。操作符图中的操作符依次修改矩阵元数据集，以生成相应的格式和内核实现。</li>
<li><strong>内核生成器 (Kernel Builder)</strong>：内核生成器基于模板生成内核，包括内核骨架和内核片段。内核片段是操作符在实现阶段的具体表示，通过组合不同的内核片段，生成高性能的SpMV内核代码。</li>
</ul>
</li>
<li><strong>搜索引擎 (Search Engine)</strong>：<!-- -->
<ul>
<li><strong>操作符图搜索</strong>：搜索引擎通过枚举操作符图和选择最佳组合来驱动AlphaSparse。搜索策略包括三个步骤：1) 枚举图结构，2) 粗粒度网格搜索节点（操作符）参数，3) 通过机器学习模型插值到细粒度网格，以减少直接运行SpMV程序的开销。</li>
<li><strong>剪枝策略</strong>：为了减少搜索空间，搜索引擎采用剪枝策略，根据输入矩阵的稀疏性模式和已有的操作符图，对不必要的操作符进行剪枝。</li>
</ul>
</li>
<li><strong>优化器 (Optimizer)</strong>：<!-- -->
<ul>
<li><strong>模型驱动格式压缩 (Model-Driven Format Compression)</strong>：优化器通过将数组类型数据转换为模型并用计算代替内存访问，减少内存访问次数，从而优化内核性能。
通过以上组件和方法，<font color="red"><b>AlphaSparse能够自动生成高性能的SpMV程序，超越现有人工设计格式和传统自动调优器的性能限制</b></font>。文章中还提供了广泛的实验评估，证明了AlphaSparse在处理843个稀疏矩阵时，平均性能提升了3.2倍，最大提升了22.2倍，显著优于五种最先进的人工格式和传统自动调优器。</li>
</ul>
</li>
</ol>
<p>笔记📒：本文提出了AlphaSparse系统，<strong>通过自动生成稀疏矩阵格式和SpMV内核实现，以应对现有方法的局限性</strong>。AlphaSparse由设计器、格式和内核生成器、搜索引擎和优化器组成。设计器使用操作符图模型，将格式和内核实现细化为多个设计策略。格式和内核生成器通过矩阵元数据集和内核生成器生成高性能的SpMV内核代码。搜索引擎通过多级搜索策略和剪枝策略优化操作符图，并利用机器学习模型提高搜索效率。优化器采用模型驱动格式压缩，减少内存访问次数，从而提升内核性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="与现有工作的关系">与现有工作的关系<a class="hash-link" aria-label="Direct link to 与现有工作的关系" title="Direct link to 与现有工作的关系" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#与现有工作的关系">​</a></h3>
<p>为之后论文的发表提供文献支持，同时观察该idea能否作为论文中的组件进行应用。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0-abstract">0-Abstract<a class="hash-link" aria-label="Direct link to 0-Abstract" title="Direct link to 0-Abstract" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#0-abstract">​</a></h2>
<p>稀疏矩阵-向量乘法（SpMV）是许多应用场景中的重要计算内核。已经提出了几十种稀疏矩阵格式和实现方法来压缩内存存储并加速SpMV性能。我们开发了AlphaSparse，它是<font color="red"><b>所有现有工作的一种超集</b></font>，超越了人工设计格式和实现的范围。<font color="red"><b>AlphaSparse完全基于输入稀疏模式和硬件架构的知识，自动创建新的机器设计格式和SpMV内核实现</b></font>。</p>
<p>基于我们提出的<strong>表达SpMV格式和内核设计路径的操作符图</strong>（Operator Graph），AlphaSparse由三个主要组件组成：设计器（Designer）、格式和内核生成器（Format &amp; Kernel Generator）以及搜索引擎（Search Engine）。<font color="red"><b>它以任意稀疏矩阵作为输入，输出高性能的机器设计格式和SpMV实现</b></font>。</p>
<p>通过对来自SuiteSparse矩阵集合的843个矩阵进行广泛评估，AlphaSparse相比五种最先进的人工格式平均实现了3.2倍的性能提升，相比最新的传统自动调优方法平均提升了1.5倍（最高可达2.7倍）。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#1-introduction">​</a></h2>
<p>稀疏矩阵-向量乘法（SpMV，y=Ax）是许多领域中的重要计算内核之一，例如气候模拟、计算机图形学、分子动力学、数据分析、机器学习和深度学习等。在过去的几十年中，已经进行了许多努力来通过提出<strong>稀疏矩阵格式</strong>、利用<strong>各种性能优化方法</strong>和<strong>自动性能调优</strong>（auto-tuning）来改进SpMV性能。</p>
<p>已经提出了几十种稀疏矩阵格式，以在<strong>多核CPU</strong>、<strong>图形处理单元（GPU）</strong>、<strong>Intel Xeon Phi加速器</strong>和<strong>现场可编程门阵列</strong>（FPGA）等现代架构上高效地压缩稀疏矩阵的内存存储。这些格式的设计目标多种多样：<font color="red"><b>减少内存访问</b></font>、<font color="red"><b>改善负载平衡</b></font>、<font color="red"><b>减少GPU线程发散</b></font>等。它们只存储非零元素，而忽略占据稀疏矩阵大部分的零元素。我们将稀疏矩阵格式分为三类：根格式、派生格式和混合格式。</p>
<p>通常认为有四种基本格式或根格式，它们是：</p>
<ul>
<li>坐标格式（COO）</li>
<li>压缩稀疏行格式（CSR）</li>
<li>ELLPACK格式（ELL）</li>
<li>对角线格式（DIA）</li>
</ul>
<p>为了处理更不规则的矩阵、更好的内存压缩或更高性能的稀疏内核，已经提出了许多派生格式。本文<strong>将派生格式定义为基于仅一个根格式手动设计的格式</strong>，例如基于COO的块坐标格式（BCOO）、基于CSR的CSR5格式、基于ELL的切片ELLPACK格式（SELL）等。除了根格式和派生格式，<strong>混合格式灵活地使用多种格式来处理稀疏矩阵的不同部分</strong>。它们可以是根格式和派生格式的混合，例如HYBrid（HYB）、COCKTAIL和扩展压缩稀疏格式（CSX）。</p>
<p>由于稀疏模式的多样性以及输入矩阵特征、架构特性与SpMV性能之间的密切关联，找到一种通用的格式或优化方法是不现实的。因此，已经设计了如SMAT、clSpMV和Zhao等人的<font color="red"><b>SpMV自动调优器</b></font>，<strong>从一组候选人工格式中为给定矩阵选择最合适的格式</strong>。</p>
<p>尽管上述研究已经做出了努力，这个经典但顽固的内核仍然远未达到其可实现的性能，特别是对于高度不规则的稀疏数据。观察到在现  有的最先进研究中，有三个问题阻碍了SpMV实现更高的性能。</p>
<ul>
<li>问题1：<strong>有限的人工实践难以应对不断增长的稀疏矩阵数量</strong>。<!-- -->
<ul>
<li>一般来说，一种矩阵格式只能处理特定的矩阵模式，并且在这种矩阵上表现良好。因此，不在该格式覆盖范围内的模式会导致性能低下。根据我们在SuiteSparse矩阵集合中的实验，主流格式ELL、HYB、ACSR和CSR-Adaptive之间的性能最大值与最小值相差约10倍。</li>
<li>从另一个角度来看，SuiteSparse矩阵集合已逐渐收集了来自91个领域的2893个矩阵。随着实际问题中领域和数据的不断涌现，我们很可能会面对新的稀疏数据和模式，这些都需要新的格式和内核实现。不断为新出现的矩阵设计新的格式对研究人员来说既不高效，也不现实，甚至是不可能的。</li>
</ul>
</li>
<li>问题2：<strong>不规则稀疏性的挑战</strong>。<!-- -->
<ul>
<li><font color="red"><b>不规则性几乎是当前SpMV程序设计中最大的挑战</b></font>。它带来了行长度和行位置的多样化分布，<strong>导致高效并行化和内存访问变得极其困难</strong>。</li>
<li>在本文中，<strong>将行长度方差超过100的稀疏矩阵定义为不规则矩阵</strong>，根据最近的格式研究目标矩阵。不规则矩阵在SuiteSparse矩阵集合中占比超过35%。由于<strong>高度冗余计算</strong>、<strong>不平衡负载</strong>、<strong>内存访问热点</strong>等原因，<font color="red"><b>一般的稀疏矩阵格式无法很好地适应不规则稀疏性</b></font>。尽管一些新格式（如CSR5、ACSR和Merge-based CSR）已经被提出，特别是针对不规则稀疏性，但它们的适用性仍然有限（在评估中仅关注10-20个矩阵）。</li>
</ul>
</li>
<li>问题3：<strong>现有自动调优器的局限性</strong>。<!-- -->
<ul>
<li><font color="red"><b>现有的自动调优器被建模为粗粒度的格式选择器，并且受限于人类经验和实现</b></font>。在图1a中描绘了一小部分人工格式和SpMV实现（分别用蓝色圆圈和方块表示）。每种格式都有一个或多个耦合的内核实现。</li>
<li><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240526200154.png" alt="image.png|center|1000" class="img_ev3q"></li>
<li>(a)传统自动调谐器的搜索空间。(b)原始设计空间中格式选择自动调谐器和 AlphaSparse 的搜索方法。</li>
<li><strong>传统的自动调优器本质上是选择一种格式-内核组合</strong>（用实心蓝线表示），而<font color="green"><b>其他潜在存在但人为未发现的格式、内核实现及其之间的连接（用红色显示的情况1-3）则被忽略</b></font>。以情况1为例，它使用现有的行分组CSR格式，但结合了CSR5的线程级归约和行分组CSR的全局内存归约进行新的实现。这些被忽略的情况使自动调优器错失了潜在的性能提升机会。更糟糕的是，不规则稀疏性的复杂性放大了格式选择器的这一缺点。</li>
</ul>
</li>
</ul>
<p>AlphaSparse通过实现一个最终目标来解决这些问题：<font color="red"><b>创建超越人类实践范围且性能优于人工格式和传统自动调优器的机器设计SpMV程序</b></font>。</p>
<p>本文通过直接<strong>在SpMV程序的原始设计空间中搜索</strong>来实现这一目标，该设计空间包含三个维度：</p>
<ul>
<li>1）<strong>格式</strong>，即数据在内存中的布局；</li>
<li>2）<strong>内核</strong>，即数据的计算方式；</li>
<li>3）<strong>参数</strong>，即前两个维度的定量细节（如图1b所示）。（这里的参数具体指的是什么参数？）</li>
</ul>
<p>设计空间的每个位置都代表一个SpMV程序。</p>
<ul>
<li>蓝色路径展示了传统自动调优器的选择策略，这些调优器只能在三个方向中的任意一个方向上并行 移动。</li>
<li>红色路径：本文的选择策略。<!-- -->
<ul>
<li>相比之下，AlphaSparse提出了一种新的模型，称为<strong>操作符图</strong>（Operator Graph），它模拟SpMV的设计理念，以利用更大的空间。</li>
<li><strong>操作符图</strong>是通过连接任意数量的操作符到设计空间特定位置的“路径”（详见第IV节）。</li>
<li><strong>操作符</strong>是设计空间中的一个向量，<strong>代表SpMV程序的设计策略</strong>，能够在三个维度中同时“移动”。</li>
<li>这种更灵活和集成的模型使AlphaSparse能够实现现有人类工作无法达到的设计，并获得更多的高性能机会。</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240526203145.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>表格I从稀疏性、不规则性和创造性三个角度比较了AlphaSparse与主流相关工作的区别。与人工格式设计和传统SpMV自动调优器相比，AlphaSparse在创造性和不规则性方面展现了其新颖性。它是第一个创建全新机器设计格式及其SpMV实现以追求高性能的工作。一些编译器似乎更灵活，尤其是TACO。然而，其通用的中间表示（IR）隐藏了算法和硬件架构的细节，仅涵盖了对一般稀疏问题的基本优化，错失了许多优化机会。此外，TACO仍然通过利用“层级格式”概念来探索有限的人工格式，这与格式选择器相同。</p>
<p>然而，构建智能AlphaSparse需要克服三个挑战。</p>
<ul>
<li>第一个是<strong>更大的搜索空间</strong>。<!-- -->
<ul>
<li>设A为所有已知人工格式的数量，并假设每种格式提供一种独特的格式或内核设计策略。仅比较搜索空间的格式-内核子集，传统自动调优的大小为O(A)，而在包含p个操作符的操作符图中，AlphaSparse的大小理论上为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>A</mi><mi>p</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(A^p)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.02778em">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>。</li>
</ul>
</li>
<li>第二个挑战是<strong>集成建模</strong>。<!-- -->
<ul>
<li>从大量现有工作中提取SpMV的设计策略并将其表达为统一的中间表示（IR）并非易事。</li>
</ul>
</li>
<li>最后一个挑战是<strong>将原始设计空间中的位置投影到三维空间中</strong>
<ul>
<li>以获得相应的SpMV程序。</li>
</ul>
</li>
</ul>
<p>AlphaSparse有三个主要组件来解决这些挑战：<strong>设计器（Designer）、格式和内核生成器（Format &amp; Kernel Generator）以及搜索引擎（Search Engine）</strong>，以实现设计空间的表达、投影和探索。</p>
<p>设计器和格式与内核生成器将操作符图作为输入，生成具有相应内核实现的格式。搜索引擎旨在找到高性能的操作符图。在搜索过程中，可以通过直接运行生成的SpMV程序来获得与操作符图对应的SpMV性能。</p>
<p>本文用超过11万行的C++代码实现了AlphaSparse，这些代码将被发布。尽管本文仅关注SpMV，但AlphaSparse的方法甚至可以通过定义新的对应操作符和后端来适应更多稀疏问题。</p>
<p>本文的主要贡献总结如下：</p>
<ul>
<li>本文首先展示了<strong>现有工作中被忽视的潜在高性能SpMV程序</strong>，并论证了AlphaSparse的必要性和可行性基础（第二节）。</li>
<li>本文开发了AlphaSparse，它<strong>通过输入Matrix Market文件并输出由机器生成的高性能SpMV代码</strong>，使用起来非常方便。<!-- -->
<ul>
<li>AlphaSparse可以被视为高性能稀疏问题领域的AlphaFold，相当于从头预测蛋白质结构，而传统的自动调优器则对应于蛋白质结构预测中的传统模板方法（第三节）。</li>
</ul>
</li>
<li>设计空间通过一种新提出的基于图的建模方法——<font color="red"><b>操作符图</b></font>（第四节）来表达；<strong>通过格式和内核生成器进行投影，生成压缩的数据表示和高性能的实现</strong>（第五节）；并<strong>在AlphaSparse中通过三级搜索和剪枝策略进行探索</strong>（第六节）。</li>
<li>我们在SuiteSparse矩阵集合中的843个大型矩阵上评估了AlphaSparse。<!-- -->
<ul>
<li>AlphaSparse相比五种最先进的人类设计格式，最多可以将SpMV性能提高22.2倍（平均提高3.2倍）。</li>
<li>将AlphaSparse与最新的格式选择器实现进行比较，AlphaSparse的性能提升最多达到2.7倍（平均1.5倍）（第七节）。</li>
</ul>
</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-motivation">2-Motivation<a class="hash-link" aria-label="Direct link to 2-Motivation" title="Direct link to 2-Motivation" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#2-motivation">​</a></h2>
<p>通过两个观察，分别说明了该方法的必要性和可行性。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-观察-1">2.1-观察 1<a class="hash-link" aria-label="Direct link to 2.1-观察 1" title="Direct link to 2.1-观察 1" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#21-观察-1">​</a></h3>
<p><font color="green"><b>人工格式及其稀疏内核算法受到人类经验和狭窄搜索空间的限制，未能发挥出更高的性能潜力</b></font>。新提出的人工稀疏矩阵格式和自动调优器涵盖了越来越多的稀疏模式。然而，人类实践忽略了大量潜在的格式和内核。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240529225331.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 2 AlphaSparse 在矩阵2D27628bjtcai 的格式和内核空间中发现了混合设计 </font> </center>
如图2所示，在SuiteSparse矩阵集合中的矩阵2D_27628_bjtcai上，CSR-Adaptive、行分组CSR和SELL分别达到了39 GFLOPS、58 GFLOPS和61 GFLOPS。通过结合行分组CSR的块策略与CSR-Adaptive的归约策略，混合格式的性能提升至75 GFLOPS。同样，<strong>通过混合所有这些源格式的格式和内核</strong>，性能可以进一步提升至95 GFLOPS。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-观察2">2.2-观察2<a class="hash-link" aria-label="Direct link to 2.2-观察2" title="Direct link to 2.2-观察2" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#22-观察2">​</a></h3>
<p><font color="green"><b>稀疏格式通过共同步骤从源矩阵转换而来，使得通过这些共同步骤的更多组合创建新格式变得可行</b></font>。这一观察结果已经被其他工作所证实 ，尽管他们强调了现有人工格式之间的转换。通常，当设计一种新的人工格式时，转换程序也会从原矩阵中提供。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606205908.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 3 ：将微小稀疏矩阵转换为 CSR、 COO 和 ELL 的步骤 </font> </center>
本文以三种根格式的转换为例，如图3所示。在开始时 ，通过忽略所有的零，原始的输入矩阵被压缩。通过分块每一行中的矩阵，可以获得 CSR 格式。此外，通过在每个块中进一步填充或在每个列中阻塞，可以生成 ELL 或 COO。这四个步骤通常存在于其他格式转换中。因此，通过采取更常见的转换步骤来自动生成甚至创建格式是可行的。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-overview">3-Overview<a class="hash-link" aria-label="Direct link to 3-Overview" title="Direct link to 3-Overview" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#3-overview">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240526200154.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 1 </font> </center>
AlphaSparse 提出了一种集成模型——算子图(Operator Graph)。运算符图描述和探讨了原点的三维设计空间的格式，内核和参数同时与运算符(如图1所示)。<strong>它提供了一个细致的搜索来处理与 SpMV 性能高度相关的稀疏模式所带来的复杂性</strong>。算子统一地表达内核和格式设计的信息，包括它们的参数配置。通过对算子图的转换，不仅可以生成高性能的算子图，而且可以生成新的机器设计的格式和内核。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606212608.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 4 ：AlphaSparse 概述 </font> </center>
AlphaSparse由<font color="red"><b>搜索引擎</b></font>（第VI节）、<font color="red"><b>设计器</b></font>（第IV节）和<font color="red"><b>格式与内核生成器</b></font>（第V节）组成。如图4所示。</p>
<ul>
<li><strong>搜索引擎</strong>首先通过生成图结构和相应的参数来枚举运算符图，在给定的搜索策略下 。枚举的运算符图将被发送到设计器那里。</li>
<li><strong>设计器</strong>按顺序执行这些运算符，以修改矩阵元数据集，其中包括矩阵状态的所有细节。</li>
<li>最后，<strong>格式与内核生成器</strong>根据运算符图和矩阵元数据集<strong>产生内核和格式</strong>，并进行多项优化。
对于特定结构的运算符图，AlphaSparse首先通过直接在粗粒度网格上对每个参数组合的SpMV程序进行性能评估。为了进一步实现低开销参数空间中的详细搜索，AlphaSparse使用<font color="red"><b>轻量级机器学习（ML）成本模型</b></font>将参数插值到一个细粒度网格中。直到基于模拟退火满足停止条件时，搜索过程停止并输出其找到的最佳SpMV代码。</li>
</ul>
<p>AlphaSparse已经提供了高开箱即用性能，并且对顶级用户易于使用。<strong>用户只需输入一个稀疏矩阵的Matrix Market文件，AlphaSparse将输出以特定格式存储的矩阵和核实现</strong>。基本上，除了传统的自动调谐器外，AlphaSparse作为算法研究人员在开发新的SpMV格式和核心时的替代品迈出了重要一步。通常，这种算法工作不仅高度依赖个人灵感，而且需要花费数月甚至数年时间。AlphaSparse只需几小时就能大幅胜过几乎所有人工设计。从这个角度看，AlphaSparse不是传统意义上的在线性能调谐器，而是SpMV算法研究工具或极其优化库生成器，它将焦点从整个算法缩小到特定操作符(s)。生成的代码可以直接在实际应用中调用。本文中关于该论文成果描述展示了其用途。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-designer设计器">4-Designer（设计器）<a class="hash-link" aria-label="Direct link to 4-Designer（设计器）" title="Direct link to 4-Designer（设计器）" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#4-designer设计器">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606213522.png" alt="image.png|center|600" class="img_ev3q">
设计器维护操作图，这是AlphaSparse的关键数据结构。本文率先将现有的格式和内核实现分解为更细的粒度设计策略，并使用它们对SpMV程序进行建模（如表2所示）。作为算子的组合，算子图打开了更广阔的格式和内核设计集成空间。与现有的格式选择器相比，AlphaSparse在性能调优方面具有更高的灵活性，从而在更大的概率下获得优于SpMV代码的性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-1-操作符">4-1 操作符<a class="hash-link" aria-label="Direct link to 4-1 操作符" title="Direct link to 4-1 操作符" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#4-1-操作符">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606214122.png" alt="image.png|center|1000" class="img_ev3q"></p>
<ul>
<li><strong>Converting 转换阶段</strong>
<ul>
<li>ROW(COL)_DIV 操作：将矩阵划分为行或列</li>
<li>SORT操作：按照每行非零元素的数量对行进行降序排列</li>
<li>SORT_SUB操作：在子矩阵中按照每行非零元素的数量对行进行降序排列</li>
<li>BIN操作：根据每行的非零元素的数量将行放入不同的bins中</li>
<li>COMPRESS操作：忽略稀疏矩阵的所有零</li>
</ul>
</li>
<li><strong>Mapping 映射阶段</strong>
<ul>
<li>BMTB(BMW,BMT)_ROW(COL) _BLOCK 操作：在行/列维度中拆分矩阵，每个矩阵都映射到一个线程块/warp/thread</li>
<li>BMT_NNZ_BLOCK 操作：将连续的非零元映射到线程</li>
<li>BMTB(BMW,BMT)_PAD 操作：零填充到：块映射到线程块、块映射到warp、块映射到线程</li>
<li>SORT_BMTB 操作：在块映射到线程块中，块中的每行按照该行非零元素的数量行进行降序排列</li>
</ul>
</li>
<li><strong>Implementing 实现阶段</strong>
<ul>
<li>SET_RESOURCES 操作：设置运行时配置</li>
<li>GMEM_ATOM_RED 操作：将中间结果原子地添加到全局内存</li>
<li>SHMEM_OFFSET_RED 操作：根据行偏移将多行的中间结果移动（还原）到共享内存</li>
<li>SHMEM_TOTAL_RED 操作：合并共享内存中同一行的中间结果</li>
<li>WARP_TOTAL_RED 操作：将每次wrap的所有中间结果合并到一行</li>
<li>WARP_BITMAP_RED 操作：通过位图合并每个wrap的所有中间结果</li>
<li>WARP_SEG_RED 操作：通过分段求和合并每个warp的所有中间结果</li>
<li>THREAD_TOTAL_RED 操作：将每个线程的所有中间结果合并到一行。</li>
<li>THREAD_BITMAP_RED 操作：通过位图合并每个线程的中间结果</li>
</ul>
</li>
</ul>
<p>给定一个稀疏矩阵，本文总结其SpMV程序通常分为三个步骤：</p>
<ol>
<li><strong>定义矩阵的压缩内存布局</strong>（即格式）==&gt; <font color="red"><b>转换阶段</b></font></li>
<li><strong>将其映射（分配）到不同并行级别的硬件单元</strong>  ==&gt; <font color="red"><b>映射阶段</b></font></li>
<li><strong>设计核心实现</strong>，主要是SpMV结果合并策略 ==&gt; <font color="red"><b>实施阶段</b></font></li>
</ol>
<p>每个阶段包括多种设计或优化策略，称为<strong>运算符</strong>。定义运算符是非平凡且具有挑战性的，<strong>需要大量准备工作从现有作品中抽象出优化策略，并验证它们在最终性能中的有效性</strong>。为了原型目的，AlphaSparse目前仅考虑GPU上的运算符。在表II中列出了AlphaSparse中所有运算符。</p>
<p>在SpMV程序整体设计层面上，AlphaSparse通过Operator Graph 的三个阶段覆盖了整个设计过程。在设计策略层面（所谓的运算符），很难获得它们的定量和理论覆盖范围。目前，AlphaSparse已经涵盖了几乎所有高性能流行格式。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606230913.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 5 ：格式生成示例 </font> </center>
上面是运算符图，下面是矩阵元数据集的子集。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="转换阶段">转换阶段<a class="hash-link" aria-label="Direct link to 转换阶段" title="Direct link to 转换阶段" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#转换阶段">​</a></h4>
<p>在转换阶段的运算符定义了稀疏矩阵压缩存储格式。</p>
<ul>
<li>ROW(COL)_DIV 将整个矩阵分成横向或纵向条纹子矩阵，在操作图中分支。每个子矩阵可以在后续设计中单独处理（如图4右上角所示），有助于处理高度不规则的矩阵。</li>
<li>SORT、SORT SUB 和 BIN 根据它们的长度重新排序矩阵行。</li>
<li>COMPRESS 忽略稀疏矩阵的所有零以进行存储。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="映射阶段">映射阶段<a class="hash-link" aria-label="Direct link to 映射阶段" title="Direct link to 映射阶段" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#映射阶段">​</a></h4>
<p>映射阶段始终在COMPRESS运算符之后开始。</p>
<ul>
<li>以<code>_BLOCK</code>为后缀的运算符将矩阵中相邻的非零元素切割成块，并将它们映射到不同级别的并行性。此阶段中的其他运算符进一步调整块内存布局。</li>
<li>以<code>_PAD</code>为后缀的运算符在矩阵特定位置添加零，以获得更规则化索引，提高性能。</li>
<li><code>SORT_BMTB</code>重新排序每个BMTB的行，可以减少排序范围并创造降低填充率的机会。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="实施阶段">实施阶段<a class="hash-link" aria-label="Direct link to 实施阶段" title="Direct link to 实施阶段" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#实施阶段">​</a></h4>
<p>在实施阶段的操作 符与内核实现更相关。除了<code>SET\_RESOURCES</code>之外，所有操作符都以<code>RED</code>为后缀，这是BMTB、BMW或BMT的SpMV内核中间结果的不同合并策略。</p>
<ul>
<li><code>GMEM\_ATOM\_RED</code> 直接且原子地将中间结果添加到全局内存中的向量y。</li>
<li>以<code>SHMEM_</code>为前缀的运算符是在共享内存中进行<strong>线程块级</strong>合并的策略。<!-- -->
<ul>
<li>SHMEM_TOTAL_RED适用于 BMBT 中所有中间结果来自同一行的情况。它将一个线程块的所有中间结果相加得到一个结果。</li>
<li>SHMEM_OffSET_RED 包括类似 CSR 的行偏移量 ，记录 BMBT 中每行的第一个中间结果的位置。它并行地合并每行的中间结果。</li>
</ul>
</li>
<li>由<code>WARP_</code>前缀的三个运算符代表了合并<strong>warp级别</strong>的三种主流策略。<!-- -->
<ul>
<li><code>WARP_TOTAL_RED</code>是CSR-Stream中的经典策略。</li>
<li>对于包含短行和长行的不规则矩阵，<code>WARP_BITMAP_RED</code>和<code>WARP_SEG_RED</code>使用位图和分段求和来按行合并BMW结果。</li>
<li>为了从硬件的底层细节中获得更多优化机会，运算符利用GPU的一系列独特功能。<font color="red"><b>在warp级别操作符中，使用硬件级Warp Shuffle Functions 来实现高性能的归约</b></font>。</li>
</ul>
</li>
<li>以<code>THREAD_</code>为前缀的操作符是<strong>寄存器中线程级别</strong>的归约。<!-- -->
<ul>
<li>THREAD_TOTOAL_RED 类似于其他后缀为TOTAL_RED 的操作符。</li>
<li>THREAD_BITMAP_RED 串行地合并每行结果，使用位图来标记行边界。</li>
</ul>
</li>
</ul>
<p>操作符后面仍然有一个巨大的搜索空间，其中包含其详细参数（图1b中的参数空间），例如排序粒度、结果合并算法的并行性、阻塞大小等。一些从HYB、CSB 等格式派生出来的设计策略对于SpMV性能也至关重要，但尚未得到AlphaSparse的支持。AlphaSparse允许用户自行实现操作符。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-2-操作图">4-2 操作图<a class="hash-link" aria-label="Direct link to 4-2 操作图" title="Direct link to 4-2 操作图" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#4-2-操作图">​</a></h3>
<p><font color="red"><b>运算符图是通过按顺序连接操作符生成的</b></font>。 图5的上半部分显示了一个基本示例。 一个真正高性能的运算符图可能会更深，并且有时包括分支。</p>
<p>操作符之间存在依赖关系。 它们通常源于操作符的语义。 以图5中的运算符图为例，BMT_ROW_BLOCK 和 BMT_PAD 不能跟在 BMTB_ROW_BLOCK 后面 。 因为当数据块已经映射到线程时，在CUDA中无法进一步拆分并映射到线程块作为更高级别并行性 。 用户也可以定义依赖关系以进行搜索修剪。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-formatkernel-generator格式内核生成器">5-Format、Kernel Generator（格式、内核生成器）<a class="hash-link" aria-label="Direct link to 5-Format、Kernel Generator（格式、内核生成器）" title="Direct link to 5-Format、Kernel Generator（格式、内核生成器）" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#5-formatkernel-generator格式内核生成器">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606232415.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>给定一个操作图，可以移动到 SpMV 设计空间的特定位置。为了获得相应的格式和内核实现，<strong>格式和内核生成器将此位置投影到格式、内核和参数空间</strong>。与传统的源代码生成器不同，后者基于静态模板并且只关注内核实现，<strong>格式和内核生成器需要通过两个组件来处理灵活的格式和内核组合</strong>：<font color="red"><b>矩阵元数据集</b></font>和<font color="red"><b>内核构建器</b></font>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="51-矩阵元数据集">5.1-矩阵元数据集<a class="hash-link" aria-label="Direct link to 5.1-矩阵元数据集" title="Direct link to 5.1-矩阵元数据集" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#51-矩阵元数据集">​</a></h3>
<p><strong>矩阵元数据集包括对当前矩阵状态的多角度描述，记录了矩阵如何转换</strong>。它是一个巨大的<font color="red"><b>键值内存数据库</b></font>，其内容用于生成格式和内核。</p>
<p>矩阵元数据集包含基本矩阵信息（矩阵大小、列数和行数、每列和每行的长度）、基本非零信息（父块索引、行索引、列索引）以及分布到不同并行级别的块信息（块大小、第一个非零索引、第一行索引、第一个子块索引）、约简信息（中间结果的行索引等）。</p>
<p>在操作符图中，<strong>操作符通过按顺序修改矩阵元数据集来转换矩阵</strong>。在迭代了操作符图之后，矩阵元数据集将累积包含所有操作符对原始矩阵的影响。</p>
<p>图5下部展示了一个简单的矩阵元数据示例。红色文本表示添加或修改元数据的位置。以行索引和列索引为例。它们由输入矩阵添加，记录非零值的行和列索引，并且操作符BMT_PAD 进一步通过在特定位置（1, 1）添加零元素的索引来修改它们。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-生成存储格式">5.2-生成存储格式<a class="hash-link" aria-label="Direct link to 5.2-生成存储格式" title="Direct link to 5.2-生成存储格式" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#52-生成存储格式">​</a></h3>
<p><strong>所有格式的数组都是通过选择内核所需的元数据从矩阵元数据集中提取出来的</strong>。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606234255.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>在图5中显示的最终格式中，bmtb nz偏移、bmt行偏移和bmtb bmt偏移记录了每个BMT或BMTB中第一个非零子块行的索引。它们由操作符BMT_ROW _BLOCK和BMTB_ROW_BLOCK生成，定义了矩阵如何分配给每个线程和线程块。bmtb的大小是每个BMTB中非零数目的数量，由 BMT_PAD 生成。原始行（由 SORT 生成）和 bmt 行偏移记录了来自非零乘法结果的中间结果的原始行索引，这些对于 GMEM ATOM RED 的规约（在向量 y 中）是必要的。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="53-构建计算内核">5.3-构建计算内核<a class="hash-link" aria-label="Direct link to 5.3-构建计算内核" title="Direct link to 5.3-构建计算内核" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#53-构建计算内核">​</a></h3>
<p>SpMV内核的构建过程包括两个部分：</p>
<ul>
<li><strong>分发</strong>，主要由映射阶段确定。它获取不同并行级别中每个块的元数据，主要包括任务分配和合并策略的信息。</li>
<li><strong>合并</strong>，主要由实现阶段确定。它将矩阵的非零元素与向量元素相乘，并按行归纳合并它们的结果。</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240606235020.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 6 ：通过剪接内核片段生成内核的示例 </font> </center></p>
<p>根据SpMV程序的普遍性，Kernel Builder的模板包括两个关键组件：<font color="red"><b>内核骨架</b></font>和<font color="red"><b>内核片段</b></font>。</p>
<ul>
<li><strong>内核骨架：它是包含多个嵌套循环的根符号</strong>。<!-- -->
<ul>
<li>每个循环遍历分布在不同并行级别（线程块、warp、线程）上的块，其中包括一系列用于内核片段的插槽。</li>
<li>标记为“获取BM*(BMTB、BMT、BMW)元数据”的内核 片段读取同一循环中其他内核片段所需的元数据数组，这构成了存储格式。通过分析数据依赖关系可以轻松自动生成。</li>
<li>为了减少当前中间结果，以“reduction in”为前缀的内核片段由实现阶段中运算符确定。</li>
<li>非正交因素可能出现在不同减少策略的组合中。为解决此问题，需要<strong>预定义称为Adapter 的特殊内核片段</strong>，其中仅包含几个赋值表达式。<!-- -->
<ul>
<li>如图6右侧所示，在线程级别归约（THREAD_TOTAL_RED）产生的中间结果进一步在线程块级别归约（SHMEM_OFFSET_RED）中进行归约处理。前者将其输出放入寄存器组中；后者只接受共享存储器输入，并使得这两种减少策略不能直接连接起来。需要一个Adapter 将结果从寄存器复制到共享存储器以获得可接受布局形式。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240607000146.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 7 ：优化后生成的图5内核的示例 </font> </center></p>
<p>图7显示了图5中显示的运算符图的示例内核。在这种情况下，整个矩阵在行方向上被划分为BMTBs和BMTs。每个线程将其内容减少到一个结果。来自线程的这些结果进一步在全局内存中减少。第3-6行和11-12行获取BMTB和BMT的格式（元数据）数组。第14-18行将每个BMT的非零乘以向量x的元素，并将它们缩小到由临时结果表示的一个寄存器中。第20-21行通过原子加法在全局内存中进一步减少每个线程的中间结果。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="54-优化器">5.4-优化器<a class="hash-link" aria-label="Direct link to 5.4-优化器" title="Direct link to 5.4-优化器" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#54-优化器">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240607001426.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>为了提高内核性能，Kernel Builder 支持一系列优化策略，如删除不必要的代码、组合多个短数据类型的数组等。由于内核优化以前已经得到了很好的研究，因此本文在调优系统中利用了一些最先进的技术。一个突出的优化是<strong>模型驱动的格式压缩</strong> ，它对内存访问优化特别有效。它通过将数组类型的数据(在内存中)转换为模型和用计算代替内存访问来减少内存访问的数量。</p>
<p>如图8所示，名为BMTB_ROW_DIV的操作符将矩阵每64行划分为行带，并将每个行带映射到一个线程块。它向格式中添加了一个名为reduce row offsets的数组，其中包括用于线程块级减少的BMTBs的第一行索引。可以直接从BMTB的索引计算出行偏移量（row offset=64*bid），通过<strong>将数组索引和值拟合到线性模型中来实现这一点</strong>，<font color="green"><b>使得全局内存访问（row offset=reduce row offsets[bid]）变得不必要</b></font>。在手动编写代码时，程序员可以自然地发现数据结构的规律并直接编写优化实现。由于AlphaSparse是完全自动化的，需要明确执行此优化以达到与人工编写代码竞争性能相当。<strong>除了线性函数外，还支持其他函数，例如阶跃函数和周期线性函数。用户还可以扩展假设函数</strong>。与数据分析中常见回归问题不同，<strong>在模型中存在任何错误都会导致SpMV实现不正确。为提高此优化成功率，可以容忍少量错误，并通过添加if语句来单独为模型无法适配的特定数组索引赋值。</strong></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-search-engine搜索引擎">6-Search Engine（搜索引擎）<a class="hash-link" aria-label="Direct link to 6-Search Engine（搜  索引擎）" title="Direct link to 6-Search Engine（搜索引擎）" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#6-search-engine搜索引擎">​</a></h2>
<p><strong>搜索引擎通过枚举操作符图并选择最佳的一个来驱动 AlphaSparse</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240607001542.png" alt="image.png|center|400" class="img_ev3q">
为了处理由参数和操作符图结构组成的庞大搜索空间（作为第一部分详细介绍的挑战），<font color="red"><b>搜索引擎提供了从粗到细的多级搜索。它利用粗粒度搜索的经验，通过机器学习模型加速细粒度搜索</b></font>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="61-操作图搜索">6.1-操作图搜索<a class="hash-link" aria-label="Direct link to 6.1-操作图搜索" title="Direct link to 6.1-操作图搜索" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#61-操作图搜索">​</a></h3>
<p>搜索引擎的搜索策略包括三个步骤（级别）。</p>
<ul>
<li>在第一步中，通过随机选择空操作符并将它们连接到现有操作符图的末尾来枚举图结构。</li>
<li>第二步在粗粒度网格中搜索操作符参数，并通过直接运行相应的SpMV程序获得操作符图的性能。</li>
<li>在第三步中，从第二步得到的测试结果进一步由ML模型插值到细粒度参数网格上。
本文不直接进行细粒度搜索，因为运行SpMV程序的开销非常高，甚至几乎占据了所有搜索开销。相比之下，ML模型的开销可以忽略不计。为了进一步合理地减少SpMV程序执行次数，前两个步骤可以通过模拟退火提前终止。此外，根据我们的经验，我们还将<strong>搜索时间限制为不超过8小时</strong>作为强制终止条件。</li>
</ul>
<p>根据我们的实践，XGBoost 在插值方面表现非常出色，这也得到了TVM的验证。它实现了5% 的平均绝对偏差，甚至比GPU的性能波动还要小。由于架构的内存层次结构，推测内存受限程序的成本模型包括线性决策边界，这适合树状模型。第三步显著减少了参数搜索的开销。假设有一个具有 q 个参数的操作图。将搜索步长减半会使搜索空间增加 2q 倍，最终将搜索时间从几小时增加到几周。<strong>XGBoost 可以通过产生相对可忽略的开销来实现相同效果</strong>。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="52-剪枝">5.2-剪枝<a class="hash-link" aria-label="Direct link to 5.2-剪枝" title="Direct link to 5.2-剪枝" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#52-剪枝">​</a></h3>
<p>尽管AlphaSparse提供了三级搜索以加速搜索过程，但由于AlphaSparse的巨大搜索空间，前两个步骤的开销仍然很昂贵。因此，除了粗粒度参数搜索和模拟退火外，还需要更多的修剪策略。</p>
<p><strong>修剪参数搜索</strong>。 参数指示运算符的可量化细节。 最大的挑战是数组类型参数。 例如，ROW_DIV包括一个数组类型参数，其中包含矩阵在行方向上分割的位置。 假设输入矩阵有105行，则仅此单个参数的搜索空间大小为105！，这是不可能掌握的。 每个运算符中都包含一种或多种参数离散化策略来处理数组类型参数。 参数离散化策略可以减少参数空间，特别是数组类型参数的空间。 在这种情况下，可以使用名为DIV_IN_ROW_LEN_MUTATION 的一种参数离散化策略来划分行长度变异的矩阵。 它将数组类型参数转换为描述此类突变程度的几个整数参数，这些整数可以轻松枚举出来。</p>
<p><strong>图结构的剪枝搜索</strong>。当发现特定的矩阵稀疏模式不需要运算符时，增加了图结构的剪枝策略。例如，具有短行的矩阵不需要尝试运算符来减少长行。用户可以添加他们的修剪策略。AlphaS 解析根据已经存在的图的运算符和输入矩阵的稀疏模式，为剪枝运算符提供了一个禁止列表。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="7--evaluation">7- Evaluation<a class="hash-link" aria-label="Direct link to 7- Evaluation" title="Direct link to 7- Evaluation" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#7--evaluation">​</a></h2>
<p>评估表明，AlphaSparse 在最先进的人工格式和传统自动调优的最新实现中提供了最高的整体性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="71-实验设置">7.1-实验设置<a class="hash-link" aria-label="Direct link to 7.1-实验设置" title="Direct link to 7.1-实验设置" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#71-实验设置">​</a></h3>
<p><strong>平台</strong>：实验在NVIDIA A100和RTX 2080上进行。前者基于安培架构，具有6912个CUDA核心，40GB HBM2内存（1.5TB/s），峰值性能为19.49 TFLOPS。后者基于图灵架构，具有2944个CUDA核心，8GB GDDR6内存（448GB/s），峰值性能为10.07 TFLOPS。我们在实验中使用单精度浮点数值。</p>
<p><strong>测试集</strong>：实验包括来自SuiteSparse矩阵收藏的843个矩阵（其中大多数是不规则的），其特征满足以下三个条件：</p>
<ul>
<li>（1）行数大于9K</li>
<li>（2）非零元素数量在50K和60M之间</li>
<li>（3）没有空行。（因为：这篇文章中提到的机制没有包含处理空行的操作符。）
我们忽略了尺寸极大的矩阵，因为它们难以把握。小型矩阵也被忽略，因为它们不适合GPU。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="72-对比样本">7.2-对比样本<a class="hash-link" aria-label="Direct link to 7.2-对比样本" title="Direct link to 7.2-对比样本" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#72-对比样本">​</a></h3>
<p>基线根据与SpMV的耦合程度分为三种：</p>
<ul>
<li><strong>人工格式</strong>表示手动实现的特殊库。</li>
<li><strong>格式选择器</strong>代表传统的自动调优框架。</li>
<li><strong>张量代数编译器</strong>代表将SpMV视为许多对象之一的更通用编译器。</li>
</ul>
<p><strong>人工格式</strong>：
为了与人工格式进行比较，本文选择了几种性能高且具有不规则特定设计的流行先进格式，如下所示：</p>
<ul>
<li>1）ACSR ，由我们实现，因为迄今为止我们还没有找到其高质量的实现</li>
<li>2）CSR-Adaptive，来自ViennaCL 1.7.1</li>
<li>3）CSR5</li>
<li>4）基于合并的CSR(Merge)</li>
<li>5）HYB，来自cuSPARSE 9.2</li>
</ul>
<p><strong>格式选择器</strong>：
与基于格式选择的传统自动调优原理进行公平比较是不现实的。最先进的自动调优选择器，SMAT(ER)和clSpMV存在历史限制：</p>
<ul>
<li>1）它们仅包含过时的格式，有时无法处理不规则性并且无法利用新GPU功能</li>
<li>2）长时间以来它们没有得到积极维护。
为了进行合理比较，本文实现了一个完美格式选择器（PFS），作为代表最新自动调谐器作为基准。</li>
</ul>
<p><strong>张量代数编译器</strong>：
编译器更注重代码级优化，而不是算法级设计。为了进行更充分的比较，本文将TACO 作为张量代数编译器的基准。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="721-与人工格式的比较">7.2.1-与人工格式的比较<a class="hash-link" aria-label="Direct link to 7.2.1-与人工格式的比较" title="Direct link to 7.2.1-与人工格式的比较" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#721-与人工格式的比较">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240610232904.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 9 不同尺寸矩阵的 SpMV 整体性能 </font> </center>
图9a显示了AlphaSparse和843个矩阵中最先进格式的整体性能。x轴是矩阵大小，我们使用  每秒浮点运算（GFLOPS）来表示性能作为y轴。AlphaSparse在所有人工格式中实现了最高性能。在A100上，AlphaSparse平均获得3.2倍加速，并且在所有人工格式中的最大加速达到22.2倍（在矩阵TSOPF RS b300 c2）。特别地，在ACS、CSR-Adaptive、CSR5、Merge和HYB方面，它分别比这些格式平均快2.3倍、5.7倍、2.0倍、2.0倍和3.9倍。AlphaSparse在全部843个矩阵中表现优于Merge、ACSR、CSR-Adaptive和CSR5，而对于841个矩阵也优于HYB（因为AlphaSparse没有包含HYB的矩阵分解策略）。在RTX 2080上，AlphaSparse平均获得2.0倍加速，并且在某些情况下最大可达8.3倍（例如，在矩阵TSOPF RS b2052 c1）。具体来说，相较于ACSR, CSR-Adaptive, CSR5, Merge 和 HYB ，它分别实现了平均快 2 倍, 23 倍 ,20 倍 ,17 倍 和24 倍 的提升。</p>
<p>Merge和CSR5在所有人工格式中提供了最高的整体性能，因为它们通过将平衡数量的非零元素或行分配给每个线程来受益于线程级负载平衡。CSR-Adaptive的整体性能最低。它在相对较小的矩阵中表现良好，实现更高的并行性。然而，由于放弃寄存器减少，导致其在剩余矩阵上表现最差。ACSR和HYB基于矩阵分解，提供了适度的性能。</p>
<p>在图9a 中，AlphaSparse 在每个矩阵大小中的最大性能组成了一个平尾形状的趋势，用红色虚线表示。作为一种内存受限程序，当矩阵大小不太大时，通过增加内存带宽的占用可以提高 SpMV 的性能。当内存带宽得到充分利用时，性能不会进一步提高。在我们的评估中，只有 AlphaSparse 接近这一趋势。</p>
<p>为了展示输入矩阵如何影响性能，本文取RTX 2080测试结果的样本，并将其分成两部分如图9b所示。选择这个结果范围是因为它显示出明显的上下边界，使得我们容易在中间进行划分。尽管这两部分案例对应相同的矩阵大小，但上半部分（红色）的性能比下半部 分高达5.0×（平均1.4×）。根据进一步观察，我们怀疑<strong>这种性能差距是由两个矩阵特征</strong>引起的。</p>
<ul>
<li>一个是<strong>平均行长度</strong>（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi>n</mi><mi>n</mi><mi>z</mi></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{nnz}{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">nn</span><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>），在上半部分比下半部分高出1.9×。我们推测更高的平均行长度通过增加计算与内存访问之间的比率和减少SpMV程序中需要同步操作的缩减操作比例来提高性能。</li>
<li>另一个是<strong>行方差</strong>（规则程度，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mo>∑</mo><mo stretchy="false">(</mo><mi>r</mi><mi>o</mi><mi>w</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo>−</mo><mfrac><mrow><mi>n</mi><mi>n</mi><mi>z</mi></mrow><mi>n</mi></mfrac><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{\sum(row\_len-\frac{nnz}{n})^2}{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5197em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.1747em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.5508em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mop op-symbol small-op mtight" style="position:relative;top:0em">∑</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">ro</span><span class="mord mathnormal mtight" style="margin-right:0.02691em">w</span><span class="mord mtight" style="margin-right:0.02778em">_</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">n</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6915em"><span style="top:-2.656em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span style="top:-3.2255em"><span class="pstrut" style="height:3em"></span><span class="frac-line mtight" style="border-bottom-width:0.049em"></span></span><span style="top:-3.384em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">nn</span><span class="mord mathnormal mtight" style="margin-right:0.04398em">z</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.344em"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mclose mtight"><span class="mclose mtight">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em"><span style="top:-2.931em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>），在上半部分比下半部分低20×。较低规则度通常可以实现更高的缩减性能、更好地负载平衡和更少计算浪费。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="722-与格式选择器的性能比较">7.2.2-与格式选择器的性能比较<a class="hash-link" aria-label="Direct link to 7.2.2-与格式选择器的性能比较" title="Direct link to 7.2.2-与格式选择器的性能比较" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#722-与格式选择器的性能比较">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240610233911.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图10 A100上 AlphaSparse 加速比在 PFS 上的频率分布 </font> </center>
图10显示了AlphaSparse在A100上相对于PFS的加速比的频率分布。在99.3%的情况下，AlphaSparse的性能更高。在剩余的0.7%矩阵中，AlphaSparse表现较差，因为PFS中一些格式设计策略未包含在AlphaSparse中（详见第VII-H节）。大多数（40.8%）情况下实现了1.2×至1.4×之间的加速。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240610234104.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 11 PFS 上 AlphaSparse 的加速度对应于(a)矩阵大小和(b) A100上行长度的方差 </font> </center>
图11进一步展示了AlphaSparse相对于PFS的加速效果，同时提供了矩阵大小和行方差（以显示不规则稀疏性的影响）。图11a显示在矩阵适合A100的40 MB L2缓存时可以实现令人印象深刻的加速，在大型矩阵（≥107个非零元素）中提供较低的加速。在图11b中，红线显示了正则性和不规则性之间的界限（如前述102）。加速峰值为2.7×，出现在中等大小和不规则度量程内，这表明Operator Graph提供的细粒度权衡适用于适度稀疏模式。相反，大多数人工格式设计基于对特定极端稀疏模式（如Webbase、mip1、FullChip等）从矩阵及其论文中观察到。它们忽略了具有适度稀疏模式的矩阵。此外，我们发现不规则矩阵更受益于AlphaSparse：对于正常稀疏性，平均加速为1.4×；而对于不规则稀疏性，则平均加速增至1.6×。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="723-与-taco-的性能比较">7.2.3-与 TACO 的性能比较<a class="hash-link" aria-label="Direct link to 7.2.3-与 TACO 的性能  比较" title="Direct link to 7.2.3-与 TACO 的性能比较" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#723-与-taco-的性能比较">​</a></h4>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240610234329.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 12 对应于(a)矩阵大小和(b) A100上行长的方差的 TACO 上的 AlphaSparse 的加速。 </font> </center>
AlphaSparse在性能上远远优于TACO。在A100上，AlphaSparse相对TACO实现了18.1倍的平均加速和最大950.8倍的加速。如图12a所示，与PFS不同，加速度对矩阵大小不敏感。图12b显示高度不规则矩阵中出现了加速峰值。有两个原因导致其相对较低的性能。<strong>第一个原因是TACO并非专为SpMV而设计</strong>。它的三个关键特性：索引压缩、循环优化和自动并行化，只针对一般稀疏问题。这些特性都无法处理由SpMV带来的问题，尤其是不规则性。<strong>第二个原因是TACO缺乏利用GPU功能</strong>，甚至与人工设计程序相比也欠竞争力。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="73-搜索开销">7.3 搜索开销<a class="hash-link" aria-label="Direct link to 7.3 搜索开销" title="Direct link to 7.3 搜索开销" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#73-搜索开销">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240610234723.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 13 A100上的搜索迭代次数及行方差 </font> </center></p>
<p>由于前两个搜索步骤几乎占据了所有的搜索开销（如第 VI 节所述），我们使用前两个步骤中的迭代次数来表示搜索策略的性能。图 13 显示了搜索迭代次数以及矩阵不规则度（即所谓的行方差）。测试结果的回归线  说明了搜索开销与矩阵不规则度之间存在正相关关系：普通矩阵比高度不规则矩阵需要少 3.5 倍的迭代次数。这些证明了我们的修剪规则通过在输入矩阵为常规时忽略不规则操作符，显著降低了搜索开销。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240610235820.png" alt="image.png|center|600" class="img_ev3q">
表III显示了修剪策略如何影响AlphaSparse的搜索时间和性能。我们记录了来自已发表研究中评估的13个流行矩阵在修剪前后的测试结果。修剪策略平均减少了2.5倍的搜索时间。由于修剪策略包括高质量人类经验，它们消除了不必要的枚举，并使搜索引擎专注于设计空间中可能找到高性能格式的区域，在有限的搜索时间内进行查找。修剪策略还平均提高了1.2倍性能。与现有离线自动调谐器相比，例如PATUS（8小时）、SDSL（≥33小时）、Halide（2小时至2天）、PARTANS（2.5小时至32天），AlphaSparse 的搜索时间具有竞争力。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="74-alphasparse-的创新能力">7.4-AlphaSparse 的创新能力<a class="hash-link" aria-label="Direct link to 7.4-AlphaSparse 的创新能力" title="Direct link to 7.4-AlphaSparse 的创新能力" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#74-alphasparse-的创新能力">​</a></h3>
<p>创建新的机器设计格式是性能改进的主要驱动力。从我们的统计数据来看，在73.1% 的测试用例中，AlphaSparse 通过创建源格式中没有涉及到的机器设计的格式(如表 II 中所引用的) ，表现优于所有相应的测试用例。在提供新格式的案例中，有16.5% 的分支出现在运算符图中，这意味着 AlphaSparse 为原始矩阵的不同部分设计不同的格式和相应的内核实现。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240611000217.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 在A100上矩阵scfxm1 − 2r的示例。 (a) 其操作图的快照，(b) 与人工格式的性能比较以及(c) AlphaSparse 的两个关键优化所实现的性能改进。 </font> </center>
图14a显示了由AlphaSparse生成的用于矩阵scfxm1-2r的新格式的操作符图示例。它主要包括来自SELL的线程块级阻塞策略，来自行分组CSR的线程级阻塞策略，以及来自CSR-Adaptive的减少策略。最终，如图14b所示，它比PFS和最先进的人工格式实现了2.7倍加速（这是最高值）。不同设计策略之间适当权衡可以实现高性能。与源格式相比，在这个矩阵中，机器设计的格式避免了SELL高填充率、行分组CSR低效全局内存减少、CSR-Adaptive忽视线程级减少，并受益于SELL规则行块索引、行分组CSR低填充率、CSR-Adaptive有效共享内存减少。就其最先进对应物而言，昂贵策略（例如ACSR划分和CSR5负载平衡阻塞）是不必要的，因为该矩阵并不太规则。此外，在这个矩阵中HYB包含一个庞大且低效COO部件，使其也比机器设计格式更差。图14c显示模型驱动格式压缩带来32%性能改善，并修剪策略带来额外78%性能改善。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="75-局限性">7.5-局限性<a class="hash-link" aria-label="Direct link to 7.5-局限性" title="Direct link to 7.5-局限性" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#75-局限性">​</a></h3>
<p>在AlphaSparse中，<strong>运算符的缺乏是导致特定矩阵性能略低的主要原因</strong>。一个代表性案例是GL7d19矩阵。它最好的人工格式是HYB，其性能甚至比AlphaSparse自带的机器设计格式更好。在这个矩阵中，几乎所有行的长度都相对平衡，除了少数几行长数倍于其他行。HYB的矩阵分解策略非常适合这种稀疏模式，但当前版本  的AlphaSparse尚未包含此策略。</p>
<p>除了类似HYB分解之外，还有两种流行类型的运算符没有被包括进来：用于本地密度、对角线模式 的运算符。它们将矩阵正则部分与其他部分进行隔离处理以实现高性能。然而，它们只覆盖了少量矩阵。我们原型实现并未考虑它们，但将会在未来考虑为更完整支持加入其中。</p>
<p>目前概念验证版AlphaSparse仅支持CUDA 。然而通过实现新定制操作符可以扩展到其他平台上去 。用户只需要定义操作符如何修改元数据，并偶尔需要定义内核片段即可 。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="8-related-work">8-Related Work<a class="hash-link" aria-label="Direct link to 8-Related Work" title="Direct link to 8-Related Work" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#8-related-work">​</a></h2>
<p>自动调优器。自动调优器已被证明是一种成功的性能调优方法，代表作包括ATLAS、FFTW、SPIRAL和OSKI，适用于日益多样化和复杂的计算机架构设计。对于稀疏线性代数，SMAT、clSpMV、TileSpMV、Naser Sedaghati等人和CSX选择了最佳的人工格式和SpMV实现；而IA-SpGEMM为SpGEMM选择了最佳格式。TVM和Ansor是用于密集张量计算的自动调优器，通过自动生成代码结构并选择最佳参数。COGENT在GPU上提供了高性能的张量收缩。CASpMV在Sunway上包含了矩阵分区的自动调优器。一些通用的自动调优器，如ATF、OpenTuner、CLTune、Optuna、mNM、Muthu等人、Tiwari等人、Rigel和SMAC3，旨在简化自动调优器的设计工作，并在更广泛的范围内应用。AlphaSparse不仅限于在人工格式、内核实现、参数之间进行选择，它能够创建SpMV代码，突破人类设计的限制。</p>
<p>人工格式和内核设计。为了提高SpMV的性能，已经提出了几十种格式。最先进的格式是从几种基础格式派生而来的。ALIGNED_COO、SCOO、BRO-COO、BCOO派生自COO ；ICSR、CSR-Adaptive、ACSR、CSR5、LightSpMV派生自CSR；ELL-R、AdELL、JAD派生自ELL；HYB、HDC和HEC是混合格式。这些人工格式是根据人类观察设计的，而AlphaSparse能够在无需人工干预的情况下自动创建格式。</p>
<p>代码生成。TVM是一个用于密集张量计算的基于模板的机器代码生成器。TACO可以通过压缩每个维度的索引来处理高阶稀疏张量计算。LL是一个用于定义矩阵格式及其SpMV内核的DSL（领域特定语言）。AlphaSparse提供了一种基于图的表达方式，用于生成格式和内核。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="9-conclusion-and-future-work">9-Conclusion and Future Work<a class="hash-link" aria-label="Direct link to 9-Conclusion and Future Work" title="Direct link to 9-Conclusion and Future Work" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#9-conclusion-and-future-work">​</a></h2>
<p>本文介绍了 AlphaSparse，一个完全自动的 SpMV 代码设计器，它直接从输入稀疏矩阵生成高性能的格式和内核。它统一了格式建模和内核实现，在 NVIDIA GPU 上实现了高达22.2倍的人工设计格式加速。我们将研究现有研究的高级搜索策略，并在未来添加有效的格式转换例程。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/paper_notes/3_Kernel/AlphaSparse/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/Kernel/AlphaSparse/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/Kernel/CSR5/论文原件"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">论文原件</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#文章笔记提前梳理">文章笔记提前梳理</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#背景">背景</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#解决措施">解决措施</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#与现有工作的关系">与现有工作的关系</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#0-abstract">0-Abstract</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#1-introduction">1-Introduction</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#2-motivation">2-Motivation</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#21-观察-1">2.1-观察 1</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#22-观察2">2.2-观察2</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#3-overview">3-Overview</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#4-designer设计器">4-Designer（设计器）</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#4-1-操作符">4-1 操作符</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#4-2-操作图">4-2 操作图</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#5-formatkernel-generator格式内核生成器">5-Format、Kernel Generator（格式、内核生成器）</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#51-矩阵元数据集">5.1-矩阵元数据集</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#52-生成存储格式">5.2-生成存储格式</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#53-构建计算内核">5.3-构建计算内核</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#54-优化器">5.4-优化器</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#6-search-engine搜索引擎">6-Search Engine（搜索引擎）</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#61-操作图搜索">6.1-操作图搜索</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#52-剪枝">5.2-剪枝</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#7--evaluation">7- Evaluation</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#71-实验设置">7.1-实验设置</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#72-对比样本">7.2-对比样本</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#73-搜索开销">7.3 搜索开销</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#74-alphasparse-的创新能力">7.4-AlphaSparse 的创新能力</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#75-局限性">7.5-局限性</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#8-related-work">8-Related Work</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/AlphaSparse/阅读笔记#9-conclusion-and-future-work">9-Conclusion and Future Work</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper-notes-intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs-intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>