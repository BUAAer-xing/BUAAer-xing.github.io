<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/Kernel/DASP/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/Kernel/DASP/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="文章笔记提前梳理"><meta data-rh="true" property="og:description" content="文章笔记提前梳理"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/DASP/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/DASP/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/DASP/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.2ec13e6f.css">
<script src="/assets/js/runtime~main.828cf1ea.js" defer="defer"></script>
<script src="/assets/js/main.a99845c3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper-notes-intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs-intro">个人博客</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper-notes-intro">笔记说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/Kernel/intro">Kernel</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/intro">说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/AlphaSparse/论文原件">AlphaSparse</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/CSR5/论文原件">CSR5</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/Kernel/DASP/论文原件">DASP</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/DASP/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/Kernel/DASP/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件">HPC加速体系结构中Linpack优化</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HiCOO/Z-Morton顺序">HiCOO</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/IA-SpGEMM/论文原件">IA-SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/J-基于 SpMV 的应用程序开销自觉的格式选择/论文原件">J-基于 SpMV 的应用程序开销自觉的格式选择</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/ML-SpMV-thread/论文原件">ML-SpMV-thread</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/MSREP/论文原件">MSREP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Spmv任务自动分配/intro">Spmv任务自动分配</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Tile-GEMM/论文原件">Tile-GEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/z-模版/论文原件">z-模版</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Kernel</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">DASP</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">阅读笔记</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="文章笔记提前梳理">文章笔记提前梳理<a href="#文章笔记提前梳理" class="hash-link" aria-label="Direct link to 文章笔记提前梳理" title="Direct link to 文章笔记提前梳理">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="文章背景">文章背景<a href="#文章背景" class="hash-link" aria-label="Direct link to 文章背景" title="Direct link to 文章背景">​</a></h3>
<p>这篇文章提出的背景基于以下几点：</p>
<ol>
<li><strong>稀疏矩阵-向量乘法（SpMV）的重要性</strong>：稀疏矩阵-向量乘法在计算科学与工程、图处理和机器学习应用中扮演关键角色。现有的许多工作致力于解决如向量随机访问和负载不平衡等问题 。</li>
<li><strong>计算开销问题</strong>：尽管已经有大量研究改善了SpMV的内存访问性能，但在实验中发现内积计算仍然占据了大量的计算开销，这在现有工作中被大大忽略了。</li>
<li><strong>现有方法的局限性</strong>：已有方法在SpMV中的表现仍不令人满意。通过图1和图2可以看到，当前的方法（如CSR5、cuSPARSE）无法将带宽性能接近峰值，这表明SpMV算法仍有改进空间 。</li>
<li><strong>专用计算单元的引入</strong>：近些年，GPU等并行处理器引入了专用的矩阵乘法累加（MMA）单元，如NVIDIA Tensor Cores，以显著加速小型密集矩阵乘法。这些单元在其他算法（如深度神经网络、稀疏矩阵-密集矩阵乘法等）中已经显示出显著的性能提升。</li>
<li><strong>不规则数据布局的挑战</strong>：由于稀疏矩阵的非零元素分布非常不规则，而MMA单元需要严格的规则数据布局以充分利用硬件资源，因此将MMA单元应用于SpMV并非易事。
基于以上背景，文章提出了DASP算法，通过使用专用的密集MMA单元来加速一般的SpMV计算，从而解决上述挑战和局限性。</li>
</ol>
<p>📒：尽管已有大量研究改善了SpMV的内存访问性能，但实验发现<font color="red"><b>内积计算仍然占据了大量的计算开销</b></font>（这一方面在现有工作中被忽略）。此外，现有方法<font color="red"><b>无法充分利用带宽</b></font>（无法使带宽性能接近峰值）。与此同时，GPU等并行处理器引入了<font color="red"><b>专用的矩阵乘法累加（MMA）单元</b></font>，显著提升了稀疏矩阵-密集矩阵乘法的性能。然而，<strong>由于稀疏矩阵的非零元素分布非常不规则，而MMA单元需要严格的数据布局才能充分利用硬件资源</strong>，因此，将MMA单元应用到SpMV中仍存在挑战。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="解决措施">解决措施<a href="#解决措施" class="hash-link" aria-label="Direct link to 解决措施" title="Direct link to 解决措施">​</a></h3>
<p>文章提出的解决方法是DASP算法，使用特定的密集矩阵乘法累加（MMA）单元来加速稀疏矩阵-向量乘法（SpMV）。具体解决方法包括以下几个方面：</p>
<ol>
<li><strong>数据结构转换</strong>：<!-- -->
<ul>
<li>分析稀疏矩阵每行的非零元素分布，将行分为三类：长行（long rows）、中等长度行（medium rows）和短行（short rows）。<!-- -->
<ul>
<li>对于长行，将其划分为适当大小的块，以符合MMA单元的计算需求。如 果行中的非零元素不足以形成完整块，则用零填充。</li>
<li>对于中等长度行，进一步分为规则部分和不规则部分，分别存储和处理。</li>
<li>对于短行，通过拼接形成合适的块以提高MMA单元的利用率。</li>
</ul>
</li>
</ul>
</li>
<li><strong>计算策略</strong>：<!-- -->
<ul>
<li><strong>长行的计算</strong>：将长行中的数据分块存储，每个块的数据加载到寄存器后，调用MMA指令进行计算。使用CUDA shuffle指令汇总计算结果，并写回全局内存。</li>
<li><strong>中等长度行的计算</strong>：将中等长度行按块存储，分别处理规则部分和不规则部分。规则部分通过MMA单元计算，不规则部分使用基本计算单元进行计算。</li>
<li><strong>短行的计算</strong>：对不同类型的短行采用不同的计算策略。例如，通过拼接后的短行直接利用MMA单元进行计算，单一非零元素的短行使用基本计算单元。</li>
</ul>
</li>
<li><strong>优化技术</strong>：<!-- -->
<ul>
<li>使用缓存旁路（cache bypass）方法，提高向量x在缓存中的命中率。</li>
<li>采用自适应的工作负载分配策略，提高计算效率。
通过这些方法，DASP算法有效地利用了GPU中的MMA单元，解决了稀疏矩阵-向量乘法中计算部分的瓶颈问题，并显著提高了整体性能。</li>
</ul>
</li>
</ol>
<p>📒：该论文采用了三种方式来对<font color="red"><b>基于MMA单元的SpMV计算进行优化</b></font>，首先，设计了新的数据结构，分析稀疏矩阵中每行的非零元素分布，将行分为长、中、短三类，并对不同的类别进行以适应MMA单元的调整。同时，由于设计了新的数据结构，所以，针对不同类别的行分别设计了不同的计算策略。最后，还使用了一些优化技术，比如：缓存旁路技术来提高向量x在缓存中的命中率，采用自适应分工作负载分配策略，从而进一步提高计算效率。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="0-abstract">0-Abstract<a href="#0-abstract" class="hash-link" aria-label="Direct link to 0-Abstract" title="Direct link to 0-Abstract">​</a></h2>
<p>稀疏矩阵-向量乘法（SpMV）在计算科学与工程、图处理和机器学习应用中扮演关键角色。大量关于SpMV的工作致力于解决如向量x的随机访问和负载不平衡等问题。然而，我们通过实验发现，<font color="red"><b>内积计算在SpMV操作中仍占据了大量的计算开销</b></font>，这在现有工作中被大大忽略了。</p>
<p>在本文中，提出了DASP，一种<font color="red"><b>使用特定密集MMA单元来加速一般SpMV计算部分的新算法</b></font>。本文分析了非零元素的行分布，并将行分为长、中、短三类。然后，将它们组织成适当大小的<strong>小块</strong>，以<strong>满足MMA计算的要求</strong>。对于这三类行，DASP提供了不同的策略，<strong>通过有效利用MMA单元来完成SpMV</strong>。</p>
<p>在最新的两款NVIDIA GPU（A100和H800）上的实验结果显示，DASP在FP64精度下，平均比最新的五种SpMV方法（CSR5、TileSpMV、LSRB-CSR、cuSPARSE BSR格式和cuSPARSE CSR格式）分别快1.46倍、2.09倍、3.29倍、2.08倍和1.52倍（最高分别可达12.64倍、17.48倍、90.59倍、283.92倍和6.94倍）。至于FP16精度的SpMV，我们的DASP在A100和H800上平均比cuSPARSE快1.70倍和1.75倍（最高分别可达26.47倍和65.94倍）。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-introduction">1-Introduction<a href="#1-introduction" class="hash-link" aria-label="Direct link to 1-Introduction" title="Direct link to 1-Introduction">​</a></h2>
<p>稀疏矩阵操作是计算科学与工程中最基本的基石之一。由于稀疏矩阵的<strong>非零元素位置可能非常不规则</strong>，相比于密集矩阵计算，还需要解决更多的问题，如<font color="green"><b>内存局部性差</b></font>和<font color="green"><b>负载不平衡</b></font>。稀疏矩阵-向量乘法（SpMV）可能是稀疏矩阵操作中研究最多的核心问题。</p>
<p><strong>大量研究集中在通过垂直切片和二维平铺非零元素来改善其内存访问，并通过重构接近均匀大小的基本工作单元来平衡工作负载</strong>。然而，即使这些现有的工作已经显示出有希望的改进，所取得的性能仍然不能令人满意。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240521013231.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 1 ：多个矩阵的计算带宽与理论、测量峰值带宽的对比 </font> </center></p>
<p>图1显示了三种双精度 SpMV 方法的带宽吞吐量(GB/s) ，即 CSR5(可能是在现有的 SpMV 工作中测试最多的开源baseline) ，cuSPARSE v12.0(最新的供应商支持的库)和 DASP (在本文中提出的算法)通过使用 SuiteSparse Matrix Collection 中最大的202个稀疏矩阵(不少于1000万个非零)在 NVIDIA A10040GB PCIe GPU 上运行。可以看到，CSR5和 cuSPARSE 都不能将所获得的带宽带到接近<strong>峰值带宽</strong>(使用类似 STREAM 的 Triad 测试测量)。这表明 SpMV 算法仍有改进的空间。</p>
<p>📒：<strong>测量峰值带宽使用类似STREAM的Triad测试进行测量</strong></p>
<p>为了理解SpMV的性能行为，本文进一步将标准的CSR SpMV（用CUDA编写并在NVIDIA A100上运行）的耗时分为三部分：</p>
<ul>
<li>（1）向量𝑥的随机访问 ---- random access</li>
<li>（2）加载非零元素的内积计算和𝑥的对应部分 ---- compute</li>
<li>（3）只包括读取和写入数组如𝑟𝑜𝑤_𝑝𝑜𝑖𝑛𝑡𝑒𝑟和𝑦的杂项 ---- miscellaneous</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240521013944.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 2 ： 执行时间分解 </font> </center></p>
<p>我们将SuiteSparse矩阵集合中所有2893个矩阵的结果绘制在图2中。可以看到，尽管<font color="red"><b>SpMV是一个众所周知的受内存限制的内核</b></font>，其计算部分仍然占据了大量开销。然而，据我们所知，现有工作在很大程度上忽略了优化这一部分，导致性能不佳（回想图1中实际带宽和峰值带宽之间的差距）。</p>
<p>幸运的是，最近的并行处理器，特别是GPU，包含了<strong>专用的矩阵乘法累加（MMA）单元</strong>，以显著加速小型密集矩阵乘法（GEMM）。NVIDIA Tensor Cores、AMD Matrix Cores、Apple Matrix Co-processors（AMX）以及Intel Xe Matrix Extensions（XMX）和Advanced Matrix Extensions（AMX）都是这种MMA单元的代表。</p>
<p>除了GEMM之外，近年来，通过使用MMA单元，许多其他基础算法的性能也得到了提升，例如归约和扫描、模板匹配、FFT、深度神经网络、分子动力学、块迭代求解器、<font color="red"><b>稀疏矩阵-密集矩阵乘法（SpMM）</b></font>【⭐️⭐️后面可以看一下⭐️⭐】。</p>
<p>然而，利用 MMA 单元的计算能力来处理 SpMV 并非易事。主要原因是：</p>
<ul>
<li>一方面，SpMV 中矩阵非零点的分布可能非常不规则</li>
<li>另一方面，MMA 单元需要严格规则的数据布局来充分利用硬件。</li>
</ul>
<p>针对这一问题，本文提出了 DASP 算法，这是一种利用特定密集 MMA 单元加速一般 SpMV 的新算法。</p>
<ul>
<li>首先分析非零行的分布，并将行分为三类，分别包含长行、中行和短行。</li>
<li>然后根据 MMA 计算的需要，将每个长行划分为适当大小的块，并将短行聚集在一起形成 MMA 的规则布局。对于中等大小的行，进一步将它们区分为规则的和不规则的部分，并相应地使用不同的计算单位。</li>
<li>在 MMA  友好的数据结构之上，利用 MMA 单元为三组行开发了不同的 CUDA 内核。</li>
</ul>
<p>本文通过使用硬件支持的 FP64和 FP16 MMA 单元，在两个最新的 NVIDIA GPU A100(Ampere)和 H800(Hopper)上使用 SuiteS 解析矩阵集合中的所有2893个矩阵来评估 DASP。图1展示了通过利用 MMA 单元，我们的 DASP 算法产生了更高的整体性能，并使更多矩阵的带宽更接近测量的峰值。</p>
<p>第四节列出的更完整的实验结果表明，与 FP64中最新的5种 SpMV 方法相比，我们的 DASP 在2403个矩阵上的精度要高于 CSR5,在2579个矩阵上快于 TileSpMV  ，在2251个矩阵上快于 LSRB-CSR ，在2340个矩阵上快于 cuSPARSE v12.0 BSR 格式 SpMV，在2344个矩阵上快于 cuSPARSE v12.0 CSR 格式 SpMV,并在 A100上分别达到平均(几何平均值)1.46 x，2.09 x，3.29 x，2.08 x 和1.52 x (最高12.64 x，17.48 x，90.59 x，283.92 x 和6.94 x)加速。对于 FP16中的 SpMV 精度，我们的 DASP 在2578和2576个矩阵上比 cuSPARSE CSR 格式的 SpMV 更快，在 A100和 H800上分别达到了1.70 x 和1.75 x (高达26.47 x 和65.95 x)的平均加速。</p>
<p>这项工作做出了以下贡献:</p>
<ul>
<li>认为计算部分可能是 SpMV 的一个关键性能瓶颈，而 <strong>MMA 作为一个新的硬件单元可以带来更高的性能</strong>;</li>
<li>提出了 DASP 算法，使稀疏矩阵中的不规则数据布局规则，以<strong>有效地利用 MMA 单元</strong>;</li>
<li>证明本文的方法带来的大多数矩阵性能高于最新的 NVIDIA Ampere 和 Hopper GPU 的最先进的 SpMV 工作。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-background">2-Background<a href="#2-background" class="hash-link" aria-label="Direct link to 2-Background" title="Direct link to 2-Background">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="21-spmv-及其性能分析">2.1-SpMV 及其性能分析<a href="#21-spmv-及其性能分析" class="hash-link" aria-label="Direct link to 2.1-SpMV 及其性能分析" title="Direct link to 2.1-SpMV 及其性能分析">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240521233402.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 3 ：SpMV示意图 </font> </center></p>
<p>SpMV操作将稀疏矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>与密集向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">x</span></span></span></span>相乘，以得到密集向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03588em">y</span></span></span></span>作为结果。图3展示了一个简单的SpMV示例。在该操作中，压缩稀疏行（CSR）格式是目前最常用的存储格式，也是本文数据结构的基础。</p>
<p>在CSR格式中，非零元素的行坐标信息被压缩，它使用三个密集数组来表示一个矩阵：</p>
<ul>
<li>（1）<code>Val</code> : 存储矩阵中所有非零元素的值，其大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>n</mi><mi>z</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">nnzA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">nn</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mord mathnormal">A</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>n</mi><mi>z</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">nnzA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">nn</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mord mathnormal">A</span></span></span></span>表示矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>的非零元素数量。</li>
<li>（2）<code>ColIdx</code>，存储数组Val中对应元素的列索引，其大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>n</mi><mi>z</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">nnzA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">nn</span><span class="mord mathnormal" style="margin-right:0.04398em">z</span><span class="mord mathnormal">A</span></span></span></span>。</li>
<li>（3）<code>RowPtr</code>，存储稀疏矩阵中每行第一个元素的内存偏移，即Val的下标。<code>RowPtr[𝑖+1]-RowPtr[𝑖]</code>计算矩阵第<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6595em"></span><span class="mord mathnormal">i</span></span></span></span>行的非零元素数量。其大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>o</mi><mi>w</mi><mi>A</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">rowA + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">ro</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>o</mi><mi>w</mi><mi>A</mi></mrow><annotation encoding="application/x-tex">rowA</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">ro</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord mathnormal">A</span></span></span></span>是矩阵<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span>的行数。</li>
</ul>
<p>在 SpMV 操作中，<strong>行之间没有依赖关系，因此可以很容易地实现行到行的并行执行</strong>。算法程序1显示了一个并行 SpMV 的伪代码，使用 CSR 进行处理。对于矩阵 A 的每一行，它首先创建一个变量 sum 作为该行的累加器，遍历该行的每一个非零元素，并根据非零元素的列索引(算法1中的第4行)获得相应的 x。然后，它将 x 和当前非零的乘积累加到变量 sum (算法运算式1中的第5行) ，最后将累加器 sum 的值写回 y。</p>
<p>回想一下，在第1节中将 SpMV 操作分为三个部分: RANDOM ACCESS、 COMPUTE 和 MISCELLANEUS，图2显示了所有2893个矩阵在 SpMV 执行时间中三个部分的比例。除了随机存取部分外，COMPUTE 部分的开销也占了很大一部分，在 SpMV 的整个执行时间中，随机存取部分、计算部分和杂项部分的平均比例分别为25.1% 、21.1% 和53.8%</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="22-特殊的-mma-单元">2.2-特殊的 MMA 单元<a href="#22-特殊的-mma-单元" class="hash-link" aria-label="Direct link to 2.2-特殊的 MMA 单元" title="Direct link to 2.2-特殊的 MMA 单元">​</a></h3>
<p>近年来，人工智能的快速发展促使许多处理器加入了<strong>专用的矩阵乘法累加单元</strong>，以提高其最耗时的算术操作（如密集GEMM和卷积）的性能。这些单元的例子包括NVIDIA Tensor Cores、AMD Matrix Cores等。</p>
<p>以张量核心为例，它是一种专门为小型GEMM设计的ASIC，可以<font color="red"><b>在一个时钟周期内将两个4x4矩阵相乘，并将结果加到另一个4x4矩阵上</b></font>。相关指令使用32个线程（一个warp）的操作数在张量核心中完成GEMM操作。到了第三代张量核心，它已经能够支持整数、半精度、单精度和双精度浮点数据类型。</p>
<p>NVIDIA提供了一个CUDA C++ Warp矩阵乘法累加（WMMA）API来编程张量核心，但为了更灵活地支持SpMV操作，本文<strong>调用了PTX中提供的mma指令来完成矩阵乘法累加操作</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522002702.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 4 ： 利用张量核心进行矩阵乘法操作 </font> </center></p>
<p>图4展示了不同线程持有的FP64精度mma_m8n8k4指令的片段布局，其中𝑀𝑀𝐴_𝑀、𝑀𝑀𝐴_𝑁和𝑀𝑀𝐴_𝐾分别为8、8和4。调用该指令的warp将一个8x4矩阵𝐴与一个4x8矩阵𝐵相乘，得到一个8x8的密集矩阵𝐶。在这个操作中，组成这三个矩阵的三个片段分布在warp的32个线程中。代码清单1展示了对应的PTX代码。在本文中，<font color="red"><b>DASP的计算部分主要通过调用mma指令来完成</b></font>。</p>
<div class="language-cpp codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-cpp codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token operator" style="color:#393A34">%</span><span class="token plain"> __device__ __forceinline__  </span><span class="token comment" style="color:#999988;font-style:italic">// 设备函数 + 内联函数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">void</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">mma_m8n8k4</span><span class="token punctuation" style="color:#393A34">(</span><span class="token keyword" style="color:#00009f">double</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">*</span><span class="token plain">acc</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">double</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">frag_a</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">double</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">frag_b</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">asm</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">volatile</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// 内联汇编 volatile 确保编译器不会优化或重排序下面的指令</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot;mma.sync.aligned.m8n8k4.row.col.f64.f64.f64.f64&quot;</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic">// 执行8*8的矩阵乘法累加（8*4 乘 4*8）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot; { %0, %1 }, &quot;</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// 累加器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot; { %2 }, &quot;</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic">// 操作数a</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot; { %3 }, &quot;</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic">// 操作数b</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token string" style="color:#e3116c">&quot; { %0, %1 };&quot;</span><span class="token plain">   </span><span class="token comment" style="color:#999988;font-style:italic">// 累计器</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;+d&quot;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">acc</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">0</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;+d&quot;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">acc</span><span class="token punctuation" style="color:#393A34">[</span><span class="token number" style="color:#36acaa">1</span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic">// 输出操作数：累加器的两个元素（T0、T0、T1、T1）</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token operator" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;d&quot;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">frag_a</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;d&quot;</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain">frag_b</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic">// 输入操作数</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-dasp">3-DASP<a href="#3-dasp" class="hash-link" aria-label="Direct link to 3-DASP" title="Direct link to 3-DASP">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="31-dasp-概述">3.1-DASP 概述<a href="#31-dasp-概述" class="hash-link" aria-label="Direct link to 3.1-DASP 概述" title="Direct link to 3.1-DASP 概述">​</a></h3>
<p>DASP是一种<font color="red"><b>使用特定密集MMA单元来加速通用SpMV</b></font>的新算法。它包含两个主要部分：</p>
<ul>
<li>一种可以高效用于MMA单元计算模式的新数据结构</li>
<li>对应新的数据结构的SpMV算法。</li>
</ul>
<p>由于<strong>MMA单元对数据布局有严格要求</strong>，首先需要将稀疏矩阵𝐴从基本的CSR格式转换为某种大小的块状格式（由对应的MMA指令中的𝑀𝑀𝐴_𝑀、𝑀𝑀𝐴_𝑁和𝑀𝑀𝐴_𝐾决定），以便我们可以直接在GPU内核中使用MMA指令进行计算。对于稀疏矩阵𝐴，根据其行长度对其进行分类，并使用不同的格式存储每部分的非零元素。第3.2节将详细介绍DASP数据结构。</p>
<p>对于不同部分的非零元素，使用<strong>不同的分配方法将它们分配给MMA单元进行计算</strong>。然后，通过调用<strong>CUDA shuffle</strong>指令，从MMA指令获得的累加器中提取所需的结果。最后，将结果写回向量𝑦。在GPU内核中，本文还采用了诸如<strong>缓存旁路</strong>和<strong>自适应工作负载分配</strong>等优化技术，这些将在第3.3节中介绍。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="32-数据结构">3.2-数据结构<a href="#32-数据结构" class="hash-link" aria-label="Direct link to 3.2-数据结构" title="Direct link to 3.2-数据结构">​</a></h3>
<p>首先分析了非零元素在稀疏矩阵 A 的每一行中的分布，并根据每一行中非零元素的数量(即 Row _ len)将所有行分为三类:</p>
<ul>
<li>长行：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>o</mi><mi>w</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo>&gt;</mo><mi>M</mi><mi>A</mi><mi>X</mi><mi mathvariant="normal">_</mi><mi>L</mi><mi>E</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">Row\_len &gt; MAX\_LEN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em">EN</span></span></span></span></li>
<li>中行：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>&lt;</mo><mi>R</mi><mi>o</mi><mi>w</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo>≤</mo><mi>M</mi><mi>A</mi><mi>X</mi><mi mathvariant="normal">_</mi><mi>L</mi><mi>E</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">4 &lt; Row\_len \leq MAX\_LEN</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6835em;vertical-align:-0.0391em"></span><span class="mord">4</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.9933em;vertical-align:-0.31em"></span><span class="mord mathnormal" style="margin-right:0.10903em">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.07847em">X</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em">EN</span></span></span></span></li>
<li>短行：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi><mi>o</mi><mi>w</mi><mi mathvariant="normal">_</mi><mi>l</mi><mi>e</mi><mi>n</mi><mo>≤</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">Row\_len \leq 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em"></span><span class="mord mathnormal" style="margin-right:0.00773em">R</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em">w</span><span class="mord" style="margin-right:0.02778em">_</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">4</span></span></span></span></li>
</ul>
<p>𝑀𝐴𝑋_𝐿𝐸𝑁是一个可调参数，表示中等长度行的最大长度，这里将其<font color="red"><b>值设置为256</b></font>（<strong>这个值正好适合线程块的工作负载，详细信息将在第3.3节中描述</strong>）。在实际计算中，MMA指令支持的最小布局是m8n8k4（𝑀𝑀𝐴_𝑀 = 8，𝑀𝑀𝐴_𝑁 = 8，𝑀𝑀𝐴_𝐾 = 4），因此实际数据结构中的块大小为8×4。图5显示了一个大小为20×20的示例矩阵。在这个图中，我们假设MMA指令支持的模式是m2n2k4，因此示例中的非零块大小为2×4。（乘法计算为：2*4  × 4*2）</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522022348.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 5 ：新的稀疏矩阵存储结构以及其转换方式 </font> </center></p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="长行部分">长行部分<a href="#长行部分" class="hash-link" aria-label="Direct link to 长行部分" title="Direct link to 长行部分">​</a></h4>
<p>对于长行部分，每行的非零元素将被分成若干组，每组的非零元素数量为2 × 𝑀𝑀𝐴_𝑀(8) × 𝑀𝑀𝐴_𝐾(4)，即64。<strong>如果某行的非零元素数量不足以构成完整的组，则会用零填充</strong>，使非零元素的数量可以被组大小整除。</p>
<p>📒：也就是这一行中的数，就按照列的顺序来进行排布，每个组的大小为16，每个组包括两个小的矩阵，矩阵的大小都为2 * 4。每行的元素首先会填充第一组的左边的矩阵，随后会填充右边的矩阵，如果该组的左右两侧的矩阵都被填充完全，再启用新的组，以此类推，如果某一行的所属最后一个组的左侧或右侧矩阵没有被填满，则使用零元素来进行填充。也就是说，一个行非零元素越多，则它可以分成的组数就越多。（每种行的分组策略都是不同的！！）
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522013531.png" alt="center|800" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522012533.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 6 长行部分的存储结构 </font> </center>
长行部分的数据存储在三个数组中：</p>
<ul>
<li>(1) <code>longVal</code>：存储长行中元素的值，包括填充的零元素。<!-- -->
<ul>
<li>这些零元素附加在每行非零元素的末尾，该数组的大小为𝑛𝑛𝑧_𝑙𝑜𝑛𝑔_𝑛𝑒𝑤，即长行部分非零元素数量与填充零元素数量的总和；</li>
</ul>
</li>
<li>(2) <code>longCid</code>：存储数组longVal中对应元素的列索引。<!-- -->
<ul>
<li><strong>零元素的列索引设为0</strong>，数组大小为𝑛𝑛𝑧_𝑙𝑜𝑛𝑔_𝑛𝑒𝑤；</li>
</ul>
</li>
<li>(3) <code>groupPtr</code>：存储每行第一个组的偏移量，表示每行第一个组在所有组中的位置，其大小为𝑟𝑜𝑤_𝑙𝑜𝑛𝑔 + 1（𝑟𝑜𝑤_𝑙𝑜𝑛𝑔是长行部分的总行数）。
图6展示了长行部分的一个示例  ，假设每组有16个元素（作者在文章中假设的是支持2*4 4*2张量核的，故 2 * 4 * 2 = 16），因此两行长行被分成2组。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="中行部分">中行部分<a href="#中行部分" class="hash-link" aria-label="Direct link to 中行部分" title="Direct link to 中行部分">​</a></h4>
<p>对于中等长度行部分，首先将所有行按每行的非零元素数量进行降序排列。之后，每𝑀𝑀𝐴_𝑀(两)行被视为一个行块（row-block），每个行块根据𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑参数分成若干大小为𝑀𝑀𝐴_𝑀 × 𝑀𝑀𝐴_𝐾的块。𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑是DASP中的一个自定义参数，<strong>设定为0.75。当在一个𝑀𝑀𝐴_𝑀 × 𝑀𝑀𝐴_𝐾空间中的非零元素数量超过𝑀𝑀𝐴_𝑀 × 𝑀𝑀𝐴_𝐾 × 𝑡ℎ𝑟𝑒𝑠ℎ𝑜𝑙𝑑时，将其视为一个块，空余位置填充零元素，这些块称为中等长度行的规则部分</strong>(<font color="red"><b>这里控制的是：什么时候将多出来的非零元素认为是新的块中元素，什么时候当作不规则的元素进行处理。</b></font>)；否则，这些未被视为块的非零元素属于中等长度行的不规则部分。我们将规则部分和不规则部分的元素分别存储，因此中等长度行部分使用六个数组来存储相关数据：</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522020506.png" alt="image.png|center|800" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522015129.png" alt="image.png|center|800" class="img_ev3q">
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522024914.png" alt="image.png|center|800" class="img_ev3q"></p>
<center> <font face="华文宋体" size="4"> 图 7 中 行的存储结构 </font> </center>
<ol>
<li><strong>regVal</strong>：存储规则部分元素的值，包括原始矩阵中的非零元素和填充的零元素。该数组使用块内行优先布局，其大小为𝑛𝑛𝑧_𝑟𝑒𝑔_𝑛𝑒𝑤；</li>
<li><strong>regCid</strong>：存储数组regVal中对应元素的列索引，其大小为𝑛𝑛𝑧_𝑟𝑒𝑔_𝑛𝑒𝑤；</li>
<li><strong>rowblockPtr</strong>：存储每个行块中规则部分第一个元素的内存偏移量，其大小为𝑟𝑜𝑤𝑏𝑙𝑜𝑐𝑘_𝑛𝑢𝑚+1（𝑟𝑜𝑤𝑏𝑙𝑜𝑐𝑘_𝑛𝑢𝑚是中等长度行中的行块数量）；</li>
<li><strong>irregVal</strong>：存储不规则部分中非零元素的值，其大小为𝑛𝑛𝑧_𝑖𝑟𝑟𝑒𝑔；</li>
<li><strong>irregCid</strong>：存储数组irregVal中对应非零元素的列索引，其大小为𝑛𝑛𝑧_𝑖𝑟𝑟𝑒𝑔；</li>
<li><strong>irregPtr</strong>：存储不规则部分中每行第一个非零元素的内存偏移量，其大小为𝑟𝑜𝑤_𝑚𝑒𝑑𝑖𝑢𝑚+1（𝑟𝑜𝑤_𝑚𝑒𝑑𝑖𝑢𝑚是中等长度行中的行数）。</li>
</ol>
<p>📒：也就是说，当行为中行时，每𝑀𝑀𝐴_𝑀行被视为一个行块（row-block），在示例中为2，也就是每两行对应一个行块，也可以理解为一个组，这时，每两行只对应一个组，组内的子矩阵块的数量会根据这两行的非零元素的数量而变化，不再仅仅是左右两个。如果，非零元素无法正好填充好一个子块，则利用threshold来进行控制，判断这个多出来的非零元素是属于新的子矩阵块中的元素，后面用零元素补充，还是认为为不规则元素，进行一个重新处理。</p>
<p>图7展示了中等长度行的存储格式。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="短行部分">短行部分<a href="#短行部分" class="hash-link" aria-label="Direct link to 短行部分" title="Direct link to 短行部分">​</a></h4>
<p>短行部分采用<strong>拼接成块的策略</strong>来提高MMA单元的利用率。
可以拼接成完整行：</p>
<ul>
<li>将行长为1和3的行拼接在一起，得到行长为4的行</li>
<li>将行长为2的行拼接在一起，得到行长为4的行。
拼接完的后的剩余部分处理措施：</li>
<li>对于与行长为1的行拼接后仍剩下的行长为3的行（不足以形成一个块），通过填充一个零元素将其处理为行长为4。<!-- -->
<ul>
<li>剩下3个非零元，填充1个非零元，让它成为新的一行。</li>
</ul>
</li>
<li>对于与行长为3的行拼接后剩下的行长为1的行，我们将它们放置在所有短行元素的末尾。<!-- -->
<ul>
<li>剩下1个非零元，放在所有短行的末尾。</li>
</ul>
</li>
</ul>
<p>因此，短行部分的数据被分为四类：<strong>1&amp;3拼接行</strong>、<strong>行长为4的行</strong>（包括填充零元素的行）、<strong>2&amp;2拼接行</strong>和<strong>行长为1的行</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522022621.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 8 ： 短行的存储结构 </font> </center></p>
<p>短行部分的数据使用两个数组存储：</p>
<ul>
<li>(1) shortVal：存储短行部分所有元素的值，数组大小为𝑛𝑛𝑧_𝑠ℎ𝑜𝑟𝑡_𝑛𝑒𝑤；</li>
<li>(2) shortCid：存储数组shortVal中对应元素的列索引，零元素的索引设为0，数组大小为𝑛𝑛𝑧_𝑠ℎ𝑜𝑟𝑡_𝑛𝑒𝑤。
由于短行中四类行的长度是固定的，因此不需要冗余数组来存储元素内存偏移量。</li>
</ul>
<p>图8展示了短行部分的一个示例。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="33-算法介绍">3.3-算法介绍<a href="#33-算法介绍" class="hash-link" aria-label="Direct link to 3.3-算法介绍" title="Direct link to 3.3-算法介绍"> ​</a></h3>
<p>DASP 为不同类别的行提供了不同的计算策略，在下面的算法中，本文还采用了<strong>旁路缓存</strong>的方法来尽可能地<strong>提高 x 在缓存中的命中率</strong>。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="长行">长行<a href="#长行" class="hash-link" aria-label="Direct link to 长行" title="Direct link to 长行">​</a></h4>
<p>每个长行将被分成几组2×𝑀𝑀𝐴_𝑀 × 𝑀𝑀𝐴_𝐾个元素。算法2展示了计算长行部分的伪代码。在调用mma指令之前，数据块（大小为 𝑀𝑀𝐴_𝑀 × 𝑀𝑀𝐴_𝐾）会临时存储在每个线程的寄存器中。然后调用mma指令使32个线程一起计算一个大小为m8n8k4的GEMM。完成两次MMA计算后，会产生八个有意义的结果，并分发给32个线程中的寄存器fregY。下一步是调用CUDA Shuffle指令对这8个值进行求和，并将结果存储在第一个线程的寄存器中。然后将结果写入预先分配好的全局内存数组warpVal中。当所有warp都已经计算并将其结果写入warpVal后，通过对生成于一行中 warpVal 中所有值进行warp级别求和来获得最终值y 。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522031215.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 9 ：长行的计算过程 </font> </center>
设置每个线程块有4 个warps，在长行中每一个warp 计算 2 份数据块，因此一个线程块会在一行上计算256 个元素 。因此, MA_X_LEN 的值被称为一个thread block 的工作量. 图6说明了以256 大小计算长行的过程。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="中行">中行<a href="#中行" class="hash-link" aria-label="Direct link to 中行" title="Direct link to 中行">​</a></h4>
<p>在执行中行计算时引入了一个新参数𝐿𝑂𝑂𝑃_𝑁𝑈 𝑀，该参数表示每个warp要计算的行块数。当row_ medium小于59990时，LOO P_NU M的值为1；当row_medium大于或等于59990且小于400000时，LOO P_NU M的值为2；而当row_medium大于或等于400000时，LOO P_NU M的值为4。
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522025558.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 10 ：中行的计算过程 </font> </center>
算法3显示了中间行计算的伪代码。类似地，在进行计算之前将相应块的数据加载到本地寄存器中，然后调用mma指令进行计算。一般来说，一个行块将包含多个块，因此循环计算次数由行块长度控制，并且一个行块多次计算结果在寄存器fragY中累积。将寄存器fragY中的值提取到CUDA Shuffle指令对应位置寄存器res 中后，基本完成了中行常规部分的计算。</p>
<p>对于不规则部分中的元素，则每个线程负责并行处理一行，并将运算结果累加到相应寄存器r es 中最终写回数组valY 。图7展示了当LOO P_NU M = 1 时中间行的计算过程。图表格示例中包含三个块组成一个行块 ，需要执行三次MMA 计 算 。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="短行">短行<a href="#短行" class="hash-link" aria-label="Direct link to 短行" title="Direct link to 短行">​</a></h3>
<p>由于短行部分被进一步分为四类，因此它们也对应四种算法。算法4展示了1&amp;3拼接短行的计算过程伪代码。为了优化计算资源和MMA单元的利用，一个warp将调用四次MMA指令来完成两个块的计算。这样，一个warp可以精确地计算32个连续的𝑦值。</p>
<p>在调用MMA指令进行计算之前，相关块的数据必须存储在寄存器𝑓𝑟𝑎𝑔𝐴和𝑓𝑟𝑎𝑔𝑋中。然而，每个块只需要加载一次矩阵𝐴的值和两次𝑥的值，而不是进行两次完整的数据加载和MMA计算：第一次加载𝑥的值对应每个块的第一列（𝑓𝑟𝑎𝑔𝑌中的其余空位置设置为零），第二次加载𝑥的值对应每个块的后三列。MMA计算的结果分布在寄存器𝑓𝑟𝑎𝑔𝑌的32个线程中。使用CUDA Shuffle指令，这些结果按顺序存储在寄存器𝑟𝑒𝑠中，然后写回到数组valY中。图11展示了一个warp内1&amp;3拼接短行的计算过程。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240522030943.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 11 ：短行的计算过程 </font> </center></p>
<p>类似地，2&amp;2拼接短行采用几乎相同的计算策略。当将块中的𝑥值加载到寄存器𝑓𝑟𝑎𝑔𝑋时，首先加载前两列，然后加载后两列。这种拼接方法有效地减少了数据传输开销，并提高了MMA单元的效率。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-experimental-results">4-Experimental results<a href="#4-experimental-results" class="hash-link" aria-label="Direct link to 4-Experimental results" title="Direct link to 4-Experimental results">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="41-实验设置">4.1-实验设置<a href="#41-实验设置" class="hash-link" aria-label="Direct link to 4.1-实验设置" title="Direct link to 4.1-实验设置">​</a></h3>
<p>本文的实验平台包括两个 NVIDIA 图形处理器: 一个 A100(Ampere architecture)和一个 H800(Hopper architecture)。GPU 驱动程序版本是525.85.12，CUDA 版本是12.0。</p>
<p><center> <font face="华文宋体" size="4"> 表 1 ： 对两个 GPU 和四个算法的评估 </font> </center>
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523232033.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>在两个GPU的硬件支持下，本文评估了DASP算法在FP64和FP16精度下的表 现。对于FP64双精度的DASP，本文在A100上进行测试，并与Liu和Vinter提出的CSR5算法、Niu等提出的TileSpMV算法、Liu等提出的LSRB-CSR算法，以及最新的cuSPARSE v12.0中的例程cusparseSpMV()（使用CSR格式）和cuSPARSE bsrmv()（使用BSR格式）进行比较。</p>
<p>对于FP16半精度的DASP，本文在A100和H800 GPU上进行实验，并将本文的工作与常规的cusparseSpMV()（使用CSR格式）的cuSPARSE v12.0进行比较（因为CSR5、TileSpMV、LSRB-CSR和cuSPARSE bsrmv()都不支持半精度）。两个图形处理器的规格和六个测试算法如表1所示。请注意，本文不会将DASP与最新的SpMV工作AlphaSparse进行比较，因为它只支持单一精度，并且测试耗时过长（即使是单个稀疏矩阵的预处理也需要几个小时）。</p>
<p><center> <font face="华文宋体" size="4"> 表2 : 21个代表性矩阵的信息</font> </center>
<img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523233243.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>本文的实验数据集包括SuiteSparse矩阵收藏中的全部2893个矩阵。本文还在表2中列出了21个代表性矩阵，这些矩阵已经在现有SpMV工作中广泛测试过，以更深入地分析DASP性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="42-现有-spmv-工作的性能比较">4.2-现有 SpMV 工作的性能比较<a href="#42-现有-spmv-工作的性能比较" class="hash-link" aria-label="Direct link to 4.2-现有 SpMV 工作的性能比较" title="Direct link to 4.2-现有 SpMV 工作的性能比较">​</a></h3>
<p>本文将DASP与CSR5、TileSpMV、LSRB-CSR、cuSPARSE v12.0进行比较，使用BSR和CSR格式，在这里本文将BSR块大小设置为2x2/4x4/8x8，并选择三组中最佳的设置作为cuSPARSE BSR方法的最终性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523233609.png" alt="image.png|center|800" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 12 ： DASP 与 cuSPARSE 在两种GPU上的比较 </font> </center></p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523233756.png" alt="image.png|center|400" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 13 ： 6种计算方式在A100GPU上的性能对比 </font> </center></p>
<p>这六种方法在A100 GPU上针对<strong>FP64精度</strong>的性能如图13所示，而DASP和cuSPARSE v12.0在两个GPU上使用CSR格式进行<strong>FP16精度</strong>时的性能如图12所示。</p>
<p>对于FP64精度性能的比较，可以从图13顶部的子图中看到，<strong>本文的方法在A100 GPU上对于大多数矩阵表现出最佳性能</strong>。具体来说，与这四种方法相比，我们的方法在2403个矩阵上比CSR5快，在2579个矩阵上比TileSpMV快，在2251个矩阵上比LSRB-CSR快，在2340个矩阵上比cuSPARSE BSR快，在2344个矩阵上比cuSPARSE CSR快，平均（几何平均）速度分别提升了1.46倍、2.09倍、3.29倍、2.08倍和1.52倍（最高可达12.64倍、17.48倍、90.59倍、283.92倍和6.94倍）。最佳加速分别出现在矩阵‘rel19’、‘kron_g500-logn20’、‘mycielskian18’、‘lp_osa_60’和‘wiki-Talk’中。</p>
<p>📒：针对性能不太行的矩阵进行了相应的分析：</p>
<p>矩阵‘rel19’的行非常短，因此该矩阵的所有行在DASP中都属于短行类别，并且该矩阵的零元素填充率仅为0.85%，这意味着只有少量的零元素被填充以组成合适的大小。矩阵‘kron_g500-logn20’缺乏明显的块结构，这对TileSpMV方法来说不太友好。矩阵‘wiki-Talk’的非零元素分布相当不规则，少数行占据了大多数非零元素，DASP中处理长行类别的方法正好应对这种情况。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="43-数据结构的有效性">4.3- 数据结构的有效性<a href="#43-数据结构的有效性" class="hash-link" aria-label="Direct link to 4.3-数据结构的有效性" title="Direct link to 4.3-数据结构的有效性">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523234450.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 14 ： 上面的子图显示了在 NVIDIA A100图形处理器上执行21个代表性矩阵的双精度 SpMV 操作的性能比较。下面的子图显示了在 NVIDIA A100和 NVIDIA H800图形处理器上执行21个代表性矩阵的半精度 SpMV 操作的性能比较。条形区域上的“0.00”表示相应的算法无法在矩阵上执行其 SpMV 操作。 </font> </center></p>
<p>为了进行更详细的分析，在图14中列出了 A100和 H800图形处理器上21个代表性矩阵(表2)的 FP64和 FP16精度性能比较。同时，DASP 中不同的类别及其相应的方法使得对各种模式的矩阵进行合适的任务分配以获得良好的性能成为可能。为了证明 DASP 数据结构的有效性，通过分析21个表示矩阵，我们绘制了不同类别中的行数与总行数的比率，以及图14中不同类别中的非零行数与总非零行数的比率。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523234850.png" alt="image.png|center|400" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图15 ： 两个图分别显示了不同类别中的行数和非零数与行数和非零数总数的比率 </font> </center></p>
<p>结合图14和图15可以看出，大多数矩阵在各个类别中相比竞争对手都能表现出更理想的性能。对于短行占大多数的矩阵，例如‘webbase-1M’、‘ASIC_680k’和‘mc2depi’，这些矩阵在FP64和FP16精度上的性能在两种GPU上都完全超越了比较方法。以‘mc2depi’为例，该矩阵的所 有行都属于短行类别，在A100 GPU上，FP64精度性能相较于CSR5、TileSpMV、LSRB-CSR、cuSPARSE-BSR和cuSPARSE-CSR分别提升了2.29倍、4.54倍、3.42倍、4.60倍和1.97倍；在A100和H800 GPU上，FP16精度性能分别比cuSPARSE提升了1.85倍和1.94倍。</p>
<p>对于几乎完全由中等长度行组成的矩阵，例如‘rma10’、‘cant’、‘cop20k_A’、‘pdb1HYS’、‘conf5_4-8x8-10’、‘consph’、‘shipsec1’和‘pwtk’，它们的FP64和FP16精度性能仍能优于其他方法。以‘cop20k_A’为例，该矩阵包含99843个中等长度行和21349个空行（没有非零元素的行），在A100 GPU上，其FP64精度性能相较于CSR5、TileSpMV、cuSPARSE-BSR和cuSPARSE-CSR分别提升了1.53倍、3.63倍、3.08倍和5.75倍；在A100和H800 GPU上，FP16精度性能相较于cuSPARSE分别提升了3.65倍和2.58倍。</p>
<p>对于主要由长行组成的矩阵，例如‘Si41Ge41H72’、‘mip1’和‘Ga41As41H72’，尽管与其他两类方法相比，长行类别的计算方法需要更多的归约操作，但在这些矩阵上仍然能表现出竞争力。图12(a)中的这些矩阵在长行类别中似乎只有很少的行，但长行的长度通常非常大，导致这些矩阵仍然包含大量的长行，如图12(b)所示。</p>
<p>至少由两种类别组成的矩阵也不会因方法差异而导致性能下降，例如‘FullChip’、‘circuit5M’和‘dc2’。以一个较大的矩阵‘circuit5M’和一个中等大小的矩阵‘dc2’为例：在A100上，‘circuit5M’的FP64性能相比于CSR5、LSRB-CSR和cuSPARSE分别提升了1.02倍、2.63倍和1.39倍；在A100和H800上，该矩阵的FP16性能相比cuSPARSE分别提升了3.84倍和6.42倍。在A100 GPU上，‘dc2’的FP64性能相比于CSR5、TileSpMV、LSRB-CSR、cuSPARSE-BSR和cuSPARSE-CSR分别提升了1.35倍、2.11倍、4.95倍、66.89倍和1.50倍；在A100和H800上，该矩阵的FP16性能相比cuSPARSE分别提升了4.72倍和5.60倍。</p>
<p>因此，DASP 可以有  效地利用 MMA 单元，通过在三个类别中使用不同的方法来加速 SpMV。总的来说，DASP 方法是一种广义的 SpMV 方法，这种方法不需要计算具有一定形态特征和字符特征的矩阵，而且几乎任意的矩阵都可以通过 DASP 方法获得良好的性能。我们还发现，一些矩阵在安培和霍珀体系结构上表现出不同的性能: 例如，在 A100上，使用 DASP 方法得到的矩阵‘ Ga41As41H72’的性能优于使用 cuSPARSE 的性能，而在 H800上，使用 cuSPARSE 的性能更好。我们推测这种差异是由于硬件厂商的架构升级，或者可能是 CUDA 核心的优化导致了 H800上某些矩阵的更好性能。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="44-预处理开销比较">4.4-预处理开销比较<a href="#44-预处理开销比较" class="hash-link" aria-label="Direct link to 4.4-预处理开销比较" title="Direct link to 4.4-预处理开销比较">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240523235318.png" alt="image.png|center|600" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 图 16 ：SpMV 方法的预处理成本比较(将基本 CSR 格式转换为新的数据结构) </font> </center></p>
<p>本文还比较了将CSR格式转换为我们的新数据结构的预处理成本。图16显示了CSR5、TileSpMV、cuSPARSE v12.0和我们的DASP的预处理时间。可以看到，与TileSpMV和cuSPARSE相比，DASP的预处理几乎总是更快，并且在矩阵中非零元素数量小于约104.5时也比CSR5（在GPU上原地转换CSR数据格式）更快。即使当矩阵很大时，DASP的预处理时间可能会长于CSR5，但如果迭代求解器需要更多SpMV核心调用，则这被认为是可以接受的。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-related-work">5-Related work<a href="#5-related-work" class="hash-link" aria-label="Direct link to 5-Related work" title="Direct link to 5-Related work">​</a></h2>
<p>许多工作致力于通过各种方法加速SpMV，<strong>例如平衡工作负载、利用数据局部性以及使用机器学习进行算法选择或格式生成</strong>。Anzt等人和Li等人分析了SpMV的性能和能效。Goumas等人、Langr和Tvrdík以及Filippone等人对SpMV的研究进行了综述。在这些研究中，利用块结构受到了很多关注。Im等人、Vuduc等人和Demmel等人的早期工作利用CPU寄存器优化了一些问题（如有限元方法）生成的非常小的块。Buttari等人、Choi等人和Ashari等人研究了块SpMV方法的建模。Buluç等人设计了CSB格式，以利用块布局和缓存局部性。Martone开发了一种用于SpMV的递归分块方法。Yan等人存储了密集块并调整其大小以提高性能。</p>
<p>最近，Niu等人开发了一种<strong>二维块方法，并在GPU上以各种稀疏格式存储这些块</strong>，这种二维块方法还被应用于稀疏矩阵-稀疏向量乘法、稀疏三角求解和稀疏矩阵-矩阵乘法（SpGEMM）。Gao等人提出了一种基于将一个矩阵分成多个密集和稀疏块的对角占优二进制稀疏矩阵的混合压缩格式TaiChi。尽管这些工作将稀疏矩阵分割成小矩阵块，但它们不能直接被最初为小型密集GEMM设计的新兴MMA单元使用。与现有工作不同，本文提出的DASP重构了一种通用的稀疏行数据布局，以利用特定的MMA单元，大大减少了计算部分的成本，并显著提高了整体性能。</p>
<p>由于MMA单元能够为现代处理器带来更高的计算能力，从各个方面对其实际性能和潜在问题进行了评估。Martineau等人对V100 GPU进行了详细的基准测试。Choquette等人介绍了A100 GPU的架构及其相比前几代产品的创新。Sun等人讨论了张量核心编程的吞吐量和延迟。Domke等人确定了在高性能计算和机器学习应用中使用矩阵引擎的实际好处。Chowdhury等人提出了一种名为TCU的计算模型  ，通过捕捉张量单元的主要特征来提供相应的算法。Tukanov等人展示了如何使用延迟分割模型统一不同矩阵引擎的许多硬件特性。Markidis等人量化了GEMM中的精度损失，并提出了一种以增加计算量为代价来减少这种损失的方法。此外，如果正确使用MMA单元，不同精度的GEMM（例如半精度、混合精度和恢复精度）都可以大大提高。此外，<strong>通过架构支持稀疏性、重复内存访问、冗余片上内存层次结构以及与CUDA核心协同工作，张量核心的设计得到了进一步优化。</strong></p>
<p>除了GEMM及其在机器学习和深度学习相关操作中的应用外，还有更多算法可以通过MMA单元加速。<strong>一些基本操作符，如扫描和归约、模板计算和FFT，通过使用张量核心得到了改进</strong>。当在稀疏矩阵中找到小的密集或近密集块结构时，张量核心也能为块级SpGEMM带来好处。此外，当稀疏矩阵与密集矩阵相乘时，关键过程也可以通过张量核心加速，Chen等人、Sun等人和Li等人对此进行了研究。此外，张量核心还被用于一些其他应用，例如线性求解器、分子动力学、量子退火模拟、基因相互作用检测和紧凑分形。与上述使用张量核心解决非GEMM问题的工作相比，本文展示了更多不规则的一般SpMV（输入的稀疏矩阵不一定有小的密集块）也可以通过使用特定的MMA单元加速。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-conclusion">6-Conclusion<a href="#6-conclusion" class="hash-link" aria-label="Direct link to 6-Conclusion" title="Direct link to 6-Conclusion">​</a></h2>
<p>本文提出了一种<strong>利用特定密集 MMA 单元加速一般 SpMV 的新算法 DASP</strong>。本文认为计算部分可能是 SpMV 的一个关键性能瓶颈，并提出了<strong>一种适用于 MMA 单元的 MMA 友好规则稀疏数据结构</strong>。在最新的 NVIDIA Amere 和 Hopper 图形处理器上的实验结果表明，我们的 DASP 比最先进的 SpMV 工作带来了显著的加速。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/paper_notes/3_Kernel/DASP/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/Kernel/DASP/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">论文原件</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#文章笔记提前梳理" class="table-of-contents__link toc-highlight">文章笔记提前梳理</a><ul><li><a href="#文章背景" class="table-of-contents__link toc-highlight">文章背景</a></li><li><a href="#解决措施" class="table-of-contents__link toc-highlight">解决措施</a></li></ul></li><li><a href="#0-abstract" class="table-of-contents__link toc-highlight">0-Abstract</a></li><li><a href="#1-introduction" class="table-of-contents__link toc-highlight">1-Introduction</a></li><li><a href="#2-background" class="table-of-contents__link toc-highlight">2-Background</a><ul><li><a href="#21-spmv-及其性能分析" class="table-of-contents__link toc-highlight">2.1-SpMV 及其性能分析</a></li><li><a href="#22-特殊的-mma-单元" class="table-of-contents__link toc-highlight">2.2-特殊的 MMA 单元</a></li></ul></li><li><a href="#3-dasp" class="table-of-contents__link toc-highlight">3-DASP</a><ul><li><a href="#31-dasp-概述" class="table-of-contents__link toc-highlight">3.1-DASP 概述</a></li><li><a href="#32-数据结构" class="table-of-contents__link toc-highlight">3.2-数据结构</a></li><li><a href="#33-算法介绍" class="table-of-contents__link toc-highlight">3.3-算法介绍</a></li><li><a href="#短行" class="table-of-contents__link toc-highlight">短行</a></li></ul></li><li><a href="#4-experimental-results" class="table-of-contents__link toc-highlight">4-Experimental results</a><ul><li><a href="#41-实验设置" class="table-of-contents__link toc-highlight">4.1-实验设置</a></li><li><a href="#42-现有-spmv-工作的性能比较" class="table-of-contents__link toc-highlight">4.2-现有 SpMV 工作的性能比较</a></li><li><a href="#43-数据结构的有效性" class="table-of-contents__link toc-highlight">4.3-数据结构的有效性</a></li><li><a href="#44-预处理开销比较" class="table-of-contents__link toc-highlight">4.4-预处理开销比较</a></li></ul></li><li><a href="#5-related-work" class="table-of-contents__link toc-highlight">5-Related work</a></li><li><a href="#6-conclusion" class="table-of-contents__link toc-highlight">6-Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper-notes-intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs-intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>