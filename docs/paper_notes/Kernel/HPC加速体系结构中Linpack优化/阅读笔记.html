<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="Abstract"><meta data-rh="true" property="og:description" content="Abstract"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.0287982b.css">
<script src="/assets/js/runtime~main.dfc3d2e7.js" defer="defer"></script>
<script src="/assets/js/main.c1d9f81a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper-notes-intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs-intro">个人博客</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper-notes-intro">笔记说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/Kernel/intro">Kernel</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/intro">说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/AlphaSparse/论文原件">AlphaSparse</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/CSR5/论文原件">CSR5</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/DASP/论文原件">DASP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件">HPC加速体系结构中Linpack优化</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HiCOO/Z-Morton顺序">HiCOO</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/IA-SpGEMM/论文原件">IA-SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/J-基于 SpMV 的应用程序开销自觉的格式选择/论文原件">J-基于 SpMV 的应用程序开销自觉的格式选择</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/ML-SpMV-thread/论文原件">ML-SpMV-thread</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/MSREP/论文原件">MSREP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Spmv任务自动分配/intro">Spmv任务自动分配</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Tile-GEMM/论文原件">Tile-GEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/z-模版/论文原件">z-模版</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Kernel</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">HPC加速体系结构中Linpack优化</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">阅读笔记</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#abstract">​</a></h2>
<p>本文介绍了在rocHPL中进行的性能优化。【<font color="gray" face="华文宋体"><b>rocHPL是基于HPL基准应用程序的一个基准，它在AMD的Radeon Open Compute ROCm平台、运行时和工具链之上实现。rocHPL使用HIP编程语言创建，并针对AMD最新的离散型GPU进行了优化。</b></font>】，这是AMD开源实现的<font color="red"><b>面向加速节点架构</b></font>的<strong>高性能Linpack（HPL）基准测试</strong>，旨在用于像Frontier超级计算机这样的exascale系统。rocHPL通过<strong>高度优化的线性代数库</strong>和<strong>整个CPU插槽执行延迟敏感型分解阶段</strong>，使节点上高吞吐量的GPU得到了加速。</p>
<p>基于此基础上，本文详细介绍了一些<strong>新颖的性能改进</strong>，例如<strong>在CPU上使用多线程方法计算panel分解阶段</strong>，<strong>在节点上对CPU核心进行进程时间共享</strong>，以及<strong>隐藏MPI通信</strong>等多项优化。</p>
<p>最后展示了性能改进后的HPL基准测试实现  在Frontier早期访问集群中单个节点上的一些性能结果，并展示了扩展到多个节点时的情况。</p>
<p>（本篇文章是对HPL基准测试进行的改进！）</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduce">Introduce<a class="hash-link" aria-label="Direct link to Introduce" title="Direct link to Introduce" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#introduce">​</a></h2>
<p>2022年6月，位于橡树岭国家实验室（ORNL）的Frontier超级计算机以1.1 ExaFLOPS 的高性能Linpack（HPL）得分登上了Top500超级计算机排行榜的首位。Frontier的得分是前一名超级计算机得分的两倍以上，它是有史以来<font color="red"><b>第一台在HPL测试中达到超过一ExaFLOPS的超级计算机</b></font>，标志着它成为了第一台真正意义上的百亿亿次规模计算机。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240111143333.png" alt="image.png|center|800" class="img_ev3q"></p>
<blockquote>
<font color="gray" face="宋体-简" size="4"><b>HPL测试通常指的是High Performance Linpack测试，是一种用于衡量计算机性能的基准测试。HPL测试的主要目标是评估计算机系统在解决大规模线性代数问题时的性能。这个测试通常涉及解决一个非常大的线性代数系统的问题，该问题由线性方程组和矩阵运算组成。解这个问题的性能被用作衡量计算机集群、超级计算机或其他高性能计算系统性能的指标之一。HPL测试的结果通常以每秒浮点运算次数（Floating Point Operations Per Second，FLOPS）来衡量。这个测试在高性能计算领域中被广泛使用，用于比较不同系统的性能，并帮助评估其在科学、工程和其他计算密集型任务中的适用性。</b></font>
</blockquote>
<p>不久之后，AMD 对 HPL 的优化实现，命名为 rocHPL  ，<strong>开源并免费提供</strong>。rocHPL是由HPL实现的一个具有惠普企业(HPE)提供优化通信性能并且能够在Frontier运行且可以超过一个EFlops的变体。在本文中详细介绍了<strong>一些有助于实现这一效果的性能优化</strong>，并期望这些<strong>性能优化为用户在异构架构上优化 HPL 提供有用的信息</strong>。</p>
<p>HPL 是用于度量计算机系统某些方面的许多基准测试之一。其他常见的基准包括高性能共轭梯度(HPCG)基准，它强调系统的主要内存带宽和全系统的全降性能，以及高性能 Linpack 混合精度(HPL-MxP)基准，它强调系统混合和低精度数学运算的计算吞吐量。与这些其他基准测试一样，<strong>HPL</strong> 有效地强调了计算机系统的几个方面，包括<strong>64位浮点计算速率</strong>、<strong>网络带宽</strong>和<strong>延长时间的网络延迟</strong>，同时<strong>基本上利用了系统可以使用的峰值功率</strong>。这使得 HPL 成为验证新计算机系统的可靠性和整体性能的一个非常有用的压力测试。</p>
<p>在Frontier上，HPL的高FLOP率<font color="red"><b>几乎完全归功于其GPU加速节点架构和高速网络</b></font>。<font color="red"><b>加速器的存在</b></font>是高性能计算中的一个增长趋势。事实上，截至2022年6月，在Top500榜单上排名前十的超级计算机中，有七台采用了<font color="green"><b>GPU加速节点架构</b></font>。</p>
<p>在Frontier的情况下，每个<strong>节点</strong>由一个64核心的AMD EPYC CPU和四个AMD Instinct MI250X GPU加速器组成【一个节点= 一个64核心的CPU + 四个GPU加速器（cpu核心数与显卡数的比值为16 : 1 ）】。EPYC CPU和MI250X GPU都利用了AMD先进的封装技术作为多芯片模块（MCMs）。CPU插槽由八个8核心Core Complex Dies（CCDs）和一个IO die组成，而每个MI250X GPU由两个图形计算Die（GCDs）组成。这些GCDs彼此连接，并通过AMD Infinity Fabric与CPU插槽 相连。采用这种架构，每个Frontier节点中的MI250X加速器贡献了超过98%的节点峰值FLOPS速率。</p>
<p>HPL基准测试中进行的计算是使用带有<font color="red"><b>部分主元高斯消去法【partial pivoting】</b></font>的N×N随机线性方程组的解。</p>
<p>矩阵A（大小为N×N）通过<font color="green"><b>2D块循环分布方式</b></font>在P×Q个MPI进程网格上进行负载平衡。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240302140819.png" alt="image.png|center|600" class="img_ev3q"></p>
<blockquote>
<p>3.3: Partial Pivoting When performing Gaussian elimination, the diagonal element that one uses during the elimination procedure is called the pivot. To obtain the correct multiple, one uses the pivot as the divisor to the elements below the pivot. Gaussian elimination in this form will fail if the pivot is zero. In this situation, a row interchange must be performed. Even if the pivot is not identically zero, a small value can result in big roundoff errors. For very large matrices, one can easily lose all accuracy in the solution. To avoid these round-off errors arising from small pivots, row interchanges are made, and this technique is called partial pivoting (partial pivoting is in contrast to complete pivoting, where both rows and columns are interchanged).
在执行高斯消元法时，消元过程中使用的对角元素称为主元(<strong>枢轴</strong>)。为了获得正确的倍数，可以将主元作为除数应用于主元下方的各个元素。如果主元为零，则以此情况下需要进行行交换。即使主元不完全等于零，一个很小的值也可能导致大量舍入误差。对于非常大的矩阵，解可能会失去所有精度。为了避免由于小主元而产生舍入误差，进行行交换，并且这种技术被称为<font color="red"><b>partial pivoting</b></font>（与complete pivoting相反，在complete pivoting中同时交换行和列）。</p>
</blockquote>
<p>利用GPU加速器在HPL中的高FLOP速率需要仔细考虑其四个主要阶段的实现，每个阶段具有不同的计算特性。</p>
<ul>
<li>Panel factorization (FACT)</li>
<li>Panel broadcast (LBCAST)</li>
<li>Row-swapping (RS)</li>
<li>Trailing update (UPDATE)<!-- -->
<ul>
<li>在这个阶段需要三角形矩阵的转置操作以及矩阵和矩阵相乘的操作。</li>
</ul>
</li>
</ul>
<p>通常，<font color="red"><b>HPL 基准测试中的绝大多数时间都花费在后续更新阶段的 DGEMM 例程中</b></font>。这些例程经常在不同的硬件上进行高度优化，使得 HPL 分数能够达到硬件峰值浮点运算率的显著部分。随着加速器在过去十年中变得越来越流行，已经有一些研究在 HPL 中利用它们的工作。</p>
<p>一种自然的方法是<strong>使用加速器来提高 HPL 中大型 DGEMM 计算的性能</strong>，<em>将矩阵保留在 CPU 内存中，并将 DGEMM 操作分解成更小的块，一块一块地处理，与数据传输交织在一起，从而将 DGEMM 操作加载到加速器中</em>。</p>
<font color="grey" size="3" face="宋体-简"><p>一些研究现状：</p><br><p>    Endo 和 Matsuoka 首次研究使用 Clear-Speed SIMD 加速器来提高 HPL 中 DGEMM 性能，该异构集群中只有一些节点包含加速器。</p><br><p>    Kistler 等人在 Road-runner 超级计算机上也将这种将 DGEMM 工作加载到加速器的想法应用于 HPL  ，他们使用了 IBM Power XCell 8i 加速器。</p><br><p>    Fatica 描述了在 GPUs 上使用 CUDA 的方法，在其中他们描述了一个管道策略，用于移动矩阵的部分到GPU 来加速 DGEMM 和 DTRSM 例程，并隐藏这个数据传输在 GPU 上的计算时间后面。</p><br><p>    Wang 等人和 Rohr 等人描述了将这种管道策略扩展到完整集群的演示。其他作者考虑了类似的方法来处理其他编程模型，如 OpenCL ，以及其他加速器如 Intel Xeon Phi ，甚至混合不同类型加速器的集群.</p><br><p>    在更近期的文章中，一些作者已经注意到 <b>加速器的计算速率增长超过了主机-加速器链接带宽</b> 的改进。事实上，一些现代GPU加速器，包括MI250X GPU，还包括专门的硬件单元，进一步加快了矩阵乘法运算的计算速率。</p><br><p>    为了隐藏主机和加速器之间的数据传输，在每个内核中进行的计算量必须大幅增加，通常导致HPL中出现不合理大的阻塞参数，在其他阶段引发瓶颈。为缓解这种情况，Tan等人和Kim等人提出了在现代GPU加速器上实施HPL时，<b>将整个问题存储在GPU内存中而非主机DDR上</b>，并且这个想法最初出自Kistler等人。这样做有利于消除对大型计算例程移动数据到加速器所需操作，然后几个较大规模MPI通信阶段也可以利用支持GPU-aware的MPI例程直接在不同GPU之间移动数据，并且利用节点内部各GPU之间快捷硬件连接链路。在这种实现中，一些复杂性问题会出现。<b>面板分解仍然是HPL中一个复杂的通信和延迟敏感阶段，不适合加速器上的细粒度并行处理</b>。此外，MPI通信仍然必须由主机进程协调，并且将这些通信与加速器上的有用工作重叠可能具有挑战性。</p><br><p>    Tan等人和Kim等人选择利用主机CPU执行面板分解，在每次迭代时只传输所需数据到GPU，这减少了数据移动量，使得FACT和LBCAST阶段可以轻松地与GPU上的尾部更新计算重叠。执行行交换阶段所需的通信随后引入了GPU空闲时间，两项研究通过将行交换和尾部更新拆分为几个较小的片段并进行流水线处理来隐藏较小尾部更新的通信以解决该问题。</p><br><p>     Tan等人甚至进一步使用多个CPU线程进行流水线处理以推进面板广播阶段同时进行面板分解过程。这种方法可能导致网络接口拥塞，并且Kim等人没有使用此方法，而是使用NVIDIA的NCCL通信库进行GPU直接通信，该库使用GPU内核进行数据传输，使其与其他通信重叠变得不切实际。</p></font>
<hr>
<p>笔记📒：在利用加速器来加速GEMM的过程中，首先是利用包含SIMD加速器的一些节点来进行加速，随后，发展出了使用GPU（管道）的策略，使用管道的基本思想是：通过移动矩阵的一部分到GPU上来进行加速相应部分的计算，并将这个传输数据的时间隐藏在GPU计算时间的后面。但是，慢慢的加速器的计算速率的增长超过了主机-加速器之间的链接带宽，因此不得不增加每个内核中的计算量来隐藏数据传输的时间，但这又会引发不合理的阻塞参数从而在其他阶段引发瓶颈。为了缓解该现象，提出将整个问题存储在GPU内存上的想法，使得数据的移动直接通过GPU内部的数据通道来进行。不幸的是，面板分解是HPL中复杂的通信和延迟敏感的阶段，不适合在加速器上进行细粒度的并行处理，并且MPI通信仍然必须由主机进程进行协调，因此实现通信和计算的重叠并不容易。一个改进的办法是，利用CPU执行面板分解阶段，每次只传输部分数据到GPU中进行舒尔布更新的计算（GEMM），从而实现计算的重叠。</p>
<hr>
<p>在本文中，详细介绍了我们为HPL实施的一些优化措施，以提高在GPU加速节点架构（如Frontier）上的性能。特别是，<font color="red" face="华文宋体"><b>在固有串行面板因子化阶段中，详细介绍了一种多线程策略，用于提取数据并行性，并通过分散舒尔补更新公式，来重叠CPU和GPU计算和隐藏GPU-GPU通信时间</b></font>。然后，我们展示了这种HPL基准测试实现在ORNL Crusher集群上的性能结果，显示出我们优化措施在隐藏MPI通信时间方面的有效性，并展示出良好的扩展到多个节点的性能，并随后给出一些结论性意见。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="hpl-overview">HPL Overview<a class="hash-link" aria-label="Direct link to HPL Overview" title="Direct link to HPL Overview" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#hpl-overview">​</a></h2>
<p>HPL基准测试从在P×Q个进程的二维网格上生成一个分布式N×N双精度矩阵A开始。为了负载平衡，全局矩阵A被划分成大小为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mi>B</mi><mo>×</mo><mi>N</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">NB×NB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">NB</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05017em">NB</span></span></span></span>的面板，并以2D块循环方式将这些<strong>面板</strong>分配给处理器网格。</p>
<p>对于2×2处理器网格，此分配示例在图1中有图形表示。还生成长度为N的向量b，并附加到A以形成一个N×(N+1)的增广系统。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240302143450.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>线性系统的求解采用<strong>分块高斯消元算法</strong>，并带有<strong>部分旋转</strong>（partial pivoting）。
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>P</mi><mi>L</mi><mi>U</mi></mrow><annotation encoding="application/x-tex">A = PLU</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal" style="margin-right:0.10903em">LU</span></span></span></span>
其中，P是通过partial pivoting引入的矩阵，使得LU更容易分解，更具有健壮性。</p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mi>L</mi><mi>U</mi><mi>x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>b</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>L</mi><mi>U</mi><mi>x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>P</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>b</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>U</mi><mi>x</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>L</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>P</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>b</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>x</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><msup><mi>U</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>L</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><msup><mi>P</mi><mrow><mo>−</mo><mn>1</mn></mrow></msup><mi>b</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
PLUx &amp;= b \\
LUx &amp;= P^{-1}b \\
Ux &amp;= L^{-1}P^{-1}b \\
x &amp;= U^{-1}L^{-1}P^{-1}b
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6.0723em;vertical-align:-2.7862em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2862em"><span style="top:-5.4462em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal">LUx</span></span></span><span style="top:-3.9221em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">LUx</span></span></span><span style="top:-2.3979em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">Ux</span></span></span><span style="top:-0.8738em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">x</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.7862em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.2862em"><span style="top:-5.4462em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">b</span></span></span><span style="top:-3.9221em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span><span style="top:-2.3979em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span><span style="top:-0.8738em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">b</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.7862em"><span></span></span></span></span></span></span></span></span></span></span></span>
<p>分块高斯算法沿 A 对角线迭代进行，每次迭代由四个主要阶段组成，这四个阶段本身包括不同层次的计算和进程之间的通信。这四个阶段如下图所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240302171310.png" alt="image.png|center|1000" class="img_ev3q"></p>
<ul>
<li>a:首先，在每次迭代中，沿着A的对角线当前位置的NB列块被LU分解，仅在这些NB列块内应用<strong>行pivot</strong>，并保持矩阵的其余部分不变。（ <font color="red"><b>在这里不仅仅进行了块LU分解，并且在分解之前，还应用了row-pivot（虽然仅仅是对一小块对角线元素进行partial pivot，但是仍然需要和该对角线块下的各个列块中的行元素进行比较，选出最好的行，交换到需要分解的对角线块中）</b></font>，因此，在计算U块时所需要的A块不能使用之前的A块，需要等待之前的进程进行完row-pivot之后，再进行应用。）此阶段称为“面板分解”（FACT）阶段，如图2a中2 × 2流程网格的图形化显示。只有最左边的面板块被访问，如图中有图案的面板所示，并且只有在拥有这些NB列的部分的进程中才能访问。<strong>参与面板分解的进程必须经常通信，以便确定在分解过程中应用的NB行枢轴</strong>。图中这些进程之间的通信用箭头表示。每次确定主行的通信本质上是一个集体的all-reduce操作，涉及该进程列中的所有进程，因为这些进程必须共同确定主行并接收该行的副本。在此阶段结束时，面板列将被旋转并进行LU因子分解，产生分布在过程列之间的N × NB下三角矩阵L。</li>
<li>b:一旦面板分解完成，参与因式分解的每个进程都会将他们的L矩阵部分打包，以及传达枢轴信息的一些索引数据，放入缓冲区，并将此缓冲区广播给处理器网格中其行中的所有其他进程。这一步骤在图2b中以图形方式显示。在此步骤中不执行任何计算，只访问或修改保存L的缓冲区中的数据。由于对于大多数HPL基准测试来说L矩阵通常很大，因此该阶段的性能严重依赖于可用于进程间通信的带宽量以及所使用广播算法的效率。</li>
<li>c:随着L矩阵和枢轴信息广播到所有进程，每个进程的最后主要通信阶段是将FACT中确定的所有行枢轴应用于每个进程上A矩阵的剩余部分，并共同构建位于NB × NB当前因子面板右侧的U矩阵。由于在此阶段已知NB节点的全部集合，因此我们可以通过相当于MPI_Scatterv的例程，然后是|MPI_Allgatherv|，来批量执行所需的通信。每个进程首先将它们要通信的行组装到缓冲区中，这需要对它们的局部A矩阵进行不规则访问。包含当前因子面板的流程行中的每个流程然后通过Scatterv通信将NB源行分散到每个流程列中的目标流程。在此之后，列中的所有进程通过Allgatherv通信共同组装分布式NB×N矩阵U的各自部分。所访问的数据和通信方向如图2c所示。</li>
<li>d:迭代的最后阶段是计算需求最高的阶段，但不需要进程间通信。全局矩阵的主元行已经组装成U矩阵，并且从FACT中进行的计算被扩展到这些行，并作为单个DTRSM例程应用，使用因子化对角面板的下三角部分。随着L和U矩阵在处理行和列上构建并复制，最后一次计算是对A尾部子矩阵应用秩为NB的更新，在所有进程之间分布。这个计算是一个分布式N×N×NB DGEMM，它从A尾部子矩阵中减去LU乘积。用于此计算访问的数据在图2d中以图形方式显示。</li>
</ul>
<p>和之前论文（[[A Communication-Avoiding 3D LU Factorization Algorithm for Sparse Matrices#^818cc3|3D-LU分解过程]]）的区别：</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20231018152130.png" alt="image.png|center|800" class="img_ev3q">
这篇文章，在使用LU分解算法之前，就对整体实施了partial-pivot算法，因此在进行信息传递时，不需要等待新的Aii块，所以阶段会少一个。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="rochpl-design">rocHPL Design<a class="hash-link" aria-label="Direct link to rocHPL Design" title="Direct link to rocHPL Design" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#rochpl-design">​</a></h2>
<p>AMD 对 HPL 基准的实现，命名为 rocHPL，是基于开源 HPL 实现的，托管在Netlib上。这个参考的 HPL 代码是使用 MPI 进行并行化处理的，但除此之外不包含其他并行编程模型。我们对这个 HPL 实现进行了修改，通过 AMD 的 ROCm 平台、运行时和工具链添加了 GPU 支持。rocHPL 代码是用 HIP 编程语言编写的，通过 rocBLAS 数学库，并利用针对 AMD 最新离散 GPU 高度优化的线性代数例程来实现。</p>
<p>如上所述，Tan等人的最新论文和Kim等人的最新论文都认为现代加速器的计算吞吐量非常大，以至于<font color="red"><b>整个矩阵A必须存储在加速器的高带宽内存（HBM）中，因为加速器和CPU内存之间传输数据成本过高</b></font>。由于AMD Instinct MI250X加速器包含专门用于加速关键DGEMM计算的硬件，计算吞吐量甚至进一步提高，超出了这些论文呢所考虑的范围。因此，在rocHPL中我们必须遵循类似设计，在MI250X每个128 GB HBM容量上存储矩阵A。</p>
<p>然后，考虑是否应该在加速器上执行 HPL 基准测试的所有阶段就变得很自然了，因为主机进程只用于协调 MPI 通信。当然，UPDATE 阶段非常适合加速器的高计算吞吐量。同样，LBCAST 和 RS 相位很容易映射到加速器，因为使用 GPU 的高内存带宽加速了行交换所需的本地数据运动，MPI 通信可以利用 GPU 之间的高带宽 Infinity Fabric 链接以及网络接口卡(NIC)与节点上的 GPU 的直接连接。然而，在加速器上执行 FACT 阶段仍然是一个挑战。虽然 FACT 中的许多单个 BLAS 计算确实会在 GPU 上加速，但行旋转所需的通信将需要频繁的主机-设备同步，并因此由于内核启动延迟而引入大量的 GPU 空闲时间。因此，我们遵循类似于 Tan 等人和 Kim 等人的方法，并<font color="red"><b>将必要的数据传输回主机进程，以便在将所需数据发送回加速器之前，在 CPU 上执行 FACT 计算</b></font>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240302173846.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>幸运的是，通过在 CPU 上执行 FACT 阶段，可以使用 HPL 基准测试中的“ look-ahead”机制，通过本地计算隐藏一些必要的 MPI 通信，这种方法相对简单。通过注意到每个迭代的 FACT 阶段只需要矩阵的下一个 NB 列，前瞻通过在下一个迭代中执行 FACT 阶段的每个流程上拆分 UPDATE 阶段来工作。<font color="red"><b>这些进程首先只对前导 NB 列执行 UPDATE 阶段，然后立即开始将这些列传输到主机进行因式分解，同时在剩余的本地矩阵上完成 UPDATE 阶段。</b></font>这种方法导致了一个迭代，其执行时间线与图3中所示的类似。当 UPDATE 阶段开始时，计算首先在前瞻上执行，这样这部分列可以传输到 CPU，然后在 FACT 阶段之后传输回来。一旦 FACT 数据返回到 GPU 上，LBCAST 通信就可以在 GPU 上完成剩余的后续 UPDATE。不参与 FACT 阶段的进程只需在 LBCAST 阶段中等待。在 UPDATE 阶段完成后，应用 FACT 中计算的行枢纽，这需要 GPU 内核收集要通信的行，然后  是 MPI 通信，再用 GPU 内核将接收到的行分散回 A。</p>
<p>上面是基础的rocHPL的思想。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="多线程panel分解">多线程Panel分解<a class="hash-link" aria-label="Direct link to 多线程Panel分解" title="Direct link to 多线程Panel分解" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#多线程panel分解">​</a></h3>
<p>在HPL基准测试开始时，加速器中每次迭代的计算工作可以有效地隐藏用于FACT计算的主机传输和LBCAST通信。但随着基准测试的进行，UPDATE阶段中执行的工作量逐渐减少，直到无法再隐藏这些其他阶段。</p>
<p>为了最大化通过UPDATE隐藏通信和分解的持续时间，并尽量减少关键路径上没有UPDATE阶段所需的时间，<font color="red"><b>尽快在CPU上执行FACT阶段是至关重要的</b></font>。</p>
<p>rocHPL中的设计是让每个MPI进程管理一个且仅有一个GPU设备。在MI250X GPU的情况下，模块的每个GCD都会被操作系统识别为独立的GPU，因此<strong>每个MPI等级管理一个唯一的GCD。假设每个MPI等级也绑定到不同的CPU核心，这将导致潜在地有很多未使用的CPU核心可以通过多线程在FACT阶段中利用</strong>。虽然许多CPU BLAS库提供了计算密集型BLAS例程（如FACT所需的DGEMM和DTRSM） 的多线程实现，但我们选择手动将计算分配给CPU线程来对整个FACT阶段进行多线程处理。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240302175734.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>在FACT阶段LU分解的矩阵是高而瘦的。它只包含NB列，但可能有成千上万行。这使得可以通过在主机上将行块分配给线程来并行化处理，<font color="red"><b>在FACT阶段开始时，创建一个包含T个线程的OpenMP并行区域，并通过将高而瘦的矩阵划分为NB行大小的块状图块，在每个线程之间以轮流方式分配块来分配工作</b></font>，如图4中所示。我们选择方形图块尺寸纯粹是出于方便考虑，因为这样第一个图块将被保证被指定给主线程，并且该图块将包含上三角形因子以及在选择枢轴期间的所有源行，都保证被分配给主线程。</p>
<p>基于rocHPL的原始Netlib HPL代码包含几种串行和分块LU分解方法，包括左向、右向和Crout分解。</p>
<ul>
<li>每种方法都可以直接使用平铺策略进行并行化。枢轴行的确定被实现为在所有OpenMP线程上的并行归约，之后主线程调用MPI来完成跨进程列的归约。然后主线程应用行交换，并与其余线程同步，以便使用所有线程以并行方式对尾部子矩阵进行秩-1更新。</li>
<li>对于分块分解方法，类似的思想被应用，在此主线程执行DTRSM更新到上三角因子，之后每个线程使用结果执行他们各自部分的尾随更新。通过这种方法，每个块中的数据只能由一个线程访问，除了在应用行交换时主要线程可能会有任何访问外。因此，数据可以驻留在 CPU 缓存附近，此外，使用 Frontier 上的64核 AMD CPU，在 FACT 阶段访问的所有数据通常都驻留在 L3缓存中</li>
</ul>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240302181741.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>为了展示 FACT 阶段中这种多线程策略的性能优势，我们在单个 Frontier 节点上使用 BLIS v4.0 作为 CPU BLAS 库进行性能测试，并在图 5 中展示结果。当对一个 M × NB 矩阵进行因式分解时，我们测量了 NB = 512 和 取不同倍数的 NB（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>−</mo><mn>1</mn><msup><mn>0</mn><mn>5</mn></msup></mrow><annotation encoding="application/x-tex">0-10^5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">0</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span>） 的情况下 FACT 阶段的性能。我们使用单个进程运行此测试，以消除主线程确定和交换 MPI 中枢所需的时间。通过不同数量的 CPU 核心跨越这些问题规模执行 FACT 计算。从图表中可以看出，通过多线程技术大幅提高了 FACT 阶段的性能，并且即使对于相对较小的问题规模来说，使用大量 CPU 核心也会带来更好的性能效果。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="cpu核心时间共享">CPU核心时间共享<a class="hash-link" aria-label="Direct link to CPU核心时间共享" title="Direct link to CPU核心时间共享" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#cpu核心时间共享">​</a></h3>
<p>对于 FACT 阶段的多线程策略，<strong>一个重要的考虑因素是在哪里放置 CPU 线程以最大限度地提高每个 FACT 计算的性能</strong>。考虑 Frontier 节点体系结构的例子; <strong>因为节点中存在8个 GCD，所以我们启动8个 MPI 进程，并将每个进程绑定到最接近它将要管理的 GCD 的 CCD</strong> 。因此，一个自然的选择是让每个进程在进入 FACT 阶段时  创建7个额外的 OpenMP 线程，以便该进程可以利用其 CCD 中的所有8个 CPU 核。</p>
<p>然而，通常情况下，<font color="red"><b>一个进程可以利用比通过简单分区所有可用核心更多的CPU核心</b></font>。考虑Frontier节点架构上的P×Q=2×4的二维进程网格。在HPL计算的任何迭代中，只有两个进程会协调计算面板因子化，而其他六个进程则等待接收LBCAST。如果执行面板因子化的两个进程每个使用八个CPU核心，而其余六个MPI进程每个使用一个CPU核心，则在此迭代期间套接字上将有42个空闲CPU核心。随着基准测试进行迭代，FACT阶段中正在使用的16总CPU核心将在不同CCD之间循环，并且我们仍然会在每次迭代中观察到42总空闲CPU核心。<strong>根据这一观察结果，我们考虑了一种通用方法，在HPL每次迭代时通过超订阅OpenMP线程到物理CPU内核来利用所有CPU内核</strong>。（这段讨论了如何在计算过程中更有效地利用CPU核心。在Frontier节点架构的系统上，作者考虑了一个2维的进程网格，其中有P×Q = 2×4个进程。在HPL计算中的每个迭代中，只有两个进程会协调计算面板分解，而其他六个进程则处于等待状态。如果这两个执行面板分解的进程每个都使用了八个CPU核心，而其余的六个进程每个只使用了一个CPU核心，那么在此迭代期间会有42个CPU核心处于空闲状态。尽管在不同的迭代中，正在使用的16个CPU核心会在不同的计算单元之间轮换，但每次迭代中仍会保持42个总的空闲CPU核心。作者提出了一种通用的方法，通过超订阅OpenMP线程到物理CPU核心，来利用每个HPL迭代中的所有CPU核心。简而言之，这段文字讨论了如何在计算过程中通过合理分配CPU核心资源来提高计算效率。）</p>
<p>在启动节点本地 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>Q</mi></mrow><annotation encoding="application/x-tex">P × Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span> 进程网格到具有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span></span> CPU 核的节点的一般情况下，首先，将每个进程绑定到一个不同的根核（就是每个进程先分配一个CPU cores，而不是像之间简单分区那样，每个进程上来就给平均分配8个CPU cores），并将剩余的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>C</mi><mo stretchy="true">‾</mo></mover><mo>=</mo><mi>C</mi><mo>−</mo><mi>P</mi><mi>Q</mi></mrow><annotation encoding="application/x-tex">\overline{C} = C-PQ</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8833em"></span><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8833em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span><span style="top:-3.8033em"><span class="pstrut" style="height:3em"></span><span class="overline-line" style="border-bottom-width:0.04em"></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">PQ</span></span></span></span> 核视为一个资源池。这个池被划分为不重叠的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi></mrow><annotation encoding="application/x-tex">P</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span></span></span></span> 组，每个组都有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mover accent="true"><mi>C</mi><mo stretchy="true">‾</mo></mover><mi>P</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{\overline{C}}{P}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3888em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0438em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord overline mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9283em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span></span></span><span style="top:-3.8303em"><span class="pstrut" style="height:3em"></span><span class="overline-line mtight" style="border-bottom-width:0.049em"></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 核心，并且每个组被分配到一个不同的进程行。</p>
<p>然后，每个进程列中的每个 MPI rank 使用 OpenMP 绑定来指定总共的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>1</mn><mo>+</mo><mfrac><mover accent="true"><mi>C</mi><mo stretchy="true">‾</mo></mover><mi>P</mi></mfrac></mrow><annotation encoding="application/x-tex">T = 1 + \frac{\overline{C}}{P}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.3888em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0438em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord overline mtight"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9283em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em">C</span></span></span><span style="top:-3.8303em"><span class="pstrut" style="height:3em"></span><span class="overline-line mtight" style="border-bottom-width:0.049em"></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> OpenMP 线程，并将它们绑定到它的根核心和它的进程行的池分区。通过这种方式，每个 FACT 阶段都将利用节点上总共的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mi>T</mi><mo>=</mo><mi>P</mi><mo>+</mo><mover accent="true"><mi>C</mi><mo stretchy="true">‾</mo></mover></mrow><annotation encoding="application/x-tex">P\times T = P + \overline{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8833em"></span><span class="mord overline"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8833em"><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">C</span></span></span><span style="top:-3.8033em"><span class="pstrut" style="height:3em"></span><span class="overline-line" style="border-bottom-width:0.04em"></span></span></span></span></span></span></span></span></span> CPU 核。</p>
<p>在节点上的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">P × 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span>本地进程网格的极端情况下，这种核心绑定简化为对可用 CPU 核的简单分区，因为节点上的所有进程都必须同时参与 FACT 阶段。在节点上的1 × Q 局部进程网格的相反极端，CPU 核心共享的数量最大化，因为在任何给定的时间，节点上最多只有一个进程将计算 FACT 阶段。</p>
<p>在rocHPL中，我们已经实现了一个通用的包装脚本，在启动基准测试时计算这些OpenMP绑定。CPU核心时间共享以及将全局问题分解到计算节点之间使用描述了每个节点上所需的本地进程网格配置的用户输入。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="分解-舒尔补更新">分解 舒尔补更新<a class="hash-link" aria-label="Direct link to 分解 舒尔补更新" title="Direct link to 分解 舒尔补更新" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#分解-舒尔补更新">​</a></h3>
<p>对图3中执行的时间线视图的检查表明，主机 CPU 和加速器之间的工作分工允许在本地 UPDATE 计算后有效地隐藏 FACT 和 LBCAST 阶段。但是，执行 RS 相位所需的通信时间仍然会导致加速器上的空闲时间。因此，直接的想法是将RS的时间也隐藏到Update的阶段中。</p>
<p>一种简单的实现通信隐藏的方法是<strong>将RS和UPDATE阶段按列划分为几个较小的块，并应用流水线策略</strong>。通过这种方式，<strong>执行更新阶段时对一个块进行本地计算可以隐藏下一个  块RS阶段的通信时间</strong>。这种策略在Tan和Kim中被应用，他们都使用多线程实现来协调不同块和不同阶段。然而，在我们HPL实现中，这样的多线程策略成本高昂，因为使用多个线程来流水线化不同阶段会利用CPU核心，否则可能被用于FACT。</p>
<p>我们选择另一种替代方法来隐藏RS阶段的通信时间，而无需额外的多线程，我们称之为“分割更新”。让n表示HPL基准测试开始时，A矩阵的局部矩阵块的列数量。请注意，由于矩阵A的2D块循环分布，对于每个进程列中的所有进程，n将是相同的。考虑将局部矩阵块按列拆分为两部分，其中包含n1和n2列，我们称之为局部A矩阵的“左”和“右”部分。我们选择使n1成为NB的倍数。我们用UPDATE1和UPDATE2表示在左侧和右侧部分上应用UPDATE阶段，并且类似地进行RS阶段处理。<font color="red"><b>拆分更新的想法是利用一个区域上的UPDATE计算来隐藏另一个区域RS阶段MPI通信所需时间</b></font>。关键观察结果是要实现这一点：<strong>在另一个区域开始UPDATE之前必须先收集该区域RS阶段所需行数</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240303234445.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>拆分更新公式导致执行时间表的时间轴类似于图6所示。在迭代开始时，我们假设RS2通信已经完成。也就是说，我们假设本地A矩阵右侧部分的行已经被通信了，尽管不一定散回到A中。我们通过从前瞻和左侧部分收集需要进行通信的行，并将右侧部分通信的行散回到A来开始迭代。当行被散回时，仅对前瞻进行行通信，并将接收到的行写入前瞻中。然后迭代继续进行，<strong>与未拆分更新相同，在前瞻上执行UPDATE阶段并将结果复制回主机以供FACT阶段和随后的LBCAST使用</strong>  。在传输、FACT和LBCAST执行期间，在加速器上计算UPDATE2阶段。但是，由于A左侧部分的行已经准备好用于通信，因此此时还可以执行RS1通信并且可以被UPDATE2隐藏起来。<strong>在UPDATE2之后，在准备下一个迭代中要用于RS2通信的A右侧部分中收集这些行。然后可以排队执行UPDATE1阶段，首先将已经通讯过得列返回到A中，并且RS2  交流可以被这个本地计算隐藏起来</strong> 。</p>
<p>由于左右更新以交错方式执行，与它们各自的行收集和散射相间隔，我们必须保持局部 A 矩阵右侧部分的列数 n2 在每次迭代中固定在每个进程上，而 n1 递减。由于我们<strong>选择使 n1 成为 NB 的倍数，最终 n1 将等于 NB</strong>，并且预测将最终成为剩余左侧部分的全部内容。发生这种情况后，不再存在拆分更新公式，并且迭代回到图3所示形式，在该形式中 RS 通信不会被 UPDATE 隐藏。</p>
<p><font color="red"><b>对于分割更新公式要有效地隐藏所有通信时间，本地A矩阵的右侧部分必须至少足够大，以隐藏与主机之间的数据传输，以及FACT、LBCAST和RS1阶段</b></font>。因此很自然地会问：如果UPDATE2阶段最初可以隐藏这些阶段中花费的所有时间，那么随着基准测试的进行，它是否会继续隐藏它们？为了确定这一点，<strong>请注意n2保持不变而n1减小时，UPDATE2阶段在每次迭代中始终更新相同数量的A矩阵列数只要n1保持非零</strong>。就计算成本而言，在n2保持不变时，UPDATE2计算与正在处理上述过程中更新的本地A片段中行数m呈线性关系。同样，在UPDATE2所隐藏的其他各个阶段（除了RS1 阶段）也具有与m成比例增长的线性缩放。实际上，与主机之间的数据传输、FACT 阶段和 LBCAST 阶段在每次迭代中更新本地 A 矩阵行数方面都具有线性复杂度。另一方面，在 RS1 中进行行交换通信具有与 n1 成正 比且随着 n1 减少而递减 的复杂度 。该速率大致等同于 A 本地行数逐渐减少 的速率 。因此我们可以得出结论：<font color="red"><b>如果 UPDATE2 最初能够隐藏这些时间，则将继续隐藏它们直到左侧部分已经减少到零列，并且 RS2 通信无法再被隐藏为止</b></font>。实践证明，在单个 Frontier 节点上执行 HPL 基准测试期间 ，我们观察到 这种分裂更新公式能够在约75% 的执行时间内通过 UPDATE 阶 段来完全屏蔽所有 MPI 通信。</p>
<p>由于 n2的选择至关重要，只能大到足以隐藏 FACT、 LBCAST 和 RS1阶段，因此在基准测试开始时，<font color="red"><b>选择 n2 是拆分更新公式中的一个关键考虑因素</b></font>。虽然一些性能模型可以用来估计 n2 的最佳大小，但是我们允许用户向 rocHPL 输入一个“分割分数”参数，以指示 A 的右侧应该有多少百分比的列，并将这个输入作为一个调优参数。对于运行在单个 Frontier 节点上的 HPL，我们通常会发现将本地 A 矩阵分成左右两部分的工作效果最佳。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="performance-results">Performance results<a class="hash-link" aria-label="Direct link to Performance results" title="Direct link to Performance results" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#performance-results">​</a></h2>
<p>在本节中，我们展示了橡树岭领导计算设施（OLCF）的Crusher系统上rocHPL基准测试的性能结果，该基准测试在单个节点上运行，并扩展到多个节点。Crusher是一个Frontier早期访问集群，因此与Frontier具有相同的节点架构。Crusher是一台HPE Cray EX超级计算机系统，每个节点由一个经过优化的第三代EPYC 64核处理器、四个AMD Instinct MI250X加速器和四个HPE Slingshot 200Gbps网络接口组成，每个接口直接连接到不同的MI250X GPU。对于以下所有性能结果，我们使用GCC v11.2.0作为我们的C++编译器，ROCm v5.4.0来编译HIP内核，并使用随ROCm v5.4.0分发的rocBLAS v2.46 GPU BLAS库。对于CPU BLAS库，我们使用BLIS v4.0。最后，我们使用Cray-MPICH v8.1.17作为MPI实现。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="单节点性能">单节点性能<a class="hash-link" aria-label="Direct link to 单节点性能" title="Direct link to 单节点性能" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#单节点性能">​</a></h3>
<p>从在Crusher上运行的单个节点开始，我们通过在P×Q = 4×2进程网格中启动八个进程来执行rocHPL基准测试。我们使用全局问题规模N = 256,000，结合必要的工作空间缓冲区，有效地填满了节点上每个四个MI250X GPU的HBM容量。与HPL实现一样，阻塞因子NB的选择是计算和通信性能之间重要平衡。块大小NB应该至少足够大，以使大型DGEMM计算达到设备峰值性能的高百分比，同时选择尽可能小的NB允许在每次迭代中最大化通信和计算之间的重叠。对于Frontier节点架构，我们通常选择NB = 512来取得这种平衡。在NB = 512时，在rocBLAS中可用高度调整过的DGEMM内核下，在HPL中Typically achieve49 TFLOPS 的性能. 使用此NB值时, 我们还利用<strong>50-50左右拆分更新公式来隐藏MPI通信进行行交换</strong>. 在这些参数下, Crusher 上 rocHPL 基准测试单节点执行总体平均达到153 TFLOPS 的性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240304000453.png" alt="image.png|center|400" class="img_ev3q"></p>
<p>在上图中展示了rocHPL基准测试单节点运行中每次迭代的时间分解情况。对于每个时间（秒）迭代，拥有当前对角面板的进程记录了几个计时器。我们记录了整体迭代时间以及其他几个组件，即：GPU在此迭代中积极计算所花费的总时间、将数据发送到  主机和从主机接收数据所花费的总时间、MPI通信所花费的总时间以及CPU上进行FACT阶段计算所花费的总时间。我们在这幅图中绘制了每次迭代的时间以及GPU活跃总时间。剩下三个计时器显示为堆叠线条，以展示基准测试末尾附近执行关键路径。</p>
<p>在第250次迭代左侧的分裂更新中，<strong>左侧部分太小，无法充分隐藏RS2通信，并且可以看到每次迭代时间略高于GPU活动时间。此后不久，分裂更新的左侧部分变为零，右侧部分收缩直至GPU活动不再是整个关键路径上的一部分</strong>。从图7中主机-设备传输时间、MPI通信时间和FACT计算时间的堆叠线图中我们可以看到，在剩余基准测试执行过程中这些组合阶段成为了执行的关键路径。在尾部阶段，基准测试运行时计算吞吐量大幅下降至最终值，因为该阶段每次迭代所需时间不再由计算限制，而是由延迟和通信限制。然而，使用上述优化方法，在rocHPL中实现了总体性能达到单个Crusher节点上MI250X可实现NB = 512 DGEMM 计算速率49 TFLOPS 的78% 的性能水平。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="多节点性能">多节点性能<a class="hash-link" aria-label="Direct link to 多节点性能" title="Direct link to 多节点性能" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#多节点性能">​</a></h3>
<p>当弱扩展到多个节点时，我们期望HPL运行的每次迭代时间分解会遵循类似于图7所示的趋势，尽管随着节点数量增加，总迭代次数会更多。然而，在每个GPU和CPU插座中的计算工作在问题被扩展时保持不变，但<strong>预计MPI通信时间与单节点结果相比会增长</strong>。这是由于两个因素造成的。</p>
<ul>
<li>首先，跨节点带宽使用具有较低峰值带宽的网络接口，而不是单个节点上GCD之间Infinity Fabric链接。这影响了像LBCAST和RS阶段 中那些对带宽敏感的通信操作。</li>
<li>其次，随着节点数量增加，通信延迟成本预计会增加。这在像FACT阶段中的延迟敏感通信中非常重要，在该阶段中实际上是整个进程列上MPI集合操作（individual row pivots）。</li>
</ul>
<p>我们在图8中展示了在Crusher的1、2、4、8、...、128个节点上测得的rocHPL基准性能。我们还展示了从单节点性能到理想完美弱扩展的情况。对于每个节点计数，我们保持P×Q进程网格为正方形，或者具有P与Q之间2:1比例的网格。对于确定我们可以执行CPU核心时间共享量的本地进程网格，我们最大化节点上处理器列的数量。也就是说，一旦Q至少为8，我们选择本地进程网格为1×8。我们将全局问题规模N缩放以再次填满GPU HBM容量，并且保持NB固定为512，并且<strong>左右分割比例均为50%</strong>，适用于所有测试。从图表中可以看出，rocHPL基准很好地扩展到多个节点，在128个节点上实现了超过90%的弱扩展效率，从153 TFLOPS（单节点得分）提升到17.75 PFLOPS得分。尽管这次测试所使用的节点数量相对较小，在2022年11月Top500榜单上这一成绩将排名第38位。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="discussion">Discussion<a class="hash-link" aria-label="Direct link to Discussion" title="Direct link to Discussion" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#discussion">​</a></h2>
<p>我们提出了rocHPL，AMD的开源实现的HPL基准测试，针对加速节点架构设计的exascale系统。与最近其他关于在HPL中利用现代加速器的工作一样，HPL得分（TFLOPS）rocHPL将整个问题保存在加速器高带宽内存中，并仅将面板移动到CPU上以执行小型延迟敏感面板因子化。我们详细介绍了rocHPL中使用的一些性能优化，包括<strong>改进CPU上面板因子化性能的多线程策略</strong>、<strong>在同一节点上不同进程之间共享CPU核资源的方法</strong>，以及<strong>可以有效隐藏通信时间所需进行行交换操作更新策略</strong>。</p>
<p>在Crusher系统的单个节点上执行rocHPL的详细时间显示，我们的优化能够完全隐藏MPI通信和CPU工作在GPU计算活动背后，在基准测试的前50%迭代中。这与rocBLAS中高性能DGEMM例程相结合，使得基准测试能够在每个加速器上实现高百分比的有效DGEMM计算吞吐量。在基准测试结束时，MPI通信和CPU上FACT阶段的性能成为关键组件。我们<strong>针对FACT阶段采用多线程策略有助于减少花费在该领域内的时间</strong>。</p>
<p>这个HPL实现的扩展性能在从单个Crusher节点到128个节点进行弱扩展时被观察到效率超过90%。当然，像Frontier这样的机器上进行全规模运行需要远远超过128个节点的高效扩展。然而，对于这些大规模运行，需要仔细考虑HPL中MPI例程的性能。很可能需要专门优化系统网络拓扑结构的通信算法来保持高效的扩展性，这是本文讨论范围之外的话题。在rocHPL中我们一般实现这些例程时并没有进行此类优化，但代码设计为模块化以便用户可以轻松地实现自定义例程，并进一步针对目标系统/架构进行优化。</p>
<p>计算吞吐量在加速节点架构中的代际跃迁稳步增长，持续给混合了计算、网络带宽和延迟敏感阶段的基准测试（如HPL）带来挑战。<font color="red"><b>随着计算吞吐量的提高超过进程间通信性能，性能瓶颈从受到计算速率限制转移到降低整体性能上，这由峰值计算吞吐效率衡量</b></font>。未来工作将不得不解决这种变化，并仔细考虑加速器在HPL基准测试的延迟和通信主导尾部区域中是否可以进一步利用。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/paper_notes/3_Kernel/HPC加速体系结构中Linpack优化/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/Kernel/HiCOO/Z-Morton顺序"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Z-Morton顺序</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#abstract">Abstract</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#introduce">Introduce</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#hpl-overview">HPL Overview</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#rochpl-design">rocHPL Design</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#多线程panel分解">多线程Panel分解</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#cpu核心时间共享">CPU核心时间共享</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#分解-舒尔补更新">分解 舒尔补更新</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#performance-results">Performance results</a><ul><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#单节点性能">单节点性能</a></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#多节点性能">多节点性能</a></li></ul></li><li><a class="table-of-contents__link toc-highlight" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/阅读笔记#discussion">Discussion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper-notes-intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs-intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>