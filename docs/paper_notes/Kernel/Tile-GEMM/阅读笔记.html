<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-paper_notes/Kernel/Tile-GEMM/阅读笔记" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.5.2">
<title data-rh="true">阅读笔记 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/paper_notes/Kernel/Tile-GEMM/阅读笔记"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="阅读笔记 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="Abstract"><meta data-rh="true" property="og:description" content="Abstract"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/Tile-GEMM/阅读笔记"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/Tile-GEMM/阅读笔记" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/paper_notes/Kernel/Tile-GEMM/阅读笔记" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">



<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.2ec13e6f.css">
<script src="/assets/js/runtime~main.2dd4f1d7.js" defer="defer"></script>
<script src="/assets/js/main.a99845c3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/paper-notes-intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a class="navbar__item navbar__link" href="/docs/blogs-intro">个人博客</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/paper-notes-intro">笔记说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/HYCOM/HYCOM概述">HYCOM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/LU/intro">LU</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/paper_notes/Kernel/intro">Kernel</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/intro">说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/AlphaSparse/论文原件">AlphaSparse</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/CSR5/论文原件">CSR5</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/DASP/论文原件">DASP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HPC加速体系结构中Linpack优化/论文原件">HPC加速体系结构中Linpack优化</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/HiCOO/Z-Morton顺序">HiCOO</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/IA-SpGEMM/论文原件">IA-SpGEMM</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/J-基于 SpMV 的应用程序开销自觉的格式选择/论文原件">J-基于 SpMV 的应用程序开销自觉的格式选择</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/ML-SpMV-thread/论文原件">ML-SpMV-thread</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/MSREP/论文原件">MSREP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/Spmv任务自动分配/intro">Spmv任务自动分配</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/paper_notes/Kernel/Tile-GEMM/论文原件">Tile-GEMM</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/paper_notes/Kernel/Tile-GEMM/论文原件">论文原件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/paper_notes/Kernel/Tile-GEMM/阅读笔记">阅读笔记</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/paper_notes/Kernel/z-模版/论文原件">z-模版</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/paper_notes/未分类/intro">未分类</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Kernel</span><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Tile-GEMM</span><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">阅读笔记</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>阅读笔记</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="abstract">Abstract<a href="#abstract" class="hash-link" aria-label="Direct link to Abstract" title="Direct link to Abstract">​</a></h2>
<p>稀疏一般矩阵乘法（SpGEMM）是稀疏线性求解器、图处理框架和机器学习应用中最基本的构建块之一。现有的共享内存 SpGEMM 的并行方法主要使用行-行风格，可能具有良好的并行性。然而，由于稀疏结构的不规则性，现有的行-行方法经常面临三个问题：</p>
<ul>
<li>（1）负载不平衡</li>
<li>（2）高全局空间复杂度和令人不满意的数据局部性</li>
<li>（3）稀疏累加器选择。</li>
</ul>
<p>在本文中提出了一种名为TileSpGEMM的平铺并行SpGEMM算法。我们的算法将稀疏化方法应用于密集通用矩阵-矩阵乘法（GEMM）中，并以稀疏形式保存每个非空块。优势如下：</p>
<ul>
<li>基本工作单元现在是一个包含少量非零元素的固定大小稀疏块，而不是可能非常长的行。因此，负载不平衡问题可以自然地得到缓解。</li>
<li>每个块所需的临时空间较小，并且始终可以位于芯片上的划分内存中。因此，无需为大量中间结果分配芯片外空间，并且数据局部性会更好。</li>
<li>因为计算限制在单个tile内，因此相对容易选择一个快速的稀疏累加器来处理稀疏tile。</li>
</ul>
<p>在两款最新的NVIDIA GPU 上进行的实验结果显示，TileSpGEMM 在所有 142 个执行不少于十亿次浮点运算的方阵中，优于四种最先进的 SpGEMM 方法 cuSPARSE、bhSPARSE、NSPARSE 和 spECK 中的 139、138、127 和 94 种方阵，并分别提供高达2.78倍、145.35倍、97.86倍和3.70倍的加速。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>稀疏一般矩阵乘法（SpGEMM）操作将两个稀疏矩阵𝐴和𝐵相乘，并给出一个结果稀疏矩阵𝐶。作为第3级稀疏基本线性代数子程序（Sparse BLAS）中的关键核心，组合BLAS和GraphBLAS，SpGEMM在稀疏线性求解器中有着广泛的应用。由于两个输入和一个输出矩阵都是稀疏的，因此并行化SpGEMM通常比其他稀疏内核（如稀疏矩阵-向量乘法（SpMV）和稀疏矩阵-多向量乘法（SpMM）等）更复杂，因此近年来在各种现代并行平台上受到了广泛关注，例如GPUs、Xeon Phi领域特定架构和分布式集群。</p>
<p>目前，<strong>大多数现有的并行处理器上的SpGEMM方法都使用Gustavson的行-行方法作为基础</strong>。这种并行方法通过合并由A中相应稀疏行中的非零元素缩放后得到的B的稀疏行来生成结果矩阵C的稀疏行。然而，尽管行-行方法通常能够带来足够的并发性，但它们很难解决三个具有挑战性问题：</p>
<ul>
<li>（1）如何通过各种检查和分箱方法解决负载平衡问题</li>
<li>（2）如何找到一个良好临时空间大小以分配用于计算具有良好数据局部性结果矩阵所需的中间矩阵</li>
<li>（3）如何设计更高效地利用密集列、堆、哈希、排序和合并不同长度和稀疏结构的列。</li>
</ul>
<p>尽管这三个问题已经在最近的 SpGEMM 工作中得到了深入的研究，但是需要注意的是现代  并行处理器(如 GPU)的硬件资源仍然没有得到充分的利用。原因主要有三个方面:</p>
<ul>
<li>(1)很难有效地处理数以千计甚至更多的非零行，这不仅带来负载不平衡，而且需要比芯片暂存式记忆体容量大得多的空间;</li>
<li>(2)分配给存储中间数据的临时空间的大小取决于操作的总数和对最终 C 大小的初步猜测。在许多情况下，中间空间可能很大，占用了大量的全局存储空间和较长的执行时间</li>
<li>(3)行行方法中基于行的稀疏累加器不能利用矩阵的二维空间结构，从而只能带来有限的数据局部性。因此，现有的行行方法往往不能提供令人满意的性能。</li>
</ul>
<p>为了更好地利用现代GPU的硬件资源，我们在本文中提出了一种名为TileSpGEMM的新方法。<font color="red"><b>简而言之，TileSpGEMM 可以看作是一般密集矩阵-矩阵乘法(GEMM)中广泛使用的平铺算法的稀疏版本。</b></font>其<strong>基本工作单元是一个稀疏块，具有良好的边界大小</strong>（例如，一个16x16的稀疏块不包含超过256个非零元素），<strong>并且可以存储在芯片上的临时内存中，而不是各种长度的稀疏行</strong>。因此，经典行-行SpGEMM方法中存在的三个性能问题可以得到更好地解决：</p>
<ul>
<li>（1）由于不同行长度导致的负载不平衡问题可以得到很大程度上缓解；</li>
<li>（2）无需全局内存空间来存储中间数据；</li>
<li>（3）更容易设计具有更好数据局部性的稀疏累加器。</li>
</ul>
<p>为了使在现代GPU上的平铺形式更加高效，设计了</p>
<ul>
<li>一种包含掩码信息的平铺稀疏格式和CSR风格的自适应非零结构</li>
<li>一个优化各种输入稀疏块结构的自适应稀疏累加器</li>
<li>一个用于计算块布局、符号和数值SpGEMM的三阶段优化框架</li>
</ul>
<p>通过在两个最新的 NVIDIA RTX 3060和3090 Am pere GPU 上测试所有142个平方稀疏矩阵，使用不少于十亿个浮点运算对来自 SuiteSparse Matrix Col 选集的 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C = A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">C = AA^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 运算进行测试，我们的 TilespGEMM 算法显着超过了四种现有方法: NVIDIA cuSPARSE v11.4 ，bhSPARSE ，NSPARSE和 spECK 。实验结果表明，该方法在139、138、127和94矩阵上的加速比它们分别快2.78 x、145.35 x、97.86 x 和3.70 x。与在 GPU 张量核心上使用半精确密集平铺式乘法的 tSparse library相比，我们的 TileSpGEMM 平均获得1.98 x 和高达4.04 x 的加速。此外，我们的实验表明，与标准的 CSR 格式相比，我们的平铺稀疏格式通常占用更少的空间。</p>
<p>这项工作做出了以下贡献：</p>
<ul>
<li>避免了经典行-行SpGEMM的三个主要性能问题。</li>
<li>提出TileSpGEMM，包括稀疏块数据结构和相应的SpGEMM算法。</li>
<li>为现代GPU上的TileSpGEMM开发了优化技术。</li>
<li>在各种结构的大型矩阵上，实现了比现有SpGEMM工作更显著的加速。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="background">Background<a href="#background" class="hash-link" aria-label="Direct link to Background" title="Direct link to Background">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="稀疏矩阵乘法以及行-行算法">稀疏矩阵乘法以及行-行算法<a href="#稀疏矩阵乘法以及行-行算法" class="hash-link" aria-label="Direct link to 稀疏矩阵乘法以及行-行算法" title="Direct link to 稀疏矩阵乘法以及行-行算法">​</a></h3>
<p>SpGEMM操作计算<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">C= AB</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05017em">B</span></span></span></span>，其中𝐴、𝐵和𝐶都是稀疏矩阵。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240304145724.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图1给出了将具有八个非零元素的A与具有十个非零元素的B相乘并得到11个非零元素的C的示例。</p>
<p>目前，大多数并行SpGEMM算法使用Gustavson的行-行公式，如算法1所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240304151720.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>这种方法利用了计算C的各行是彼此独立的事实，因此可以并行化（算法1中的第1行）。（问题：在第7个步骤时，为什么需要判断，为什么不能在一开始就分配固定的大小呢？）</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="row-row-spgemm的性能问题">Row-Row SpGEMM的性能问题<a href="#row-row-spgemm的性能问题" class="hash-link" aria-label="Direct link to Row-Row SpGEMM的性能问题" title="Direct link to Row-Row SpGEMM的性能问题">​</a></h3>
<p>尽管行-行算法具有良好的并行性，但仍存在三个主要性能问题（分别在算法1中突出显示的第1、2-3和7-12行）。</p>
<ul>
<li>第一个性能问题（第1行）是𝐶的计算量可能非常不平衡，因此当少数长行占据运行时长时，很难充分利用大规模并行GPU。</li>
<li>第二个性能问题（第2-3行）是𝐶的大小事先未知，并且需要为存储可能大量中间产品而保留空间，因此很难在运行时分配适当大小。</li>
<li>第三个性能问题（第7-12 行）是行方法将非零元素插入到 𝐶 的各自不可预测稀疏度的随机位置中，因此很难设计一种稀疏累加器以有效地累积新条目。</li>
</ul>
<p>为了解决上述三个问题，近年来已经提出了数十种SpGEMM算法。然而不幸的是，这些问题在行行样式中是固有的意味着即使设计得再聪明的方法也无法突破限制只要行行计算仍然是基本模式。我们可以以表2中列出的顺序为1000005阶‘webbase-1M’矩阵上运行<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C = A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>作为例子。这是一个经典的幂律矩阵容易带来不平衡计算。具体地，在1000005行中有3个需要超过100000次浮点运算，并且190个需要超过10000次操作，而其余999812行大多数只需要少于100次操作。<strong>这种  普遍存在的计算量不平衡通常导致当调用行 - 行SpGEMM方法时GPU核心被低效利用，因为较少数量的行将主导运行时间</strong>。此外，<strong>在计算这些数据时需要分配大量空间来存储中间产品同时难以设计高效累加器长数据因为它们一般不能完全保存在小型芯片内存中</strong>。</p>
<p>这一事实激励我们从底层解决挑战，并探索一种新的方式并行的 SpGEMM。在这项工作中，我们选择了一个实际上更经典的平铺方法，这几乎总是在密集 GEMM 中使用。平铺的 SpGEMM 和平铺的 GEMM 之间的区别在于，我们只在 A、 B 和 C 中存储非空的贴片，并且这些贴片都是稀疏形式的。因为现在一个固定大小的稀疏瓷砖(16 × 16)被设置为基本工作单元，并且可以存储在快速片上存储器中，所以更容易处理负载不平衡(问题1)、中间空间分配(问题2)和随机插入(问题3)。图7中的实验结果还证明，我们的 TileSpGEMM 明显优于行方法。通过解决上述三个挑战，使用我们的 TileSpGEMM 在‘webbase-1M’上运行 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C = A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>比使用行样式方法 cuSPARSE，bhSPARSE，NSPARSE 和 spECK 分别快2.17 x，7.26 x，3.11 x 和1.96 x。</p>
<p>尽管tile（平铺/瓷砖）模式具有优势，但要使TileSpGEMM高效并非易事，并且需要解决三个新问题：</p>
<ul>
<li>（1）如何存储稀疏tiles的最有效信息</li>
<li>（2）如何高效地收集从𝐴和𝐵中所需的稀疏tiles以计算𝐶中的tile</li>
<li>（3）如何设计自适应的基于块的稀疏累加器。</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="tilespgemm">TileSpGEMM<a href="#tilespgemm" class="hash-link" aria-label="Direct link to TileSpGEMM" title="Direct link to TileSpGEMM">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="概述">概述<a href="#概述" class="hash-link" aria-label="Direct link to 概述" title="Direct link to 概述">​</a></h3>
<p>TileSpGEMM 的工作由<font color="red"><b>稀疏的tile数据结构</b></font>和<font color="red"><b>使用该数据结构的tile SpGEMM 算法</b></font>组成。</p>
<p>与<font color="green"><b>以行为基本工作单元的标准 CSR 格式</b></font>相比，TileSpGEMM 的主要特点是<strong>输入和输出稀疏矩阵都存储为大小相同的非空稀疏块，稀疏块现在成为 Tile SpGEMM 的基本工作单元</strong>。在这项工作中，tile大小总是设置为16乘16(方便地使用8位无符号字符数据类型进行本地索引) ，表明每个瓦片包含不超过256个非零。<font color="red"><b>对于每个稀疏平铺，以 CSR 样式加上行索引和位掩码存储它的非零值</b></font>。</p>
<p>在稀疏瓦片数据结构的基础上，TileSpGEMM算法包括三个步骤：</p>
<ul>
<li>（1）查找𝐶中可能非空的瓦片</li>
<li>（2）确定每个𝐶中瓦片的非零数和行指针数组，并为𝐶分配内存</li>
<li>（3）计算每个 𝐶中瓦片的非零值的行索引、列索引和值。
此外，还开发了几种优化技术，如用于集合交集的二进制搜索、用于符号SpGEMM的位掩码操作以及用于选择芯片内存中稀疏或密集累加器的自适应方法，以提高效率。</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="稀疏瓦片数据结构">稀疏瓦片数据结构<a href="#稀疏瓦片数据结构" class="hash-link" aria-label="Direct link to 稀疏瓦片数据结构" title="Direct link to 稀疏瓦片数据结构">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240304174740.png" alt="image.png|center|1000" class="img_ev3q">
<center> <font face="华文宋体" size="4"> 示例矩阵 A 的大小为16乘16，存储在6个大小为4乘4的稀疏瓷砖中。瓦片结构包括三个数组 tilePtr、 tileColIdx 和 tileNnz，代表瓦片的内存偏移量、瓦片列索引和稀疏瓦片中非零数目的偏移量。同时，每个稀疏平铺由五个数组组成: rowPtr、 rowIdx、 colIdx、 val 和掩码。 </font> </center></p>
<p>稀疏瓦片数据结构存储两层瓦片信息。</p>
<ul>
<li><strong>更高级别存储矩阵的瓦片结构并由三个数组组成</strong>:<!-- -->
<ul>
<li>(1) <code>tilePtr</code>：大小为划分瓦片后的行数+1，用于在瓦片行中存储瓦片的内存偏移量。</li>
<li>(2) <code>tileColidx</code>：大小为该矩阵中，稀疏瓦片的数量。用于定位某个瓦片所处的列。</li>
<li>(3) <code>tileNnz</code>：大小为该矩阵中稀疏瓦片的数量+1，用于保存稀疏瓦片中的非零数目。</li>
</ul>
</li>
<li><strong>在较低级别，每个瓦片中的非零元素以CSR样式存储，包括行索引和位掩码</strong>。创建四个数组来存储它们：<!-- -->
<ul>
<li>（1）<code>val</code>：存储某个瓦片内所有的非零值，大小为某个瓦片内的非零值的数量。</li>
<li>（2）<code>rowIdx</code> 和 <code>colIdx</code>：分别存储每个瓦片中非零元素的行和列索引。<!-- -->
<ul>
<li>请注意，这里始终将瓦片大小设置为 16×16 以最大化空间利用率，因为一个瓦片中的行或列索引只需要四位，并且可以一起存储在一个8位无符号字符内。</li>
</ul>
</li>
<li>（3）<code>rowPtr</code>：行指针数组 <code>rowPtr</code> 保存了该瓦片中非零元素的 16 个内存偏移量，这与常规 CSR 行指针数组不同，后者包含了 16+1 条目。<!-- -->
<ul>
<li>之所以仅使用了 16 条目是因为我们希望限制指针数组中的值在0-255之间，并且也可以保存在一个8位无符号字符内。尽管我们没有存储标准指针数组的第17条目，但如果需要时该值可以从从 rowPtr 的最后一项减去相应 tileNnz 中对应值得到（tileNnz 存储着各个瓦片中非零元素数量）</li>
</ul>
</li>
<li>（4）<code>mask</code>：此外, 我们还为每个砖块设置了一个掩码阵列, 因为<font color="red"><b>常规比特掩码能够加速预处理阶段并且通常只占用极小空间</b></font>. 在这里, 创建了一个大小为 𝑐 × 16 的16位无符号short型数组来存放稀松图块的比特掩码. 具体地说, 对于每一行上面有非0值位置处标记1 , 否则标记0.<!-- -->
<ul>
<li>这种结合格式使得矩阵A中某一特定图块上面有非0值能够同时访问到矩阵B相应图块及其比特掩码 。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>请注意，将瓦片大小设置为16 × 16的原因是，充分利用8位无符号字符来存储索引和指针，以及16位无符号字符来存储位掩码。与本文中使用的16 × 16相比，其他瓦片大小(如4 × 4和8 × 8)不能饱和8位数据类型，并将带来更复杂的数据打包和解包。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="算法介绍">算法介绍<a href="#算法介绍" class="hash-link" aria-label="Direct link to 算法介绍" title="Direct link to 算法介绍">​</a></h3>
<p>TileSpGEMM方法包括三个步骤，用于确定𝐶的三组信息：</p>
<ul>
<li>(1)整体瓦片结构数组tilePtr和tileColidx</li>
<li>(2)非零元素数量数组tileNnz、每个稀疏瓦片的行指针数组rowPtr和位掩码数组mask</li>
<li>(3)每个瓦片中非零元素的索引和值数组rowidx、colidx和val。</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第一步-确定结果矩阵c的稀疏结构">第一步 确定结果矩阵C的稀疏结构<a href="#第一步-确定结果矩阵c的稀疏结构" class="hash-link" aria-label="Direct link to 第一步 确定结果矩阵C的稀疏结构" title="Direct link to 第一步 确定结果矩阵C的稀疏结构">​</a></h4>
<p>第一步的目的根据瓦片划分结构，同时得到结果矩阵C的上层平铺结构。</p>
<p>在计算结果矩阵的上层平铺结构时，只需要用到矩阵A和B的上层平铺结构即可，不需要内部的细节处理。（也就是说可以直接生成一个简单的新矩阵，新矩阵的非零数就是原矩阵的非空瓦片数），原矩阵经过抽象后的上层矩阵以及矩阵乘积运算如下图所示。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240304184749.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>可以看出，含有8个非零矩阵块的A矩阵乘以含有6个非零矩阵块的B矩阵 ，得到含有10个非零矩阵块的结果矩阵C。这里的非零矩阵块也可以叫做稀疏块。</p>
<p>由于 A ′和 B ′（新矩阵）的行数和列数是 A 和 B （原矩阵）的行数和列数的比例（行和列都除以16），而且它们的稀疏块数通常比 A 和 B 的非零数少得多，所以第一步的浮点运算量和执行时间往往只占整个 SpGEMM 时间的很小百分比。第一步通常不会占用 TileSpGEMM 总执行时间的5% 。</p>
<p>为了简单起见，我们在本步骤中直接调用<font color="red"><b>NSPARSE 库</b></font>中的 SpGEMM 函数。<strong>使用 NSPARSE 的原因是，与其他现有的开源 SpGEMM 库相比，NSPARSE 为小型用例提供了更好的性能，并且使用起来更简单</strong>。（其实，在这一步中，就是对根据CSR格式存储的抽象上层稀疏矩阵进行GEMM操作，因此可以直接调用别人写好的，性能高的函数）</p>
<p>还应该注意到，乘法不考虑逐个瓦片的取消，<font color="green"><b>因为这个阶段不知道𝐶每个瓦片中非零元素的数量，并且无法删除任何一个瓦片，即使它实际上是空的。换句话说，最终的C允许存储空瓦片</b></font>。</p>
<p>在此步骤之后，得到了 C 的瓦片结构(例如，稀疏瓦片数目<code>numtileC</code>、瓦片指针数组<code>tilePtr</code> 和瓦片列索引数组 <code>tileColidx</code>)。</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="第二步-生成每个瓦片的内部结构">第二步 生成每个瓦片的内部结构<a href="#第二步-生成每个瓦片的内部结构" class="hash-link" aria-label="Direct link to 第二步 生成每个瓦片的内部结构" title="Direct link to 第二步 生成每个瓦片的内部结构">​</a></h4>
<p>在第二步中，在已知的C稀疏瓦片结构之上，<font color="red"><b>生成行指针数组、位掩码数组和每个瓦片的非零数目</b></font>。然后可以在这一步结束时为C分配内存空间。</p>
<p><font color="red"><b>这里使用Cij来表示C中第i个瓦片行和第j个瓦片列的稀疏瓦片，并通过以符号方式将A中第i个瓦片行中的相应稀疏瓦片Aik与B中第j个稀疏块Bkj相乘来计算它。（也就是通过每个瓦片内部的mask值，来计算出结果矩阵中每个非零瓦片的内部结构）</b></font>由于A和B中的空白块不应参与计算，因此只需要找到并匹配<strong>A的块行和B的块列中具有相同索引的非空块</strong>。该过程实际上等效于出现在两组（即A 的块行和B的块列）中都出现的稀疏瓦片集合进行交集运算 。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240311153536.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>算法2显示了TileSpGEMM的第二步的伪代码，图4绘制了生成两个稀疏瓦片𝐶的示例。从图中可以看出，瓦片𝐶12是通过计算在𝐴的第一个瓦片行和在𝐵的第二个瓦片列中三个瓦片之间的乘积之和得到的。根据基本存储结构，我们可以提取两个数组<code>tilecolidx_A1∗</code>，包括<font color="red"><b>瓦片行的列索引</b></font>以及<code>tilerowidx_B∗2</code>，包括<font color="red"><b>瓦片列的行索引</b></font>。然后需要<font color="red"><b>找到这两个索引数组之间相交部分，并将对应位置上的瓦片相乘</b></font>。我们假设这里两个数组中的列/行索引是有序且可以使用串联合并类似方法来设置两个指针并遍历这两组数直至找到所有匹配对应关系为止。然而，在我们实验中发现合并原语通常比用于集合交集查找时更慢一些二进制搜索方法。具体地说，当这两组数大小不同时，我们让一个CUDA线程<strong>在长数组上用典型二进制搜索操作来搜索较小数组中每一个元素与长数组匹配情况下所需寻找匹配项</strong>。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240311160743.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>在每个搜索步骤中，我们在芯片暂存式记忆体中设置了两个索引数组 match _ pos _ a1 * 和 match _ pos _ b * 2，分别记录相交元素的索引位置。由于两个索引数组都是有序的，当一个搜索完成时，下一个搜索范围将会缩小。具体来说，左边界将被设置为上一个匹配位置的下一个索引，而右边界仍然是数组的最终索引。例如，在图4中间的左侧，‘3’的搜索范围从 tilecolidx _ A1的位置3开始，因为最后一个元素‘1’在位置2匹配。在成功匹配最后一个元素“3”之后，获得了需要相乘以生成最终的瓦片 C12的相交瓦片对。可以看出，应该用 A11 × B12 + A13 × B32来计算瓷砖 C12。与 C12类似，瓷砖 C32也是通过这种方式计算的。</p>
<p>在完成 A 和 B 中某个瓷砖与 C 中某个瓷砖的集合交集之后，需要生成它的行指针数组和非零数目来分配最终 C 的完整结构,通过存储了每个瓷砖的位掩码，可以减少重复加载 B 中瓷砖信息的结构信息的内存传输成本。与 A 和 B 中的位掩码类似，可以设置了mask _ Cij 数组来标记 C 中瓷砖 Cij 的非零计算位置。<strong>对于每对匹配的瓷砖 Aik 和 Bk j,将 Bk j 的位掩码加载到芯片内存中，遍历 Aik 的所有非零值，并将每个非零值的列索引作为 Bk j 位掩码的行索引</strong>。然后在暂存式记忆体中对所有匹配的行掩码使用 AtomicOr 操作来获得 Cij 的结果行掩码(第19-25行)。<strong>最后，当掩码 Cij 中的所有行掩码都生成时，可以通过掩码中的1相加并计算前缀和扫描来轻松计算 Cij 的行指针数组。</strong></p>
<p>上图展示了一个关于如何生成mask _ C12并确定平铺 C12(c1)的非零数目的示例。可以看到，C12由两组匹配的瓷砖(A11，B12)和(A13，B32)计算。对于 A11和 B12的乘法，首先遍历 A11中每一行的非零点。对于列索引为0的 a00，可以从 B12(b1)中找到第一行掩码1100(b10)。然后第二个条目 a02将提取第三行掩码1010(b12) ，因为 a02的列索引是2。接下来，继续用同样的方法乘以 A13和 B32。匹配操作完成后，AtomicOr 操作将处理两个匹配的行掩码 b10和 b12，最后更新 C12的第一行掩码1110(c10)。类似地，c11由来自瓷砖 B12中的 b11和 b12以及瓷砖 B32中的 b20和 b23的四行掩码产生。该过程将重复执行，直到完成最后一行掩码 c13，如上图所示。在这 个步骤中，所有的内存需求都被很好地限制到不超过256个非零，并且可以在片上内存中完成。因此，我们不分配任何中间数组的全局内存和节省总体空间开销。</p>
<p>到目前为止，我们已经计算了每个瓦片的非零数目、行指针数组 rowPtr 和位掩码数组掩码，以及最终 C 的非零数目 nnzC 的总数。现在，我们可以为第三步中大小为 nnzC 的 val 和 idx 数组准备内存。</p>
<p>在第三个步骤中，<strong>使用数值阶段来计算C块中非零元素的值和行/列指数</strong>。除了在第二个步骤中使用的二进制搜索操作之外，我们在这个步骤中提出了一种<font color="red"><b>自适应方法</b></font>来为每个tile在片上存储器中选择稀疏或密集的累加器以提高性能。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240311175240.png" alt="image.png|center|600" class="img_ev3q"></p>
<p><strong>设置阈值 tnnz，自适应地选择工作在稀疏平板上的稀疏累加器，或者选择工作在稠密完全矩阵上的稠密累加器，然后将结果保存为稀疏形式。使用选择的原因是，在我们的观察中，当 tnnz 大于瓷砖大小的75% (即256个非零)时，在密集空间中工作通常会带来更好的性能。相比之下，对于非零值较少的瓷砖，稀疏累加器通常更快。</strong></p>
<p>在第2步中从𝐶获得的稀疏瓦片的位掩码用于确定瓦片所有非零元素的列索引。通过这种方式，可以根据列索引直接在某个位置累积中间乘积，而不是为它们分配临时空间。此外，根据列索引，在相应位置使用AtomicAdd操作来获取结果值。如图4所示，由于其非零元素数量（即6）少于其大小的75%（即16×75%=12），因此通过稀疏累加器计算了瓦片𝐶32。对于非零元素数量大于𝑡𝑛𝑛𝑧的瓦片，密集累加器将在共享内存上运行。我们直接在芯片内存中分配一个256大小的密集矩阵，并将中间乘积添加到其中。请注意，由于这些瓦片足够小，TileSpGEMM完全不会为节省空间而分配全局内存。例如，在图4中，通过密集累加器计算了瓦片 𝐶12 ，因为它有12个非零元素。对于第2和第3步骤的实现，在GPU上为处理一个稀疏块指定了一个warp包含32个CUDA线程以节省线程同步成本。在将所有 𝐶 的稀疏块都累积并保存到全局内存后, TileSpGEMM 算法完成, 获得了以稀缺块形式表示的一张表格信息.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="experimental-results">Experimental Results<a href="#experimental-results" class="hash-link" aria-label="Direct link to Experimental Results" title="Direct link to Experimental Results">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="实验设置">实验设置<a href="#实验设置" class="hash-link" aria-label="Direct link to 实验设置" title="Direct link to 实验设置">​</a></h3>
<p>使用安装在 Ubuntu 18.04机器上的两个 NVIDIA Ampere GPU 作为测试平台。CUDA 和 GPU 驱动程序版本分别是11.4和470.57.02。我们将我们的 TileSpGEMM 与四种最先进的 SpGEMM 方法 cuSPARSE v11.4 ，bhSPARSE  ，NSPARSE 和 spECK 以双精度进行比较，并使用 tSparse 优化以半精度使用 GPU 张量核心。表1列出了设置的一些规范。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240311180022.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>至于数据集，为了使现代 GPU 饱和，我们测试了 SuiteSparse Matrix Col 集中的所有142个稀疏方阵，当计算 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C = A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">C = AA^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span> 时，需要不少于十亿个浮点运算。我们还评估了表2中18个有  代表性的稀疏矩阵，以便进行更深入的性能比较。请注意，前12个矩阵首先由 Williams 等人进行测试，并且是随后许多稀疏矩阵研究中的经典数据集。至于与 tSparse 的比较，我们在其原始论文中使用了16个矩阵的数据集。原因是数据集可以最好地利用 GPU 上的半精度张量核。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240311175946.png" alt="center|600" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="与现有工作进行性能对比">与现有工作进行性能对比<a href="#与现有工作进行性能对比" class="hash-link" aria-label="Direct link to 与现有工作进行性能对比" title="Direct link to 与现有工作进行性能对比">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312005610.png" alt="image.png|center|800" class="img_ev3q"></p>
<p>上图显示了在142个方阵上运行双精度<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C=A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><msup><mi>A</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">C=A A^T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8413em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span></span></span></span></span></span></span></span>的性能比较，使用cuSPARSE v11.4 、bhSPARSE、NSPARSE、spECK以及我们的TileSpGEMM在RTX 3060和3090 GPU上。如上图的前五个子图所示，供应商支持的cuSPARSE v11.4、bhSPARSE和NSPARSE只能完成数据集中一部分矩阵，而spECK和我们的TileSpGEMM可以完成所有142个矩阵。总体而言，在RTX 3090上，TileSpGEMM比其他四种方法分别快139、138、127和94个矩阵，在RTX 3060上则为142、128、114和92个矩阵（请注意，在我们的基准测试中没有任何一个矩阵可以在RTX 3060上使用cuSPARSE计算）。此外，我们的TileSpGEMM明显优于cuSPARSE、bhSPARSE、NSPARSE和spECK。</p>
<p>首先，值得注意的是，我们的算法在 RTX 3090 GPU 上的峰值性能可以达到203.05 Gflops (在矩阵TSOPF_FS_b300_c2) ，而它的 spECK 峰值为91.29 Gflops (cuSPARSE，bhSPARSE 和 NSPARSE 不能计算它)。此外，SpGEMM 的整体性能也得到了很大的改善。具体而言，五种 SpGEMM 方法在 RTX 3090上的平均 SpGEMM 性能分别为30.82,11.54,37.73,46.92和54.56 Gflops，这意味着我们的 TileSpGEMM 平均比其他四种方法快1.77 x，4.73 x，1.45 x，1.16 x (几何平均值)。至于 RTX 3060上的最大加速比，TileSpGEMM 分别比 cuSPARSE、 bhSPARSE、 NSPARSE 和 spECK 提高了2.78 x、145.35 x、97.86 x 和3.70 x 的加速比。在 RTX 3060上，性能趋势是相似的。从线性回归可以看出，我们的 TilespGEMM 带来了良好的性能趋势，并可能为压缩率更高的矩阵提供相对更高的 spGEMM 吞吐量。</p>
<hr>
<p>压缩率是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><msup><mi>A</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">C = A^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.07153em">C</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>的中间产品数量(即浮点运算数量的一半)与C中非零数量的比率。</p>
<hr>
<p>此外，底部的其余五个子图显示了 RTX 3090相对于 RTX 3060的可扩展性。考虑到 RTX 3090的峰值计算能力和带宽是 RTX 3060的3倍左右。我们期望测试的 SpGEMM 方法可以按比例扩展。正如我们所看到的，bhSPARSE、 NSPARSE、 spECK 和我们的 TilespGEMM 在 RTX 3090上比 RTX 3060平均实现了2.12 x、2.66 x、2.82 x 和2.53 x 的加速。我们的可伸缩性比 NSPARSE 和 spECK 稍低的原因是，使用我们的方法的一些矩阵在 GPU 上分配更多的数组，并且在内存分配上花费更长的时间(参见图10)。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312011200.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>为了进行更详细的比较和分析，我们列出了18个代表性矩阵(见表2) ，并在 RTX 3090 GPU 上使用5个 SpGEMM 方法计算 C = A2和 C = AAT 时绘制了它们的性能条。如图7所示，运行 C = A2的 TileSpGEMM 在大多数常用矩阵上的表现一般优于其他四种方法。具体而言，对于由于“ TSOPF _ FS _ b300 _ c2”和“ gupta3”等内存容量过大而无法通过某些方法计算的 ma trice，我们的方法自然地避免了临时中间产品的分配(回想一下稀疏的瓷砖是在片上共享内存中计算的) ，并反映了明显的优势。与成功完成这两个矩阵的 spECK 算法相比，该方法的加速比分别为2.20 x 和1.53 x。此外，我们的 TileSpGEMM 在负载不平衡问题严重的矩阵‘ webbase-1M’上取得了超过12 Gflop 的性能，这是近年来的一个很大的进步。</p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312011330.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图8显示了对18个代表性矩阵中的6个非对称矩阵的 AAT 运算的性能。可以看出，我们的方法的效率变得更有希望时，计算 AAT。特别是 webbase-1M 的性能达到了30.89 GFlops，而 cuSPARSE 和 NSPARSE 都因为内存不足而失败，bhSPARSE 和 spECK 的性能分别为6.61和13.85 GFlops。然而，对于像“ cop20k _ A”和“ Circuit”这样的矩阵，我们的算法需要更多的时间来完成，因为它们的矩阵结构太稀疏，而且每个瓦片只有很少的计算量。以“ cop20k _ A”为例，其中的大多数贴片都非常稀疏(具体来说，18,705,069个非零分布在15,900,566个贴片中) ，这使得我们方法的第二步(生成和分配贴片结构)主宰了整个运行时。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="运行时峰值空间成本的比较">运行时峰值空间成本的比较<a href="#运行时峰值空间成本的比较" class="hash-link" aria-label="Direct link to 运行时峰值空间成本的比较" title="Direct link to 运行时峰值空间成本的比较">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312011431.png" alt="image.png|center|1000" class="img_ev3q"></p>
<p>图9绘制了 Tile SpGEMM 和其他三种算法(cuSPARSE 是一个封闭的源代码库，因此在此不进行比较)的内存消耗过程，这些算法在表2中的18个矩阵上运行 C = A2。可以看出，在大多数矩阵中，bhSPARSE 使用的空间最多，而 NSPARSE 和 spECK 是可比较的。我们的 TileSpGEMM 通常比这三个方法使用更少的空间，并提前完成。例如，对于矩阵‘ can’，TileSpGEMM 使用最多257 MB 的空间，分别比 bhSPARSE、 NSPARSE 和 spECK 少16% 、16% 和55% 。然而，对于一些非常稀疏的矩阵，比如“ cop20k _ A”，我们的方法为本地行指针和位掩码分配了大量的稀疏块，因此分配和计算时间要长得多。这也反映了图7和图8所示的 SpGEMM 性能的下降。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tilespgemm算法的运行时间分解">TileSpGEMM算法的运行时间分解<a href="#tilespgemm算法的运行时间分解" class="hash-link" aria-label="Direct link to TileSpGEMM算法的运行时间分解" title="Direct link to TileSpGEMM算法的运行时间分解">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312011628.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>图10显示了TileSpGEMM算法的运行时分解。包括三个算法步骤以及运行时CPU和GPU上的所有内存分配。可以看到，通常第一步（红色）占整个运行时间的不到5%。第2步（绿色）和第3步（黄色）平均占整体时间的15%和70%，因此进行了精心优化。此外，在某些情况下，内存分配（蓝色）平均占用大约20% 的时间，这也与 Gelado 和 Garland [50] 的观察相吻合。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tile格式空间开销的比较">tile格式空间开销的比较<a href="#tile格式空间开销的比较" class="hash-link" aria-label="Direct link to tile格式空间开销的比较" title="Direct link to tile格式空间开销的比较">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312011819.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>我们比较了我们的 TileSpGEMM 与标准 CSR 的空间成本，以及组合 BLAS 中设计的 CSB-M 和 CSB-I。如图11所示，我们的平铺数据结构比 CSR 平均少占用31.28 MB 的空间，但比 CSB-M 和 CSB-I 分别多占用113.43和82.09 MB 的空间。主要原因是我们的格式存储每个瓦片的本地行指针(16个无符号字符)和位掩码(16个无符号短片)。然而，由于它通常使得 SpGEMM 操作更加方便快捷，因此仍然值得节省额外的内存空间。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="格式转换开销">格式转换开销<a href="#格式转换开销" class="hash-link" aria-label="Direct link to 格式转换开销" title="Direct link to 格式转换开销">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312011955.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>我们记录了将 CSR 矩阵转换为平铺数据结构的开销，在 RTX 3090 GPU 上的转换时间和 SpGEMM 执行时间的比较如图12所示。可以看到，我们的转换时间一般不会超过10个单独的 SpGEMM 操作所需的时间。这种转换成本不会影响 SpGEMM 的效率，<strong>因为在运行 TileSpGEMM 之前，我们总是假设矩阵已经以平铺格式存储</strong>。这个假设在许多应用中是非常合理的，例如代数多重网格(AMG)求解器使用来自一个 SpGEMM 的输出矩阵作为下一轮中另一个 SpGEMM 的输入。</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="tsparse-的张量核比较">TSparse 的张量核比较<a href="#tsparse-的张量核比较" class="hash-link" aria-label="Direct link to TSparse 的张量核比较" title="Direct link to TSparse 的张量核比较">​</a></h3>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240312012149.png" alt="image.png|center|600" class="img_ev3q"></p>
<p>TSparse 是一个相对较新的 SpGEMM 工作，设计用于在现代 GPU 上使用张量核。它还节省了瓦片形式的稀疏矩阵，但使用硬件加速张量核上的密集 GEMM 到多个瓦片，并最终将密集的结果瓦片转换为其稀疏形式。由于其开源代码目前只支持半精度输入和单精度输出，我们使用相同的精度设置在我们的 TileSpGEMM 更直观的性能比较子。图13显示了在 RTX 3090 GPU 上的 tSparse 文件中列出的16个稀疏矩阵上 C = A2的性能比较。可以看到，TileSpGEMM 外部在所有16个矩阵上形成 tSparse。平均(地理度量平均值)加速比为1.98 x，最大加速比为4.04 x。为了进行更全面的分析，我们绘制了图14中16个矩阵的运行时分解图。可以看到，tSparse 的“内存分 配”阶段在许多矩阵上占据了更大的总时间比例。这是因为 C 的内存分配需要在执行期间重复调整大小。此外，对于其瓷砖非常稀疏的矩阵(例如“ webbase-1M”和“ cage12”) ，我们的使用稀疏瓷砖结构的 TileSpGEMM 在步骤2和步骤3上花费的时间比 tSparse 少得多。因此，尽管在硬件加速的张量核心上使用密集乘法可以比正常的 CUDA 核心快得多，但是将稀疏的瓦片重铸成密集的瓦片以在一般的稀疏性中使用该技术，因此可能仍然不如在 TileSpGEMM 中使用的稀疏乘法有效。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="related-work">Related Work<a href="#related-work" class="hash-link" aria-label="Direct link to Related Work" title="Direct link to Related Work">​</a></h2>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>本文提出了一种基于 GPU 的并行 SpGEMM 算法 TileSpGEMM。我们的方法解决了三个主要的性能问题，设计了高效的平铺存储数据结构和一个现代 GPU 架构的三步 SpGEMM 算法。在两个最新的 NVIDIA Ampere 图形处理器上的实验结果表明，我们的 TileSpGEMM 比最先进的 SpGEMM 工作有显著的加速，具有良好的可伸缩性，并且在运行时节省了大量的内存空间。</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/paper_notes/3_Kernel/Tile-GEMM/阅读笔记.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/paper_notes/Kernel/Tile-GEMM/论文原件"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">论文原件</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/paper_notes/Kernel/z-模版/论文原件"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">论文原件</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#abstract" class="table-of-contents__link toc-highlight">Abstract</a></li><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#background" class="table-of-contents__link toc-highlight">Background</a><ul><li><a href="#稀疏矩阵乘法以及行-行算法" class="table-of-contents__link toc-highlight">稀疏矩阵乘法以及行-行算法</a></li><li><a href="#row-row-spgemm的性能问题" class="table-of-contents__link toc-highlight">Row-Row SpGEMM的性能问题</a></li></ul></li><li><a href="#tilespgemm" class="table-of-contents__link toc-highlight">TileSpGEMM</a><ul><li><a href="#概述" class="table-of-contents__link toc-highlight">概述</a></li><li><a href="#稀疏瓦片数据结构" class="table-of-contents__link toc-highlight">稀疏瓦片数据结构</a></li><li><a href="#算法介绍" class="table-of-contents__link toc-highlight">算法介绍</a></li></ul></li><li><a href="#experimental-results" class="table-of-contents__link toc-highlight">Experimental Results</a><ul><li><a href="#实验设置" class="table-of-contents__link toc-highlight">实验设置</a></li><li><a href="#与现有工作进行性能对比" class="table-of-contents__link toc-highlight">与现有工作 进行性能对比</a></li><li><a href="#运行时峰值空间成本的比较" class="table-of-contents__link toc-highlight">运行时峰值空间成本的比较</a></li><li><a href="#tilespgemm算法的运行时间分解" class="table-of-contents__link toc-highlight">TileSpGEMM算法的运行时间分解</a></li><li><a href="#tile格式空间开销的比较" class="table-of-contents__link toc-highlight">tile格式空间开销的比较</a></li><li><a href="#格式转换开销" class="table-of-contents__link toc-highlight">格式转换开销</a></li><li><a href="#tsparse-的张量核比较" class="table-of-contents__link toc-highlight">TSparse 的张量核比较</a></li></ul></li><li><a href="#related-work" class="table-of-contents__link toc-highlight">Related Work</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper-notes-intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs-intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>