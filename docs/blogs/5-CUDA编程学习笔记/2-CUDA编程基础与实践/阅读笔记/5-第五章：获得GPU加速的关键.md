在开发CUDA程序时，往往要验证某些改变是否提高了程序的性能，这就需要对程序进行比较精确的计时。

## 5.1 用CUDA事件计时

CUDA提供了一种基于CUDA事件的计时方式，可用来给一段CUDA代码（包含主机代码和设备代码）计时。

比较常用的计时方式如下：

```cpp
cudaEvent_t start, stop;
CHECK(cudaEventCreate(&start));
CHECK(cudaEventCreate(&stop));
CHECK(cudaEventRecord(start));
cudaEventQuery(start);  // 此处不能用CHECK宏函数

// 需要计时的代码块

CHECK(cudaEventRecord(stop));
CHECK(cudaEventSynchronize(stop));
float elapsed_time;
CHECK(cudaEventElapsedTime(&elapsed_time, start, stop));
printf("Time = %g ms.\n", elapsed_time);

CHECK(cudaEventDestroy(start));
CHECK(cudaEventDestroy(stop));
```

注意：
- 第5行对于TCC驱动模式的GPU来说，可以省略，但对于处于WDDW驱动模式的GPU来说，必须保留，这是因为，在处于WDDM驱动模式的GPU中，一个CUDA流中的操作（比如前面的record操作）并不是直接提交给GPU执行，而是先提交到一个软件队列，需要添加一条对该流的cudaEventQuery操作刷新队列，才能促使前面的操作在GPU执行。
- 不能使用CHECK宏函数的解释：
	- `cudaEventQuery()` 是一个<font color='red'><b>非阻塞的函数</b></font>，它用于**查询指定的 CUDA 事件是否已经完成**。它的返回值可能是 cudaSuccess（表示事件已完成）或者 cudaErrorNotReady（表示事件尚未完成）。因此，使用 CHECK 宏函数（会在非 cudaSuccess 的情况下退出程序）是不合适的。
	- 具体来说，cudaEventQuery() 的作用是检查某个事件是否已经完成。**如果它返回 cudaErrorNotReady，说明事件还没完成，但这并不是一个错误，仅仅是状态的反馈。因此，直接用 CHECK 宏来处理会导致程序错误退出，而这并非期望的行为**。

---

TCC驱动模式（**Tesla Compute Cluster**）和WDDW驱动模式（**Windows Display Driver Model**）的区别：
1. 用途与使用场景：
	- **TCC 模式**：TCC 模式主要用于高性能计算（HPC）、科学计算以及数据中心环境，适用于 Tesla、Quadro 和一些其他专业级显卡。这种模式下，GPU 被配置为计算加速设备，专门用来进行 CUDA 计算而不与显示图形相关联。这种模式通常在数据中心和服务器中使用。
		- 计算密集型任务，如科学计算、深度学习、人工智能训练、物理模拟等。
		-  高性能计算环境或需要专门计算加速的工作站。
	- **WDDM 模式**：WDDM 模式是 Windows 操作系统的标准显示驱动模式，主要用于图形渲染和显示输出，广泛用于 GeForce 系列显卡以及台式机/笔记本电脑的普通图形工作。在 WDDM 模式下，GPU 除了可以用于计算任务外，还负责图形渲染和显示。
		- 桌面显示、图形渲染、3D 游戏、视频播放等日常使用场景。
		- 在不需要专门的高性能计算环境时，GPU 既可用于计算，也可用于图形渲染。
2. 性能与效率：
	- **TCC 模式**：在纯计算任务中，TCC 模式的性能通常优于 WDDM 模式。原因是 TCC 模式优化了 GPU 的计算能力，并且消除了与图形渲染相关的开销，允许更低的延迟和更高的并发计算效率。此外，TCC 模式下，GPU 可以运行多个进程，这对于高性能计算环境非常重要。
	- **WDDM 模式**：虽然也可以进行计算，但由于 GPU 同时负责图形渲染和计算任务，性能不如 TCC 模式高效。WDDM 模式的 GPU 需要处理操作系统的图形显示任务，这会影响 GPU 的纯计算性能。

---

<font color='red'><b>注意</b></font>：在进行计时时，往往需要进行多次计时，然后求取平均值。同时，往往忽略第一次测得的时间，因为第一次计算时，机器（无论是CPU还是GPU）都可能处于预热状态，测得的时间往往偏大。根据后面的测的时间求取平均值。得到测试的时间。

## 5.2 几个影响GPU加速的关键因素

### 5.2.1 数据传输的比例

要获得可观的GPU加速，就必须<font color='red'><b>尽量缩减数据传输所花时间的比例</b></font>。有时，即使有些计算在GPU中的速度并不高，也要尽量在GPU中实现，避免过多的数据经由PCIe传递。

比如：假设计算任务不是做一次数组相加的计算，而是做10000次数组相加的计算， 而且**只需要在程序的开始和结束部分进行数据传输，那么数据传输所占的比例将 可以忽略不计**。此时，整个CUDA程序的性能将大为提高。

### 5.2.2 算术强度

一个计算问题的算术强度指的是**其中算术操作的工作量与必要的内存操作的工作量之比**。例如，在数组相加的问题中，在对每对数据进行求和时需要先将一对数据从设备内存中取出来，然后对它们实施求和计算，最后将计算的结果存放到设备内存。这个问题的算术强度其实是不高的，因 为在取两次数据、存一次数据的情况下只做了一次求和计算。在CUDA中，设备内存的读、写都是代价高昂（比较耗时）的。

那么，如何判断程序的瓶颈是出现在传输过程还是计算过程呢？以下是我的个人观点：

我认为，可以在设计程序时，分别定义两套精度，一个是float，一个是double。在测试时，进行精度的替换，观察实验结果：
- 如果更换两个精度后，实验结果相差不大，那么说明传输时间等其他时间占总时间的比重较大。
- 如果更换两个精度后，实验结果相差较大，那么说明计算时间占总时间的比重较大。

### 5.2.3 并行规模

只有在GPU满负荷工作的情况下，GPU总的计算资源才能充分地发挥作用，从而获得较高的加速比。

## 5.3 CUDA中的数学函数库

CUDA 中的数学函数库是一个高效的工具集，提供了广泛的数学运算支持，能够在 GPU 上执行并行的算术、三角、指数、对数等运算。它通过针对 GPU 架构的优化，可以在执行计算密集型任务时显著提高性能，尤其适用于需要大量数学运算的高性能计算应用。

大部分可以直接像在C中使用函数那样，直接使用即可。

参考网站：https://docs.nvidia.com/cuda/cuda-math-api/


















