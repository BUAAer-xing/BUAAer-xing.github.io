## 10.1 单指令-多线程执行模式

一个GPU被分为若干个流多处理器(SM)。核函数中定义的**线程块在执行时将被分 配到还没有完全占满的SM中**。<font color='red'><b>一个线程块不会被分配到不同的SM中，而总是在一个SM中，但一个SM可以有一个或多个线程块</b></font>。不同的线程块之间可以并发或顺序地执行，一般来说，不能同步。当某些线程块完成计算任务后，对应的SM会 部分或完全地空闲，然后会有新的线程块被分配到空闲的SM。

从更细的粒度看，<font color='red'><b>一个SM以32个线程为单位产生、管理、调度、执行线程</b></font>。 这样的32个线程称为一个线程束。**一个SM可以处理一个或多个线程块。一个线程块又可分为若干个线程束**。例如，一个128线程的线程块将被分为4个线程束， 其中每个线程束包含32个具有连续线程号的线程。

在伏特架构之前，一个线程束中的线程拥有同一个程序计数器(program counter)，但各自有不同的寄存器状态(register state)，从而可以根据程序的逻辑判断选择不同的分支。
- 虽然可以选择分支，但是在执行时，各个分支是依次顺序执行的。
- 在同一时刻，一个线程束中的线程只能执行一个共同的指令或者闲置，这称为单指令-多线程(single instruction multiple thread，SIMT)的执行模式。 
- 当一个线程束中的线程顺序地执行判断语句中的不同分支时，称发生了**分支发散**(branch divergence)。
- <font color='red'><b>分支发散是针对同一个线程束内部的线程的</b></font>。

从伏特架构开始，引入了**独立线程调度(independent thread scheduling)机制**。 每个线程有自己的程序计数器。这使得<font color='red'><b>伏特架构有了一些以前的架构所没有的新的线程束内同步与通信的模式</b></font>，从而提高了编程的灵活性，降低了移植已有CPU 代码的难度。

## 10.2 线程束内的线程同步函数

在归约问题中，当<font color='red'><b>所涉及的线程都在一个线程束内</b></font>时，可以将线程块同步函数`__syncthreads()`换成一个更加廉价的线程束同步函数`__syncwarp()`。可以将它简称为束内同步函数。

```cpp
void __syncwarp(unsigned mask Oxffffffff);
```

该函数有一个可选的参数。该参数是一个代表掩码的无符号整型数，默认值的全部32个二进制位都为1，代表线程束中的所有线程都参与同步。如果要排除一些线程，可以用一个对应的二进制位为0的掩码参数。例如，掩码0xfffffffe代表排除第0号线程。

Tips：束内同步函数`__synwarp()`要比线程块同步函数`__syncthreads()`更加高效。


## 10.3 更多线程束内的基本函数⭐️

### 10.3.1 介绍

这些线程束内的基本函数也需要熟练的掌握，包括：**线程束表决函数**（warp vote functions）、**线程束匹配函数**（warp match functions）、**线程数洗牌函数**（warp shuffle functions）以及**线程束矩阵函数**（warp matrix functions）。

#### (1) 线程束表决函数

1.  `__all_sync()`：在指定的线程掩码下，判断掩码范围内的<font color='red'><b>所有线程的谓词是否都为真</b></font>。
	- `int __all_sync(unsigned mask, int predicate);`
	- **mask**：指定需要参与表决的线程掩码。
	- **predicate**：当前线程的布尔条件。
	- **返回值**：如果掩码范围内的所有线程的predicate都为真，返回1，否则返回0。
2.  `__any_sync()`：在指定的线程掩码下，判断掩码范围内<font color='red'><b>是否有任意一个线程的谓词为真</b></font>。
	- `int __any_sync(unsigned mask, int predicate);`
	- **mask**：指定需要参与表决的线程掩码。
	- **predicate**：当前线程的布尔条件。
	- **返回值**：如果掩码范围内有任意一个线程的 `predicate` 为真，返回非零值；否则返回0。
3.  `__ballot_sync()`：在指定的线程掩码下，返回掩码范围内所有线程的谓词结果的位掩码。（也就是说，返回所有线程的结果）
	- `unsigned int __ballot_sync(unsigned mask, int predicate);`
	- **mask**：指定需要参与表决的线程掩码。
	- **predicate**：当前线程的布尔条件。
	- **返回值**：返回一个位掩码，每一位表示线程束中相应线程的 `predicate` 结果，真为1，假为0。
4.  `__activemask()`：返回当前线程束中的活动线程掩码。
	- `unsigned int __activemask();`
	- **返回值**：返回一个位掩码，每一位表示线程束中对应线程的活跃状态，活跃为1，非活跃为0。
5.  `__match_any_sync()`：在指定的线程掩码下，<font color='red'><b>查找与当前线程的值相等的其他线程</b></font>，并返回相应的位掩码。
	- `unsigned int __match_any_sync(unsigned mask, T value);`
	- **mask**：指定需要参与表决的线程掩码。
	- **value**：当前线程的值。
	- **返回值**：返回一个位掩码，表示哪些线程的值与当前线程的值相同。
6.  `__match_all_sync()`：在指定的线程掩码下，<font color='red'><b>判断掩码范围内的所有线程是否都具有相同的值</b></font>，并返回相应的**位掩码**。
	- `unsigned int __match_all_sync(unsigned mask, T value, int* pred);`
	- **mask**：指定需要参与表决的线程掩码。
	- **value**：当前线程的值。
	- **pred**：输出指针，存储是否所有线程的值都相同（1为相同，0为不同）。
	- **返回值**：返回一个位掩码，表示哪些线程的值与当前线程的值相同。

拿第一个函数举例来说：
```cpp
__global__ void testAllSync(int* result) {
    unsigned int mask = 0b01010101010101010101010101010101;
    int predicate = (threadIdx.x % 2 == 0); // 偶数线程为真，奇数线程为假
    int allSyncResult = __all_sync(mask, predicate);
    if (threadIdx.x == 0) {
        *result = allSyncResult;
    }
}
// 结果为1，因为上面的只让具有偶数标号的线程参与表决。
```
其中，mask表示参与的线程掩码，它是一个32位的无符号整数。将其展开为32位的二进制，如果要让第1个线程（也就是threadId.x为0）的线程参与，则只需要将从右边开始的第一个数变为1即可。


#### (2) 线程束洗牌函数

CUDA 中的线程束同步洗牌函数（Shuffle Functions）用于<font color='red'><b>在一个线程束（warp）内的不同线程之间交换数据或从某个线程读取数据</b></font>。这些函数能够**直接在寄存器之间进行数据交换，无需使用共享内存，从而实现高效的线程间通信**。

1.  **`__shfl_sync()`**：  
    从同一个线程束中指定的线程获取一个变量。  参与线程返回标号为srcLane的线程中变量v的值。这是一种广播式数据交换，即**将一个线程中的数据广播到所有线程**（包括自己）。
	- `T __shfl_sync(unsigned mask, T var, int srcLane, int width = warpSize);`
	- **mask**：指定需要参与洗牌操作的线程掩码。
	- **var**：当前线程拥有的变量（<font color='red'><b>填你想要获得目标线程中的变量名</b></font>）。
	- **srcLane**：源线程的索引（范围：0 到 `warpSize - 1`）（<font color='red'><b>填你想要获得目标线程的线程id</b></font>）。
	- **width**：指定参与洗牌的线程数量，默认为线程束大小（`warpSize`）。
	- **返回值**：返回指定 `srcLane` 线程的 `var`。
2.  **`__shfl_up_sync()`**：  
    从较低索引的线程获取变量。可以用于执行前缀操作。  
	- `T __shfl_up_sync(unsigned mask, T var, unsigned int delta, int width = warpSize);`
	- **mask**：指定需要参与洗牌操作的线程掩码。
	- **var**：当前线程拥有的变量。
	- **delta**：指定从较低索引的线程获取数据的<font color='red'><b>偏移量</b></font>。
		- 比如，当delta=2时（假如w=8），使用该函数后，0～5号线程中变量v的值将会传送到第2～7号线程的变量v中，而第0～1号线程返回它们原来的变量v值。也就是说，将数据向上整体平移2位。
		- ![image.png|400](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240930152634.png)
		- 比较形象的说法是，这是一种将<font color='red'><b>数据向上平移</b></font>的操作。
	- **width**：指定参与洗牌的线程数量，默认为线程束大小（`warpSize`）。
	- **返回值**：返回当前线程索引减去 `delta` 的线程的 `var`。
3.  **`__shfl_down_sync()`**：  
    从较高索引的线程获取变量。可以用于执行后缀操作。  
	- `T __shfl_down_sync(unsigned mask, T var, unsigned int delta, int width = warpSize);`
	- **mask**：指定需要参与洗牌操作的线程掩码。
	- **var**：当前线程拥有的变量。
	- **delta**：指定从较高索引的线程获取数据的偏移量。
		- 比如，当delta=2时（假如w=8），使用该函数后，2～7号线程中变量v的值将会传送到第0～5号线程的变量v中，而第6～7号线程返回它们原来的变量v值。也就是说，将数据向下整体平移2位。
		- ![image.png|400](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240930153017.png)
		- 比较形象的说法是，这是一种将<font color='red'><b>数据向下平移</b></font>的操作。
	- **width**：指定参与洗牌的线程数量，默认为线程束大小（`warpSize`）。
	- **返回值**：返回当前线程索引加上 `delta` 的线程的 `var`。
4.  **`__shfl_xor_sync()`**：  
    从与当前线程索引的异或结果索引的线程获取变量。通常用于并行归约或跨线程通信。  
	- `T __shfl_xor_sync(unsigned mask, T var, int laneMask, int width = warpSize);`
	- **mask**：指定需要参与洗牌操作的线程掩码。
	- **var**：当前线程拥有的变量。
	- **laneMask**：用于与线程索引进行异或运算的掩码。
	- **width**：指定参与洗牌的线程数量，默认为线程束大小（`warpSize`）。
	- **返回值**：返回 `threadIdx.x ^ laneMask` 线程的 `var`。

注意点：
- 类型T可以是：int、long、long long、unsigned、unsigned long、unsigned long long、float、double。
- 每个线程束洗牌函数的最后一个参数w都是可选的，有默认值warpSize，在当前所有架构的GPU中都是32，因此参数w只能取2、4、8、16、32这5个整数中的一个。当w小于32时，就相当于（逻辑上的）线程束大小是w，而不是32，其他规则不变。
- **参数mask称为掩码**，是一个无符号整数，具有32位。这32个 二进制位从右边数起刚好对应线程束内的32个线程。该整数的32个二进制位要么是0，要么是1。<font color='red'><b>掩码用于指定将要参与计算的线程</b></font>：当掩码中的一个二进制位为1时，代表对应的线程参与计算；当掩码中的一个二进制位为0时，代表忽略对应的线程。特别地，各种函数返回的结果对被掩码排除的线程来说是没有定义的。所以，<font color='red'><b>不要尝试在这些被排除的线程中使用函数的返回值</b></font>。

洗牌函数提供了<font color='red'><b>线程束内高效的数据交换机制</b></font>，尤其在需要线程间通信、前缀和、归约等操作时，能避免使用共享内存而提升性能。

利用第一个函数举个例子：
```cpp
__global__ void testShflSync(int* result){
    unsigned int mask = 0xffffffff;
    unsigned int tid = threadIdx.x;
    int test = 0;
    if(tid == 6){
        test = 6;
    }
    test = __shfl_sync(mask,test,6,32);
    if(tid == 0){
        *result = test;
    }
}
// 返回结果为6
```

### 10.3.2 利用线程束洗牌函数进行归约计算

函数`__shfl_down_sync()`的作用是将高线程号的数据平移到低线程号中，这真是在归约问题中需要的操作。

```cpp
__global__ void reduce_shfl(const real *d_x, real *d_y, const int N) {
    const int tid = threadIdx.x;
    const int bid = blockIdx.x;
    const int n = bid * blockDim.x + tid;
    extern __shared__ real s_y[];
    s_y[tid] = (n < N) ? d_x[n] : 0.0;
    __syncthreads();

	// 将线程块内的数据归约到一个warp中
    for (int offset = blockDim.x >> 1; offset >= 32; offset >>= 1) {
        if (tid < offset) {
            s_y[tid] += s_y[tid + offset];
        }
        __syncthreads();
    }

    real y = s_y[tid];

	// 在warp中使用线程束洗牌函数进行归约，最终将结果归约到线程束0中。
    for (int offset = 16; offset > 0; offset >>= 1) {
        y += __shfl_down_sync(FULL_MASK, y, offset);
    }

	// 将数据放到全局内存中
    if (tid == 0) {
        atomicAdd(d_y, y);
    }
}
```

完整的测试程序如下：

```cpp
#include<cuda_runtime.h>
#include<iostream>
#include<string>
#include<vector>
#include<numeric>

using namespace std;

__global__ void reduce(const float* d_x, float* d_y, const int N){
    int tid = threadIdx.x;
    int bid = blockIdx.x;
    int n = tid + bid * blockDim.x;
    __shared__ float s_y[256];
    if(n < N){
        s_y[tid] = d_x[n];
    }
    __syncthreads();

    // if(tid == 0){
    //     for(int i=0; i<N; i++){
    //         printf("s_y[%d]=%f\n",i,s_y[i]);
    //     }
    // }
    // __syncthreads();

    for(int offset = blockDim.x>>1; offset >=32; offset = offset>>1){
        if(tid < offset){
            s_y[tid] += s_y[tid+offset];
        }
        __syncthreads();
    }

    // if(tid == 0){
    //     for(int i=0; i<32; i++){
    //         printf("s_y[%d]=%f\n",i,s_y[i]);
    //     }
    // }
    // __syncthreads();

    float y = s_y[tid];
    for(int offset = warpSize>>1; offset > 0; offset = offset>>1){
        y = y + __shfl_down_sync(0xffffffff,y,offset,32);
    }

    if(tid == 0){
        atomicAdd(d_y, y);
    }
}

int main(){

    const int N = 256;

    vector<float> h_x(N,0);
    for(int i=0; i<N; i++){
        h_x[i] = i;
    }

    float* d_x;
    float* d_y;
    
    cudaMalloc(&d_x, N*sizeof(float));
    cudaMalloc(&d_y, sizeof(float));

    cudaMemcpy(d_x, h_x.data(), N*sizeof(float), cudaMemcpyHostToDevice);

    reduce<<<1,N>>>(d_x, d_y, N);

    float h_y = 0.0;

    cudaMemcpy(&h_y, d_y, sizeof(float), cudaMemcpyDeviceToHost);

    cout<<"y="<<h_y<<endl;

    float ans = accumulate(h_x.begin(), h_x.end(), 0);

    cout<<"ans="<<ans<<endl;

    return 0;
}
```

在使用线程束内的函数进行归约时，需要注意以下几点：
- 在进行线程束内的循环之前，需要将共享内存的数据复制到寄存器中，这是因为线程束相关的函数操作对象是寄存器。
- 使用线程束内的洗牌函数进行归约时，去掉了同步函数，也去掉了对线程号的限制，这是因为洗牌函数能够自动处理同步与读写竞争的问题。

## 10.4 协作组

在CUDA编程中，协作组（Cooperative Groups）是一种使线程可以更灵活地进行同步和通信的抽象。它引入了线程组（thread group）的概念，允许程序员定义和管理线程集合，以便在这些线程中更有效地进行数据共享和同步操作。

协作组的主要特点包括：
1. **自定义线程组**：协作组允许用户创建不同大小和形状的线程组，不再局限于传统的warp（32个线程）或block（多个warp）。<font color='red'><b>用户可以根据计算需求创建更细粒度或粗粒度的线程组</b></font>。
2. **同步与通信**：在传统CUDA中，只能在同一个block中的所有线程上进行同步（通过`__syncthreads()`），而协作组允许用户在定义好的线程组内进行同步（例如通过`group.sync()`）。这样可以减少不必要的同步操作，提升性能。
3. **灵活的线程分组方式**：协作组允许通过不同的维度（如warp级、block级、grid级等）对线程进行分组。例如，可以创建只包含warp内线程的组，或者跨多个block的更大组。
4. **简化并行编程模型**：协作组的出现简化了CUDA程序中的一些并行模式，使得编写复杂的并行算法时更具灵活性和可读性。

常见的协作组API
- `cooperative_groups::this_thread_block()`：返回当前线程block的协作组。
- `cooperative_groups::tiled_partition<group_size>(group)`：将一个线程组划分为多个大小为`group_size`的小组。
- `group.sync()`：在协作组中的所有线程上进行同步。

示例代码：
```cpp
#include <cooperative_groups.h>
using namespace cooperative_groups; // 需要特定的命名空间
__global__ void kernel() {
    // 获取当前block的协作组
    thread_block block = this_thread_block();
    // 执行同步
    block.sync();
}
```

目前暂时未想到具体的作用，hold，后面用到再做详细的记录。

## 10.5 数组归约程序的进一步优化

### 10.5.1 提高线程利用率

- 在归约之前，将多个全局内存数组的数据累加到一个共享内存数组的一个元素中。为了做到这一点，可以让每个线程处理若干个数据，这里需要注意的是：**千万不要让一个线程处理相邻的若干数据，因为这必然导致全局内存的非合并访问**。
	- 要保证全局内存的合并访问，必须让相邻的线程访问相邻的数据，而同一线程所访问的数据之间必然具有某种跨度。（这个跨度可以是一个线程块的线程数，也可以是整个网格的线程数。）

### 10.5.2 避免反复分配与释放设备内存

设备内存的分配与释放是比较耗时的。

一种优化方案是使用静态全局内存代替这里的动态全局内存，因为静态内存是编译期间就会分配好的，不会在运行程序时反复地分配，故会比动态内存分配高效很多。

```cpp
__device__ double static_y[grid_size];
```

通过一个函数，可以获得该静态全局内存的指针，供核函数使用：
```cpp
double *d_y; 
cudaGetSymbolAddress((void**)&d_y, static_y);
```

除了使用静态全局内存替换动态全局内存外，还要**尽量避免在较内层循环反复地分配与释放设备内存**。
