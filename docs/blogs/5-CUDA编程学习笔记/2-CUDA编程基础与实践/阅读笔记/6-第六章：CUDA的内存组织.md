
在使用GPU进行加速时，最重要的是<font color='red'><b>合理地使用各种设备内存</b></font>。

## 6.1 CUDA的内存组织简介

现代计算机中的内存往往存在一种组织结构，在这种结构中，含有多种类型的内存，每种内存分别具有不同的容量和延迟。相对于不用分级的内存，用这种分级的内存可以降低延迟，提高计算效率。

CPU和GPU中都有内存分级的设计。相对于CPU编程来说，**CUDA编程模型向程序员提供更多的控制权**。因此，<font color='red'><b>对CUDA编程来说，熟悉其内存的分级组织是非常重要的</b></font>。

<div style={{ textAlign:'center' }}>
    <img src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240928165405.png" width="500"/>
</div>

<div style={{ textAlign:'center' }}>
<table border="1" cellpadding="5" cellspacing="0" width="100%">
    <tr>
        <th>内存类型</th>
        <th>物理位置</th>
        <th>访问权限</th>
        <th>可见范围</th>
        <th>生命周期</th>
    </tr>
    <tr>
        <td>全局内存</td>
        <td>在芯片外</td>
        <td>可读可写</td>
        <td>所有线程和主机端</td>
        <td>由主机分配与释放</td>
    </tr>
    <tr>
        <td>常量内存</td>
        <td>在芯片外</td>
        <td>仅可读</td>
        <td>所有线程和主机端</td>
        <td>由主机分配与释放</td>
    </tr>
    <tr>
        <td>纹理和表面内存</td>
        <td>在芯片外</td>
        <td>一般仅可读</td>
        <td>所有线程和主机端</td>
        <td>由主机分配与释放</td>
    </tr>
    <tr>
        <td>寄存器内存</td>
        <td>在芯片内</td>
        <td>可读可写</td>
        <td>单个线程</td>
        <td>所在线程</td>
    </tr>
    <tr>
        <td>局部内存</td>
        <td>在芯片外</td>
        <td>可读可写</td>
        <td>单个线程</td>
        <td>所在线程</td>
    </tr>
    <tr>
        <td>共享内存</td>
        <td>在芯片内</td>
        <td>可读可写</td>
        <td>所在线程块</td>
        <td>所在线程块</td>
    </tr>
</table>
</div>

❗️❗️**局部内存和共享内存的区别**：
- **局部内存** : 是每个线程私有的，用于**存储不能放入寄存器的局部变量**，但<font color='red'><b>它实际上位于全局内存中，因此访问速度较慢</b></font>。
- **共享内存** : 是**线程块内的所有线程共享的高速内存**，位于芯片上，<font color='red'><b>适合线程间频繁交换数据的场景，能极大提升并行计算的效率</b></font>。

## 6.2 CUDA中不同类型的内存

### 6.2.1 全局内存

这里全局内存（global memory）的含义是核函数中的所有线程都能访问其中的数据。全局内存由于没有放在GPU的芯片上，因此具有较高的延迟和较低的访问速度。

全局内存的主要角色是为核函数提供数据，并在主机与设备以及设备与设备之间传递数据。

全局内存对整个网格的所有线程可见。也就说，一个网格的所有线程都可以访问（读或写）传入核函数的设备指针所指向的全局内存中的全部数据。全局内存的生命周期(lifetime)不是由核函数决定的，而是由主机端决定的。 在数组相加的例子中，由指针d_x、d_y和d_z所指向的全局内存缓冲区的生命周期就是从主机端用cudaMalloc()对它们分配内存开始，到主机端用cudaFree() 释放它们的内存结束。在这期间，可以在相同的或不同的核函数中多次访问这些全局内存中的数据。

全局内存不单单可以动态进行malloc和free，也可以在编译时进行指定，从而申请一个<font color='red'><b>静态全局内存变量</b></font>。其所占内存数量是在编译期间就确定的。而且，这样的静态全局内存变量必须在所有主机与设备函数外部定义，所以是一种<font color='red'><b>全局的静态全局内存变量</b></font>。比如一个定义的例子：

```cpp
__device__ int x = 1;
__device__ float y[3];
```

其中，修饰符`__device__`说明该变量是设备中的变量，而不是主机中变量。

可以看出，由于变量定义在外部，也就是全局中，因此，**在核函数中，<font color='red'><b>可直接对静态全局内存变量进行访问</b></font>，并不需要将它们以参数的形式传给核函数**。不可在主机函数中直接访问静态全局内存变量，但是可以使用`cudaMencpyTosymbol()`函数和`cudaMemcpyFromSymbol()`函数在静态全局内存与主机内存之间传递数据。

```cpp
cudaError_t cudaMemcpyToSymbol
(
    const void* symbol,  // 静态全局内存变量名
    const void* src,     // 主机内存缓冲区指针
    size_t count,        // 复制的字节数
    size_t offset = 0,   // 从 symbol 对应设备地址开始偏移的字节数
    cudaMemcpyKind kind = cudaMemcpyHostToDevice  // 可选参数
);

cudaError_t cudaMemcpyFromSymbol
(
    void* dst,           // 主机内存缓冲区指针
    const void* symbol,  // 静态全局内存变量名
    size_t count,        // 复制的字节数
    size_t offset = 0,   // 从 symbol 对应设备地址开始偏移的字节数
    cudaMemcpyKind kind = cudaMemcpyDeviceToHost  // 可选参数
);
```

💡：这两个函数的参数symbol可以是**静态全局内存变量**的变量名，**也可以是常量内存变量的变量名**。

### 6.2.2 常量内存

常量内存（constant memory）是有常量缓存的全局内存，数量有限，只有64KB。它的可见范围和生命周期与全局内存一样。不同的是，**常量内存仅可读、不可写**。由于有缓存，**常量内存的访问速度比全局内存高**，<font color='red'><b>但得到高访问速度的前提是一个线程束中的线程（一个线程块中相邻的32个线程）要读取相同的常量内存数据</b></font>。

常量内存的数据，使用`__constant__`进行定义，并使用`cudaMemcpyTosymbol()`函数，将主机中的数据传递给设备的常量内存所在位置，然后核函数才可以进行使用。

### 6.2.3 纹理内存和表面内存

纹理内存(texture memory)和表面内存(surfa，ce memory)类似于常量内存， 也是一种**具有缓存的全局内存**，有相同的可见范围和生命周期，而且一般仅可读 (表面内存也可写)。不同的是，纹理内存和表面内存容量更大，而且使用方式和常量内存也不一样。 

对于计算能力不小于3.5的GPU来说，将某些只读全局内存数据用`__ldg()` 函数通过只读数据缓存(read-only data cache)读取，既可达到使用纹理内存的加速效果，又可使代码简洁。

该函数的原型为 ```
```cpp
T __ldg(const T*address)；
```
其中，T是需要读取的数据的类型；address是数据的地址。对帕斯卡架构和更高的架构来说，全局内存的读取在默认情况下就利用了`__ldg()`函数，所以不需要明显地使用它。

### 6.2.4 寄存器

在核函数中定义的**不加任何限定符的变量**一般来说就存放于寄存器中。核函数中定义的**不加任何限定符的数组**有可能存放于寄存器中，也有可能因为寄存器存不下，转而存放于局部内存中。

另外，之前的各种内建变量，比如：**gridDim、blockDim、blockIdx、threadIdx及warpSize都保存在特殊的寄存器中**。在核函数中访问这些内建变量是很高效的！

寄存器变量仅仅被一个线程可见。也就是说，每一个线程都有一个定义变量的副本。虽然在核函数的代码中用了同一个变量名，但是不同的线程中该寄存器变量的值是可以不同的。<font color='red'><b>每个线程都只能对它的副本进行读写。</b></font> 寄存器的生命周期也与所属线程的生命周期一致，从定义它开始，到线程消失时结束。

寄存器内存在芯片上，是所有内存中访问速度最高的，但是其数量也很有限。

一定要注意的是：<font color='red'><b>一个寄存器占有32bit(4字节)的内存</b></font>。所以，**一个双精度浮点数将使用两个寄存器**。

### 6.2.5 局部内存

核函数中定义的不加任何限定符的变量有可能在寄存器中，也有可能在局部内存中。**寄存器中放不下的变量，以及索引值不能在编译时就确定的数组，都有可能放在局部内存中**。这种判断是**由编译器自动**做的。

虽然局部内存在用法上类似于寄存器，但<font color='red'><b>从硬件来看，局部内存只是全局内存的一部分。所以，局部内存的延迟也很高</b></font>。**每个线程最多能使用高达512KB的局 部内存，但使用过多会降低程序的性能**。

### 6.2.6 共享内存

**共享内存和寄存器类似，存在于芯片上，具有仅次于寄存器的读写速度**，数量也有限。

不同于寄存器的是，**共享内存对整个线程块可见**，其生命周期也与整个线程块一致，也就是说，<font color='red'><b>每个线程块拥有一个共享内存变量的副本</b></font>。共享内存变量的值在不同的线程块中可以不同。一个线程块中的所有线程都可以访问该线程块的共享内存变量副本，但是**不能访问其他线程块的共享内存变量副本**。

共享内存的主要作用是减少对全局内存的访问，或者改善对全局内存的访问模式。

### 6.2.7 L1和L2缓存

从费米架构开始，有了SM层次的L1缓存（一级缓存）和设备（一个设备有 多个SM)层次的工2缓存（二级缓存）。它们主要用来缓存全局内存和局部内存的 访问，减少延迟。

## 6.3 SM及其占有率

### 6.3.1 SM的构成

一个GPU是由多个SM构成的。一个SM包含如下资源：
- 一定数量的寄存器
- 一定数量的共享内存
- 常量内存的缓存
- 纹理和表面内存的缓存
- L1缓存
- 多个<font color='red'><b>线程束调度器</b></font>
	- 用于在不同线程组的上下文之间迅速地切换，以及为准备就绪的线程束发出执行指令。
- <font color='red'><b>执行核心</b></font>，包括：
	- 若干个整型数运算的核心（INT 32）
	- 若干个单精度浮点数运算的核心（FP32）
	- 若干个双精度浮点数运算的核心（FP64）
	- 若干个单精度浮点数超越函数的特殊函数单元
	- 若干混合精度的张量核心（tensor cores），最初由伏特架构引入，适用于机器学习中的低精度矩阵计算。

### 6.3.2 SM的占有率

因为一个SM中的各种计算资源是有限的，那么有些情况下，一个SM中驻留的线程数目就有可能达不到理想的最大值。

要分析SM的理论占有率，还需要知道两个指标：
- 一个SM中最多能拥有的线程块个数
- 一个SM中最多能拥有的线程个数

在并行规模足够大（总线程数足够多）的前提下，分几种情况来分析SM的理论占有率：
- 寄存器和共享内存使用量很少的情况
	- 此时，SM的占有率完全由执行配置中的线程块大小决定。
- 有限的<font color='red'><b>寄存器数量</b></font>对占有率的约束情况。
	- 比如，一个SM最多能使用的寄存器个数为64K(64×1024)。如果希望在个SM中驻留最多的线程(2048个)，核函数中的每个线程最多只能用32个寄存器。当每个线程所用寄存器个数大于64时，SM的占有率将小于50%：当每个线程所用寄存器个数大于128时，SM的占有率将小于 25%。
- 有限的<font color='red'><b>共享内存</b></font>对占有率的约束情况。
	- 假如，一个SM最多运行的线程个数为2048个，当线程块大小为128时，则每个SM要激活16个线程块才能达到最大的SM线程利用率。假如，一个SM中的共享内存大小为48KB，那么，当激活16个线程块时，每个线程块只能使用3KB的共享内存。
	- 如果一个线程块使用了超过48KB的共享内存，会直接导致核函数无法运行。
	- `ptxas error   : Entry function '_Z5hellov' uses too much shared data (0x2625a00 bytes, 0xc000 max)`

可以使用编译器选项`--ptxas-options=-v`来报告每个核函数的寄存器使用数量。

CUDA还提供了核函数的`__launch_bounds__()`修饰符和 `-maxrregcount=`编译选项来让用户分别对一个核函数和所有核函数中寄存器的使用数量进行控制。

## 6.4 用CUDA运行时API函数查询设备

一个查询设备的函数：

```cpp
void print_cuda_device_properties(int device_id = 0) {
    CHECK_CUDA(cudaSetDevice(device_id));
    cudaDeviceProp prop;
    CHECK_CUDA(cudaGetDeviceProperties(&prop, device_id));
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d\n", "Device id", device_id);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %s\n", "Device name", prop.name);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d.%d\n", "Compute capability", prop.major, prop.minor);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %g GB\n", "Amount of global memory", prop.totalGlobalMem / (1024.0 * 1024 * 1024));
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %g KB\n", "Amount of constant memory", prop.totalConstMem / 1024.0);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d %d %d\n", "Maximum grid size", prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d %d %d\n", "Maximum block size", prop.maxThreadsDim[0], prop.maxThreadsDim[1], prop.maxThreadsDim[2]);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d\n", "Number of SMs", prop.multiProcessorCount);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %g KB\n", "Maximum amount of shared memory per block", prop.sharedMemPerBlock / 1024.0);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %g KB\n", "Maximum amount of shared memory per SM", prop.sharedMemPerMultiprocessor / 1024.0);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d K\n", "Maximum number of registers per block", prop.regsPerBlock / 1024);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d K\n", "Maximum number of registers per SM", prop.regsPerMultiprocessor / 1024);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d\n", "Maximum number of threads per block", prop.maxThreadsPerBlock);
    printf("+--------------------------------------------+-------------------------+ \n");
    printf("  %-42s |  %d\n", "Maximum number of threads per SM", prop.maxThreadsPerMultiProcessor);
    printf("+--------------------------------------------+-------------------------+ \n");
}
```
