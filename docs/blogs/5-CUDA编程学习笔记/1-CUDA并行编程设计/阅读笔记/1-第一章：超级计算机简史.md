## 1.1-简介

超级计算机通常走在技术发展的最前沿。超级计算是我们在现代处理器中看到的许多技术的发展动力。由于对用更快的处理器来处理更大数据集的需求，工业界不断生产出更快的计算机。正是在这些发展变化中，GPU的CUDA技术走到了今天。

超级计算机和桌面计算正在向着<font color='red'><b>异构计算</b></font>发展——人们试图通过将中央处理器（Central Processor Unit，CPU)和图形处理器(Graphics Processor Unit，GPU)技术混合在一起来实现更高的性能。

**无论在HPC行业，还是在桌面电脑领域，GPU编程已经成为主流！！！**

## 1.2-冯 · 诺依曼计算架构

**内存速度和时钟速度的比率**是限制CPU和GPU吞吐量的一个重要因素。深入分析会发现，除了CPU和GPU中的一些例外，大多数应用程序属于。“内存受限型（性能的提高收到内存速度的限制）”，而不是“处理器时钟周期或负载受限型”。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818184651.png)

在循环程序结构中，计算机执行的是相同的指令，只是处理的数据不同。如果设置多级缓存cache来避免这种限制显然是比较困难的，因为在实际程序中，循环程序往往非常大，可能达几兆字节大小。即便是程序可以存放在缓存中，但数据集往往就存不下了。所以尽管设置了缓存，处理器仍然会因为受到内存吞吐率或带宽的限制，而无法发挥其所具有的处理能力。但是随着缓存容量的不断增大，使用更大容量缓存所带来的增速收益却迅速下降。这意味着，**现代处理器中使用大容量缓存并不是提高性能的一个有效办法**，除非有办法将问题的整个数据集都装人缓存。


## 1.3-Cray（克雷）

发展超级计算机，通常会占用庞大的空间，通常有特殊的冷却需求，并且需要专门的技术团队进行管理和维护，同样，它们的运行需要消耗大量的电能，从某种程度上说，它们每年的运行费用和生产它们的费用一样昂贵。事实上，<font color='red'><b>电力供应是人们在规划是否构建一台超级计算机时考虑的关键因素之一</b></font>，也是当下超级计算机发展的主要限制条件之一。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818190444.png)
<center> <font face='华文宋体' size='4'> 全球前五名超级计算机 </font> </center>

向量机：一个操作同时处理多个操作数。

Cray系列超级计算机通过<font color='red'><b>硬件</b></font>来支持“散布”（scatter）类和“收集”（gather）类操作原语。Cray系列超级计算机仍然活跃在超级计算机市场，现在的全球前五名的超级计算机中，有三个是Cray系列的。 （它们的网址：[Cray](https://www.hpe.com/cn/zh/home.html)）

## 1.4-连接机

早在1982年，一家名为Thinking Machines的公司提出了一个非常有趣的设计方案，即连接机(Connection Machine，CM)。**他们通过一遍又一遍 地使用一些简单的零部件创造了一个16核的CPU，并在一台机器上安装了4096个这样的设备**。这是一个完全不同的概念。它们并不是通过一个高速处理器处理数据集，而是通过64K 个处理器来完成一个任务。如果将现在CPU采用的粗线程方案迁移至这种采用大规模并行方式处理的机器，处理器之间的<font color='red'><b>同步</b></font>和<font color='red'><b>通信</b></font>将是很大的问题。


## 1.5-Cell 处理器

基本思想：它的思想是用一个常规处理器作为监管处理器，该处理器与大量的高速流处理器相连。在 Cell处理器中，**常规的PowerPC(PPC)处理器担任与流处理器和外部世界的接口**。而SIMD 流处理器，IBM称其为SPE，则在常规处理器的管理下，处理数据集。
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818193256.png)

由于具有和相应处理器直接对话的能力，因此很多问题的求解就可以通过一系列简单的步骤来实现。PPC核可以取来一组待处理的数据，然后将其分配给8个SPE处理。每个SPE所做的处理是相同的，然后存回本地内存。当所有SPE完成工作后，PC核再从每个SPE中取回数据，然后将这组数据（或 数据条)写入内存区域。

它也存在着**带宽限制**以及**数据传递到下一阶段的开销**问题，因此，当通过在每个SPE上执行一个一致的程序来提高效率时，我们也会在**处理器间通信上有所损失**，并最终受到最慢的那个处理步骤的限制，这是任何基于流水线模型的工作都会遇到的一个共性问题。


## 1.6-多点计算

在计算领域里，你经常能遇见“**收益递减规律**”(The law of diminishing returns)。即便你在一个单一方面投入再多，结果也没有太大改变，因为它受限于**成本**、**空间**、**电力供应**、**散热**等因素。<font color='red'><b>解决办法是在各个影响因素之间选择一个平衡点，然后多次地复制它</b></font>。

从1990年左右开始，集群计算开始兴起。集群计算的原理十分简单，简单进行一下抽象就是：常规PC机+交换机。PC集群通常运行Linux操作系统的集群版本，在这种版本中，它的每个节点从中央主控节点上获取引导指令和操作系统。一个集群的微缩模型如下：
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818194844.png)
然而，集群计算存在的问题是它的速度受到节点之间通信总量的限制，而这些通信是求解问题所必须的。
- 如果有32个计算节点，问题正好被划分为32个子任务，并且各个节点之间无需通信，这是最适合进行集群计算的。
- 但是，如果每个数据点都需要从所有节点上获取数据，那对于通信速度较为弱势的集群来说，这就很糟糕了。

现代GPU的体系结构也完全相同。一个GPU内有许多**流处理器簇**（Streaming Multiprocessor，**SM**)，它们就类似CPU的核。这些SM与共享存储（一级缓存）连接在一起， 然后又与相当于SM间互联开关的二级缓存相连。数据先是存储在全局存储中，然后被主机取出并使用。除留一部分自己处理外，主机将剩余的数据通过PCI-E互联开关直接送往另一 个GPU的存储空间。<font color='red'><b>PCI-E互联开关的传输速度比任何一个互联网络快好多倍</b></font>（这就相当于加快了之前集群计算中各个节点之间通信速度，从而，相对比而言，弥补了集群处理的劣势）。
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818195258.png)

## 1.7-早期的GPGPU编程

图形处理器（Graphics Processing Unit，GPU)是现代PC机中的常见设备。它们向CPU 提供一些基本的操作，比如，对内存中的图像进行着色，然后将其显示在屏幕上。一个GPU 通常会处理一个复杂的多边形集合，即需要着色的图片映像，然后给这些多边形涂上图片的纹理，进而再做阴影和光照处理。

重要的进步之一就是可编程着色器(programmable shader)的出现。它们是GPU运行的 一些用来计算各种图片效果的小程序。这样，着色就不必固定在GPU中进行。通过可下载的着色器，就可以完成这些操作。这就是最初的通用图形处理器（GPGPU)编程。这表示GPU设计朝着“处理单元功能不再是固定的”方向迈出了第一步。
将GPU变成一个具有和CPU一样运行模式的可编程设备是很多人当时的目标。但是，一句话，一项不容易学习的技术不可能获得程序员的追捧， 也不可能激起程序员广泛的兴趣。这些产品一直没有在市场上获得成功。而**CUDA可能是首次实现了上述目标并向程序员提供了一个真正通用的GPU编程语言**。


## 1.8-单核解决方案的消亡

单个核已经到达了4GHz左右的时钟速度极限了，超过该点后，处理器会产生太多的热量（因为随着时钟频率的提升，电力功耗增大了）。

面对不能再提高时钟频率的挑战，却还需要制造更快的处理器，处理器制造商只好另辟蹊径（堆核，从单核到多核）。
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818201138.png)
<center> <font face='华文宋体' size='4'> 具有96个物理核心的CPU芯片 </font> </center>

## 1.9-英伟达和CUDA

2007年，英伟达发现了一个能使GPU进入主流的契机，那就是为GPU增加一个易用的**编程接口**，也就是所谓的**统一计算架构**(Compute Unified Device Architecture，CUDA)。这为无须学习复杂的着色语言或者图形处理原语，就能进行GPU编程提供了可能。

CUDA是C语言的一种扩展，它允许使用标准C来进行GPU代码编程。这个代码既适用于主机处理器(CPU)，也适用于设备处理器(GPU)。
- 主机处理器负责<font color='red'><b>派生</b></font>出运行在GPU设备处理器上的多线程任务(CUDA称其为**内核程序**)。
- GPU设有内部调度器来把这些**内核程序**分配到相应的**GPU硬件**上。
假设这些任务有足够的并行度，随着GPU中流处理器簇数量的增加，程序的运算速度就会提升。

随着CUDA一起引入的，是**Tesla系列板卡**。这些并不是图形卡，事实上这些卡既没有 DVI接口，也没有VGA接口，它们是专用于科学计算的计算卡，使用它们可以为科学计算提供很大的加速比。这些卡既可以安装在常规的桌面PC上，也可以安装在专用的服务器机架上。CUDA和GPU正在改变着高性能计算领域的形式。


## 1.10-GPU硬件

英伟达G80系列处理器以及后续产品是采用类似连接机和IBM的Cell处理器的设计方案来进行实现的。每个图形卡由若干个流处理器簇（**SM**）组成，每个SM配备8个或者更多的**流处理器**（Stream Processor ，SP）。

![image.png|center|1000](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240818205240.png)
<center> <font face='华文宋体' size='4'> 一个SM的内部结构 </font> </center>
❗️❗️：不同的架构中，SM内部含有的CUDA核心数量是不同？？？

## 1.11-CUDA的代替选择

### OpenCL

后期再看，作者推荐：在学习OpenCL之前，先学习CUDA。因为在某种意义上讲，CUDA是一种比OpenCL更高级的语言扩展。

### DirectCompute

DirectCompute是微软开发的可替代CUDA和OpenCL的产品。它是集成在Windows操作系统，特别是DirectX 11API上的专用产品。但是，由于以Windows操作系统为核心，DirectCompute技术被排除在冬种版本的NX上主导地位的高端系统之外。

微软还推出了基于C++的AMP(加速大规模并行计算)库，它是标准模板库(Standard Template Library，STL)的补充部分。对于熟悉C+风格的STL的程序员，它更具有吸引力。（Kokkos？？？）

### CPU的代替选择

主流的并行程序设计扩展语言有MPI和OpenMP。

<font color='red'><b>MPI(Message Passing Interface)</b></font>可能是目前使用最广泛的消息传递接口。它是基于**进程**的，通常在各个大规模计算实验室中得到应用。它需要一个系统管理员来正确地安装配置，并且它适合于可控的计算环境。它实现的并行处理表现为，在集群的各个节点上，派生出成百上千个进程，通常这些进程通过基于网络的高速通信链路（如，以太网或InfiniBand) 显式地交换消息，以协同完成一个大的任务。MPI被广泛使用和学习。在可控的集群环境下， 它是一个很好的解决方案。

<font color='red'><b>OpenMP(Open Multi-Processing)</b></font>是专门面向**单个节点或单个计算机系统**而设计的并行计算平台，它的工作方式是完全不同的。在使用OpenMP时，程序员需要利用编译器指令精确写出并行运算指令。然后编译器根据可用的处理器核数，自动将问题分为N部分。很多 编译器对OpenMP的支持都是内嵌的，包括用于CUDA的NVCC编译器。OpenMP希望根据底层的CPU架构，实现对问题的可扩展并行处理。但是，CPU内的访存带宽常常不够大， 满足不了所有核连续将数据写入内存或者从内存中取出数据的要求。

### 编译指令和库

cuSPARSE

在现代化软件开发的各个方面，很多你准备开发的东西别人已经做好了。在你准备花费数周时间开发一个库之前，请先去互联网上搜索一下，看看哪些是已经存在的。除非你是一 个CUDA专家，否则你自己开发不大可能比使用已有的更快。

## 1.12-本章小结

<center> <font face='华文宋体' size='5' color='red'> 我现在应该看到世界正在向并行编程模型转变，我必须能够站在技术挑战与创新浪潮的最前沿。我必须要需要掌握那些代表计算机世界发展方向的技术，而不是那些日趋没落的技术。 GPU正在改变计算机世界的面貌，GPU是一项翻天覆地的技术革新，它使每个人拥有超级计算机级别的计算能力成为可能。 </font> </center>






