## 6.1 简介

<font color='red'><b>抽象</b></font>已经在现代程序语言中成为了一种趋势。它使程序员离底层硬件越来越远，以确保程序员不必过多了解底层硬件就可以编写程序。虽然抽象将问题提升到一个更高的层次，但是，它仍然需要灵活的编译器将上层的抽象问题转换成底层硬件能够理解的形式。抽象虽然很便捷，但是事实上却很难将其毫无瑕疵地实现。因此，要想程序在不同的平台获得高性能，还必须了解硬件是如何工作的，这是问题的关键所在。

**时间局部性原则**：如果程序调用了一个函数，很有可能该程序会很快再次调用这个函数，如果程序对某一块特殊的内存进行了访问，很有可能在很短的时间内程序会再次对这块内存进行访问。当对某块数据已经使用过一次后还可能再次使用，某个函数执行一次之后还可能再次执行，这就是时间局部性(temporal locality)原则。

在数据存储这里，有两个比较重要的概念，一个是<font color='red'><b>存储带宽</b></font>（memory bandwidth），即**在一定时间内从DRAM读出或写入的数据量**。另一个是<font color='red'><b>延迟</b></font>（latency），即**响应一个获取内存的请求所花费的时间**，通常这个时间会是上百个时钟周期。

另一个比较重要的概念是**事务开销**，在计算机内存管理中，事务开销指的是为确保数据的一致性、原子性、隔离性和持久性（ACID属性）而在执行事务操作时产生的额外代价。这些开销可能包括日志记录、锁管理、事务的开始与结束管理，以及数据的复制或快照等操作，它们共同导致了内存和处理资源的额外消耗。因此，当一次读取的数据量较大时，才会使得事务开销的占比较小，从而使得存储效率更高。因此，在GPU上，为了获得更高的存储效率，GPU需要大量的庞大事务和尽可能少的轻量级事务。

## 6.2 高速缓存

高速缓存是硬件上非常接近处理器核的高速存储器组。高速缓存的最大速度与缓存的大小成反比关系。比如一级缓存、二级缓存、三级缓存的大小依次递增，但是最大速度却依次递减。二级缓存或三级缓存一般在处理器的核之间是共享的，处理器核可通过设备上的这块共享内存快速的进行通信。

在费米架构的GPU实现中，第一次引入了不基于程序员托管的数据缓存这个概念。这个架构的GPU中**每个SM有一个一级缓存**，这个一级缓存既是基于程序员托管的又是基于硬件托管的。**在所有的SM之间有一个<font color='red'><b>共享</b></font>的二级缓存**，这个仅仅是基于硬件托管的。

![image.png|center|800](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240902214231.png)

缓存在处理器的核或SM之间共享的意义是：<font color='red'><b>为了让设备之间能够通过相同的共享缓存进行通信</b></font>。使用共享缓存可以减少处理器之间通过全局内存（通常是主存储器）进行通信的需求。共享缓存特别在执行原子操作时非常有用，因为它能够确保处理器在执行这些操作时获取的数据是一致的。具体来说，由于二级缓存（L2缓存）在处理器中的所有流处理器（SM, Streaming Multiprocessors）之间是统一的，当处理器核（核心）在指定的内存地址上操作时，可以确保获取到的数据是最新的版本。这样，**处理器核之间不需要将数据写回到速度较慢的全局内存中再重新读取，只需要在共享缓存中确保数据的一致性即可**。这提高了处理器之间的通信效率，减少了访问全局内存的开销，从而提升了整体系统的性能。

### 数据存储类型

GPU提供了不同层次的若干区域供程序员存放数据，每块区域根据其能达到的最大带宽以及延迟而定义。

![image.png|center|800](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240902214341.png)

最快速也是最受偏爱的存储器是设备中的存储器，接着是共享内存（如基于程序员托管的一级缓存，一个SM中线程共享的内存），然后是常量内存、纹理内存、常规设备内存（也就是GPU上的全局内存），最后则是主机端内存（就是主板上的内存条中的内存）。 一定要注意不同存储器之间的存储速度的数量级的变化规律。

因此，在程序之初就要考虑使用速度较快的存储器，并且准确知道在何处以及如何提高程序的性能，而不是在程序写完之后才想到用哪些快速的存储器对程序进行优化。另外，<font color='red'><b>不仅要思考如何高效的访问全局内存，也要时刻想办法减少对全局内存的访问次数，尤其在数据会被重复利用的时候</b></font>，要充分的利用到程序的局部性原理。

一些总结：
将数据存储在寄存器中：**声明局部变量**
将数据存储在SM的一级共享内存中：`__share__`
将数据存储在全局内存中：`__device__`


## 6.3 寄存器的用法

与CPU不同，GPU的每个SM有上千个寄存器，每个SM中有许多的SP，因此，一个SM可以看作是一个多线程的CPU核。所以，当GPU上的应用线程进入流水线、进行上下文切换并分配到多个SM中，就意味着在一台GPU设备的所有SM中活跃的线程数目通常数以万计。

另外，CPU与GPU架构的一个主要区别就是<font color='red'><b>CPU与GPU映射寄存器的方式</b></font>。
- CPU通过使用寄存器重命名和栈来执行多线程。为了运行一个新任务，**CPU需要进行上下文切换，将当前所有寄存器的状态保存到栈（系统内存）上，然后从栈中恢复当前需要执行的新线程上次的执行状态。这些操作通常需要花费上百个CPU时钟周期**。如果在CPU上开启过多的线程， 时间几乎都将花费在上下文切换过程中寄存器内容的换进/换出操作上。因此，如果在CPU 开启过多的线程，有效工作的吞吐量将会快速降低。
- GPU利用多线程隐藏了内存获取与指令执行带来的延迟。因此， 在GPU上开启过少的线程反而会因为等待内存事务使GPU处于闲置状态。此外，GPU也不使用寄存器重命名的机制，而是致力于为每一个线程都分配真实的寄存器。因此，**当需要上下文切换时，所需要的操作就是将指向当前寄存器组的选择器（或指针）更新**，以指向下一个执行的线程束的寄存器组，因此几乎是零开销。
	- 线程束：**一个线程束就是可以同时调度的一组线程**，在当前的硬件中，一个线程束包含32个线程，因此，<font color='red'><b>在一个SM中，每次换进/换出、调度都是32个线程同时执行</b></font>。(注意：分配到每个SM上的线程束的数量是有限制的！不能无限的增加！)
	- **每个SM能调度若干个线程块（为了实现流水线的需要），在SM层，线程块就是若干个独立线程束的逻辑组。每个 SM 能调度若干个线程块**。编译时会计算出每个内核线程需要的寄存器数目。所有的线程块都具有相同的大小，并拥有已知数目的线程，每个线程块需要的寄存器数目也就是已知和固定的。因此，GPU 就能为在硬件上调度的线程块分配固定数目的寄存器组。

在线程层，这些细节对程序员是完全透明的。如果一个内核函数中的每个线程需要的寄存器过多，在每个SM中GPU能够调度的线程块的数量就会受到限制，因此总的可以执行的线程数量也会受到限制。开启的线程数量过少会造成硬件无法被充分利用，性能急剧下降，但开启的过多又意味着资源可能短缺，调度到SM的线程块数量会减少。因此，这一点要特别注意，因为它可能引起应用程序性能突然下降。

牢记，<font color='red'><b>每个线程中的一个变量会占用一个寄存器</b></font>。即使是一个布尔类型也会占用一个寄存器，因此，在使用布尔类型的数据时，最高效的办法是将32个布尔值封装到一个32位的字中，然后进行解封的操作（也就是**移位操作**）。

同时，在sum、min、max等普通的归约操作（**归约操作：利用函数将某个较大的数据集减少为较小的集合，通常减少到一个单项**）中也会看到类似的关系。
将结果累积在寄存器中可省去大量的内存写操作。（在CUDA编程中，将<font color='red'><b>结果存储在本地寄存器中是通过直接在内核函数中声明和使用局部变量来实现的</b></font>。**CUDA中的局部变量默认存储在寄存器**中，除非寄存器资源耗尽或变量的大小超过寄存器的限制，此时变量可能会被溢出到本地内存。）
```cpp
__global__ void myKernel(int *d_data) {
    // 声明局部变量
    int localResult = 0;
    // 获取线程的全局索引
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    // 简单计算
    localResult = d_data[idx] * 2;
    // 将结果写回全局内存
    d_data[idx] = localResult;
}
```

这里还需要了解一个叫做循环展开的操作，在 CUDA 编程中，循环展开（Loop Unrolling）是一种优化技术，通过减少循环控制开销和增加指令级并行性来提高性能。具体来说，循环展开是指将循环体的多次迭代直接展开成一系列不包含循环控制结构的顺序指令，从而减少循环头部（如循环计数器增量、条件判断等）的开销。

在 CUDA 编程中，手动进行循环展开需要通过直接将循环的多次迭代写成一系列语句来完成。如果循环次数是已知的，并且不大，可以直接展开成多个语句。
在 CUDA 中，通常通过以下方式进行手动循环展开：

1. **完全展开**：如果循环的迭代次数是常量且较小，可以完全展开循环。
```cpp
// 未展开
for (int i = 0; i < 4; i++) {
    array[i] = array[i] * 2;
}
// 完全循环展开
array[0] = array[0] * 2;
array[1] = array[1] * 2;
array[2] = array[2] * 2;
array[3] = array[3] * 2;
```

2. **部分展开**：如果循环的迭代次数较大，可以选择部分展开，即将循环的每几次迭代展开为一个单一的语句块。这通常与剩余的循环部分结合使用。例如：
```cpp
// 未展开
for (int i = 0; i < 4; i++) {
    array[i] = array[i] * 2;
}
// 部分循环展开
for (int i = 0; i < N; i += 4) {
    array[i] = array[i] * 2;
    array[i + 1] = array[i + 1] * 2;
    array[i + 2] = array[i + 2] * 2;
    array[i + 3] = array[i + 3] * 2;
}
```

在 CUDA 中，循环展开的主要目的是为了减少分支和循环控制的开销，从而提高内核的执行效率。不过，循环展开也会增加代码大小，可能导致指令缓存溢出等问题，因此需要根据实际情况进行权衡。

基于寄存器的优化能够为代码的执行时间带来巨大的影响。使用寄存器可以有效消除内存访问，以此实现GPU内核函数的加速，这是最为有效的方法之一。

## 6.4 共享内存

需要注意的是，在CUDA编程中，共享内存（shared memory）和SM（Streaming Multiprocessor）中的一级缓存（L1 cache）是两种不同的存储资源，但它们在某些架构上有一定的关联。
1. **共享内存（Shared Memory）：**  
   共享内存是每个SM上的一块高速、低延迟的内存，供同一线程块（thread block）中的所有线程共享。程序员可以显式地使用共享内存，通过声明`__shared__`变量在CUDA内核中使用它。<font color='red'><b>共享内存适合用来实现线程间的高效通信以及减少对全局内存的访问</b></font>。
2. **一级缓存（L1 Cache）：**  
   L1缓存是为每个SM配置的缓存，主要用于缓存全局内存访问的数据。它是硬件管理的，程序员不能直接控制其行为。L1缓存的主要作用是通过缓存最近使用的数据来加速对全局内存的访问。
3. **共享内存与L1缓存的关系：**  
   在某些NVIDIA GPU架构（例如Fermi、Kepler和Maxwell）中，共享内存和L1缓存共享同一块物理内存资源。也就是说，L1缓存和共享内存之间的总容量是固定的，但可以根据需求动态分配。
**在较新的架构（如Volta及之后的架构）中，L1缓存和共享内存有各自独立的物理内存，不再共享物理资源**。因此，它们之间的关联减少，程序员也无需再手动配置它们之间的比例。总结而言，**共享内存**是编程时显式管理的，而**L1缓存**是由硬件自动管理的，两者在不同架构上的关联性有所不同。

因此，由于共享内存是编程时可以显式管理的，所以，除了使用寄存器，还要更有效地使用共享内存。事实上，仅看带宽数据，共享内存的带宽为 1.5TB/s，全局内存的带宽最高为 190GB/s，比率为7：1。换言之，有效使用共享内存有可能获得7倍的加速比。毫无疑问，<font color='red'><b>共享内存是所有关心性能的 CUDA 程序员应该认真掌握的一个概念</b></font>。

同时，值得注意的是，GPU执行的是一种内存的加载/存储模型（load-store model），也就是说，所有的操作都要在指令载入寄存器后才能执行。因此，加载数据到共享内存与加载数据到寄存器中是不同的（一个变量使用__share__修饰，一个变量直接是局部变量），所以，<font color='red'><b>只有当数据重复利用、全局内存合并、或者线程之间有共享数据时，使用共享内存才更合适</b></font>。否则，**将数据直接从全局内存加载到寄存器性能会更好**。

共享内存是基于<font color='red'><b>存储体切换</b></font>的架构（bank-switched architecture）。在共享内存中，<font color='red'><b>一个存储体的大小通常是32位（4字节）</b></font>。这是因为共享内存是按存储体（**bank**）组织的，**每个存储体可以在同一时刻服务一个线程的访问请求**。
- 在CUDA中，访问共享内存时，每个存储体对应一个32位的数据块。如果多个线程（**线程束**）在同一时刻访问不同存储体中的不同数据，访问可以并行化进行，从而达到高效的内存访问。
	- ![image.png|200](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903001821.png)
- 如果多个线程（线程束）在同一时刻访问同一个存储体的不同地址（即发生了存储体冲突，bank conflict），这些访问将被序列化，从而降低并行性。
	- ![image.png|200](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903001743.png)
- 当线程束中的所有线程同时访问相同地址的存储体时，使用共享内存会有很大帮助。同常量内存一样，当所有线程访问同一地址的存储单元时，会触发一个广播机制到线程束的每个线程中。（通常0号线程会写一个值，然后与线程束中的其他线程进行通信）

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903002101.png)

注意：使用CUDA，必须要牢记，SM的执行单元是线程束，因此，任何线程数少于线程束的大小都意味着未充分利用硬件。

## 6.5 常量内存

常量内存（constant memory）是CUDA编程模型中的一种特殊内存类型，用于存储在整个CUDA程序执行期间保持不变的数据。它是一块只读内存区域，通常用于存储不变的参数或常量值，这些值在内核（kernel）执行期间不会被修改。
### 常量内存的特点：
1. **只读特性：** 常量内存只能由主机（CPU）进行写入操作，设备（GPU）上的内核函数只能读取常量内存中的数据。
2. **缓存机制：** 常量内存有一个特殊的缓存系统，<font color='red'><b>常量内存的访问速度很快</b></font>，因为它会被缓存到每个SM中的常量缓存（constant cache）中。当多个线程读取相同的常量内存地址时，常量缓存可以确保这些读取操作是高效的。
3. **大小限制：** 常量内存的总大小通常比较有限，最多<font color='red'><b>64KB</b></font>。这对于存储大数据集显然是不够的，但对于小型的常量数据集，常量内存是非常有效的选择。
4. **高效的广播能力：** <font color='red'><b>如果多个线程同时读取相同的常量内存地址，常量缓存可以进行广播，从而使所有线程同时接收到数据，这样可以非常有效地利用带宽</b></font>。
### 使用场景：
常量内存非常适合用于存储在内核执行期间不变的小数据集，例如一些物理常数、查找表、或传递给内核的配置参数。因为常量内存的读取性能非常高，所以在适当的场景下使用常量内存可以显著提升内核的执行效率。
在CUDA代码中，可以通过`__constant__`关键字来声明常量内存。例如：
```cpp
#include <cuda_runtime.h>
__constant__ float constData[256];
float h_data[256];  // 主机上的数据
// 假设h_data已经被赋值
// 将数据从主机拷贝到设备的常量内存中
cudaMemcpyToSymbol(constData, h_data, sizeof(h_data));
```
这个声明表示`constData`是一个大小为256的浮点数组，存储在常量内存中，且只能由主机写入，内核函数只能读取。

同时，在使用常量内存时应该注意：如果一个常量只是字面值，那么最好使用`#define`对字面值进行定义，因为这样可以减少常量内存的使用。所以，尽量不要把像$\pi$这样的字面值放到常量内存中，而应该是用`#define`的去进行定义。


小Tips：

CUDA提供了cudaEvent API来精确测量CUDA内核（kernel）执行的时间。
```cpp
#include <cuda_runtime.h>
#include <iostream>
__global__ void myKernel(float* data) {
    int idx = threadIdx.x + blockIdx.x * blockDim.x;
    data[idx] = data[idx] * data[idx];
}
int main() {
    int n = 1 << 20;  // 1M 个元素
    float *d_data;
    cudaMalloc(&d_data, n * sizeof(float));
    // 初始化 CUDA 事件
    cudaEvent_t start, stop;
    cudaEventCreate(&start);
    cudaEventCreate(&stop);
    // 记录开始事件
    cudaEventRecord(start);
    // 启动内核
    myKernel<<<(n + 255) / 256, 256>>>(d_data);
    // 记录结束事件
    cudaEventRecord(stop);
    // 等待结束事件完成
    cudaEventSynchronize(stop);
    // 计算耗时
    float milliseconds = 0;
    cudaEventElapsedTime(&milliseconds, start, stop);
    std::cout << "内核执行时间: " << milliseconds << " 毫秒" << std::endl;
    // 清理资源
    cudaEventDestroy(start);
    cudaEventDestroy(stop);
    cudaFree(d_data);
    return 0;
}
```

## 6.6 全局内存

GPU的全局内存之所以是全局的，主要是因为GPU与CPU都可以对它进行写操作，任何设备都可以通过PCI-E总线对其进行访问。它是所有线程（无论是同一个线程块中的线程还是不同线程块中的线程）都可以访问的内存区域。

通常的执行模型是：CPU将一个数据块传输到GPU，GPU内核对其进行处理，然后再由CPU将数据块传输回主机端内存中。比较高级的模型是使用流，将数据传输和内核执行部分重叠，以保证GPU一直在工作。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903010028.png)

### 合并内存访问

为了提高全局内存的访问效率，CUDA引入了“合并内存访问”（coalesced memory access）机制。当**多个线程按照连续的内存地址访问全局内存时，访问请求可以被<font color='red'><b>合并为一个内存事务</b></font>**，从而大大提高内存访问的效率。因此，在编写CUDA内核时，**建议对数据进行对齐和优化，以实现合并内存访问**。

![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903010704.png)
比如，如果我们对内存进行一对一连续对齐访问，则每个线程的访问地址可合并起来，只需一次存储事务即可解决问题。假设我们访问一个单精度值或者整型值，每个线程将访问一个4字节的内存块。内存会基于<font color='red'><b>线程束的方式</b></font>进行合并，也就是说，访问一次内存将得到32\*4=128个字节的数据。

合并大小支持32字节、64字节以及128字节，分别表示线程束中每个线程以一个字节、16位以及32位为单位读取数据，但**前提是访问必须连续，并且是以32字节为基准对齐的**！

将标准的cudaMalloc替换成cudaMallocPitch，使用这种特殊的分配内存指令可以得到对齐的内存块。其语法如下： 
```cpp
cudaMallocPitch(void **devPtr，size_t *pitch， size_t width，size_t height)；
```

因此，如果有一个数组，行数为100，每一行有60 个浮点元素，若使用传统的 cudaMalloc分配内存，则分得的内存大小为 100× 60 x sizeof（float）个字节，即100×60×4=24000个字节。访问数组索引为`[1][0]`的元素（即第一行第零个元素） 将导致非合并的访问。这是因为每一行有60 个元素，其长度为240字节，显然不是二的指数倍。这些线程访问的地址中，第一个地址都无法满足合并对齐的要求。
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903011527.png)
使用 cudaMallocPitch函数，其将根据当前设备的对齐要求对每一行进行必要的填充（如图6-18 所示）。在这个例子中，大多数情况下每一行将被填充至64 个元素，即256个字节。设备填充之后每一行的大小由 cudaMallocPitch 中的 pitch 参数返回得到。

由于GPU这种合并访问的机制，并且，结构体内各个数据元素的内存地址是连续排列的，这会导致在访问结构体内的单个数据时（比如所有线程都访问结构体中的A元素），无法充分利用合并访问来提升性能。
![image.png|center|600](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240903012018.png)

对于这种情况，有个思路，就是扩充大小，然后再筛选出游有用的数据：

比如，现在需要基于字节的数据，但是结构体内有4个，所以，可以设定需要的数据类型是基于整型的，也就是4个字节的数据，最后再筛选出来即可，这样就保证了数据的连续访问，也就可以合并访问了。

```cpp
const unsigned int value_u32 = some_data[tid];
const unsigned char value_01 = (Value_u32 & Ox000000FF);
const unsigned char value_02 = (Value_u32 & 0x0000FF00) >> 8;
const unsigned char Value_03 = (value_u32 & 0x00FF0000) >> 16;
const unsigned char value_04 = (value u32 & OxFF000000) >> 24;
```

然而，这种类型的解决方案并不适合于当需要的数据为结构体中的好几个元素时，例如，1号线程需要结构体中的x、y和z坐标。当出现这种情况时，最好对数据重新排列，可能在CPU端加载或**传输数据阶段就需要将数据划分到N个分离的数组**。这样，数组就能独立并存于内存中。我们可以直接对数组a、b、c或d 进行访问，而不是像之前那样通过strcut-->a对结构体元素间接引用访问。**相比于交错、非合并的访问方式，现在得到了4个合并的访问，保持全局内存带宽的使用最优**。

注意：如果是CPU版本，则情况就正好相反了：在交错访问的例子中，CPU访问元素的同时会将结构体中元素b、c以及d读入缓存中，使它们在相同的缓存行中。然而，非交错版本则需要对4个独立的物理内存区进行访问。这意味着存储事务的数目为交错版本的4倍，并且CPU使用的**任何预读策略**都不会起作用。 因此，如果存在一个CPU应用程序需要以交错的方式对结构体中的元素进行处理，可简单地将其复制到GPU中执行，但由于低效的内存合并会导致相当大的开销。**如果在声明阶段就对数据重新排布，改变访问机制**，通过小小的付出将获得显著的加速比。

### 注意

全局内存通常用于存储需要在多个线程块之间共享的大量数据，如输入数据、输出结果、以及程序运行期间需要频繁访问的大型数组。由于全局内存访问开销较大，通常通过将数据分块加载到共享内存或寄存器中，进行计算后再写回全局内存，来优化性能。


## 6.7 纹理内存

纹理内存通常用来做局部优化，也就是说，它希望数据提供给连续的线程进行操作。与一级缓存机制基本相同。纹理内存在适当的场景下可以显著提高CUDA程序的性能，特别是在处理具有空间局部性的数据访问模式时。纹理内存非常适合访问模式具有空间局部性或规律性的数据，例如在图像处理中，像素的访问通常是连续的，这种情况下使用纹理内存可以显著提高性能。

## 6.8 总结

需要深入理解三种主要的存储类型：<font color='red'><b>寄存器</b></font>、<font color='red'><b>共享内存</b></font>以及<font color='red'><b>全局内存</b></font>，这样才能在编写程序中正确高效使用各种存储类型。 
根据提供的内容，各类内存的使用场景总结如下：
1. **全局内存**：  
   适用于存储大量数据，并且所有线程都需要访问的数据。应优化数据访问模式，尽量合并访问以减少内存子系统的访问次数，从而提高效率。
2. **常量内存**：  
   适用于需要在多个线程或线程块中共享的只读数据。使用常量内存可以有效地减少重复数据加载，提高访问效率，特别是在多个线程访问相同数据时。
3. **共享内存**：  
   适用于需要在线程块内部共享和重用的数据。共享内存适合那些具有高重用性的临时数据存储。如果数据不被重用，则应直接使用寄存器或全局内存，以减少不必要的内存开销。
4. **寄存器**：  
   最适合存储局部数据，特别是那些需要多次访问或重复使用的数据。寄存器提供最高的访问速度和设备吞吐量。尽量将数据声明为局部变量，以利用寄存器的高速访问能力，但要避免过度使用，防止寄存器溢出到本地内存，从而导致性能下降。
   















