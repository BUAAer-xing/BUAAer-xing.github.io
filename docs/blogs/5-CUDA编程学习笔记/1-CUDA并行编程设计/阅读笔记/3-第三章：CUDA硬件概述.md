## 3.1-GPU硬件结构

![image.png|center|1200](https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20240819211107.png)

这里需要注意的是，**GPU实际上是一个SM的阵列，每个SM包含N个计算核心**（比如，图中G80 GPU的SM中有8个核）。一个GPU设备中包含一个或多个SM，这是处理器具有可扩展性的关键因素。如果向设备中增加更多的SM，GPU就可以在同一时刻处理更多的任务，或者对于同一任务，如果有足够的并行性的话，GPU可以更快地完成它。（这里要着重理解到：<font color='red'><b>每个SM中有若干个SP</b></font>，需要注意，不同代的GPU上，每个SM中的SP的数量是不同的，大多数都是会随着代数的迭代，每个SM中的SP会逐渐增大。）

每个SM都需要访问一个所谓的寄存器文件（Register File），这是一组能够以与SP相同速度工作的存储单元，所以，访问这组存储单元几乎不需要任何等待时间。不同型号GPU中，寄存器文件的大小可能是不同的。它用来存储SP上运行的线程内部活跃的寄存器。

另外，另一个比较重要的部分是：<font color='red'><b>只供每个SM内部访问的共享内存（shared memory）</b></font>，这可以用作程序可控的高速缓存。它完全是由程序员去进行控制的。

**纹理内存**是针对全局内存的一个特殊视图，用来存储插值 (interpolation)计算所需的数据，它拥有基于硬件进行插值的特性。常量内存用于存储那些只读的数据，所有的GPU卡均对其进行缓存。**常量内存**也是全局内存建立的一个视图。 **图形卡通过GDDR(Graphic Double Data Rate)接口访问全局内存**。GDDR是 DDR(Double Data Rate)内存的一个高速版本，其内存总线宽度最大可达512位， 提供的带宽是CPU对应带宽的5~10倍， 在费米架构GPU中最高可达190GB/s。每个SM还有两个甚至更多的**专用单元(Special-Purpose Unit，SPU)**，SPU专门执行诸如高速的24位正弦函数/余弦函数/指数函数操作等类似的特殊硬件指令。


可以大概这样进行理解：共享内存和L1cache负责的范围是单个SM的内容访问？L2 cache负责的是所有的SM，也就是说，L2 cache是一个统一的缓存，即是个共享的缓存，对所有的SM提供了一个一致的视图。（Tips：通过L2 cache来实现程序块间的通信，要比通过全局原子操作实现快的多。因为访问GPU上的全局存储器，需要越过线程块，比较起来，使用共享缓存（L2 cache）要快一个数量级。）

由于引入了一级和二级缓存，为优化访存二提出的**对齐**（**alignment**）要求就要更加的严格。<font color='red' face='华文楷体' size='4'><b>在两级缓存中，缓存存储块（cache line）的大小均为128B</b></font>。而每次访问缓存，<font color='red'><b>取来最少数据量就是一个存储块（cache line）</b></font>。因此，如果程序是顺序访问数据元素，那么这个要求会发挥很好的作用。事实上，绝大多数CUDA程序都是这么工作的，即<font color='red'><b>一组线程读取的都是相邻的存储单元</b></font>。

