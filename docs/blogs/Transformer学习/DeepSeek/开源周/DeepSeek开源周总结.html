<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.8.1">
<title data-rh="true">DeepSeek开源周总结 | BUAAer-xing Blog</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://buaaer-xing.github.io/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://buaaer-xing.github.io/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="DeepSeek开源周总结 | BUAAer-xing Blog"><meta data-rh="true" name="description" content="1-DeepSeek产生背景"><meta data-rh="true" property="og:description" content="1-DeepSeek产生背景"><link data-rh="true" rel="icon" href="/img/icon.png"><link data-rh="true" rel="canonical" href="https://buaaer-xing.github.io/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结" hreflang="en"><link data-rh="true" rel="alternate" href="https://buaaer-xing.github.io/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结" hreflang="x-default"><link data-rh="true" rel="preconnect" href="https://YOUR_APP_ID-dsn.algolia.net" crossorigin="anonymous"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"DeepSeek开源周总结","item":"https://buaaer-xing.github.io/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结"}]}</script><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="BUAAer-xing Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="BUAAer-xing Blog Atom Feed">




<link rel="search" type="application/opensearchdescription+xml" title="BUAAer-xing Blog" href="/opensearch.xml">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.24/dist/katex.min.css" integrity="sha384-odtC+0UGzzFL/6PNoE8rX/SPcQDXBJ+uRepguP4QkPCm2LBxH3FA3y+fKSiJ+AmM" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/styles.98cc3bd4.css">
<script src="/assets/js/runtime~main.b1a1434e.js" defer="defer"></script>
<script src="/assets/js/main.8b44110d.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t="light";var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",e||t),document.documentElement.setAttribute("data-theme-choice",e||t)}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/icon.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Home</b></a><a class="navbar__item navbar__link" href="/docs/paper_notes_intro">论文笔记</a><a class="navbar__item navbar__link" href="/docs/week_report/week_report_intro">周报汇总</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/blogs_intro">个人博客</a><a class="navbar__item navbar__link" href="/docs/my_papers_intro">发表论文</a><a class="navbar__item navbar__link" href="/blog">相关内容</a><a class="navbar__item navbar__link" href="/resume">个人简历</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/BUAAer-xing/BUAAer-xing.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search (Command+K)"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20" aria-hidden="true"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/blogs_intro">博客说明</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/Linux学习笔记/Linux基础/虚拟机部分">Linux学习笔记</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/Fortran语言/笔记/fortran 简介">Fortran语言</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/高性能计算/高性能计算学习路线/高性能计算的学习路线">高性能计算</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/CUDA编程学习笔记/Tips/CUDA中的统一虚拟内存">CUDA编程学习笔记</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/blogs/Transformer学习/入门/机器学习与深度学习">Transformer学习</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/blogs/Transformer学习/入门/机器学习与深度学习">入门</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结">DeepSeek</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结">开源周</a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/DeepSeek开源周总结">DeepSeek开源周总结</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/Flash MLA">Flash MLA</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/DeepEP">DeepEP</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/DeepGEMM">DeepGEMM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/DualPipe&amp;EPLB">DualPipe&amp;EPLB</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/开源周/5-3FS">5-3FS</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/blogs/Transformer学习/DeepSeek/论文精读/DeepSeek架构引入">论文精读</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" tabindex="0" href="/docs/blogs/Transformer学习/MOE/混合专家模型MoE">MOE</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/blogs/CANN异构架构/概述">CANN异构架构</a></div></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Transformer学习</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">DeepSeek</span></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">开源周</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">DeepSeek开源周总结</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>DeepSeek开源周总结</h1></header><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-deepseek产生背景">1-DeepSeek产生背景<a href="#1-deepseek产生背景" class="hash-link" aria-label="Direct link to 1-DeepSeek产生背景" title="Direct link to 1-DeepSeek产生背景">​</a></h2>
<p>从第一天的FlashMLA，到第二天的DeepEP到今天的DeepGEMM，<strong>这些工作都是基于一款特定的英伟达-H800</strong>，H的来源于Hopper架构。而这款GPU的特殊之处就在于它是<font color="red"><b>中国特供</b></font>的，而这个特供可不是什么好词，而是因为美国芯片限制法案。</p>
<p>而国外的AI大厂情况完全不一样，完全没有禁售，可以说Nvidia造多少他们能买到多少。</p>
<table><thead><tr><th>公司</th><th>主力模型</th><th>主力芯片</th></tr></thead><tbody><tr><td>OpenAI</td><td>ChatGPT / GPT-4</td><td><a href="https://www.nvidia.com/en-us/data-center/a100/" target="_blank" rel="noopener noreferrer">Nvidia A100</a> &amp; H100 GPUs</td></tr><tr><td>Anthropic</td><td>Claude</td><td>Nvidia GPUs (A100/H100)</td></tr><tr><td>xAI</td><td>Grok (and future iterations)</td><td><a href="https://www.nvidia.com/en-us/data-center/h100/" target="_blank" rel="noopener noreferrer">Nvidia H100</a> GPUs (with planned expansion to H200/Blackwell)</td></tr><tr><td>Google</td><td>Gemini</td><td>Google&#x27;s in-house TPU</td></tr></tbody></table>
<p>他们在这种弹药充足的情况下，根本不会想着去压榨英伟达性能，而是加大pre-train投入，比如Grok3，世界上目前GPU用量最大的模型（貌似是20万块），硬件投入是DeepSeek的数倍，性能提升并不明显。快是真的快，<strong>不过卡只要多，谁都快到飞起</strong>。</p>
<center> <font> <font color="red" size="5"><b>DeepSeek最大程度的压榨英伟达显卡的性能</b></font> </font> </center>
<p>而DeepSeek是真不一样，开源了三套专门针对于阉割版H800的性能优化方法，</p>
<ul>
<li>FlashMLA 能在显存有限的情况下高效处理长文</li>
<li>DeepEP 则类似超高速的网络，让多台电脑迅速协同工作</li>
<li>而 DeepGEMM 则像一个极简但强大的超级计算器，能够快速完成大规模数学运算，从而大幅提升 AI 模型的训练和推理速度
<font color="red"><b><center> <font face="微软雅黑" size="5" color="red"> 未来对于软硬件皆通的人才需求会更大 </font> </center></b></font>
第二个和第三个工作的核心都是在压榨英伟达的性能，而纯粹搞大模型的人其实对一个领域并不是很了解。而只有这种，<strong>既懂AI大模型，又懂显卡这种硬件的复合型人才</strong>，才是这一波大模型爆发的关键先生。可以说真正做到了比英伟达还要懂英伟达，英伟达这家公司的确伟大，但重要的是它就是个卖铲子的，而铲子怎么用，如何优化，他们可能在未来要更多的仰仗DeepSeek这样的公司。</li>
</ul>
<p>因为对于英伟达来说，OpenAI这类型公司其实对于芯片的态度就是不够就买，很少会从底层去优化，真的没必要。而DeepSeek这样的公司，<strong>软硬都搞，几个算法和优化下来，1万块芯片甚至可以当几万，甚至10万块</strong>，真的是对于AGI的超级加速。</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-五大项目贡献总结">1-五大项目贡献总结<a href="#1-五大项目贡献总结" class="hash-link" aria-label="Direct link to 1-五大项目贡献总结" title="Direct link to 1-五大项目贡献总结">​</a></h2>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250429143258.png" alt="image.png|center|600" class="img_ev3q"></p>
<table><thead><tr><th>天数</th><th>项目名称</th><th>核心贡献与特点</th></tr></thead><tbody><tr><td>Day 1</td><td>FlashMLA</td><td>针对 NVIDIA Hopper GPU 优化的高性能解码内核；支持 BF16 与分块 KV 缓存，实现高内存带宽（3000 GB/s）与高算力（580 TFLOPS），专注于处理交长序列。</td></tr><tr><td>Day 2</td><td>DeepEP</td><td>专为 MoE（混合专家）模型设计的高性能通信库；利用 FP8 压缩与 NVLink 技术，实  现节点间外高带宽传输，降低通信延迟，为大规模训练提供支持。</td></tr><tr><td>Day 3</td><td>DeepGEMM</td><td>基于 FP8 的通用矩阵乘法库，仅用 300 行代码实现；支持常规密集乘运算和 MoE 模型分组计算，有效提升运算效率，突破传统工程库的性能瓶颈。</td></tr><tr><td>Day 4</td><td>DualPipe &amp; EPLB</td><td>分布式训练优化方案：DualPipe 实现双向流水线（“一边做饭一边洗碗”），EPLB 实现专家载均衡，显著减少训练中的“气泡”时间，提高整体训练效率。</td></tr><tr><td>Day 5</td><td>3FS 文件系统</td><td>高性能分布式文件系统，通过 SSD+RDMA 技术实现高吞吐（6.6 TiB/s）与低延迟数据存取，保障数据一致性，为大数据处理和 AI 推理提供支持。</td></tr></tbody></table>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-flashmla">2-FlashMLA<a href="#2-flashmla" class="hash-link" aria-label="Direct link to 2-FlashMLA" title="Direct link to 2-FlashMLA">​</a></h2>
<p>FlashMLA 是 DeepSeek 推出的高效解码内核，专为 NVIDIA Hopper 架构（如 H100/H800）GPU 优化，旨在加速大语言模型（LLM）在自回归解码阶段的推理性能，特别适用于处理可变长度序列的场景。</p>
<font color="red"><b><center> <font color="red" size="5"> 通过手撸CUDA和PTX的Kernel来实现MLA，相当于是直接优化的MLA kernel，当然也可以说是算子融合！！！ </font> </center></b></font>
<p>其主要优化措施包括：</p>
<ol>
<li><strong>低秩分解的多头潜在注意力机制（MLA）</strong>
<ul>
<li>FlashMLA 引入了低秩分解的 MLA 机制，通过对 Key 和 Value 进行低维压缩，显著减少了 KV 缓存的内存占用，降低了计算复杂度，提升了长序列处理的效率。</li>
</ul>
</li>
<li><strong>分页式 KV 缓存机制</strong>
<ul>
<li>采用块大小为 64 的分页 KV 缓存，有效解决了传统 KV 缓存的内存碎片化问题，提高了显存利用率，支持  高效处理不同长度的序列数据。</li>
</ul>
</li>
<li><strong>针对 Hopper GPU 的深度优化</strong>
<ul>
<li>FlashMLA 充分利用 Hopper 架构的高带宽内存和 Tensor Core，结合 CUDA 核心的优化，实现了高达 3000 GB/s 的内存带宽和 580 TFLOPS 的计算性能，显著提升了推理效率。</li>
</ul>
</li>
<li><strong>支持 BF16 精度计算</strong>
<ul>
<li>通过支持 BF16 精度，FlashMLA 在保持计算准确度的同时，降低了内存带宽压力，提高了计算效率。</li>
</ul>
</li>
<li><strong>内核级的调度优化</strong>
<ul>
<li>在新版本中，FlashMLA 通过重构内核调度策略，实现了 CUDA 核心与 Tensor Core 操作的重叠执行，以及内存访问与计算的并行，进一步提升了计算资源的利用率。</li>
</ul>
</li>
</ol>
<p>这些优化措施使得 FlashMLA 在处理长序列和可变长度输入时，显著降低了延迟和资源占用，提升了推理性能，特别适用于聊天机器人、文档分析和实时翻译等应用场景。</p>
<hr>
<p><strong>KV Cache</strong></p>
<p><img decoding="async" loading="lazy" src="https://cdn.jsdelivr.net/gh/NEUQer-xing/Markdown_images@master/images-2/20250430155436.png" alt="image.png|center|800" class="img_ev3q"></p>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>Attention</mtext><mo stretchy="false">(</mo><msub><mi>Q</mi><mi>t</mi></msub><mo separator="true">,</mo><msub><mi>K</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo separator="true">,</mo><msub><mi>V</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo><mo>=</mo><mtext>softmax</mtext><mrow><mo fence="true">(</mo><mfrac><mrow><msub><mi>Q</mi><mi>t</mi></msub><msubsup><mi>K</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow><mi>T</mi></msubsup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo fence="true">)</mo></mrow><msub><mi>V</mi><mrow><mn>1</mn><mo>:</mo><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\text{Attention}(Q_t, K_{1:t}, V_{1:t}) = \text{softmax}\left( \frac{Q_t K_{1:t}^T}{\sqrt{d_k}} \right) V_{1:t}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord text"><span class="mord">Attention</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.4684em;vertical-align:-0.95em"></span><span class="mord text"><span class="mord">softmax</span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="minner"><span class="mopen delimcenter" style="top:0em"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em"><span style="top:-2.2528em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8572em"><span class="svg-align" style="top:-3em"><span class="pstrut" style="height:3em"></span><span class="mord" style="padding-left:0.833em"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.8172em"><span class="pstrut" style="height:3em"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em"><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1828em"><span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.07153em">K</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8413em"><span style="top:-2.4519em;margin-left:-0.0715em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2481em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:-0.2222em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mrel mtight">:</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span></span>
<hr>
<p><strong>结构上：多头注意力的 QKV 是如何计算的？</strong></p>
<p>假设模型隐藏维度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span></span></span></span>，有 h 个注意力头，每个头的维度是 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>d</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub><mo>=</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mi mathvariant="normal">/</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">d_{head} = d_{model} / h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8444em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight" style="margin-right:0.01968em">l</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathnormal">h</span></span></span></span>。那么，对于每个输入 X，有：</p>
<span class="katex-error" title="ParseError: KaTeX parse error: Expected &#x27;EOF&#x27;, got &#x27;&amp;&#x27; at position 5: Q_h &amp;̲= X W_h^Q, \\
K…" style="color:#cc0000">Q_h &amp;= X W_h^Q, \\
K_h &amp;= X W_h^K, \\
V_h &amp;= X W_h^V, \quad \text{for } h = 1,…,H
\end{aligned}$$

所有头的输出被拼接后再经过输出投影：

$$\text{MultiHead}(X) = \text{Concat}(\text{head}_1,…,\text{head}_h) W^O$$

因此：
	•	每个头拥有一组独立的 QKV 投影权重；
	•	每个头计算自己的 Q、K、V；
	•	每个头的注意力是独立计算的；

----

在 Transformer 架构中，KV Cache（Key-Value Cache）是一种优化自回归推理性能的关键技术。在生成任务中，模型逐步生成每个 token，每一步都需要计算当前 token 与之前所有 token 的注意力关系。**由于之前 token 的键（Key）和值（Value）在后续步骤中保持不变，重复计算这些值会导致冗余计算和资源浪费。KV Cache 通过缓存这些键和值，避免了重复计算，从而提升了推理效率**。

具体而言，KV Cache 的工作流程包括两个阶段：
1. **预填充阶段（Prefill Phase）**：在生成第一个 token 时，模型计算并缓存输入序列中所有 token 的键和值。
2. **解码阶段（Decoding Phase）**：对于每个新生成的 token，模型仅需计算其对应的键和值，并将其追加到缓存中。随后，模型使用当前 token 的查询（Query）与缓存中的键和值进行注意力计算，生成下一个 token。
这种缓存机制显著减少了每步生成所需的计算量，提高了推理速度。例如，在使用 GPT-2 模型生成 1000 个 token 时，启用 KV Cache 的平均推理时间为约 11.9 秒，而禁用 KV Cache 时则为约 56.2 秒，显示出明显的性能提升 。

然而，KV Cache 也带来了一些挑战，**特别是在处理长序列和大批量数据时，缓存的键和值会占用大量显存，限制了模型的扩展性**。为此，研究人员提出了多种优化策略，如多查询注意力（MQA）、分组查询注意力（GQA）、跨层注意力（CLA）和多层键值共享（MLKV）等，这些方法通过共享或压缩键和值，减少了缓存的内存占用，同时保持了模型的性能 。

存储对应硬件位置：**KV Cache 在硬件上对应的是显存中的连续内存区域，通常以层级（per-layer）分组管理，通过高效的内存布局和低精度存储格式，配合 Tensor Core 高效执行矩阵运算，以支撑高速、自回归推理任务的需要**

---

## 3-DeepEP

DeepEP 是 DeepSeek 团队为**混合专家模型**（MoE, Mixture of Experts）和**专家并行**（EP, Expert Parallelism）场景设计的高性能通信库，&lt;font color=&#x27;red&#x27;&gt;&lt;b&gt;旨在解决大规模分布式训练和推理中的通信瓶颈问题&lt;/b&gt;&lt;/font&gt;。其优化措施主要体现在以下几个方面：

- 首先，DeepEP 提供了高效的 **All-to-All 通信内核**，支持节点内的 NVLink 和节点间的 RDMA 通信，显著提升了数据传输效率。在实际测试中，单节点 NVLink 带宽利用率超过 95%，跨节点 RDMA 延迟仅为 163 微秒，极大地减少了通信延迟 。
- 其次，DeepEP 支持低精度数据类型，如 FP8 和 BF16，降低了通信数据量，进一步提升了通信效率。此外，库中引入了&lt;font color=&#x27;red&#x27;&gt;&lt;b&gt;基于 Hook 的通信与计算重叠机制&lt;/b&gt;&lt;/font&gt;，允许在不占用 GPU 流式多处理器（SM）资源的情况下，实现通信和计算的并行执行，提高了整体计算资源的利用率 。
- 在内核优化方面，DeepEP 针对非对称带宽转发场景（如 NVLink 到 RDMA）进行了深度优化，确保在不同通信路径下都能达到高性能。同时，库中还使用了未公开的 PTX 指令 ld.global.nc.L1::no_allocate.L2::256B，**通过绕过 L1 缓存并直接访问 L2 缓存，以 256 字节的事务大小加载数据，进一步提升了内存访问效率** 。
- 在实际应用中，DeepEP 显著提升了 MoE 模型的训练和推理效率。例如，在 H800 GPU 上，使用 DeepEP 的常规内核进行训练时，吞吐量达到了 153 GB/s，接近 NVLink 的理论带宽上限；而在推理阶段，使用纯 RDMA 的低延迟内核，端到端延迟降至微秒级，带宽达到 46 GB/s，接近 RDMA 的理论极限 。

DeepEP 通过高效的通信内核、低精度支持、通信与计算重叠机制以及深度的内核优化，极大地提升了 MoE 模型在大规模分布式环境下的训练和推理效率，为实现高性能的专家并行计算提供了有力支持。

---
**All-to-All通信内核对MoE模型的必要性**

在大规模分布式训练，尤其是**MoE（Mixture of Experts，混合专家）模型**中，**All-to-All 通信内核**是必须的：

在 MoE 模型中，每个 token（或小批次 token）根据路由器（Router）的决策，只会激活少量专家（比如 Top-1 或 Top-2 选择）。这些专家通常跨越多个 GPU 分布。当输入 token 被分配给不同的专家时，为了进行正确的专家计算，**需要把每个 GPU 上属于其他 GPU 上专家的数据发送过去**；同样，处理完后结果还要**再发回对应的 GPU**。这就自然形成了一个典型的 **All-to-All 通信模式**。

具体来说：
- **输入阶段（Dispatch）**：每个 GPU 持有的 token 需要根据路由决策，发送到其他 GPU 上对应的专家处理单元。
- **输出阶段（Gather）**：各个 GPU 处理完自己负责的专家计算后，再把结果按 token 顺序归并回原来的 GPU。 

这一过程就需要执行一次完整的 **All-to-All 通信**，即每个参与节点都需要同时向所有其他节点发送和接收数据。

在这种背景下，为什么一定要专门的 All-to-All 内核呢？主要原因是：
1. **通信量巨大且频繁**：在大规模 MoE 中，每次推理或训练步都需要交换大量激活 token 的特征向量，带宽和延迟直接决定整体吞吐率。
2. **通信模式高度稠密**：每个 GPU 与所有其他 GPU 都有通信需求，简单的点对点（P2P）拷贝或广播（Broadcast）根本无法满足这种稠密全连接通信需求，必须使用 All-to-All 机制。
3. **需要极致优化通信带宽与延迟**：如果 All-to-All 通信没有足够高效，会导致计算单元等待数据，形成**通信瓶颈**，整体训练和推理吞吐量严重下降。因此，通信内核必须充分利用硬件资源（NVLink、PCIe、RDMA），并实现计算与通信的高度重叠。
4. **负载不均问题**：MoE 特有的“稀疏激活”导致数据量不均匀，All-to-All 内核还需要能够处理负载不平衡（Load Imbalance），否则会出现部分 GPU 空闲、部分 GPU 拥堵，进一步降低利用率。
5. **跨节点扩展性要求**：现代大模型（如 DeepSeekMoE-100B 量级）常常跨越数十甚至上百台服务器（节点），All-to-All 内核必须支持跨节点的高速通信，且在大规模环境下保持可扩展性，否则训练和推理的效率无法线性扩展。

因此，**需要 All-to-All 通信内核，是因为 MoE 架构的激活模式天然要求全节点间的大规模、低延迟、高带宽的数据交换。没有高效的 All-to-All 通信，MoE 模型的性能优势就无法发挥**。

---

## 4-DeepGEMM

DeepGEMM 是 DeepSeek 团队为 NVIDIA Hopper 架构（如 H100/H800）GPU 优化的高性能 &lt;font color=&#x27;red&#x27;&gt;&lt;b&gt;FP8 通用矩阵乘法&lt;/b&gt;&lt;/font&gt;（GEMM）库，旨在提升大规模 AI 模型，特别是混合专家（MoE）模型的训练和推理效率。其主要优化措施包括：
- 首先，DeepGEMM 采用了轻量级的 Just-In-Time（JIT）编译机制，在运行时根据具体的矩阵形状动态生成和优化 CUDA 内核，避免了传统模板库的复杂性，提高了开发和部署的灵活性。该库仅包含约 300 行核心内核代码，便于理解和维护。
- 其次，为了充分利用 Hopper 架构的 Tensor Core，**DeepGEMM 实现了双层累加机制，结合 CUDA 核心和 Tensor Core 的计算能力，提升了 FP8 低精度计算的数值稳定性和准确性**。此外，库中还引入了精细化的缩放策略，对每 128 通道进行独立缩放，进一步增强了低精度计算的鲁棒性。
- 在内核优化方面，DeepGEMM 对 **FFMA（Fused Multiply-Add）** 指令进行了深入分析和调整，通过修改 &lt;font color=&#x27;red&#x27;&gt;&lt;b&gt;SASS 汇编&lt;/b&gt;&lt;/font&gt;中的 yield 和 reuse 位，实现了指令级的调度优化，提升了内核的执行效率。此外，**库中还采用了 Tensor Memory Accelerator（TMA）、软件流水线和 Warp 专用化**等技术，最大化地利用了内存带宽和计算资源。
- 针对 MoE 模型的特点，DeepGEMM 支持分组 GEMM 操作，包括连续分组（contiguous-grouped）和掩码分组（masked-grouped）等形式，优化了小批量矩阵乘法的性能，提升了专家模型的计算效率。在实际测试中，DeepGEMM 在 H800 GPU 上实现了高达 1550 TFLOPS 的计算性能，超过了许多手工优化的库。

DeepGEMM 通过 JIT 编译、双层累加、精细化缩放、指令级调度优化和 MoE 特化支持等多项优化措施，显著提升了 FP8 低精度矩阵乘法的性能和稳定性，为大规模 AI 模型的高效训练和推理提供了有力支持。


## 5-DualPipe&amp;EPLB

DualPipe 和 EPLB 是 DeepSeek 团队为提升大规模模型（如 DeepSeek-V3）训练效率而设计的两项关键优化策略。
- **DualPipe** 旨在通过双向流水线并行减少计算和通信的空闲时间（即“气泡”）
- **EPLB** 则通过智能负载均衡策略优化专家模型（MoE）的资源分配。

### 5.1-DualPipe：双向流水线并行优化

传统的流水线并行（如 1F1B）在执行前向传播和反向传播时存在明显的空闲时间，导致 GPU 资源未被充分利用。DualPipe 引入了&lt;font color=&#x27;red&#x27;&gt;&lt;b&gt;双向流水线并行机制&lt;/b&gt;&lt;/font&gt;，使得前向和反向计算可以在不同阶段同时进行，从而&lt;font color=&#x27;red&#x27;&gt;&lt;b&gt;实现计算与通信的完全重叠&lt;/b&gt;&lt;/font&gt;，显著**减少了流水线中的“气泡”时间** 。

具体而言，DualPipe 的优化措施包括：
- **双向调度机制**：允许模型的前向传播和反向传播在流水线的不同阶段同时进行，提高了 GPU 的利用率。
- **计算与通信的重叠**：通过精细的任务调度，使得计算和通信可以并行执行，减少了等待时间。
- **内存优化**：尽管 DualPipe 增加了激活值的存储需求，但通过优化内存管理，确保了整体内存使用的高效性 。

### 5.2-EPLB：专家并行负载均衡器

在混合专家模型（MoE）中，不同专家的负载可能因输入数据的分布而不均，导致某些 GPU 过载，而其他 GPU 资源未被充分利用。EPLB（Expert Parallel Load Balancer）通过以下策略实现了负载的动态均衡：
- **专家复制**：对于高负载的专家，EPLB 会创建其副本，并将这些副本分配到负载较低的 GPU 上，以分担计算任务。
- **启发式分配算法**：根据专家的历史负载数据，智能地将专家分配到不同的 GPU 上，确保各 GPU 的负载均衡。
- **节点内专家分组**：尽可能将需要协同工作的专家分配到同一节点，减少跨节点通信的开销 。


## 6-3FS文件系统

3FS（Fire-Flyer File System）是 DeepSeek 团队为 AI 模型训练和推理场景设计的高性能分布式文件系统，专注于高带宽读取和低延迟访问。其优化措施主要体现在以下几个方面：

### **架构设计与一致性保障**

3FS 采用典型的分布式文件系统架构，包含客户端（Client）、集群管理服务（mgmtd）、元数据服务（Meta Service, mds）和数据服务（Storage Service）四大组件。其中，元数据服务使用分布式事务的键值存储系统 FoundationDB，简化了元数据的设计和实现，确保了系统的一致性和高可用性。

在数据存储方面，3FS 使用了 CRAQ（Chain Replication with Apportioned Queries）协议，在保证数据强一致性的同时，优化了读取性能。该协议通过链式复制的方式，将写操作按顺序传递至所有副本，读操作则可在任意副本上进行，从而提高了系统的读取吞吐量。

### **高性能客户端与零拷贝机制**

3FS 提供两种客户端接入方式：FUSE 客户端和 Native 客户端。其中，Native 客户端通过 USRBIO 库实现了用户态与内核态之间的零拷贝数据传输，显著提升了数据读写性能。该机制利用共享内存和 IoRing 技术，减少了数据在用户态和内核态之间的复制开销，从而降低了 I/O 延迟。

### **面向 AI 场景的优化策略**

3FS 在设计上充分考虑了 AI 模型训练和推理的特点，进行了多项针对性的优化：
- **高吞吐量读取**：在 180 节点的集群中，3FS 实现了高达 6.6 TiB/s 的聚合读取吞吐量，满足了大规模模型训练对数据读取速度的极高要求。
- **KVCache 高速访问**：在推理场景下，3FS 支持高效的 KVCache 查找，每个客户端节点的峰值吞吐量超过 40 GiB/s，显著提升了推理性能。
- **智能调度与负载均衡**：3FS 通过智能调度算法，根据各节点的负载情况动态分配任务，确保系统资源的最优利用，提升了整体性能。
- **小文件处理优化**：针对小文件处理性能较差的问题，3FS 引入了 FFRecord 文件格式，将多个小文件合并为一个大文件，减少了元数据操作的开销，提高了小文件的处理效率。

### **端到端无缓存设计**

3FS 采用了端到端无缓存的设计理念，摒弃了传统文件系统中的数据和元数据缓存机制，充分利用 SSD 的高性能特点，减少了缓存一致性维护的开销，提升了系统的整体性能。
























</span></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://buaaer-xing.github.io/docs/blogs/6-Transformer学习/1-DeepSeek/开源周/0-DeepSeek开源周总结.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/blogs/Transformer学习/入门/z-Tranform框架"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">z-Tranform框架</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/blogs/Transformer学习/DeepSeek/开源周/Flash MLA"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Flash MLA</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#1-deepseek产生背景" class="table-of-contents__link toc-highlight">1-DeepSeek产生背景</a></li><li><a href="#1-五大项目贡献总结" class="table-of-contents__link toc-highlight">1-五大项目贡献总结</a></li><li><a href="#2-flashmla" class="table-of-contents__link toc-highlight">2-FlashMLA</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/paper_notes_intro">论文笔记</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/blogs_intro">个人博客</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">相关内容</a></li><li class="footer__item"><a class="footer__link-item" href="/resume">个人简历</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://t.me/cx_cst" target="_blank" rel="noopener noreferrer" class="footer__link-item">Telegram<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://blog.csdn.net/qq_45575167" target="_blank" rel="noopener noreferrer" class="footer__link-item">CSDN</a></li><li class="footer__item"><a href="https://github.com/BUAAer-xing" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2025 BUAAer-xing, 此网站使用 Docusaurus 进行构建✨</div></div></div></footer></div>
</body>
</html>