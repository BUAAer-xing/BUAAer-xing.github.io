转载地址：https://www.zhihu.com/question/33576416
## 高性能计算概述

<center> <font face='华文宋体' size='5' color='green'> 古有：程序=算法+数据结构 </font> </center>

<center> <font face='华文宋体' size='5' color='red'> 今有：高性能计算 = 高性能的算法 + 高性能的软件系统 + 高性能的硬件 </font> </center>


HPC是一个比较综合的方向，涉及算法、体系结构、编程语言、操作系统、计算机网络等，还涉及专业的学科知识譬如生物等，这也正是它的趣味性所在。HPC的目标一言以蔽之就是——<font color='red'><b>用最高效的方法对一个给定问题进行求解</b></font>。而要以最高效的方式来对一个给定问题求解，我们必然需要有高效的算法设计（上层）、高效的编程模型和代码生成（中层）、以及高效的计算机体系结构来执行机器码（下层）。要实现极致的效率，三者缺一不可。

高性能（并行）计算的研究者既有CS背景的，也有从其他应用学科的角度来做高性能计算的，后者更关注如何使用并行计算机来更高效地解决本领域的科学问题，譬如计算生物、计算数学、物理仿真等等。前者更关注并行计算作为一种技术本身的问题，以及如果使用并行计算机更高效地解决CS领域的问题。

并行计算的核心目标是：<font color='red'><b>对一个问题进行拆解，拆解成若干独立的部分，然后对这些独立的部分同时进行计算，以提高整体的计算效率</b></font>。

但是由于硬件并行的范式多种多样，譬如有CPU多核并行，有SIMD并行，也有多台机器分布式内存的并行，因为这些并行的范式不一样，导致我们进行并行算法设计的时候也会有所不同，譬如不同的并行范式通信方式就不一样，而且对于这些并行范式进行编程的方式也不一样。<font color='green'>譬如CPU多核并行可以使用pthread或者openMP，对于分布式内存进行编程，因为没有共享内存，所以需要显式进行通信，例如使用mpi，而对于SIMD的情况，在GPU上则需要以SIMT的思维编程。</font>

虽然并行的范式各种各样，导致其算法设计，编程都有所区别，但是大致都可以分为三个层次

- 计算机体系结构：计算机都有哪些形式的并行？
- 并行编程：如何对于并行计算机进行编程？
- 并行算法：如何将一个问题拆解成可独立计算的子问题，如何减小通信？

这几个方面来谈，不需要样样都研究地很深入，了解下基础以后大家可以选择一个自己的侧重点。

一些基本的并行计算概念推荐看看LLNL的这个教程，里面的配图很好：[Introduction to Parallel Computing Tutorial](https://hpc.llnl.gov/documentation/tutorials/introduction-parallel-computing-tutorial)

## 推荐的课程

比较全面的介绍（包括并行算法、并行编程）：[UC Berkeley CS267](https://sites.google.com/lbl.gov/cs267-spr2021?pli=1)

更偏并行算法一些的：[Georgia Tech CSE 6220](https://omscs.gatech.edu/cse-6220-intro-hpc)

从系统优化的角度入手：[MIT 6.172](https://ocw.mit.edu/courses/6-172-performance-engineering-of-software-systems-fall-2018/)

UC Davis的一个CUDA编程教程，主要讨论GPU算法，包括排序等。除了教程本身，里面的人物也很棒：[Intro to Parallel Programming](https://www.youtube.com/watch?v=F620ommtjqk&list=PLAwxTw4SYaPnFKojVQrmyOGFCqHTxfdv2)

另外，我看过最好的CUDA入门教程（主讲是NVIDIA资深工程师），录像在每一个章节的页面里，前面的三章比较基本，后面是更加深入的内容：[CUDA Training Series](https://www.olcf.ornl.gov/cuda-training-series/)

还有加州大学伯克利分校的大佬James Demmel 和 Kathy Yelick 的并行计算机课程：[Applications of Parallel Computers](https://sites.google.com/lbl.gov/cs267-spr2021)


## 并行计算机体系结构

体系结构非常粗略地可以分为**计算**与**存储**两块

一个重要的认知是：<font color='red'><b>程序性能的瓶颈往往都是在数据移动，而非计算上。</b></font>

体系结构层面的并行主要分为这么几种：
- 多核CPU并行，可使用Pthread或openmp编程
- 每个CPU内部的SIMD（向量化）指令，一般由编译器自动向量化，也可以手动进行编程
- GPU的SIMT并行，SIMT在硬件层面依然是SIMD，但是在软件层面则比SIMD更加灵活
- 多台独立的计算机构成一个集群，可使用MPI进行通信和编程

### 计算方面的入门问题清单

- 什么是摩尔定律？（这是一个经典问题，事实是绝大部分人都知道摩尔定律，但是都知道的不够准确）？它是否已经终结？如果是，为什么会终结？碰到了什么问题？
- CPU里指令间并行（ILP）都是通过哪些技术实现的？其challenge是什么？
	- 流水线
	- 乱序执行
	- superscalar
- CPU里并行的方向是ILP和多线程还有SPMD，而GPU里并行的方向是数据并行（SIMT或SIMD）
	- 对于这些各种并行范式的理解很重要
- GPU和CPU在设计思路上的区别？
	- GPU扔掉了许多CPU里为了ILP设计的东西，因为它和CPU追求并行的方式有本质区别，扔掉branch prediction、乱序执行这些，就能用更多的晶体管堆ALU core
- Cuda编程里的各种软件硬件概念有个基本的了解，尤其是thread block和SM
	- 一定要注重官方文档的阅读：[Cuda官方文档地址](https://docs.nvidia.com/cuda/)

### 存储方面的入门问题清单

- 缓存的基本原理，如何index？知道tag和associativity等概念
- 为什么缓存（SRAM）比DRAM昂贵但更快？
	- 需要更多面积和晶体管
- 每级存储大概是多大？一个cache line大概是多大？哪级是shared among all cores？
- CPU的频率、寄存器、缓存、内存的读写时延大概是一个什么比例？
- 多核的CPU并行执行，缓存一致是什么问题？是如何保持一致的？
- 内存的latency和bandwidth
	- [Understanding Bandwidth and Latency](https://arstechnica.com/features/2002/11/bandwidth-latency/)

### 其他

这里只是些基本的概念，其他宽泛问题：
- 如何回答“GPU是不是比CPU快？为什么不让CPU也像GPU那么多核？”这类的问题？
- 英特尔、AMD、英伟达等的历史分别是什么？（不要小看历史和商业在计算机学习中的重要性）
- 超算是怎实现的？CPU还是GPU？

**推荐阅读**：Hennessy & Patterson Computer Architecture: A Quantitative Approach 最新版（第六版）

**推荐课程**：Onur Mutlu的computer architecture lecture（Onur是计算机系统架构领域最顶尖的学者之一，他的课讲的也很好，而且网上免费放送给大家）：[Computer architecture lecture](https://www.youtube.com/watch?v=wHVyshkyZ4w&list=PL5Q2soXY2Zi9OhoVQBXYFIZywZXCPl4M_)

## 并行编程

并行编程的目的就是针对某一种特定的并行硬件，我们如何将我们设计好的算法用程序编写出来。譬如CPU多核并行可以使用pthread或者openMP，对于分布式内存进行编程使用mpi进行通信，而在GPU上则需要以SIMT的思维编程。而并行编程的过程中，也会涉及到一些串行编程中不会出现的问题，譬如data race和死锁等等，我们的程序如何避免这些问题？

一些基础问题：

- 并行和并发的区别是什么？
- 进程和线程的区别是什么？原理是什么？是如何调度的？
- 单线程程序如何提高性能（各种编译优化）？
	- 提高局部性
	- 去冗余
- 如何平衡局部性和并行性？
- 如何做性能分析？都有些啥工具？
	- 如何用各种hardware performance counter？
- pthread怎么用？它是怎么实现的？
- OpenMP怎么用？它是怎么实现的？和pthread的区别与联系？
	- OpenMP里面的各种细节，譬如如何同步、如何共享数据等
- MPI怎么用？它是怎么实现的？和OpenMP分别代表了什么模型？
	- MPI里的各种通信模式，各种collect，如何同步之类的
	- MPI为什么快？跟Apache Spark之类的什么关系？
- 并行的任务应该如何调度？Scheduling算法都有哪些？
- SIMD、SPMD、SIMT之间的区别是什么？
- 数据竞争是什么？critical section是如何实现的？
- 线程之间同步的原理？
- 并行编程都有哪些模型？
- GPU怎么编程（cuda程序怎么写）？跟CPU SIMD啥区别？
- 如何把一个算法在GPU上高性能地实现？

**推荐课程**：MIT Charles和Julian一起teach的：[Performance Engineering of Software Systems](https://ocw.mit.edu/courses/6-172-performance-engineering-of-software-systems-fall-2018/)，这个课是我见过从系统优化角度讲HPC入门最好的课。

## 并行算法分析与设计

并行算法的设计目标是尽可能的把一个问题拆解成若干独立的子问题，然后并行进行计算。举一个经典的例子，在排序算法里面堆排序和归并排序都具有$O(nlogn)$复杂度，但是前者非常串行，后者的更适合并行。再譬如我们设计并行算法的时候，如何在并行的同时又使得通信或同步能够最小化？因为在并行计算中。除了计算本身的开销，通信也会带来开销，等等。

算法复杂度分析是学计算机的基础内容，在HPC里也十分常用。另外还有一个常见的分析称为IO复杂度分析（I/O complexity）用来分析data movement。另外图算法也十分重要以及常用，如果熟悉会更好。
- 基础的算法分析与设计
- 图算法
- 数据结构的设计（<font color='red'><b>好的数据结构是性能的关键</b></font>）

**推荐阅读**：
- 《算法导论》，其实Charles Leisersen也是HPC界大佬。
- 《Introduction to Parallel Computing》, Grama, Gupta, Kumar, Karypis, Addison Wesley

**推荐课程**：
- 佐治亚理工学院的Rich Vuduc教授的HPC导论课程，比较偏并行算法:[CSE 6220: Intro to High-Performance Computing](https://omscs.gatech.edu/cse-6220-intro-hpc)
并行算法部分可以看看关注如下老师们：
- [Guy E. Blelloch](http://www.cs.cmu.edu/~./blelloch/index.html)
- [RICH VUDUC](https://vuduc.org/v2/)


## 数值线性代数

如果侧重点不在数值线性代数的话，这方面其实要求很低。基本上了解矩阵、向量、张量的基本概念就行了。

推荐阅读：
- Gilbert Strang的线性代数《Introduction to Linear Algebra》
- [MIT课程地址](https://ocw.mit.edu/resources/res-18-010-a-2020-vision-of-linear-algebra-spring-2020/index.htm)


## 简要总结

上述这些也只是涵盖了HPC最基础的一些内容。

当你完成了以上学习，现在可以思考下HPC里面的一些经典问题了，譬如：如何加速（稀疏）矩阵运算？哪怕一个简单的矩阵相乘，人们都可以搞出上十种优化的奇技淫巧（比如：[Optimize GEMM on CPU](https://tvm.apache.org/docs/how_to/optimize_operators/opt_gemm.html)），让编译器和硬件完美配合，高性能计算的浪漫在于：如何设计最高性能的算法（通信方式）和最高性能的硬件来解决一个给定问题。


## 学术社区

最主要的：SC（大而广），ICS，PPoPP（偏并行编程），IPDPS（系统算法都有），SPAA（并行算法与architecture）。ICPP也不错。ISCA、MICRO、HPCA、PACT里面许多关于高性能体系结构或者编译的工作。










